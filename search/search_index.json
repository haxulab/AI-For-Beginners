{"config":{"lang":["en"],"separator":"[\\s\\-]+","pipeline":["stopWordFilter"]},"docs":[{"location":"README_chs/","title":"\u8bfe\u7a0b\u4ecb\u7ecd","text":""},{"location":"README_chs/#_1","title":"\u4eba\u5de5\u667a\u80fd\u521d\u5b66\u8005\u8bfe\u7a0b","text":"AI For Beginners - \u56fe\u89e3\u7b14\u8bb0 by @girlie_mac <p>\u901a\u8fc7\u6211\u4eec\u768412\u5468\u300124\u8bfe\u8bfe\u7a0b\u5927\u7eb2\u63a2\u7d22\u4eba\u5de5\u667a\u80fd\uff08AI\uff09\u7684\u4e16\u754c\uff01\u8bfe\u7a0b\u5305\u62ec\u5b9e\u7528\u7684\u8bfe\u7a0b\u3001\u6d4b\u9a8c\u548c\u5b9e\u9a8c\u5ba4\u3002\u8be5\u8bfe\u7a0b\u9002\u5408\u521d\u5b66\u8005\uff0c\u6db5\u76d6\u4e86TensorFlow\u548cPyTorch\u7b49\u5de5\u5177\uff0c\u4ee5\u53ca\u4eba\u5de5\u667a\u80fd\u4f26\u7406\u3002</p>"},{"location":"README_chs/#_2","title":"\u60a8\u5c06\u5b66\u4e60\u7684\u5185\u5bb9","text":"<p>\u8bfe\u7a0b\u601d\u7ef4\u5bfc\u56fe</p> <p>\u5728\u8fd9\u4e2a\u8bfe\u7a0b\u4e2d\uff0c\u60a8\u5c06\u5b66\u5230\uff1a</p> <ul> <li>\u4e0d\u540c\u7684\u4eba\u5de5\u667a\u80fd\u65b9\u6cd5\uff0c\u5305\u62ec\u201c\u8001\u597d\u4eba\u201d\u7b26\u53f7\u65b9\u6cd5\uff0c\u4f7f\u7528\u77e5\u8bc6\u8868\u793a\u4e0e\u63a8\u7406\uff08GOFAI\uff09\u3002</li> <li>\u73b0\u4ee3\u4eba\u5de5\u667a\u80fd\u6838\u5fc3\u7684\u795e\u7ecf\u7f51\u7edc\u548c\u6df1\u5ea6\u5b66\u4e60\u3002\u6211\u4eec\u5c06\u901a\u8fc7\u4ee3\u7801\u5b9e\u4f8b\u5c55\u793a\u8fd9\u4e9b\u91cd\u8981\u6982\u5ff5\uff0c\u4f7f\u7528\u4e24\u4e2a\u6700\u6d41\u884c\u7684\u6846\u67b6 - TensorFlow \u548c PyTorch\u3002</li> <li>\u7528\u4e8e\u5904\u7406\u56fe\u50cf\u548c\u6587\u672c\u7684\u795e\u7ecf\u67b6\u6784\u3002\u6211\u4eec\u5c06\u4ecb\u7ecd\u6700\u8fd1\u7684\u6a21\u578b\uff0c\u4f46\u53ef\u80fd\u6709\u70b9\u7f3a\u4e4f\u6700\u65b0\u7684\u6280\u672f\u3002</li> <li>\u4e0d\u592a\u6d41\u884c\u7684\u4eba\u5de5\u667a\u80fd\u65b9\u6cd5\uff0c\u5982\u9057\u4f20\u7b97\u6cd5\u548c\u591a\u4ee3\u7406\u7cfb\u7edf\u3002</li> </ul> <p>\u5728\u8fd9\u4e2a\u8bfe\u7a0b\u4e2d\u6211\u4eec\u4e0d\u4f1a\u6d89\u53ca\u5230\u7684\u5185\u5bb9\uff1a</p> <p>\u5728\u6211\u4eec\u7684Microsoft Learn\u96c6\u5408\u4e2d\u627e\u5230\u6240\u6709\u7684\u8bfe\u7a0b\u989d\u5916\u8d44\u6e90</p> <ul> <li>\u4eba\u5de5\u667a\u80fd\u5728\u5546\u4e1a\u4e2d\u7684\u5e94\u7528\u6848\u4f8b\u3002\u8003\u8651\u5728Microsoft Learn\u4e0a\u53c2\u52a0 Introduction to AI for business users \u5b66\u4e60\u8def\u5f84\uff0c\u6216\u4e0e INSEAD \u5408\u4f5c\u5f00\u53d1\u7684 AI Business School\u3002</li> <li>\u7ecf\u5178\u7684\u673a\u5668\u5b66\u4e60\uff0c\u6211\u4eec\u5728 \u521d\u5b66\u8005\u673a\u5668\u5b66\u4e60\u8bfe\u7a0b \u4e2d\u6709\u8be6\u7ec6\u63cf\u8ff0\u3002</li> <li>\u4f7f\u7528 \u8ba4\u77e5\u670d\u52a1 \u6784\u5efa\u7684\u5b9e\u9645AI\u5e94\u7528\u3002\u4e3a\u4e86\u5b66\u4e60\u8fd9\u5757\uff0c\u6211\u4eec\u5efa\u8bae\u4eceMicrosoft Learn\u4e0a\u7684\u6a21\u5757\u5f00\u59cb\uff0c\u5173\u4e8e \u8ba1\u7b97\u673a\u89c6\u89c9\uff0c\u81ea\u7136\u8bed\u8a00\u5904\u7406\uff0c\u4f7f\u7528Azure OpenAI\u670d\u52a1\u8fdb\u884c\u751f\u6210\u6027AI \u7b49\u7b49\u3002</li> <li>\u7279\u5b9a\u673a\u5668\u5b66\u4e60 \u4e91\u6846\u67b6\uff0c\u5982 Azure Machine Learning\uff0cMicrosoft Fabric\uff0c\u6216 Azure Databricks\u3002\u53ef\u4ee5\u8003\u8651\u4f7f\u7528 \u4f7f\u7528Azure Machine Learning\u6784\u5efa\u548c\u8fd0\u8425\u673a\u5668\u5b66\u4e60\u89e3\u51b3\u65b9\u6848 \u548c \u4f7f\u7528Azure Databricks\u6784\u5efa\u548c\u8fd0\u8425\u673a\u5668\u5b66\u4e60\u89e3\u51b3\u65b9\u6848 \u5b66\u4e60\u8def\u5f84\u3002</li> <li>\u5bf9\u8bdd\u5f0fAI\u548c\u804a\u5929\u673a\u5668\u4eba\u3002\u6709\u4e00\u4e2a\u5355\u72ec\u7684 \u521b\u5efa\u5bf9\u8bdd\u5f0fAI\u89e3\u51b3\u65b9\u6848 \u5b66\u4e60\u8def\u5f84\uff0c\u60a8\u8fd8\u53ef\u4ee5\u53c2\u8003 \u8fd9\u7bc7\u535a\u5ba2\u6587\u7ae0 \u4e86\u89e3\u66f4\u591a\u7ec6\u8282\u3002</li> <li>\u6df1\u5165\u7684\u6df1\u5ea6\u5b66\u4e60\u6570\u5b66\u3002\u4e3a\u6b64\uff0c\u6211\u4eec\u63a8\u8350Ian Goodfellow, Yoshua Bengio \u548c Aaron Courville \u7684 Deep Learning\uff0c\u5b83\u4e5f\u53ef\u4ee5\u5728\u7ebf\u8bbf\u95ee https://www.deeplearningbook.org/\u3002</li> </ul> <p>\u5982\u679c\u60a8\u5bf9_\u4e91\u4e2d\u7684AI_\u4e3b\u9898\u6709\u6e29\u548c\u7684\u4ecb\u7ecd\uff0c\u53ef\u4ee5\u8003\u8651\u53c2\u52a0 \u5728Azure\u4e0a\u5f00\u59cb\u4eba\u5de5\u667a\u80fd\u7684\u5b66\u4e60\u8def\u5f84 \u5b66\u4e60\u8def\u5f84\u3002</p>"},{"location":"README_chs/#_3","title":"\u8bfe\u7a0b\u5185\u5bb9","text":"\u8bfe\u7a0b\u94fe\u63a5 PyTorch/Keras/TensorFlow \u5b9e\u9a8c\u5ba4 0 \u8bfe\u7a0b\u8bbe\u7f6e \u8bbe\u7f6e\u60a8\u7684\u5f00\u53d1\u73af\u5883 I AI\u7b80\u4ecb 01 AI\u4ecb\u7ecd\u4e0e\u5386\u53f2 - - II \u7b26\u53f7AI 02 \u77e5\u8bc6\u8868\u793a\u548c\u4e13\u5bb6\u7cfb\u7edf \u4e13\u5bb6\u7cfb\u7edf /  \u672c\u4f53 /\u6982\u5ff5\u56fe III \u795e\u7ecf\u7f51\u7edc\u7b80\u4ecb 03 \u611f\u77e5\u5668 \u7b14\u8bb0\u672c \u5b9e\u9a8c\u5ba4 04 \u591a\u5c42\u611f\u77e5\u5668\u548c\u521b\u5efa\u6211\u4eec\u81ea\u5df1\u7684\u6846\u67b6 \u7b14\u8bb0\u672c \u5b9e\u9a8c\u5ba4 05 \u6846\u67b6\u4ecb\u7ecd\uff08PyTorch/TensorFlow\uff09\u548c\u8fc7\u62df\u5408 PyTorch / Keras / TensorFlow \u5b9e\u9a8c\u5ba4 IV \u8ba1\u7b97\u673a\u89c6\u89c9 PyTorch / TensorFlow \u5728Microsoft Azure\u4e0a\u63a2\u7d22\u8ba1\u7b97\u673a\u89c6\u89c9 06 \u8ba1\u7b97\u673a\u89c6\u89c9\u4ecb\u7ecd. OpenCV \u7b14\u8bb0\u672c \u5b9e\u9a8c\u5ba4 07 \u5377\u79ef\u795e\u7ecf\u7f51\u7edc &amp;  CNN\u67b6\u6784 PyTorch /TensorFlow \u5b9e\u9a8c\u5ba4 08 \u9884\u8bad\u7ec3\u7f51\u7edc\u548c\u8fc1\u79fb\u5b66\u4e60 \u548c \u8bad\u7ec3\u6280\u5de7 PyTorch / TensorFlow \u5b9e\u9a8c\u5ba4 09 \u81ea\u7f16\u7801\u5668\u548c\u53d8\u5206\u81ea\u7f16\u7801\u5668 PyTorch / TensorFlow 10 \u751f\u6210\u5bf9\u6297\u7f51\u7edc\u548c\u827a\u672f\u98ce\u683c\u8fc1\u79fb PyTorch / TensorFlow 11 \u76ee\u6807\u68c0\u6d4b TensorFlow \u5b9e\u9a8c\u5ba4 12 \u8bed\u4e49\u5206\u5272. U-Net PyTorch / TensorFlow V \u81ea\u7136\u8bed\u8a00\u5904\u7406 PyTorch /TensorFlow \u5728Microsoft Azure\u4e0a\u63a2\u7d22\u81ea\u7136\u8bed\u8a00\u5904\u7406 13 \u6587\u672c\u8868\u793a. Bow/TF-IDF PyTorch / TensorFlow 14 \u8bed\u4e49\u8bcd\u5d4c\u5165. Word2Vec \u548c GloVe PyTorch / TensorFlow 15 \u8bed\u8a00\u5efa\u6a21. \u8bad\u7ec3\u60a8\u81ea\u5df1\u7684\u5d4c\u5165 PyTorch / TensorFlow \u5b9e\u9a8c\u5ba4 16 \u9012\u5f52\u795e\u7ecf\u7f51\u7edc PyTorch / [TensorFlow](https://github.com/microsoft/AI"},{"location":"SECURITY/","title":"SECURITY","text":""},{"location":"SECURITY/#security","title":"Security","text":"<p>Microsoft takes the security of our software products and services seriously, which includes all source code repositories managed through our GitHub organizations, which include Microsoft, Azure, DotNet, AspNet, Xamarin, and our GitHub organizations.</p> <p>If you believe you have found a security vulnerability in any Microsoft-owned repository that meets Microsoft's definition of a security vulnerability, please report it to us as described below.</p>"},{"location":"SECURITY/#reporting-security-issues","title":"Reporting Security Issues","text":"<p>Please do not report security vulnerabilities through public GitHub issues.</p> <p>Instead, please report them to the Microsoft Security Response Center (MSRC) at https://msrc.microsoft.com/create-report.</p> <p>If you prefer to submit without logging in, send email to secure@microsoft.com.  If possible, encrypt your message with our PGP key; please download it from the Microsoft Security Response Center PGP Key page.</p> <p>You should receive a response within 24 hours. If for some reason you do not, please follow up via email to ensure we received your original message. Additional information can be found at microsoft.com/msrc. </p> <p>Please include the requested information listed below (as much as you can provide) to help us better understand the nature and scope of the possible issue:</p> <ul> <li>Type of issue (e.g. buffer overflow, SQL injection, cross-site scripting, etc.)</li> <li>Full paths of source file(s) related to the manifestation of the issue</li> <li>The location of the affected source code (tag/branch/commit or direct URL)</li> <li>Any special configuration required to reproduce the issue</li> <li>Step-by-step instructions to reproduce the issue</li> <li>Proof-of-concept or exploit code (if possible)</li> <li>Impact of the issue, including how an attacker might exploit the issue</li> </ul> <p>This information will help us triage your report more quickly.</p> <p>If you are reporting for a bug bounty, more complete reports can contribute to a higher bounty award. Please visit our Microsoft Bug Bounty Program page for more details about our active programs.</p>"},{"location":"SECURITY/#preferred-languages","title":"Preferred Languages","text":"<p>We prefer all communications to be in English.</p>"},{"location":"SECURITY/#policy","title":"Policy","text":"<p>Microsoft follows the principle of Coordinated Vulnerability Disclosure.</p>"},{"location":"SECURITY_chs/","title":"SECURITY chs","text":""},{"location":"SECURITY_chs/#_1","title":"\u5b89\u5168\u6027","text":"<p>\u5fae\u8f6f\u975e\u5e38\u91cd\u89c6\u6211\u4eec\u8f6f\u4ef6\u4ea7\u54c1\u548c\u670d\u52a1\u7684\u5b89\u5168\u6027\uff0c\u8fd9\u5305\u62ec\u901a\u8fc7\u6211\u4eecGitHub\u7ec4\u7ec7\u7ba1\u7406\u7684\u6240\u6709\u6e90\u4ee3\u7801\u5e93\uff0c\u5176\u4e2d\u5305\u62ec Microsoft, Azure, DotNet, AspNet, Xamarin\uff0c\u4ee5\u53ca \u6211\u4eec\u7684GitHub\u7ec4\u7ec7\u3002</p> <p>\u5982\u679c\u60a8\u8ba4\u4e3a\u5728\u4efb\u4f55\u5fae\u8f6f\u62e5\u6709\u7684\u4ee3\u7801\u5e93\u4e2d\u53d1\u73b0\u4e86\u5b89\u5168\u6f0f\u6d1e\uff0c\u5e76\u4e14\u7b26\u5408\u5fae\u8f6f\u7684\u5b89\u5168\u6f0f\u6d1e\u5b9a\u4e49\uff0c\u8bf7\u6309\u7167\u4e0b\u8ff0\u65b9\u5f0f\u62a5\u544a\u7ed9\u6211\u4eec\u3002</p>"},{"location":"SECURITY_chs/#_2","title":"\u62a5\u544a\u5b89\u5168\u95ee\u9898","text":"<p>\u8bf7\u4e0d\u8981\u901a\u8fc7\u516c\u5f00\u7684GitHub\u95ee\u9898\u62a5\u544a\u5b89\u5168\u6f0f\u6d1e\u3002</p> <p>\u8bf7\u6539\u4e3a\u5411\u5fae\u8f6f\u5b89\u5168\u54cd\u5e94\u4e2d\u5fc3 (MSRC) \u62a5\u544a\uff0c\u7f51\u5740\u4e3ahttps://msrc.microsoft.com/create-report\u3002</p> <p>\u5982\u679c\u60a8\u5e0c\u671b\u5728\u4e0d\u767b\u5f55\u7684\u60c5\u51b5\u4e0b\u63d0\u4ea4\uff0c\u8bf7\u53d1\u9001\u7535\u5b50\u90ae\u4ef6\u81f3 secure@microsoft.com\u3002\u5982\u679c\u53ef\u80fd\uff0c\u8bf7\u4f7f\u7528\u6211\u4eec\u7684PGP\u5bc6\u94a5\u52a0\u5bc6\u60a8\u7684\u6d88\u606f\uff1b\u60a8\u53ef\u4ee5\u4ece \u5fae\u8f6f\u5b89\u5168\u54cd\u5e94\u4e2d\u5fc3PGP\u5bc6\u94a5\u9875\u9762 \u4e0b\u8f7d\u3002</p> <p>\u60a8\u5e94\u572824\u5c0f\u65f6\u5185\u6536\u5230\u56de\u590d\u3002\u5982\u679c\u7531\u4e8e\u67d0\u79cd\u539f\u56e0\u672a\u6536\u5230\uff0c\u8bf7\u901a\u8fc7\u7535\u5b50\u90ae\u4ef6\u8ddf\u8fdb\uff0c\u4ee5\u786e\u4fdd\u6211\u4eec\u6536\u5230\u4e86\u60a8\u7684\u539f\u59cb\u6d88\u606f\u3002\u53ef\u4ee5\u5728 microsoft.com/msrc \u627e\u5230\u66f4\u591a\u4fe1\u606f\u3002</p> <p>\u8bf7\u5c3d\u91cf\u63d0\u4f9b\u4ee5\u4e0b\u4fe1\u606f\uff08\u5c3d\u53ef\u80fd\u8be6\u5c3d\uff09\uff0c\u4ee5\u5e2e\u52a9\u6211\u4eec\u66f4\u597d\u5730\u7406\u89e3\u53ef\u80fd\u95ee\u9898\u7684\u6027\u8d28\u548c\u8303\u56f4\uff1a</p> <ul> <li>\u95ee\u9898\u7c7b\u578b\uff08\u4f8b\u5982\uff1a\u7f13\u51b2\u533a\u6ea2\u51fa\uff0cSQL\u6ce8\u5165\uff0c\u8de8\u7ad9\u811a\u672c\uff0c\u7b49\u7b49\uff09</li> <li>\u4e0e\u95ee\u9898\u8868\u73b0\u76f8\u5173\u7684\u6e90\u6587\u4ef6\u5b8c\u6574\u8def\u5f84</li> <li>\u53d7\u5f71\u54cd\u6e90\u4ee3\u7801\u7684\u4f4d\u7f6e\uff08\u6807\u7b7e/\u5206\u652f/\u63d0\u4ea4\u6216\u76f4\u63a5URL\uff09</li> <li>\u590d\u73b0\u95ee\u9898\u6240\u9700\u7684\u4efb\u4f55\u7279\u6b8a\u914d\u7f6e</li> <li>\u590d\u73b0\u95ee\u9898\u7684\u9010\u6b65\u8bf4\u660e</li> <li>\u6982\u5ff5\u9a8c\u8bc1\u4ee3\u7801\u6216\u6f0f\u6d1e\u5229\u7528\u4ee3\u7801\uff08\u5982\u679c\u53ef\u80fd\uff09</li> <li>\u95ee\u9898\u7684\u5f71\u54cd\uff0c\u5305\u62ec\u653b\u51fb\u8005\u5982\u4f55\u5229\u7528\u8be5\u95ee\u9898</li> </ul> <p>\u8fd9\u4e9b\u4fe1\u606f\u5c06\u5e2e\u52a9\u6211\u4eec\u66f4\u5feb\u5730\u5206\u7c7b\u60a8\u7684\u62a5\u544a\u3002</p> <p>\u5982\u679c\u60a8\u662f\u4e3a\u6f0f\u6d1e\u5956\u52b1\u8ba1\u5212\u8fdb\u884c\u62a5\u544a\uff0c\u66f4\u5168\u9762\u7684\u62a5\u544a\u6709\u52a9\u4e8e\u83b7\u5f97\u66f4\u9ad8\u7684\u5956\u52b1\u3002\u8bf7\u8bbf\u95ee\u6211\u4eec\u7684\u5fae\u8f6f\u6f0f\u6d1e\u5956\u52b1\u8ba1\u5212\u9875\u9762\uff0c\u4e86\u89e3\u6211\u4eec\u73b0\u884c\u8ba1\u5212\u7684\u8be6\u7ec6\u4fe1\u606f\u3002</p>"},{"location":"SECURITY_chs/#_3","title":"\u9996\u9009\u8bed\u8a00","text":"<p>\u6211\u4eec\u66f4\u559c\u6b22\u6240\u6709\u4ea4\u6d41\u4f7f\u7528\u82f1\u8bed\u3002</p>"},{"location":"SECURITY_chs/#_4","title":"\u653f\u7b56","text":"<p>\u5fae\u8f6f\u9075\u5faa\u534f\u8c03\u6f0f\u6d1e\u62ab\u9732\u539f\u5219\u3002</p>"},{"location":"docs/","title":"Index","text":"<p>--8&lt;-- \"README_chs.md\"</p>"},{"location":"etc/CODE_OF_CONDUCT/","title":"Microsoft Open Source Code of Conduct","text":"<p>This project has adopted the Microsoft Open Source Code of Conduct.</p> <p>Resources:</p> <ul> <li>Microsoft Open Source Code of Conduct</li> <li>Microsoft Code of Conduct FAQ</li> <li>Contact opencode@microsoft.com with questions or concerns</li> </ul>"},{"location":"etc/CODE_OF_CONDUCT_chs/","title":"\u5fae\u8f6f\u5f00\u6e90\u884c\u4e3a\u51c6\u5219","text":"<p>\u6b64\u9879\u76ee\u5df2\u91c7\u7528\u5fae\u8f6f\u5f00\u6e90\u884c\u4e3a\u51c6\u5219\u3002</p> <p>\u8d44\u6e90\uff1a</p> <ul> <li>\u5fae\u8f6f\u5f00\u6e90\u884c\u4e3a\u51c6\u5219</li> <li>\u5fae\u8f6f\u884c\u4e3a\u51c6\u5219\u5e38\u89c1\u95ee\u9898\u89e3\u7b54</li> <li>\u5982\u6709\u4efb\u4f55\u95ee\u9898\u6216\u7591\u8651\uff0c\u8bf7\u8054\u7cfbopencode@microsoft.com</li> </ul>"},{"location":"etc/CONTRIBUTING/","title":"Contributing","text":"<p>This project welcomes contributions and suggestions. Most contributions require you to agree to a Contributor License Agreement (CLA) declaring that you have the right to, and actually do, grant us the rights to use your contribution. For details, visit https://cla.microsoft.com.</p> <p>When you submit a pull request, a CLA-bot will automatically determine whether you need to provide a CLA and decorate the PR appropriately (e.g., label, comment). Simply follow the instructions provided by the bot. You will only need to do this once across all repositories using our CLA.</p> <p>This project has adopted the Microsoft Open Source Code of Conduct. For more information see the Code of Conduct FAQ or contact opencode@microsoft.com with any additional questions or comments.</p>"},{"location":"etc/CONTRIBUTING/#looking-for-contributions","title":"Looking for Contributions","text":"<p>We are currently actively looking for contributions on the following topics:</p> <ul> <li>[ ] Write section on Deep Reinforcement Learning</li> <li>[ ] Improve section + notebook on Object Detection</li> <li>[ ] PyTorch Lightning (for this section)</li> <li>[ ] Write section + samples on Named Entity Recognition</li> <li>[ ] Create samples for training our own embeddings for this section </li> </ul>"},{"location":"etc/CONTRIBUTING_chs/","title":"\u8d21\u732e","text":"<p>\u672c\u9879\u76ee\u6b22\u8fce\u8d21\u732e\u548c\u5efa\u8bae\u3002\u5927\u591a\u6570\u8d21\u732e\u9700\u8981\u60a8\u540c\u610f\u4e00\u4efd\u8d21\u732e\u8005\u8bb8\u53ef\u534f\u8bae (CLA)\uff0c\u58f0\u660e\u60a8\u6709\u6743\uff0c\u5e76\u4e14\u786e\u5b9e\u6388\u4e88\u6211\u4eec\u4f7f\u7528\u60a8\u7684\u8d21\u732e\u7684\u6743\u5229\u3002\u8be6\u89c1 https://cla.microsoft.com\u3002</p> <p>\u5f53\u60a8\u63d0\u4ea4\u62c9\u53d6\u8bf7\u6c42\u65f6\uff0cCLA-bot \u4f1a\u81ea\u52a8\u786e\u5b9a\u60a8\u662f\u5426\u9700\u8981\u63d0\u4f9b CLA \u5e76\u9002\u5f53\u88c5\u9970 PR\uff08\u4f8b\u5982\uff0c\u6807\u7b7e\u3001\u8bc4\u8bba\uff09\u3002\u53ea\u9700\u6309\u7167\u673a\u5668\u4eba\u63d0\u4f9b\u7684\u6307\u793a\u64cd\u4f5c\u3002\u60a8\u53ea\u9700\u8981\u5728\u4f7f\u7528\u6211\u4eec CLA \u7684\u6240\u6709\u4ed3\u5e93\u4e2d\u6267\u884c\u6b64\u64cd\u4f5c\u4e00\u6b21\u3002</p> <p>\u672c\u9879\u76ee\u5df2\u91c7\u7528 Microsoft \u5f00\u6e90\u884c\u4e3a\u51c6\u5219\u3002 \u66f4\u591a\u4fe1\u606f\u8bf7\u53c2\u89c1 \u884c\u4e3a\u51c6\u5219\u5e38\u89c1\u95ee\u9898\u89e3\u7b54  \u6216\u901a\u8fc7 opencode@microsoft.com \u8054\u7cfb\u6211\u4eec\uff0c\u63d0\u51fa\u4efb\u4f55\u989d\u5916\u7684\u95ee\u9898\u6216\u8bc4\u8bba\u3002</p>"},{"location":"etc/CONTRIBUTING_chs/#_2","title":"\u5bfb\u627e\u8d21\u732e","text":"<p>\u6211\u4eec\u76ee\u524d\u6b63\u5728\u79ef\u6781\u5bfb\u627e\u4ee5\u4e0b\u4e3b\u9898\u7684\u8d21\u732e\uff1a</p> <ul> <li>[ ] \u7f16\u5199\u5173\u4e8e\u6df1\u5ea6\u5f3a\u5316\u5b66\u4e60\u7684\u90e8\u5206</li> <li>[ ] \u6539\u8fdb\u5173\u4e8e\u76ee\u6807\u68c0\u6d4b\u7684\u90e8\u5206\u548c\u7b14\u8bb0\u672c</li> <li>[ ] PyTorch Lightning\uff08\u7528\u4e8e\u8fd9\u4e00\u90e8\u5206\uff09</li> <li>[ ] \u7f16\u5199\u90e8\u5206\u548c\u793a\u4f8b\u5173\u4e8e\u547d\u540d\u5b9e\u4f53\u8bc6\u522b</li> <li>[ ] \u4e3a\u8fd9\u4e00\u90e8\u5206 \u521b\u5efa\u81ea\u5df1\u7684\u5d4c\u5165\u7684\u8bad\u7ec3\u793a\u4f8b</li> </ul>"},{"location":"etc/Mindmap/","title":"AI","text":""},{"location":"etc/Mindmap/#introduction-to-ai","title":"Introduction to AI","text":"<ul> <li>AI Definition</li> <li>History of AI</li> <li>Approaches to AI<ul> <li>Top-down/Symbolic</li> <li>Bottom-up/Neural</li> <li>Evolutionary</li> <li>Synergetic / Emergent AI</li> </ul> </li> <li>Microsoft AI Business School</li> </ul>"},{"location":"etc/Mindmap/#sybmbolic-ai","title":"Sybmbolic AI","text":"<ul> <li>Knowledge Representation</li> <li>Expert Systems</li> <li>Ontologies</li> <li>Semantic Web</li> </ul>"},{"location":"etc/Mindmap/#neural-networks","title":"Neural Networks","text":"<ul> <li>Perceptron</li> <li>Multi-Layered Networks</li> <li>Intro to Frameworks</li> <li>PyTorch</li> <li>TensorFlow</li> <li>Overfitting</li> </ul>"},{"location":"etc/Mindmap/#computer-vision","title":"Computer Vision","text":"<ul> <li>On MS Learn<ul> <li>AI Fundamentals: Explore Computer Vision</li> <li>CV with PyTorch</li> <li>CV with TensorFlow</li> </ul> </li> <li>Intro to CV. OpenCV</li> <li>Convolutional Networks</li> <li>CNN Architectures</li> <li>Trasnsfer Learning</li> <li>Training Tricks</li> <li>Autoencoders and VAEs</li> <li>Generative Adversarial Networks</li> <li>Style Transfer</li> <li>Object Detection</li> <li>Segmentation</li> </ul>"},{"location":"etc/Mindmap/#natural-language-processing","title":"Natural Language Processing","text":"<ul> <li>On MS Learn<ul> <li>AI Fundamentals: Explore NLP</li> <li>NLP with PyTorch</li> <li>NLP with TensorFlow</li> </ul> </li> <li>Text Representation<ul> <li>Bag of Words</li> <li>TF/IDF</li> </ul> </li> <li>Semantic Embeddings<ul> <li>Word2Vec</li> <li>GloVE</li> </ul> </li> <li>Language Modeling</li> <li>Recurrent Neural Networks<ul> <li>LSTM</li> <li>GRU</li> </ul> </li> <li>Generative Recurrent Networks</li> <li>Transformers and BERT</li> <li>Named Entity Recognition</li> <li>Text Generation and GPT</li> </ul>"},{"location":"etc/Mindmap/#other-techniques","title":"Other Techniques","text":"<ul> <li>Genetic Algorithms</li> <li>Deep Reinforcement Learning</li> <li>Multi-Agent Systems</li> </ul>"},{"location":"etc/Mindmap/#ai-ethics","title":"AI Ethics","text":"<ul> <li>MS Learn on Responsible AI</li> </ul>"},{"location":"etc/Mindmap/#extras","title":"Extras","text":"<ul> <li>Multimodal Networks</li> <li>CLIP</li> <li>DALL-E</li> <li>VQ-GAN</li> </ul>"},{"location":"etc/Mindmap_chs/","title":"\u4eba\u5de5\u667a\u80fd","text":""},{"location":"etc/Mindmap_chs/#_2","title":"\u4eba\u5de5\u667a\u80fd\u7b80\u4ecb","text":"<ul> <li>\u4eba\u5de5\u667a\u80fd\u7684\u5b9a\u4e49</li> <li>\u4eba\u5de5\u667a\u80fd\u7684\u5386\u53f2</li> <li>\u4eba\u5de5\u667a\u80fd\u7684\u65b9\u6cd5<ul> <li>\u81ea\u4e0a\u800c\u4e0b/\u7b26\u53f7\u65b9\u6cd5</li> <li>\u81ea\u4e0b\u800c\u4e0a/\u795e\u7ecf\u7f51\u7edc\u65b9\u6cd5</li> <li>\u8fdb\u5316\u65b9\u6cd5</li> <li>\u534f\u540c/\u6d8c\u73b0\u4eba\u5de5\u667a\u80fd</li> </ul> </li> <li>\u5fae\u8f6f\u4eba\u5de5\u667a\u80fd\u5546\u5b66\u9662</li> </ul>"},{"location":"etc/Mindmap_chs/#_3","title":"\u7b26\u53f7\u4eba\u5de5\u667a\u80fd","text":"<ul> <li>\u77e5\u8bc6\u8868\u793a</li> <li>\u4e13\u5bb6\u7cfb\u7edf</li> <li>\u672c\u4f53\u8bba</li> <li>\u8bed\u4e49\u7f51</li> </ul>"},{"location":"etc/Mindmap_chs/#_4","title":"\u795e\u7ecf\u7f51\u7edc","text":"<ul> <li>\u611f\u77e5\u5668</li> <li>\u591a\u5c42\u7f51\u7edc</li> <li>\u6846\u67b6\u7b80\u4ecb</li> <li>PyTorch</li> <li>TensorFlow</li> <li>\u8fc7\u62df\u5408</li> </ul>"},{"location":"etc/Mindmap_chs/#_5","title":"\u8ba1\u7b97\u673a\u89c6\u89c9","text":"<ul> <li>\u5728 Microsoft Learn \u4e0a<ul> <li>\u4eba\u5de5\u667a\u80fd\u57fa\u7840: \u63a2\u7d22\u8ba1\u7b97\u673a\u89c6\u89c9</li> <li>\u4f7f\u7528 PyTorch \u8fdb\u884c\u8ba1\u7b97\u673a\u89c6\u89c9</li> <li>\u4f7f\u7528 TensorFlow \u8fdb\u884c\u8ba1\u7b97\u673a\u89c6\u89c9</li> </ul> </li> <li>\u8ba1\u7b97\u673a\u89c6\u89c9\u7b80\u4ecb. OpenCV</li> <li>\u5377\u79ef\u7f51\u7edc</li> <li>\u5377\u79ef\u795e\u7ecf\u7f51\u7edc\u67b6\u6784</li> <li>\u8fc1\u79fb\u5b66\u4e60</li> <li>\u8bad\u7ec3\u6280\u5de7</li> <li>\u81ea\u52a8\u7f16\u7801\u5668\u548c\u53d8\u5206\u81ea\u52a8\u7f16\u7801\u5668</li> <li>\u751f\u6210\u5bf9\u6297\u7f51\u7edc</li> <li>\u98ce\u683c\u8fc1\u79fb</li> <li>\u76ee\u6807\u68c0\u6d4b</li> <li>\u5206\u5272</li> </ul>"},{"location":"etc/Mindmap_chs/#_6","title":"\u81ea\u7136\u8bed\u8a00\u5904\u7406","text":"<ul> <li>\u5728 Microsoft Learn \u4e0a<ul> <li>\u4eba\u5de5\u667a\u80fd\u57fa\u7840: \u63a2\u7d22\u81ea\u7136\u8bed\u8a00\u5904\u7406</li> <li>\u4f7f\u7528 PyTorch \u8fdb\u884c\u81ea\u7136\u8bed\u8a00\u5904\u7406</li> <li>\u4f7f\u7528 TensorFlow \u8fdb\u884c\u81ea\u7136\u8bed\u8a00\u5904\u7406</li> </ul> </li> <li>\u6587\u672c\u8868\u793a<ul> <li>\u8bcd\u888b</li> <li>TF/IDF</li> </ul> </li> <li>\u8bed\u4e49\u5d4c\u5165<ul> <li>Word2Vec</li> <li>GloVE</li> </ul> </li> <li>\u8bed\u8a00\u5efa\u6a21</li> <li>\u5faa\u73af\u795e\u7ecf\u7f51\u7edc<ul> <li>LSTM</li> <li>GRU</li> </ul> </li> <li>\u751f\u6210\u5f0f\u5faa\u73af\u7f51\u7edc</li> <li>transformer\u548c BERT</li> <li>\u547d\u540d\u5b9e\u4f53\u8bc6\u522b</li> <li>\u6587\u672c\u751f\u6210\u548c GPT</li> </ul>"},{"location":"etc/Mindmap_chs/#_7","title":"\u5176\u4ed6\u6280\u672f","text":"<ul> <li>\u9057\u4f20\u7b97\u6cd5</li> <li>\u6df1\u5ea6\u5f3a\u5316\u5b66\u4e60</li> <li>\u591a\u4ee3\u7406\u7cfb\u7edf</li> </ul>"},{"location":"etc/Mindmap_chs/#_8","title":"\u4eba\u5de5\u667a\u80fd\u4f26\u7406","text":"<ul> <li>Microsoft Learn \u4e0a\u5173\u4e8e\u8d1f\u8d23\u4efb\u7684\u4eba\u5de5\u667a\u80fd</li> </ul>"},{"location":"etc/Mindmap_chs/#_9","title":"\u989d\u5916\u5185\u5bb9","text":"<ul> <li>\u591a\u6a21\u6001\u7f51\u7edc</li> <li>CLIP</li> <li>DALL-E</li> <li>VQ-GAN</li> </ul>"},{"location":"etc/SUPPORT/","title":"Support","text":""},{"location":"etc/SUPPORT/#how-to-file-issues-and-get-help","title":"How to file issues and get help","text":"<p>This project uses GitHub Issues to track bugs and feature requests. Please search the existing  issues before filing new issues to avoid duplicates.  For new issues, file your bug or  feature request as a new Issue.</p> <p>For help and questions about using this project, please use the Discussion Boards.</p>"},{"location":"etc/SUPPORT/#microsoft-support-policy","title":"Microsoft Support Policy","text":"<p>Support for this project is limited to the resources listed above.</p>"},{"location":"etc/SUPPORT_chs/","title":"\u652f\u6301","text":""},{"location":"etc/SUPPORT_chs/#_2","title":"\u5982\u4f55\u63d0\u4ea4\u95ee\u9898\u548c\u83b7\u53d6\u5e2e\u52a9","text":"<p>\u6b64\u9879\u76ee\u4f7f\u7528 GitHub Issues \u8ddf\u8e2a\u9519\u8bef\u548c\u529f\u80fd\u8bf7\u6c42\u3002\u8bf7\u5728\u63d0\u4ea4\u65b0\u95ee\u9898\u4e4b\u524d\u641c\u7d22\u73b0\u6709\u95ee\u9898\u4ee5\u907f\u514d\u91cd\u590d\u3002\u5bf9\u4e8e\u65b0\u95ee\u9898\uff0c\u8bf7\u5c06\u60a8\u7684\u9519\u8bef\u6216\u529f\u80fd\u8bf7\u6c42\u63d0\u4ea4\u4e3a\u4e00\u4e2a\u65b0\u95ee\u9898\u3002</p> <p>\u5173\u4e8e\u4f7f\u7528\u6b64\u9879\u76ee\u7684\u5e2e\u52a9\u548c\u95ee\u9898\uff0c\u8bf7\u4f7f\u7528\u8ba8\u8bba\u677f\u5757\u3002</p>"},{"location":"etc/SUPPORT_chs/#_3","title":"\u5fae\u8f6f\u652f\u6301\u653f\u7b56","text":"<p>\u5bf9\u8be5\u9879\u76ee\u7684\u652f\u6301\u4ec5\u9650\u4e8e\u4e0a\u8ff0\u8d44\u6e90\u3002</p>"},{"location":"etc/TRANSLATIONS/","title":"Contribute by translating lessons","text":"<p>We welcome translations for the lessons in this curriculum!</p>"},{"location":"etc/TRANSLATIONS/#guidelines","title":"Guidelines","text":"<p>There are folders in each lesson folder and lesson introduction folder which contain the translated markdown files.</p> <p>Note, please do not translate any code in the code sample files; the only things to translate are README, assignments, and the quizzes. Thanks!</p> <p>Translated files should follow this naming convention:</p> <p>README._[language]__chs.md</p> <p>where [language] is a two letter language abbreviation following the ISO 639-1 standard (e.g. <code>README.es_chs.md</code> for Spanish and <code>README.nl_chs.md</code> for Dutch).</p> <p>assignment._[language]__chs.md</p> <p>Similar to Readme's, please translate the assignments as well.</p> <p>Quizzes</p> <ol> <li> <p>Add your translation to the quiz-app by adding a file here: https://github.com/microsoft/AI-For-Beginners/tree/main/etc/quiz-app/src/assets/translations, with proper naming convention (en.json, fr.json). Please don't localize the words 'true' or 'false' however. thanks!</p> </li> <li> <p>Add your language code to the dropdown in the quiz-app's App.vue file.</p> </li> <li> <p>Edit the quiz-app's translations index.js file to add your language.</p> </li> <li> <p>Finally, edit ALL the quiz links in your translated README_chs.md files to point directly to your translated quiz: https://red-field-0a6ddfd03.1.azurestaticapps.net/quiz/1 becomes https://red-field-0a6ddfd03.1.azurestaticapps.net/quiz/1?loc=id</p> </li> </ol> <p>THANK YOU</p> <p>We truly appreciate your efforts!</p>"},{"location":"etc/TRANSLATIONS_chs/","title":"\u901a\u8fc7\u7ffb\u8bd1\u8bfe\u7a0b\u505a\u8d21\u732e","text":"<p>\u6211\u4eec\u6b22\u8fce\u5bf9\u672c\u6559\u7a0b\u4e2d\u7684\u8bfe\u7a0b\u8fdb\u884c\u7ffb\u8bd1\uff01</p>"},{"location":"etc/TRANSLATIONS_chs/#_2","title":"\u6307\u5bfc\u65b9\u9488","text":"<p>\u5728\u6bcf\u4e2a\u8bfe\u7a0b\u6587\u4ef6\u5939\u548c\u8bfe\u7a0b\u4ecb\u7ecd\u6587\u4ef6\u5939\u4e2d\u90fd\u6709\u5305\u542b\u7ffb\u8bd1\u540e\u7684markdown\u6587\u4ef6\u7684\u6587\u4ef6\u5939\u3002</p> <p>\u6ce8\u610f\uff0c\u8bf7\u4e0d\u8981\u7ffb\u8bd1\u4ee3\u7801\u793a\u4f8b\u6587\u4ef6\u4e2d\u7684\u4efb\u4f55\u4ee3\u7801\uff1b\u552f\u4e00\u9700\u8981\u7ffb\u8bd1\u7684\u662fREADME\u3001\u4f5c\u4e1a\u548c\u6d4b\u9a8c\u3002\u8c22\u8c22\uff01</p> <p>\u7ffb\u8bd1\u6587\u4ef6\u5e94\u9075\u5faa\u4ee5\u4e0b\u547d\u540d\u7ea6\u5b9a\uff1a</p> <p>README._[language]__chs.md</p> <p>\u5176\u4e2d_[language]_\u662f\u9075\u5faaISO 639-1\u6807\u51c6\u7684\u4e24\u5b57\u6bcd\u8bed\u8a00\u7f29\u5199\uff08\u4f8b\u5982\uff0c\u897f\u73ed\u7259\u8bed\u4e3a<code>README.es_chs.md</code>\uff0c\u8377\u5170\u8bed\u4e3a<code>README.nl_chs.md</code>\uff09\u3002</p> <p>assignment._[language]__chs.md</p> <p>\u7c7b\u4f3c\u4e8eReadme\uff0c\u8bf7\u4e5f\u7ffb\u8bd1\u4f5c\u4e1a\u3002</p> <p>\u6d4b\u9a8c</p> <ol> <li> <p>\u901a\u8fc7\u5728\u6b64\u5904\u6dfb\u52a0\u4e00\u4e2a\u6587\u4ef6\u5c06\u60a8\u7684\u7ffb\u8bd1\u6dfb\u52a0\u5230quiz-app\uff1ahttps://github.com/microsoft/AI-For-Beginners/tree/main/etc/quiz-app/src/assets/translations\uff0c\u91c7\u7528\u6b63\u786e\u7684\u547d\u540d\u7ea6\u5b9a\uff08en.json\uff0cfr.json\uff09\u3002\u4f46\u662f\u8bf7\u4e0d\u8981\u672c\u5730\u5316'true'\u6216'false'\u8fd9\u4e24\u4e2a\u8bcd\u3002\u8c22\u8c22\uff01</p> </li> <li> <p>\u5c06\u60a8\u7684\u8bed\u8a00\u4ee3\u7801\u6dfb\u52a0\u5230quiz-app\u7684App.vue\u6587\u4ef6\u4e2d\u7684\u4e0b\u62c9\u83dc\u5355\u4e2d\u3002</p> </li> <li> <p>\u7f16\u8f91quiz-app\u7684translations index.js\u6587\u4ef6\u4ee5\u6dfb\u52a0\u60a8\u7684\u8bed\u8a00\u3002</p> </li> <li> <p>\u6700\u540e\uff0c\u7f16\u8f91\u60a8\u7ffb\u8bd1\u7684README_chs.md\u6587\u4ef6\u4e2d\u7684\u6240\u6709\u6d4b\u9a8c\u94fe\u63a5\uff0c\u76f4\u63a5\u6307\u5411\u60a8\u7ffb\u8bd1\u540e\u7684\u6d4b\u9a8c\uff1ahttps://red-field-0a6ddfd03.1.azurestaticapps.net/quiz/1 \u53d8\u4e3a https://red-field-0a6ddfd03.1.azurestaticapps.net/quiz/1?loc=id</p> </li> </ol> <p>\u8c22\u8c22</p> <p>\u6211\u4eec\u975e\u5e38\u611f\u8c22\u60a8\u7684\u52aa\u529b\uff01</p>"},{"location":"etc/quiz-app/","title":"Quizzes","text":"<p>These quizzes are the pre- and post-lecture quizzes for the AI curriculum at https://aka.ms/ai-beginners</p>"},{"location":"etc/quiz-app/#adding-a-translated-quiz-set","title":"Adding a translated quiz set","text":"<p>Add a quiz translation by creating matching quiz structures in the <code>assets/translations</code> folders. The canonical quizzes are in <code>assets/translations/en</code>. The quizzes are broken into several groupings by lesson. Make sure to align the numbering with the proper quiz section. There are 40 quizzes total in this curriculum, with the count starting at 0.</p> <p>After editing the translations, edit the index.js file in the translation folder to import all the files following the conventions in <code>en</code>.</p> <p>Edit the <code>index.js</code> file in <code>assets/translations</code> to import the new translated files.</p> <p>Then, edit the dropdown in <code>App.vue</code> in this app to add your language. Match the localized abbreviation to the folder name for your language.</p> <p>Finally, edit all the quiz links in the translated lessons, if they exist, to include this localization as a query parameter: <code>?loc=fr</code> for example.</p>"},{"location":"etc/quiz-app/#project-setup","title":"Project setup","text":"<pre><code>npm install\n</code></pre>"},{"location":"etc/quiz-app/#compiles-and-hot-reloads-for-development","title":"Compiles and hot-reloads for development","text":"<pre><code>npm run serve\n</code></pre>"},{"location":"etc/quiz-app/#compiles-and-minifies-for-production","title":"Compiles and minifies for production","text":"<pre><code>npm run build\n</code></pre>"},{"location":"etc/quiz-app/#lints-and-fixes-files","title":"Lints and fixes files","text":"<pre><code>npm run lint\n</code></pre>"},{"location":"etc/quiz-app/#customize-configuration","title":"Customize configuration","text":"<p>See Configuration Reference.</p> <p>Credits: Thanks to the original version of this quiz app: https://github.com/arpan45/simple-quiz-vue</p>"},{"location":"etc/quiz-app/#deploying-to-azure","title":"Deploying to Azure","text":"<p>Here\u2019s a step-by-step guide to help you get started:</p> <ol> <li> <p>Fork the a GitHub Repository Ensure your static web app code is in your GitHub repository. Fork this repository.</p> </li> <li> <p>Create an Azure Static Web App</p> </li> <li>Create and Azure account</li> <li>Go to the Azure portal </li> <li>Click on \u201cCreate a resource\u201d and search for \u201cStatic Web App\u201d.</li> <li> <p>Click \u201cCreate\u201d.</p> </li> <li> <p>Configure the Static Web App</p> </li> <li>Basics: Subscription: Select your Azure subscription.</li> <li>Resource Group: Create a new resource group or use an existing one.</li> <li>Name: Provide a name for your static web app.</li> <li> <p>Region: Choose the region closest to your users.</p> </li> <li> </li> <li>Source: Select \u201cGitHub\u201d.</li> <li>GitHub Account: Authorize Azure to access your GitHub account.</li> <li>Organization: Select your GitHub organization.</li> <li>Repository: Choose the repository containing your static web app.</li> <li> <p>Branch: Select the branch you want to deploy from.</p> </li> <li> </li> <li>Build Presets: Choose the framework your app is built with (e.g., React, Angular, Vue, etc.).</li> <li>App Location: Specify the folder containing your app code (e.g., / if it\u2019s in the root).</li> <li>API Location: If you have an API, specify its location (optional).</li> <li> <p>Output Location: Specify the folder where the build output is generated (e.g., build or dist).</p> </li> <li> <p>Review and Create Review your settings and click \u201cCreate\u201d. Azure will set up the necessary resources and create a GitHub Actions workflow in your repository.</p> </li> <li> <p>GitHub Actions Workflow Azure will automatically create a GitHub Actions workflow file in your repository (.github/workflows/azure-static-web-apps-.yml). This workflow will handle the build and deployment process. <li> <p>Monitor the Deployment Go to the \u201cActions\u201d tab in your GitHub repository. You should see a workflow running. This workflow will build and deploy your static web app to Azure. Once the workflow completes, your app will be live on the provided Azure URL.</p> </li>"},{"location":"etc/quiz-app/#deployment-details","title":"Deployment Details:","text":""},{"location":"etc/quiz-app/#build-details","title":"Build Details:","text":""},{"location":"etc/quiz-app/#example-workflow-file","title":"Example Workflow File","text":"<p>Here\u2019s an example of what the GitHub Actions workflow file might look like: name: Azure Static Web Apps CI/CD</p> <pre><code>on:\n  push:\n    branches:\n      - main\n  pull_request:\n    types: [opened, synchronize, reopened, closed]\n    branches:\n      - main\n\njobs:\n  build_and_deploy_job:\n    runs-on: ubuntu-latest\n    name: Build and Deploy Job\n    steps:\n      - uses: actions/checkout@v2\n      - name: Build And Deploy\n        id: builddeploy\n        uses: Azure/static-web-apps-deploy@v1\n        with:\n          azure_static_web_apps_api_token: ${{ secrets.AZURE_STATIC_WEB_APPS_API_TOKEN }}\n          repo_token: ${{ secrets.GITHUB_TOKEN }}\n          action: \"upload\"\n          app_location: \"etc/quiz-app # App source code path\"\n          api_location: \"\"API source code path optional\n          output_location: \"dist\" #Built app content directory - optional\n</code></pre>"},{"location":"etc/quiz-app/#additional-resources","title":"Additional Resources","text":"<ul> <li>Azure Static Web Apps Documentation</li> <li>GitHub Actions Documentation</li> </ul>"},{"location":"etc/quiz-app/README_chs/","title":"\u6d4b\u9a8c","text":"<p>\u8fd9\u4e9b\u6d4b\u9a8c\u662f AI \u8bfe\u7a0b\u7684\u8bfe\u524d\u548c\u8bfe\u540e\u6d4b\u9a8c\uff0c\u94fe\u63a5\u5982\u4e0b\uff1ahttps://aka.ms/ai-beginners</p>"},{"location":"etc/quiz-app/README_chs/#_2","title":"\u6dfb\u52a0\u7ffb\u8bd1\u540e\u7684\u6d4b\u9a8c\u96c6","text":"<p>\u901a\u8fc7\u5728 <code>assets/translations</code> \u6587\u4ef6\u5939\u4e2d\u521b\u5efa\u76f8\u5e94\u7684\u6d4b\u9a8c\u7ed3\u6784\u6765\u6dfb\u52a0\u6d4b\u9a8c\u7ffb\u8bd1\u3002\u89c4\u8303\u7684\u6d4b\u9a8c\u5728 <code>assets/translations/en</code> \u4e2d\u3002\u6d4b\u9a8c\u6309\u8bfe\u7a0b\u5206\u6210\u82e5\u5e72\u7ec4\u3002\u8bf7\u786e\u4fdd\u5c06\u7f16\u53f7\u4e0e\u9002\u5f53\u7684\u6d4b\u9a8c\u90e8\u5206\u5bf9\u9f50\u3002\u5728\u6574\u4e2a\u8bfe\u7a0b\u4e2d\u603b\u5171\u6709 40 \u4e2a\u6d4b\u9a8c\uff0c\u4ece 0 \u5f00\u59cb\u8ba1\u6570\u3002</p> <p>\u7f16\u8f91\u7ffb\u8bd1\u5b8c\u6210\u540e\uff0c\u7f16\u8f91\u7ffb\u8bd1\u6587\u4ef6\u5939\u4e2d\u7684 index.js \u6587\u4ef6\uff0c\u4ee5\u6309 <code>en</code> \u4e2d\u7684\u60ef\u4f8b\u5bfc\u5165\u6240\u6709\u6587\u4ef6\u3002</p> <p>\u7f16\u8f91 <code>assets/translations</code> \u4e2d\u7684 <code>index.js</code> \u6587\u4ef6\u4ee5\u5bfc\u5165\u65b0\u7684\u7ffb\u8bd1\u6587\u4ef6\u3002</p> <p>\u7136\u540e\uff0c\u7f16\u8f91\u8be5\u5e94\u7528\u7a0b\u5e8f\u4e2d\u7684 <code>App.vue</code> \u6587\u4ef6\u4e2d\u7684\u4e0b\u62c9\u83dc\u5355\u4ee5\u6dfb\u52a0\u60a8\u7684\u8bed\u8a00\u3002\u5c06\u672c\u5730\u5316\u7f29\u5199\u4e0e\u60a8\u7684\u8bed\u8a00\u6587\u4ef6\u5939\u540d\u79f0\u5339\u914d\u3002</p> <p>\u6700\u540e\uff0c\u5982\u679c\u5b58\u5728\u5df2\u7ffb\u8bd1\u7684\u8bfe\u7a0b\uff0c\u8bf7\u7f16\u8f91\u5176\u4e2d\u7684\u6240\u6709\u6d4b\u9a8c\u94fe\u63a5\uff0c\u4ee5\u5c06\u672c\u5730\u5316\u4f5c\u4e3a\u67e5\u8be2\u53c2\u6570\u5305\u542b\u5728\u5185: \u4f8b\u5982 <code>?loc=fr</code>\u3002</p>"},{"location":"etc/quiz-app/README_chs/#_3","title":"\u9879\u76ee\u8bbe\u7f6e","text":"<pre><code>npm install\n</code></pre>"},{"location":"etc/quiz-app/README_chs/#_4","title":"\u7f16\u8bd1\u5e76\u70ed\u91cd\u8f7d\u5f00\u53d1\u73af\u5883","text":"<pre><code>npm run serve\n</code></pre>"},{"location":"etc/quiz-app/README_chs/#_5","title":"\u7f16\u8bd1\u5e76\u538b\u7f29\u751f\u4ea7\u73af\u5883","text":"<pre><code>npm run build\n</code></pre>"},{"location":"etc/quiz-app/README_chs/#_6","title":"\u4fee\u590d\u6587\u4ef6\u4e2d\u7684\u4ee3\u7801\u6837\u5f0f\u95ee\u9898","text":"<pre><code>npm run lint\n</code></pre>"},{"location":"etc/quiz-app/README_chs/#_7","title":"\u81ea\u5b9a\u4e49\u914d\u7f6e","text":"<p>\u8bf7\u53c2\u89c1 \u914d\u7f6e\u53c2\u8003\u3002</p> <p>\u81f4\u8c22: \u611f\u8c22\u6b64\u6d4b\u9a8c\u5e94\u7528\u7a0b\u5e8f\u7684\u539f\u59cb\u7248\u672c\uff1ahttps://github.com/arpan45/simple-quiz-vue</p>"},{"location":"etc/quiz-app/README_chs/#azure","title":"\u90e8\u7f72\u5230 Azure","text":"<p>\u4ee5\u4e0b\u662f\u5e2e\u52a9\u60a8\u5feb\u901f\u5165\u95e8\u7684\u5206\u6b65\u6307\u5357\uff1a</p> <ol> <li> <p>\u6d3e\u751f GitHub \u4ed3\u5e93 \u786e\u4fdd\u60a8\u7684\u9759\u6001 web \u5e94\u7528\u4ee3\u7801\u5728\u60a8\u7684 GitHub \u4ed3\u5e93\u4e2d\u3002\u6d3e\u751f\u8fd9\u4e2a\u4ed3\u5e93\u3002</p> </li> <li> <p>\u521b\u5efa\u4e00\u4e2a Azure \u9759\u6001 Web \u5e94\u7528</p> </li> <li>\u521b\u5efa\u4e00\u4e2a Azure \u8d26\u53f7</li> <li>\u524d\u5f80 Azure \u95e8\u6237</li> <li>\u70b9\u51fb\u201c\u521b\u5efa\u8d44\u6e90\u201d\uff0c\u7136\u540e\u641c\u7d22\u201c\u9759\u6001 Web \u5e94\u7528\u201d\u3002</li> <li> <p>\u70b9\u51fb\u201c\u521b\u5efa\u201d\u3002</p> </li> <li> <p>\u914d\u7f6e\u9759\u6001 Web \u5e94\u7528</p> </li> <li>\u57fa\u7840\uff1a\u8ba2\u9605\uff1a\u9009\u62e9\u60a8\u7684 Azure \u8ba2\u9605\u3002</li> <li>\u8d44\u6e90\u7ec4\uff1a\u521b\u5efa\u4e00\u4e2a\u65b0\u7684\u8d44\u6e90\u7ec4\u6216\u4f7f\u7528\u73b0\u6709\u7684\u8d44\u6e90\u7ec4\u3002</li> <li>\u540d\u79f0\uff1a\u4e3a\u60a8\u7684\u9759\u6001 Web \u5e94\u7528\u63d0\u4f9b\u4e00\u4e2a\u540d\u79f0\u3002</li> <li> <p>\u533a\u57df\uff1a\u9009\u62e9\u79bb\u60a8\u7684\u7528\u6237\u6700\u8fd1\u7684\u533a\u57df\u3002</p> </li> <li> </li> <li>\u6765\u6e90\uff1a\u9009\u62e9\u201cGitHub\u201d\u3002</li> <li>GitHub \u5e10\u6237\uff1a\u6388\u6743 Azure \u8bbf\u95ee\u60a8\u7684 GitHub \u5e10\u6237\u3002</li> <li>\u7ec4\u7ec7\uff1a\u9009\u62e9\u60a8\u7684 GitHub \u7ec4\u7ec7\u3002</li> <li>\u4ed3\u5e93\uff1a\u9009\u62e9\u5305\u542b\u60a8\u7684\u9759\u6001 Web \u5e94\u7528\u7684\u4ed3\u5e93\u3002</li> <li> <p>\u5206\u652f\uff1a\u9009\u62e9\u8981\u90e8\u7f72\u7684\u5206\u652f\u3002</p> </li> <li> </li> <li>\u6784\u5efa\u9884\u8bbe\uff1a\u9009\u62e9\u6784\u5efa\u5e94\u7528\u7a0b\u5e8f\u6240\u7528\u7684\u6846\u67b6\uff08\u4f8b\u5982\uff0cReact\uff0cAngular\uff0cVue \u7b49\uff09\u3002</li> <li>\u5e94\u7528\u4f4d\u7f6e\uff1a\u6307\u5b9a\u5305\u542b\u60a8\u7684\u5e94\u7528\u4ee3\u7801\u7684\u6587\u4ef6\u5939\uff08\u4f8b\u5982\uff0c\u5982\u679c\u5728\u6839\u76ee\u5f55\uff0c\u5219\u4e3a /\uff09\u3002</li> <li>API \u4f4d\u7f6e\uff1a\u5982\u679c\u6709 API\uff0c\u8bf7\u6307\u5b9a\u5176\u4f4d\u7f6e\uff08\u53ef\u9009\uff09\u3002</li> <li> <p>\u8f93\u51fa\u4f4d\u7f6e\uff1a\u6307\u5b9a\u751f\u6210\u8f93\u51fa\u7684\u6587\u4ef6\u5939\uff08\u4f8b\u5982\uff0cbuild \u6216 dist\uff09\u3002</p> </li> <li> <p>\u5ba1\u6838\u548c\u521b\u5efa \u5ba1\u6838\u60a8\u7684\u8bbe\u7f6e\u5e76\u70b9\u51fb\u201c\u521b\u5efa\u201d\u3002Azure \u5c06\u8bbe\u7f6e\u5fc5\u8981\u7684\u8d44\u6e90\u5e76\u5728\u60a8\u7684\u4ed3\u5e93\u4e2d\u521b\u5efa\u4e00\u4e2a GitHub Actions \u5de5\u4f5c\u6d41\u3002</p> </li> <li> <p>GitHub Actions \u5de5\u4f5c\u6d41 Azure \u5c06\u81ea\u52a8\u5728\u60a8\u7684\u4ed3\u5e93\u4e2d\u521b\u5efa\u4e00\u4e2a GitHub Actions \u5de5\u4f5c\u6d41\u6587\u4ef6\uff08.github/workflows/azure-static-web-apps-.yml\uff09\u3002\u8be5\u5de5\u4f5c\u6d41\u5c06\u5904\u7406\u6784\u5efa\u548c\u90e8\u7f72\u8fc7\u7a0b\u3002 <li> <p>\u76d1\u63a7\u90e8\u7f72 \u524d\u5f80\u60a8\u7684 GitHub \u4ed3\u5e93\u4e2d\u7684\u201cActions\u201d\u6807\u7b7e\u3002 \u60a8\u5e94\u4f1a\u770b\u5230\u4e00\u4e2a\u6b63\u5728\u8fd0\u884c\u7684\u5de5\u4f5c\u6d41\u3002\u8be5\u5de5\u4f5c\u6d41\u5c06\u6784\u5efa\u5e76\u90e8\u7f72\u60a8\u7684\u9759\u6001 Web \u5e94\u7528\u5230 Azure\u3002 \u5de5\u4f5c\u6d41\u5b8c\u6210\u540e\uff0c\u60a8\u7684\u5e94\u7528\u5c06\u4f1a\u5728\u63d0\u4f9b\u7684 Azure URL \u4e0a\u4e0a\u7ebf\u3002</p> </li>"},{"location":"etc/quiz-app/README_chs/#_8","title":"\u90e8\u7f72\u8be6\u60c5\uff1a","text":""},{"location":"etc/quiz-app/README_chs/#_9","title":"\u6784\u5efa\u8be6\u60c5\uff1a","text":""},{"location":"etc/quiz-app/README_chs/#_10","title":"\u793a\u4f8b\u5de5\u4f5c\u6d41\u6587\u4ef6","text":"<p>\u8fd9\u662f GitHub Actions \u5de5\u4f5c\u6d41\u6587\u4ef6\u7684\u793a\u4f8b\uff1a \u540d\u79f0\uff1aAzure \u9759\u6001 Web \u5e94\u7528 CI/CD</p> <pre><code>on:\n  push:\n    branches:\n      - main\n  pull_request:\n    types: [opened, synchronize, reopened, closed]\n    branches:\n      - main\n\njobs:\n  build_and_deploy_job:\n    runs-on: ubuntu-latest\n    name: Build and Deploy Job\n    steps:\n      - uses: actions/checkout@v2\n      - name: Build And Deploy\n        id: builddeploy\n        uses: Azure/static-web-apps-deploy@v1\n        with:\n          azure_static_web_apps_api_token: ${{ secrets.AZURE_STATIC_WEB_APPS_API_TOKEN }}\n          repo_token: ${{ secrets.GITHUB_TOKEN }}\n          action: \"upload\"\n          app_location: \"etc/quiz-app # \u5e94\u7528\u6e90\u4ee3\u7801\u8def\u5f84\"\n          api_location: \"\"API \u6e90\u4ee3\u7801\u8def\u5f84\u53ef\u9009\n          output_location: \"dist\" #\u751f\u6210\u7684\u5e94\u7528\u5185\u5bb9\u76ee\u5f55 - \u53ef\u9009\n</code></pre>"},{"location":"etc/quiz-app/README_chs/#_11","title":"\u5176\u4ed6\u8d44\u6e90","text":"<ul> <li>Azure \u9759\u6001 Web \u5e94\u7528\u6587\u6863</li> <li>GitHub Actions \u6587\u6863</li> </ul>"},{"location":"lessons/","title":"Overview","text":"<p>Sketchnote by Tomomi Imura</p>"},{"location":"lessons/README_chs/","title":"\u6982\u8ff0","text":"<p>\u624b\u7ed8\u8349\u56fe\u4f5c\u8005 Tomomi Imura</p>"},{"location":"lessons/0-course-setup/for-teachers/","title":"For Educators","text":"<p>Would you like to use this curriculum in your classroom? Please feel free!</p> <p>In fact, you can use it within GitHub itself by using GitHub Classroom.</p> <p>To do that, fork this repo. You are going to need to create a repo for each lesson, so you're going to need to extract each folder into a separate repo. That way, GitHub Classroom can pick up each lesson separately. </p> <p>These full instructions will give you an idea how to set up your classroom.</p>"},{"location":"lessons/0-course-setup/for-teachers/#using-the-repo-as-is","title":"Using the repo as is","text":"<p>If you would like to use this repo as it currently stands, without using GitHub Classroom, that can be done as well. You would need to communicate with your students which lesson to work through together.</p> <p>In an online format (Zoom, Teams, or other) you might form breakout rooms for the quizzes, and mentor students to help them get ready to learn. Then invite students to for the quizzes and submit their answers as 'issues' at a certain time. You might do the same with assignments, if you want students to work collaboratively out in the open.</p> <p>If you prefer a more private format, ask your students to fork the curriculum, lesson by lesson, to their own GitHub repos as private repos, and give you access. Then they can complete quizzes and assignments privately and submit them to you via issues on your classroom repo.</p> <p>There are many ways to make this work in an online classroom format. Please let us know what works best for you!</p>"},{"location":"lessons/0-course-setup/for-teachers/#please-give-us-your-thoughts","title":"Please give us your thoughts","text":"<p>We want to make this curriculum work for you and your students. Please give us feedback in the discussion boards!</p>"},{"location":"lessons/0-course-setup/for-teachers_chs/","title":"\u7ed9\u6559\u80b2\u8005","text":"<p>\u60a8\u60f3\u5728\u60a8\u7684\u8bfe\u5802\u4e0a\u4f7f\u7528\u8fd9\u4e00\u8bfe\u7a0b\u5417\uff1f\u8bf7\u968f\u610f\u4f7f\u7528\uff01</p> <p>\u4e8b\u5b9e\u4e0a\uff0c\u60a8\u53ef\u4ee5\u901a\u8fc7\u4f7f\u7528 GitHub Classroom \u5728 GitHub \u672c\u8eab\u5185\u4f7f\u7528\u5b83\u3002</p> <p>\u4e3a\u6b64\uff0c\u5148 fork \u8fd9\u4e2a\u4ed3\u5e93\u3002\u60a8\u9700\u8981\u4e3a\u6bcf\u8282\u8bfe\u521b\u5efa\u4e00\u4e2a\u4ed3\u5e93\uff0c\u56e0\u6b64\u60a8\u9700\u8981\u5c06\u6bcf\u4e2a\u6587\u4ef6\u5939\u63d0\u53d6\u5230\u4e00\u4e2a\u5355\u72ec\u7684\u4ed3\u5e93\u4e2d\u3002\u8fd9\u6837\uff0cGitHub Classroom \u53ef\u4ee5\u5206\u522b\u83b7\u53d6\u6bcf\u8282\u8bfe\u3002</p> <p>\u8fd9\u4e9b\u5b8c\u6574\u8bf4\u660e\u5c06\u4e3a\u60a8\u63d0\u4f9b\u8bbe\u7f6e\u8bfe\u5802\u7684\u601d\u8def\u3002</p>"},{"location":"lessons/0-course-setup/for-teachers_chs/#_2","title":"\u6309\u539f\u6837\u4f7f\u7528\u4ed3\u5e93","text":"<p>\u5982\u679c\u60a8\u60f3\u6309\u5f53\u524d\u72b6\u6001\u4f7f\u7528\u8fd9\u4e2a\u4ed3\u5e93\uff0c\u4e0d\u4f7f\u7528 GitHub Classroom\uff0c\u4e5f\u662f\u53ef\u4ee5\u7684\u3002\u60a8\u9700\u8981\u544a\u77e5\u60a8\u7684\u5b66\u751f\u4e00\u540c\u5b66\u4e60\u54ea\u4e00\u8bfe\u3002</p> <p>\u5728\u5728\u7ebf\u5f62\u5f0f\uff08Zoom\u3001Teams \u6216\u5176\u5b83\uff09\u4e2d\uff0c\u60a8\u53ef\u4ee5\u4e3a\u6d4b\u9a8c\u5f62\u6210\u5206\u7ec4\uff0c\u5e76\u6307\u5bfc\u5b66\u751f\u4e3a\u5b66\u4e60\u505a\u597d\u51c6\u5907\u3002\u7136\u540e\u9080\u8bf7\u5b66\u751f\u53c2\u52a0\u6d4b\u9a8c\u5e76\u5728\u7279\u5b9a\u65f6\u95f4\u63d0\u4ea4\u4ed6\u4eec\u7684\u7b54\u6848\u4f5c\u4e3a\u201cissue\u201d\u3002\u5982\u679c\u60a8\u5e0c\u671b\u5b66\u751f\u516c\u5f00\u3001\u534f\u4f5c\u5730\u5b8c\u6210\u4f5c\u4e1a\uff0c\u60a8\u53ef\u4ee5\u7528\u540c\u6837\u7684\u65b9\u6cd5\u5904\u7406\u4f5c\u4e1a\u3002</p> <p>\u5982\u679c\u60a8\u66f4\u559c\u6b22\u66f4\u79c1\u5bc6\u7684\u5f62\u5f0f\uff0c\u8bf7\u60a8\u7684\u5b66\u751f\u9010\u8bfe\u5c06\u8bfe\u7a0b fork \u5230\u4ed6\u4eec\u81ea\u5df1\u7684 GitHub \u79c1\u4eba\u4ed3\u5e93\uff0c\u5e76\u7ed9\u4e88\u60a8\u8bbf\u95ee\u6743\u9650\u3002\u7136\u540e\u4ed6\u4eec\u53ef\u4ee5\u79c1\u4e0b\u5b8c\u6210\u6d4b\u9a8c\u548c\u4f5c\u4e1a\u5e76\u901a\u8fc7\u60a8\u8bfe\u5802\u7684\u4ed3\u5e93\u4e0a\u7684 issue \u63d0\u4ea4\u7ed9\u60a8\u3002</p> <p>\u5728\u7f51\u7edc\u8bfe\u5802\u7684\u5f62\u5f0f\u4e0b\uff0c\u6709\u5f88\u591a\u65b9\u6cd5\u53ef\u4ee5\u8fd0\u4f5c\u3002\u8bf7\u544a\u8bc9\u6211\u4eec\u4ec0\u4e48\u6700\u9002\u5408\u60a8\uff01</p>"},{"location":"lessons/0-course-setup/for-teachers_chs/#_3","title":"\u8bf7\u7ed9\u6211\u4eec\u60a8\u7684\u610f\u89c1","text":"<p>\u6211\u4eec\u5e0c\u671b\u4f7f\u8fd9\u4e2a\u8bfe\u7a0b\u5bf9\u60a8\u548c\u60a8\u7684\u5b66\u751f\u66f4\u6709\u7528\u3002\u8bf7\u5728\u8ba8\u8bba\u7248\u5757\u4e2d\u7ed9\u6211\u4eec\u53cd\u9988\uff01</p>"},{"location":"lessons/0-course-setup/how-to-run/","title":"How to Run the Code","text":"<p>This curriculum contains a lot of executable examples and labs that you would want to run. In order to do this, you need the ability to execute Python code in Jupyter Notebooks provided as part of this curriculum. You have several options for running the code:</p>"},{"location":"lessons/0-course-setup/how-to-run/#run-locally-on-your-computer","title":"Run locally on your computer","text":"<p>To run the code locally on your computer, you would need to have some version of Python installed. I personally recommend installing miniconda - it is rather lightweight installation that supports <code>conda</code> package manager for different Python virtual environments.</p> <p>After you install miniconda, you need to clone the repository and create a virtual environment to be used for this course:</p> <pre><code>git clone http://github.com/microsoft/ai-for-beginners\ncd ai-for-beginners\nconda env create --name ai4beg --file .devcontainer/environment.yml\nconda activate ai4beg\n</code></pre>"},{"location":"lessons/0-course-setup/how-to-run/#using-visual-studio-code-with-python-extension","title":"Using Visual Studio Code with Python Extension","text":"<p>Probably the best way to use the curriculum is to open it in Visual Studio Code with Python Extension.</p> <p>Note: Once you clone and open the directory in VS Code, it will automatically suggest you to install Python extensions. You would also have to install miniconda as described above.</p> <p>Note: If VS Code suggests you to re-open the repository in container, you need to decline this to use local Python installation. </p>"},{"location":"lessons/0-course-setup/how-to-run/#using-jupyter-in-the-browser","title":"Using Jupyter in the Browser","text":"<p>You can also use Jupyter environment right from the browser on your own computer. Actually, both classical Jupyter and Jupyer Hub provide quite convenient development environment with auto-completion, code highlighting, etc.</p> <p>To start Jupyter locally, go to the directory of the course, and execute:</p> <pre><code>jupyter notebook\n</code></pre> <p>or</p> <pre><code>jupyterhub\n</code></pre> <p>You then can navigate to any of the <code>.ipynb</code> files, open them and start working.</p>"},{"location":"lessons/0-course-setup/how-to-run/#running-in-container","title":"Running in container","text":"<p>One alternative to Python installation would be to run the code in container. Since our repository contains special <code>.devcontainer</code> folder that instructs how to build a container for this repo, VS Code would offer you to re-open the code in container. This will require Docker installation, and also would be more complex, so we recommend this to more experienced users.</p>"},{"location":"lessons/0-course-setup/how-to-run/#running-in-the-cloud","title":"Running in the Cloud","text":"<p>If you do not want to install Python locally, and have access to some cloud resources - a good alternative would be to run the code in the cloud. There are several ways you can do this:</p> <ul> <li>Using GitHub Codespaces, which is a virtual environment created for you on GitHub, accessible through VS Code browser interface. If you have access to Codespaces, you can just click Code button in the repo, start a codespace, and get running in no time.</li> <li>Using Binder. Binder is a free computing resources provided in the cloud for people like you to test out some code on GitHub. There is a button at the front page to open the repository in Binder - this should quickly take you to the binder site, which will build underlying container and start Jupyter web interface for you seamlessly.</li> </ul> <p>Note: To prevent misuse, Binder has access to some web resources blocked. This may prevent some of the code working, which fetches models and/or datasets from public Internet. You may need to find some workarounds. Also, compute resources provided by Binder are pretty basic, so training will be slow, especially in later more complex lessons.</p>"},{"location":"lessons/0-course-setup/how-to-run/#running-in-the-cloud-with-gpu","title":"Running in the Cloud with GPU","text":"<p>Some of the later lessons in this curriculum would greatly benefit from GPU support, because otherwise training will be painfully slow. There are a few options you can follow, especially if you have access to the cloud either through Azure for Students, or through your institution:</p> <ul> <li>Create Data Science Virtual Machine and connect to it through Jupyter. You can then clone the repo right onto the machine, and start learning. NC-series VMs have GPU support.</li> </ul> <p>Note: Some subscriptions, including Azure for Students, do not provide GPU support out of the box. You may need to request additional GPU cores through technical support request.</p> <ul> <li>Create Azure Machine Learning Workspace and then use Notebook feature there. This video shows how to clone a repository into Azure ML notebook and start using it.</li> </ul> <p>You can also use Google Colab, which comes with some free GPU support, and upload Jupyter Notebooks there to execute them one-by-one.</p>"},{"location":"lessons/0-course-setup/how-to-run_chs/","title":"\u5982\u4f55\u8fd0\u884c\u4ee3\u7801","text":"<p>\u672c\u8bfe\u7a0b\u5305\u542b\u5927\u91cf\u53ef\u6267\u884c\u793a\u4f8b\u548c\u5b9e\u9a8c\uff0c\u60a8\u53ef\u80fd\u5e0c\u671b\u8fd0\u884c\u8fd9\u4e9b\u5185\u5bb9\u3002\u4e3a\u4e86\u505a\u5230\u8fd9\u4e00\u70b9\uff0c\u60a8\u9700\u8981\u80fd\u591f\u5728\u672c\u8bfe\u7a0b\u63d0\u4f9b\u7684 Jupyter \u7b14\u8bb0\u672c\u4e2d\u6267\u884c Python \u4ee3\u7801\u3002\u60a8\u6709\u51e0\u79cd\u8fd0\u884c\u4ee3\u7801\u7684\u9009\u62e9\uff1a</p>"},{"location":"lessons/0-course-setup/how-to-run_chs/#_2","title":"\u5728\u60a8\u81ea\u5df1\u7684\u8ba1\u7b97\u673a\u4e0a\u672c\u5730\u8fd0\u884c","text":"<p>\u8981\u5728\u672c\u5730\u8ba1\u7b97\u673a\u4e0a\u8fd0\u884c\u4ee3\u7801\uff0c\u60a8\u9700\u8981\u5b89\u88c5\u67d0\u4e2a\u7248\u672c\u7684 Python\u3002\u6211\u4e2a\u4eba\u63a8\u8350\u5b89\u88c5 miniconda - \u8fd9\u662f\u4e00\u79cd\u76f8\u5f53\u8f7b\u91cf\u7684\u5b89\u88c5\u5305\uff0c\u652f\u6301\u7528\u4e8e\u4e0d\u540c Python \u865a\u62df\u73af\u5883\u7684 <code>conda</code> \u5305\u7ba1\u7406\u5668\u3002</p> <p>\u5b89\u88c5 miniconda \u540e\uff0c\u60a8\u9700\u8981\u514b\u9686\u4ed3\u5e93\u5e76\u521b\u5efa\u7528\u4e8e\u672c\u8bfe\u7a0b\u7684\u865a\u62df\u73af\u5883\uff1a</p> <pre><code>git clone http://github.com/microsoft/ai-for-beginners\ncd ai-for-beginners\nconda env create --name ai4beg --file .devcontainer/environment.yml\nconda activate ai4beg\n</code></pre>"},{"location":"lessons/0-course-setup/how-to-run_chs/#python-visual-studio-code","title":"\u4f7f\u7528\u5e26 Python \u6269\u5c55\u7684 Visual Studio Code","text":"<p>\u4f7f\u7528\u672c\u8bfe\u7a0b\u7684\u6700\u4f73\u65b9\u5f0f\u53ef\u80fd\u662f\u901a\u8fc7 Visual Studio Code \u7ed3\u5408 Python \u6269\u5c55 \u6253\u5f00\u5b83\u3002</p> <p>\u6ce8\u610f: \u514b\u9686\u5e76\u5728 VS Code \u4e2d\u6253\u5f00\u76ee\u5f55\u540e\uff0c\u5b83\u5c06\u81ea\u52a8\u5efa\u8bae\u60a8\u5b89\u88c5 Python \u6269\u5c55\u3002\u60a8\u8fd8\u9700\u8981\u6309\u7167\u4e0a\u8ff0\u8bf4\u660e\u5b89\u88c5 miniconda\u3002</p> <p>\u6ce8\u610f: \u5982\u679c VS Code \u5efa\u8bae\u60a8\u5728\u5bb9\u5668\u4e2d\u91cd\u65b0\u6253\u5f00\u4ed3\u5e93\uff0c\u60a8\u9700\u8981\u62d2\u7edd\u4ee5\u4f7f\u7528\u672c\u5730 Python \u5b89\u88c5\u3002</p>"},{"location":"lessons/0-course-setup/how-to-run_chs/#jupyter","title":"\u4f7f\u7528\u6d4f\u89c8\u5668\u4e2d\u7684 Jupyter","text":"<p>\u60a8\u4e5f\u53ef\u4ee5\u76f4\u63a5\u5728\u6d4f\u89c8\u5668\u4e2d\u4f7f\u7528\u60a8\u81ea\u5df1\u7684\u8ba1\u7b97\u673a\u8fd0\u884c Jupyter \u73af\u5883\u3002\u5b9e\u9645\u4e0a\uff0c\u7ecf\u5178\u7684 Jupyter \u548c Jupyter Hub \u90fd\u63d0\u4f9b\u4e86\u76f8\u5f53\u65b9\u4fbf\u7684\u5f00\u53d1\u73af\u5883\uff0c\u5177\u6709\u81ea\u52a8\u5b8c\u6210\u3001\u4ee3\u7801\u9ad8\u4eae\u7b49\u529f\u80fd\u3002</p> <p>\u8981\u5728\u672c\u5730\u542f\u52a8 Jupyter\uff0c\u8bf7\u8f6c\u5230\u8bfe\u7a0b\u76ee\u5f55\u5e76\u6267\u884c\uff1a</p> <pre><code>jupyter notebook\n</code></pre> <p>\u6216</p> <pre><code>jupyterhub\n</code></pre> <p>\u7136\u540e\u60a8\u53ef\u4ee5\u5bfc\u822a\u5230\u4efb\u4f55 <code>.ipynb</code> \u6587\u4ef6\uff0c\u6253\u5f00\u5b83\u4eec\u5e76\u5f00\u59cb\u5de5\u4f5c\u3002</p>"},{"location":"lessons/0-course-setup/how-to-run_chs/#_3","title":"\u5728\u5bb9\u5668\u4e2d\u8fd0\u884c","text":"<p>Python \u5b89\u88c5\u7684\u4e00\u4e2a\u66ff\u4ee3\u65b9\u6848\u662f\u5728\u5bb9\u5668\u4e2d\u8fd0\u884c\u4ee3\u7801\u3002\u56e0\u4e3a\u6211\u4eec\u7684\u4ed3\u5e93\u5305\u542b\u4e00\u4e2a\u7279\u6b8a\u7684 <code>.devcontainer</code> \u6587\u4ef6\u5939\uff0c\u6307\u793a\u5982\u4f55\u4e3a\u8be5\u4ed3\u5e93\u6784\u5efa\u5bb9\u5668\uff0cVS Code \u5c06\u4e3a\u60a8\u63d0\u4f9b\u5728\u5bb9\u5668\u4e2d\u91cd\u65b0\u6253\u5f00\u4ee3\u7801\u7684\u9009\u9879\u3002\u8fd9\u9700\u8981 Docker \u5b89\u88c5\uff0c\u5e76\u4e14\u4f1a\u66f4\u590d\u6742\uff0c\u56e0\u6b64\u6211\u4eec\u5efa\u8bae\u66f4\u6709\u7ecf\u9a8c\u7684\u7528\u6237\u4f7f\u7528\u8fd9\u79cd\u65b9\u6cd5\u3002</p>"},{"location":"lessons/0-course-setup/how-to-run_chs/#_4","title":"\u5728\u4e91\u4e2d\u8fd0\u884c","text":"<p>\u5982\u679c\u60a8\u4e0d\u60f3\u5728\u672c\u5730\u5b89\u88c5 Python\uff0c\u5e76\u4e14\u53ef\u4ee5\u8bbf\u95ee\u4e00\u4e9b\u4e91\u8d44\u6e90 - \u4e00\u4e2a\u4e0d\u9519\u7684\u66ff\u4ee3\u65b9\u6848\u662f\u5728\u4e91\u4e2d\u8fd0\u884c\u4ee3\u7801\u3002\u60a8\u53ef\u4ee5\u901a\u8fc7\u4ee5\u4e0b\u51e0\u79cd\u65b9\u5f0f\u5b9e\u73b0\uff1a</p> <ul> <li>\u4f7f\u7528 GitHub Codespaces\uff0c\u8fd9\u662f\u4e00\u4e2a\u5728 GitHub \u4e0a\u4e3a\u60a8\u521b\u5efa\u7684\u865a\u62df\u73af\u5883\uff0c\u901a\u8fc7 VS Code \u6d4f\u89c8\u5668\u754c\u9762\u8bbf\u95ee\u3002\u5982\u679c\u60a8\u53ef\u4ee5\u8bbf\u95ee Codespaces\uff0c\u53ea\u9700\u70b9\u51fb\u4ed3\u5e93\u4e2d\u7684 Code \u6309\u94ae\uff0c\u542f\u52a8\u4e00\u4e2a\u4ee3\u7801\u7a7a\u95f4\uff0c\u4e0d\u4e45\u5c31\u53ef\u4ee5\u5f00\u59cb\u8fd0\u884c\u3002</li> <li>\u4f7f\u7528 Binder\u3002Binder \u662f\u5728\u4e91\u4e2d\u4e3a\u4eba\u4eec\u63d0\u4f9b\u7684\u514d\u8d39\u8ba1\u7b97\u8d44\u6e90\uff0c\u7528\u4e8e\u6d4b\u8bd5 GitHub \u4e0a\u7684\u4e00\u4e9b\u4ee3\u7801\u3002\u5728\u4e3b\u9875\u4e0a\u6709\u4e00\u4e2a\u6309\u94ae\u53ef\u4ee5\u5728 Binder \u4e2d\u6253\u5f00\u4ed3\u5e93 - \u8fd9\u4f1a\u8fc5\u901f\u5c06\u60a8\u5e26\u5230 Binder \u7f51\u7ad9\uff0c\u5b83\u4f1a\u4e3a\u60a8\u65e0\u7f1d\u6784\u5efa\u5e95\u5c42\u5bb9\u5668\u5e76\u542f\u52a8 Jupyter \u7f51\u9875\u754c\u9762\u3002</li> </ul> <p>\u6ce8\u610f: \u4e3a\u9632\u6b62\u6ee5\u7528\uff0cBinder \u5df2\u5c4f\u853d\u4e86\u67d0\u4e9b\u7f51\u9875\u8d44\u6e90\u7684\u8bbf\u95ee\u3002\u8fd9\u53ef\u80fd\u4f1a\u963b\u6b62\u4e00\u4e9b\u4ee3\u7801\u8fd0\u884c\uff0c\u8fd9\u4e9b\u4ee3\u7801\u4ece\u516c\u5171\u4e92\u8054\u7f51\u83b7\u53d6\u6a21\u578b\u548c/\u6216\u6570\u636e\u96c6\u3002\u60a8\u53ef\u80fd\u9700\u8981\u627e\u5230\u4e00\u4e9b\u89e3\u51b3\u65b9\u6cd5\u3002\u6b64\u5916\uff0c\u7531\u4e8e Binder \u63d0\u4f9b\u7684\u8ba1\u7b97\u8d44\u6e90\u76f8\u5f53\u57fa\u7840\uff0c\u56e0\u6b64\u5728\u540e\u671f\u66f4\u590d\u6742\u7684\u8bfe\u7a0b\u4e2d\uff0c\u8bad\u7ec3\u901f\u5ea6\u4f1a\u5f88\u6162\u3002</p>"},{"location":"lessons/0-course-setup/how-to-run_chs/#gpu","title":"\u4f7f\u7528 GPU \u5728\u4e91\u4e2d\u8fd0\u884c","text":"<p>\u672c\u8bfe\u7a0b\u4e2d\u7684\u4e00\u4e9b\u540e\u7eed\u5185\u5bb9\u5c06\u5927\u5927\u53d7\u76ca\u4e8e GPU \u652f\u6301\uff0c\u5426\u5219\u8bad\u7ec3\u5c06\u975e\u5e38\u6162\u3002\u5982\u679c\u60a8\u901a\u8fc7 Azure for Students \u6216\u901a\u8fc7\u60a8\u7684\u673a\u6784\u8bbf\u95ee\u4e91\uff0c\u6709\u51e0\u79cd\u9009\u62e9\uff1a</p> <ul> <li>\u521b\u5efa Data Science Virtual Machine \u5e76\u901a\u8fc7 Jupyter \u8fde\u63a5\u5230\u5b83\u3002\u7136\u540e\u60a8\u53ef\u4ee5\u5728\u8be5\u673a\u5668\u4e0a\u514b\u9686\u4ed3\u5e93\u5e76\u5f00\u59cb\u5b66\u4e60\u3002NC\u7cfb\u5217\u865a\u62df\u673a\u652f\u6301 GPU\u3002</li> </ul> <p>\u6ce8\u610f: \u5305\u62ec Azure for Students \u5728\u5185\u7684\u4e00\u4e9b\u8ba2\u9605\u4e0d\u9ed8\u8ba4\u63d0\u4f9b GPU \u652f\u6301\u3002\u60a8\u53ef\u80fd\u9700\u8981\u901a\u8fc7\u6280\u672f\u652f\u6301\u8bf7\u6c42\u989d\u5916\u7684 GPU \u5185\u6838\u3002</p> <ul> <li>\u521b\u5efa Azure Machine Learning Workspace \u5e76\u4f7f\u7528\u5176\u4e2d\u7684 Notebook \u529f\u80fd\u3002 \u8fd9\u6bb5\u89c6\u9891 \u6f14\u793a\u4e86\u5982\u4f55\u5c06\u5b58\u50a8\u5e93\u514b\u9686\u5230 Azure ML \u7b14\u8bb0\u672c\u5e76\u5f00\u59cb\u4f7f\u7528\u5b83\u3002</li> </ul> <p>\u60a8\u4e5f\u53ef\u4ee5\u4f7f\u7528 Google Colab\uff0c\u5b83\u63d0\u4f9b\u4e00\u4e9b\u514d\u8d39\u7684 GPU \u652f\u6301\uff0c\u5e76\u4e0a\u4f20 Jupyter \u7b14\u8bb0\u672c\u5728\u5176\u4e2d\u9010\u4e00\u6267\u884c\u3002</p>"},{"location":"lessons/0-course-setup/setup/","title":"Getting Started with this Curricula","text":""},{"location":"lessons/0-course-setup/setup/#are-you-a-student","title":"Are you a student?","text":"<p>Get started with the following resources:</p> <ul> <li>Student Hub page On this page, you will find beginner resources, Student packs, and even ways to get a free cert voucher. This is one page you want to bookmark and check from time to time as we switch out content at least monthly.</li> <li>Microsoft Student Learn ambassadors Join a global community of student ambassadors, this could be your way into Microsoft.</li> </ul> <p>Students, there are a couple of ways to use the curriculum. First of all, you can just read the text and look through the code directly on GitHub. If you want to run the code in any of the notebooks - read our instructions, and find more advice on how to do it in this blog post.</p> <p>Note: Instructions on how to run the code in this curriculum</p>"},{"location":"lessons/0-course-setup/setup/#self-study","title":"Self Study","text":"<p>However, if you would like to take the course as a self-study project, we suggest that you fork the entire repo to your own GitHub account and complete the exercises on your own or with a group:</p> <ul> <li>Start with a pre-lecture quiz.</li> <li>Read the intro text for the lecture.</li> <li>If the lecture has additional notebooks, go through them, reading and executing the code. If both TensorFlow and PyTorch notebooks are provided, you can focus on one of them - choose your favorite framework.</li> <li>Notebooks often contain some of the challenges that require you to tweak the code a little bit to experiment.</li> <li>Take the post-lecture quiz.</li> <li>If there is a lab attached to the module - complete the assignment.</li> <li>Visit the Discussion board to \"learn out loud\".</li> </ul> <p>For further study, we recommend following these Microsoft Learn modules and learning paths.</p> <p>Teachers, we have included some suggestions on how to use this curriculum.</p>"},{"location":"lessons/0-course-setup/setup/#pedagogy","title":"Pedagogy","text":"<p>We have chosen two pedagogical tenets while building this curriculum: ensuring that it is hands-on project-based and that it includes frequent quizzes.</p> <p>By ensuring that the content aligns with projects, the process is made more engaging for students and retention of concepts will be augmented. In addition, a low-stakes quiz before a class sets the intention of the student towards learning a topic, while a second quiz after class ensures further retention. This curriculum was designed to be flexible and fun and can be taken in whole or in part. The projects start small and become increasingly complex by the end of the 12-week cycle.</p> <p>A note about quizzes: All quizzes are contained in this app, for 50 total quizzes of three questions each. They are linked from within the lessons but the quiz app can be run locally; follow the instructions in the <code>etc/quiz-app</code> folder.</p>"},{"location":"lessons/0-course-setup/setup/#offline-access","title":"Offline access","text":"<p>You can run this documentation offline by using Docsify. Fork this repo, install Docsify on your local machine, and then in the <code>etc/docsify</code> folder of this repo, type <code>docsify serve</code>. The website will be served on port 3000 on your localhost: <code>localhost:3000</code>. A pdf of the curriculum is available at this link.</p>"},{"location":"lessons/0-course-setup/setup_chs/","title":"\u5f00\u59cb\u4f7f\u7528\u8fd9\u4e2a\u8bfe\u7a0b","text":""},{"location":"lessons/0-course-setup/setup_chs/#_2","title":"\u4f60\u662f\u5b66\u751f\u5417\uff1f","text":"<p>\u901a\u8fc7\u4ee5\u4e0b\u8d44\u6e90\u5f00\u59cb\u5b66\u4e60\uff1a</p> <ul> <li>\u5b66\u751f\u4e2d\u5fc3\u9875\u9762 \u5728\u8fd9\u4e2a\u9875\u9762\uff0c\u4f60\u4f1a\u627e\u5230\u5165\u95e8\u8d44\u6e90\u3001\u5b66\u751f\u5305\uff0c\u751a\u81f3\u662f\u83b7\u5f97\u514d\u8d39\u8ba4\u8bc1\u51ed\u8bc1\u7684\u65b9\u6cd5\u3002\u8fd9\u4e2a\u9875\u9762\u503c\u5f97\u4f60\u6536\u85cf\uff0c\u5e76\u65f6\u4e0d\u65f6\u67e5\u770b\uff0c\u56e0\u4e3a\u6211\u4eec\u81f3\u5c11\u6bcf\u6708\u4f1a\u66f4\u6362\u5185\u5bb9\u3002</li> <li>\u5fae\u8f6f\u5b66\u751f\u5b66\u4e60\u5927\u4f7f \u52a0\u5165\u4e00\u4e2a\u5168\u7403\u5b66\u751f\u5927\u4f7f\u793e\u533a\uff0c\u8fd9\u53ef\u80fd\u662f\u4f60\u8fdb\u5165\u5fae\u8f6f\u7684\u9014\u5f84\u3002</li> </ul> <p>\u5b66\u751f\u4eec\uff0c\u6709\u51e0\u79cd\u65b9\u5f0f\u53ef\u4ee5\u4f7f\u7528\u8fd9\u4e2a\u8bfe\u7a0b\u5185\u5bb9\u3002\u9996\u5148\uff0c\u4f60\u53ef\u4ee5\u76f4\u63a5\u5728 GitHub \u4e0a\u9605\u8bfb\u6587\u672c\u5e76\u67e5\u770b\u4ee3\u7801\u3002\u5982\u679c\u4f60\u60f3\u5728\u4efb\u4f55\u7b14\u8bb0\u672c\u4e2d\u8fd0\u884c\u4ee3\u7801 - \u9605\u8bfb\u6211\u4eec\u7684\u8bf4\u660e\uff0c\u5e76\u5728\u8fd9\u7bc7\u535a\u5ba2\u6587\u7ae0\u4e2d\u627e\u5230\u66f4\u591a\u5efa\u8bae\u3002</p> <p>\u6ce8\u610f\uff1a\u5728\u8fd9\u4e2a\u8bfe\u7a0b\u4e2d\u8fd0\u884c\u4ee3\u7801\u7684\u8bf4\u660e</p>"},{"location":"lessons/0-course-setup/setup_chs/#_3","title":"\u81ea\u5b66","text":"<p>\u7136\u800c\uff0c\u5982\u679c\u4f60\u60f3\u5c06\u8bfe\u7a0b\u4f5c\u4e3a\u81ea\u5b66\u9879\u76ee\uff0c\u6211\u4eec\u5efa\u8bae\u4f60\u5c06\u6574\u4e2a\u4ed3\u5e93\u590d\u5236\u5230\u4f60\u81ea\u5df1\u7684 GitHub \u8d26\u6237\uff0c\u5e76\u81ea\u884c\u6216\u4e0e\u5c0f\u7ec4\u4e00\u8d77\u5b8c\u6210\u7ec3\u4e60\uff1a</p> <ul> <li>\u4ece\u8bfe\u524d\u5c0f\u6d4b\u9a8c\u5f00\u59cb\u3002</li> <li>\u9605\u8bfb\u8bfe\u7a0b\u7684\u4ecb\u7ecd\u6587\u672c\u3002</li> <li>\u5982\u679c\u8bfe\u7a0b\u6709\u5176\u4ed6\u7b14\u8bb0\u672c\uff0c\u9605\u8bfb\u5e76\u6267\u884c\u5176\u4e2d\u7684\u4ee3\u7801\u3002\u5982\u679c\u540c\u65f6\u63d0\u4f9b\u4e86 TensorFlow \u548c PyTorch \u7b14\u8bb0\u672c\uff0c\u4f60\u53ef\u4ee5\u4e13\u6ce8\u4e8e\u5176\u4e2d\u4e4b\u4e00\u2014\u2014\u9009\u62e9\u4f60\u559c\u6b22\u7684\u6846\u67b6\u3002</li> <li>\u7b14\u8bb0\u672c\u4e2d\u901a\u5e38\u5305\u542b\u4e00\u4e9b\u9700\u8981\u4f60\u7a0d\u5fae\u4fee\u6539\u4ee3\u7801\u4ee5\u8fdb\u884c\u5b9e\u9a8c\u7684\u6311\u6218\u3002</li> <li>\u5b8c\u6210\u8bfe\u540e\u7684\u5c0f\u6d4b\u9a8c\u3002</li> <li>\u5982\u679c\u6a21\u5757\u9644\u5e26\u5b9e\u9a8c\u5ba4\u4efb\u52a1\uff0c\u8bf7\u5b8c\u6210\u4f5c\u4e1a\u3002</li> <li>\u8bbf\u95ee\u8ba8\u8bba\u677f\u8fdb\u884c\u201c\u5916\u5411\u5b66\u4e60\u201d\u3002</li> </ul> <p>\u8fdb\u4e00\u6b65\u5b66\u4e60\uff0c\u6211\u4eec\u63a8\u8350\u8ddf\u968f\u8fd9\u4e9b Microsoft Learn \u6a21\u5757\u548c\u5b66\u4e60\u8def\u5f84\u3002</p> <p>\u6559\u5e08\u4eec\uff0c\u6211\u4eec\u5df2\u7ecf\u5305\u542b\u4e86\u4e00\u4e9b\u5efa\u8bae\u5173\u4e8e\u5982\u4f55\u4f7f\u7528\u8fd9\u4e2a\u8bfe\u7a0b\u3002</p>"},{"location":"lessons/0-course-setup/setup_chs/#_4","title":"\u6559\u5b66\u6cd5","text":"<p>\u5728\u6784\u5efa\u8fd9\u4e2a\u8bfe\u7a0b\u65f6\uff0c\u6211\u4eec\u9009\u62e9\u4e86\u4e24\u4e2a\u6559\u5b66\u539f\u5219\uff1a\u786e\u4fdd\u5b83\u662f\u5b9e\u9645\u64cd\u4f5c\u7684\u57fa\u4e8e\u9879\u76ee\u7684\uff0c\u5e76\u4e14\u5305\u542b\u9891\u7e41\u7684\u5c0f\u6d4b\u9a8c\u3002</p> <p>\u901a\u8fc7\u786e\u4fdd\u5185\u5bb9\u4e0e\u9879\u76ee\u5bf9\u9f50\uff0c\u53ef\u4ee5\u4f7f\u5b66\u751f\u7684\u5b66\u4e60\u8fc7\u7a0b\u66f4\u5177\u5438\u5f15\u529b\uff0c\u5e76\u589e\u5f3a\u6982\u5ff5\u7684\u4fdd\u7559\u3002\u6b64\u5916\uff0c\u5728\u8bfe\u5802\u524d\u8fdb\u884c\u4f4e\u96be\u5ea6\u7684\u5c0f\u6d4b\u9a8c\u53ef\u4ee5\u5f15\u5bfc\u5b66\u751f\u5b66\u4e60\u67d0\u4e00\u8bdd\u9898\uff0c\u800c\u8bfe\u540e\u7684\u7b2c\u4e8c\u4e2a\u5c0f\u6d4b\u9a8c\u53ef\u4ee5\u8fdb\u4e00\u6b65\u786e\u4fdd\u77e5\u8bc6\u7684\u4fdd\u7559\u3002\u8fd9\u4e2a\u8bfe\u7a0b\u8bbe\u8ba1\u7075\u6d3b\u6709\u8da3\uff0c\u53ef\u4ee5\u5168\u90e8\u6216\u90e8\u5206\u8fdb\u884c\u3002\u9879\u76ee\u4ece\u5c0f\u578b\u5f00\u59cb\uff0c\u523012\u5468\u5468\u671f\u7ed3\u675f\u65f6\u53d8\u5f97\u8d8a\u6765\u8d8a\u590d\u6742\u3002</p> <p>\u5173\u4e8e\u5c0f\u6d4b\u9a8c\u7684\u8bf4\u660e\uff1a\u6240\u6709\u7684\u5c0f\u6d4b\u9a8c\u90fd\u5305\u542b\u5728\u8fd9\u4e2a\u5e94\u7528\u4e2d\uff0c\u603b\u517150\u4e2a\u5c0f\u6d4b\u9a8c\uff0c\u6bcf\u4e2a\u5c0f\u6d4b\u9a8c\u5305\u542b\u4e09\u4e2a\u95ee\u9898\u3002\u5b83\u4eec\u5728\u8bfe\u7a0b\u4e2d\u88ab\u94fe\u63a5\uff0c\u4f46\u662f\u5c0f\u6d4b\u9a8c\u5e94\u7528\u7a0b\u5e8f\u53ef\u4ee5\u5728\u672c\u5730\u8fd0\u884c; \u8bf7\u6309\u7167 <code>etc/quiz-app</code> \u6587\u4ef6\u5939\u4e2d\u7684\u8bf4\u660e\u8fdb\u884c\u64cd\u4f5c\u3002</p>"},{"location":"lessons/0-course-setup/setup_chs/#_5","title":"\u79bb\u7ebf\u8bbf\u95ee","text":"<p>\u4f60\u53ef\u4ee5\u4f7f\u7528 Docsify \u79bb\u7ebf\u8fd0\u884c\u6b64\u6587\u6863\u3002\u590d\u5236\u6b64\u4ed3\u5e93\uff0c\u5b89\u88c5 Docsify \u5728\u672c\u5730\u673a\u5668\u4e0a\uff0c\u7136\u540e\u5728\u6b64\u4ed3\u5e93\u7684 <code>etc/docsify</code> \u6587\u4ef6\u5939\u4e2d\uff0c\u8f93\u5165 <code>docsify serve</code>\u3002\u7f51\u7ad9\u5c06\u5728\u672c\u5730\u4e3b\u673a\u4e0a\u7684\u7aef\u53e3 3000 \u63d0\u4f9b\u670d\u52a1\uff1a<code>localhost:3000</code>\u3002\u8bfe\u7a0b\u7684 PDF \u7248\u672c\u53ef\u4ee5\u901a\u8fc7\u6b64\u94fe\u63a5\u83b7\u5f97\u3002</p>"},{"location":"lessons/1-Intro/","title":"Introduction to AI","text":"<p>Sketchnote by Tomomi Imura</p>"},{"location":"lessons/1-Intro/#pre-lecture-quiz","title":"Pre-lecture quiz","text":"<p>Artificial Intelligence is an exciting scientific discipline that studies how we can make computers exhibit intelligent behavior, e.g. do those things that human beings are good at doing.</p> <p>Originally, computers were invented by Charles Babbage to operate on numbers following a well-defined procedure - an algorithm. Modern computers, even though significantly more advanced than the original model proposed in the 19th century, still follow the same idea of controlled computations. Thus it is possible to program a computer to do something if we know the exact sequence of steps that we need to do in order to achieve the goal.</p> <p></p> <p>Photo by Vickie Soshnikova</p> <p>\u2705 Defining the age of a person from his or her photograph is a task that cannot be explicitly programmed, because we do not know how we come up with a number inside our head when we do it.</p> <p>There are some tasks, however, that we do not explicitly know how to solve. Consider determining the age of a person from his/her photograph. We somehow learn to do it, because we have seen many examples of people of different age, but we cannot explicitly explain how we do it, nor can we program the computer to do it. This is exactly the kind of task that are of interest to Artificial Intelligence (AI for short).</p> <p>\u2705 Think of some tasks that you could offload to a computer that would benefit from AI. Consider the fields of finance, medicine, and the arts - how are these fields benefiting today from AI?</p>"},{"location":"lessons/1-Intro/#weak-ai-vs-strong-ai","title":"Weak AI vs. Strong AI","text":"Weak AI Strong AI Weak AI refers to AI systems that are designed and trained for a specific task or a narrow set of tasks. Strong AI, or Artificial General Intelligence (AGI), refers to AI systems with human-level intelligence and understanding. These AI systems are not generally intelligent; they excel in performing a predefined task but lack true understanding or consciousness. These AI systems have the ability to perform any intellectual task that a human being can do, adapt to different domains, and possess a form of consciousness or self-awareness. Examples of weak AI include virtual assistants like Siri or Alexa, recommendation algorithms used by streaming services, and chatbots that are designed for specific customer service tasks. Achieving Strong AI is a long-term goal of AI research and would require the development of AI systems that can reason, learn, understand, and adapt across a wide range of tasks and contexts. Weak AI is highly specialized and does not possess human-like cognitive abilities or general problem-solving capabilities beyond its narrow domain. Strong AI is currently a theoretical concept, and no AI system has reached this level of general intelligence <p>for more infomation refer Artificial General Intelligence (AGI).</p>"},{"location":"lessons/1-Intro/#the-definition-of-intelligence-and-the-turing-test","title":"The Definition of Intelligence and the Turing Test","text":"<p>One of the problems when dealing with the term Intelligence is that there is no clear definition of this term. One can argue that intelligence is connected to abstract thinking, or to self-awareness, but we cannot properly define it.</p> <p></p> <p>Photo by Amber Kipp from Unsplash</p> <p>To see the ambiguity of a term intelligence, try answering a question: \"Is a cat intelligent?\". Different people tend to give different answers to this question, as there is no universally accepted test to prove the assertion is true or not. And if you think there is - try running your cat through an IQ test...</p> <p>\u2705 Think for a minute about how you define intelligence. Is a crow who can solve a maze and get at some food intelligent? Is a child intelligent?</p> <p>When speaking about AGI we need to have some way to tell if we have created a truly intelligent system. Alan Turing proposed a way called a Turing Test, which also acts like a definition of intelligence. The test compares a given system to something inherently intelligent - a real human being, and because any automatic comparison can be bypassed by a computer program, we use a human interrogator. So, if a human being is unable to distinguish between a real person and a computer system in text-based dialogue - the system is considered intelligent.</p> <p>A chat-bot called Eugene Goostman, developed in St.Petersburg, came close to passing the Turing test in 2014 by using a clever personality trick. It announced up front that it was a 13-year old Ukrainian boy, which would explain the lack of knowledge and some discrepancies in the text. The bot convinced 30% of the judges that it was human after a 5 minute dialogue, a metric that Turing believed a machine would be able to pass by 2000. However, one should understand that this does not indicate that we have created an intelligent system, or that a computer system has fooled the human interrogator - the system didn't fool the humans, but rather the bot creators did!</p> <p>\u2705 Have you ever been fooled by a chat bot into thinking that you are speaking to a human? How did it convince you?</p>"},{"location":"lessons/1-Intro/#different-approaches-to-ai","title":"Different Approaches to AI","text":"<p>If we want a computer to behave like a human, we need somehow to model inside a computer our way of thinking. Consequently, we need to try to understand what makes a human being intelligent.</p> <p>To be able to program intelligence into a machine, we need to understand how our own processes of making decisions work. If you do a little self-introspection, you will realize that there are some processes that happen subconsciously \u2013 eg. we can distinguish a cat from a dog without thinking about it - while some others involve reasoning.</p> <p>There are two possible approaches to this problem:</p> Top-down Approach (Symbolic Reasoning) Bottom-up Approach (Neural Networks) A top-down approach models the way a person reasons to solve a problem. It involves extracting knowledge from a human being, and representing it in a computer-readable form. We also need to develop a way to model reasoning inside a computer. A bottom-up approach models the structure of a human brain, consisting of a huge number of simple units called neurons. Each neuron acts like a weighted average of its inputs, and we can train a network of neurons to solve useful problems by providing training data. <p>There are also some other possible approaches to intelligence:</p> <ul> <li> <p>An Emergent, Synergetic or multi-agent approach are based on the fact that complex intelligent behaviour can be obtained by an interaction of a large number of simple agents. According to evolutionary cybernetics, intelligence can emerge from more simple, reactive behaviour in the process of metasystem transition.</p> </li> <li> <p>An Evolutionary approach, or genetic algorithm is an optimization process based on the principles of evolution.</p> </li> </ul> <p>We will consider those approaches later in the course, but right now we will focus on two main directions: top-down and bottom-up.</p>"},{"location":"lessons/1-Intro/#the-top-down-approach","title":"The Top-Down Approach","text":"<p>In a top-down approach, we try to model our reasoning.  Because we can follow our thoughts when we reason, we can try to formalize this process and program it inside the computer. This is called symbolic reasoning.</p> <p>People tend to have some rules in their head that guide their decision making processes. For example, when a doctor is diagnosing a patient, he or she may realize that a person has a fever, and thus there might be some inflammation going on inside the body. By applying a large set of rules to a specific problem a doctor may be able to come up with the final diagnosis.</p> <p>This approach relies heavily on knowledge representation and reasoning. Extracting knowledge from a human expert might be the most difficult part, because a doctor in many cases would not know exactly why he or she is coming up with a particular diagnosis. Sometimes the solution just comes up in his or her head without explicit thinking. Some tasks, such as determining the age of a person from a photograph, cannot be at all reduced to manipulating knowledge.</p>"},{"location":"lessons/1-Intro/#bottom-up-approach","title":"Bottom-Up Approach","text":"<p>Alternately, we can try to model the simplest elements inside our brain \u2013 a neuron. We can construct a so-called artificial neural network inside a computer, and then try to teach it to solve problems by giving it examples. This process is similar to how a newborn child learns about his or her surroundings by making observations.</p> <p>\u2705 Do a little research on how babies learn. What are the basic elements of a baby's brain?</p> What about ML? Part of Artificial Intelligence that is based on computer learning to solve a problem based on some data is called Machine Learning. We will not consider classical machine learning in this course - we refer you to a separate Machine Learning for Beginners curriculum."},{"location":"lessons/1-Intro/#a-brief-history-of-ai","title":"A Brief History of AI","text":"<p>Artificial Intelligence was started as a field in the middle of the twentieth century. Initially, symbolic reasoning was a prevalent approach, and it led to a number of important successes, such as expert systems \u2013 computer programs that were able to act as an expert in some limited problem domains. However, it soon became clear that such approach does not scale well. Extracting the knowledge from an expert, representing it in a computer, and keeping that knowledgebase accurate turns out to be a very complex task, and too expensive to be practical in many cases. This led to so-called AI Winter in the 1970s.</p> <p></p> <p>Image by Dmitry Soshnikov</p> <p>As time passed, computing resources became cheaper, and more data has become available, so neural network approaches started demonstrating great performance in competing with human beings in many areas, such as computer vision or speech understanding. In the last decade, the term Artificial Intelligence has been mostly used as a synonym for Neural Networks, because most of the AI successes that we hear about are based on them.</p> <p>We can observe how the approaches changed, for example, in creating a chess playing computer program:</p> <ul> <li>Early chess programs were based on search \u2013 a program explicitly tried to estimate possible moves of an opponent for a given number of next moves, and selected an optimal move based on the optimal position that can be achieved in a few moves. It led to the development of the so-called alpha-beta pruning search algorithm.</li> <li>Search strategies work well toward the end of the game, where the search space is limited by a small number of possible moves. However, at the beginning of the game, the search space is huge, and the algorithm can be improved by learning from existing matches between human players. Subsequent experiments employed so-called case-based reasoning, where the program looked for cases in the knowledge base very similar to the current position in the game.</li> <li>Modern programs that win over human players are based on neural networks and reinforcement learning, where the programs learn to play solely by playing a long time against themselves and learning from their own mistakes \u2013 much like human beings do when learning to play chess. However, a computer program can play many more games in much less time, and thus can learn much faster.</li> </ul> <p>\u2705 Do a little research on other games that have been played by AI.</p> <p>Similarly, we can see how the approach towards creating \u201ctalking programs\u201d (that might pass the Turing test) changed:</p> <ul> <li>Early programs of this kind such as Eliza, were based on very simple grammatical rules and the re-formulation of the input sentence into a question.</li> <li>Modern assistants, such as Cortana, Siri or Google Assistant are all hybrid systems that use Neural networks to convert speech into text and recognize our intent, and then employ some reasoning or explicit algorithms to perform required actions.</li> <li>In the future, we may expect a complete neural-based model to handle dialogue by itself. The recent GPT and Turing-NLG family of neural networks show great success in this.</li> </ul> <p></p> <p>Image by Dmitry Soshnikov, photo by Marina Abrosimova, Unsplash</p>"},{"location":"lessons/1-Intro/#recent-ai-research","title":"Recent AI Research","text":"<p>The huge recent growth in neural network research started around 2010, when large public datasets started to become available. A huge collection of images called ImageNet, which contains around 14 million annotated images, gave birth to the ImageNet Large Scale Visual Recognition Challenge.</p> <p></p> <p>Image by Dmitry Soshnikov</p> <p>In 2012, Convolutional Neural Networks were first used in image classification, which led to a significant drop in classification errors (from almost 30% to 16.4%). In 2015, ResNet architecture from Microsoft Research achieved human-level accuracy.</p> <p>Since then, Neural Networks demonstrated very successful behaviour in many tasks:</p> Year Human Parity achieved 2015 Image Classification 2016 Conversational Speech Recognition 2018 Automatic Machine Translation (Chinese-to-English) 2020 Image Captioning <p>Over the past few years we have witnessed huge successes with large language models, such as BERT and GPT-3. This happened mostly due to the fact that there is a lot of general text data available that allows us to train models to capture the structure and meaning of texts, pre-train them on general text collections, and then specialize those models for more specific tasks. We will learn more about Natural Language Processing later in this course.</p>"},{"location":"lessons/1-Intro/#challenge","title":"\ud83d\ude80 Challenge","text":"<p>Do a tour of the internet to determine where, in your opinion, AI is most effectively used. Is it in a Mapping app, or some speech-to-text service or a video game? Research how the system was built.</p>"},{"location":"lessons/1-Intro/#post-lecture-quiz","title":"Post-lecture quiz","text":""},{"location":"lessons/1-Intro/#review-self-study","title":"Review &amp; Self Study","text":"<p>Review the history of AI and ML by reading through this lesson. Take an element from the sketchnote at the top of that lesson or this one and research it in more depth to understand the cultural context informing its evolution.</p> <p>Assignment: Game Jam</p>"},{"location":"lessons/1-Intro/README_chs/","title":"\u4eba\u5de5\u667a\u80fd\u7b80\u4ecb","text":"<p>\u6d82\u9e26\u7b14\u8bb0\u7531 Tomomi Imura \u63d0\u4f9b</p>"},{"location":"lessons/1-Intro/README_chs/#_2","title":"\u8bfe\u524d\u6d4b\u9a8c","text":"<p>\u4eba\u5de5\u667a\u80fd \u662f\u4e00\u95e8\u4ee4\u4eba\u5174\u594b\u7684\u79d1\u5b66\u5b66\u79d1\uff0c\u7814\u7a76\u5982\u4f55\u4f7f\u8ba1\u7b97\u673a\u8868\u73b0\u51fa\u667a\u80fd\u884c\u4e3a\uff0c\u4f8b\u5982\u6267\u884c\u4eba\u7c7b\u64c5\u957f\u7684\u4efb\u52a1\u3002</p> <p>\u6700\u521d\uff0c\u8ba1\u7b97\u673a\u7531 \u67e5\u5c14\u65af\u00b7\u5df4\u8d1d\u5947 \u53d1\u660e\uff0c\u7528\u4e8e\u6309\u7167\u9884\u5b9a\u7684\u6b65\u9aa4\u2014\u2014\u7b97\u6cd5\uff0c\u5bf9\u6570\u5b57\u8fdb\u884c\u64cd\u4f5c\u3002\u73b0\u4ee3\u8ba1\u7b97\u673a\u867d\u7136\u6bd419\u4e16\u7eaa\u63d0\u51fa\u7684\u539f\u578b\u673a\u66f4\u4e3a\u5148\u8fdb\uff0c\u4f46\u4ecd\u9075\u5faa\u76f8\u540c\u7684\u53d7\u63a7\u8ba1\u7b97\u601d\u60f3\u3002\u56e0\u6b64\uff0c\u5982\u679c\u6211\u4eec\u77e5\u9053\u8fbe\u5230\u76ee\u6807\u7684\u786e\u5207\u6b65\u9aa4\uff0c\u5c31\u53ef\u4ee5\u7f16\u7a0b\u4f7f\u8ba1\u7b97\u673a\u6267\u884c\u67d0\u4e2a\u4efb\u52a1\u3002</p> <p></p> <p>\u7167\u7247\u7531 Vickie Soshnikova \u63d0\u4f9b</p> <p>\u2705 \u4ece\u7167\u7247\u4e2d\u8bc6\u522b\u4eba\u7684\u5e74\u9f84\u662f\u4e00\u9879\u65e0\u6cd5\u660e\u786e\u7f16\u7a0b\u7684\u4efb\u52a1\uff0c\u56e0\u4e3a\u6211\u4eec\u4e0d\u77e5\u9053\u6211\u4eec\u5728\u8111\u6d77\u4e2d\u5f97\u51fa\u6570\u5b57\u7684\u5177\u4f53\u8fc7\u7a0b\u3002</p> <p>\u7136\u800c\uff0c\u6709\u4e9b\u4efb\u52a1\u662f\u6211\u4eec\u65e0\u6cd5\u660e\u786e\u89e3\u51b3\u7684\u3002\u8003\u8651\u4e00\u4e0b\u5982\u4f55\u4ece\u4e00\u4e2a\u4eba\u7684\u7167\u7247\u4e2d\u786e\u5b9a\u4ed6\u7684\u5e74\u9f84\u3002\u6211\u4eec\u901a\u8fc7\u89c2\u5bdf\u4e0d\u540c\u5e74\u9f84\u7684\u4eba\u7684\u5f88\u591a\u5b9e\u4f8b\u5b66\u4f1a\u8fd9\u4e00\u6280\u80fd\uff0c\u4f46\u6211\u4eec\u65e0\u6cd5\u660e\u786e\u89e3\u91ca\u662f\u5982\u4f55\u505a\u5230\u7684\uff0c\u66f4\u65e0\u6cd5\u7f16\u7a0b\u5b9e\u73b0\u3002\u8fd9\u6b63\u662f \u4eba\u5de5\u667a\u80fd (\u7b80\u5199\u4e3aAI) \u611f\u5174\u8da3\u7684\u4efb\u52a1\u3002</p> <p>\u2705 \u8bf7\u60f3\u60f3\u6709\u54ea\u4e9b\u4efb\u52a1\u53ef\u4ee5\u901a\u8fc7AI\u4ea4\u7ed9\u8ba1\u7b97\u673a\u5b8c\u6210\u3002\u8003\u8651\u91d1\u878d\u3001\u533b\u7597\u548c\u827a\u672f\u9886\u57df\u2014\u2014\u8fd9\u4e9b\u9886\u57df\u4eca\u5929\u5982\u4f55\u4eceAI\u4e2d\u53d7\u76ca\uff1f</p>"},{"location":"lessons/1-Intro/README_chs/#_3","title":"\u5f31\u4eba\u5de5\u667a\u80fd\u4e0e\u5f3a\u4eba\u5de5\u667a\u80fd","text":"\u5f31\u4eba\u5de5\u667a\u80fd \u5f3a\u4eba\u5de5\u667a\u80fd \u5f31\u4eba\u5de5\u667a\u80fd\u662f\u6307\u4e3a\u7279\u5b9a\u4efb\u52a1\u6216\u72ed\u7a84\u4efb\u52a1\u8bbe\u8ba1\u548c\u8bad\u7ec3\u7684AI\u7cfb\u7edf\u3002 \u5f3a\u4eba\u5de5\u667a\u80fd\uff0c\u53c8\u79f0\u4eba\u5de5\u901a\u7528\u667a\u80fd (AGI)\uff0c\u6307\u7684\u662f\u5177\u6709\u4eba\u7c7b\u667a\u80fd\u548c\u7406\u89e3\u80fd\u529b\u7684AI\u7cfb\u7edf\u3002 \u8fd9\u4e9bAI\u7cfb\u7edf\u901a\u5e38\u4e0d\u5177\u5907\u901a\u7528\u667a\u80fd\uff1b\u5b83\u4eec\u5728\u6267\u884c\u9884\u5b9a\u4e49\u7684\u4efb\u52a1\u4e0a\u8868\u73b0\u51fa\u8272\uff0c\u4f46\u7f3a\u4e4f\u771f\u6b63\u7684\u7406\u89e3\u6216\u610f\u8bc6\u3002 \u8fd9\u4e9bAI\u7cfb\u7edf\u5177\u5907\u6267\u884c\u4efb\u4f55\u4eba\u7c7b\u53ef\u4ee5\u6267\u884c\u7684\u667a\u529b\u4efb\u52a1\u7684\u80fd\u529b\uff0c\u53ef\u4ee5\u9002\u5e94\u4e0d\u540c\u9886\u57df\uff0c\u5e76\u5177\u6709\u67d0\u79cd\u5f62\u5f0f\u7684\u610f\u8bc6\u6216\u81ea\u6211\u8ba4\u77e5\u3002 \u5f31\u4eba\u5de5\u667a\u80fd\u7684\u4f8b\u5b50\u5305\u62ecSiri\u6216Alexa\u8fd9\u7c7b\u865a\u62df\u52a9\u624b\u3001\u6d41\u5a92\u4f53\u670d\u52a1\u4e2d\u7684\u63a8\u8350\u7b97\u6cd5\uff0c\u4ee5\u53ca\u4e13\u95e8\u4e3a\u5ba2\u6237\u670d\u52a1\u4efb\u52a1\u8bbe\u8ba1\u7684\u804a\u5929\u673a\u5668\u4eba\u3002 \u5b9e\u73b0\u5f3a\u4eba\u5de5\u667a\u80fd\u662fAI\u7814\u7a76\u7684\u957f\u671f\u76ee\u6807\uff0c\u9700\u8981\u5f00\u53d1\u80fd\u591f\u5728\u5404\u79cd\u4efb\u52a1\u548c\u80cc\u666f\u4e0b\u8fdb\u884c\u63a8\u7406\u3001\u5b66\u4e60\u3001\u7406\u89e3\u548c\u9002\u5e94\u7684AI\u7cfb\u7edf\u3002 \u5f31\u4eba\u5de5\u667a\u80fd\u9ad8\u5ea6\u4e13\u4e1a\u5316\uff0c\u4e0d\u5177\u5907\u8d85\u51fa\u5176\u72ed\u7a84\u9886\u57df\u7684\u4eba\u7c7b\u8ba4\u77e5\u80fd\u529b\u6216\u901a\u7528\u95ee\u9898\u89e3\u51b3\u80fd\u529b\u3002 \u5f3a\u4eba\u5de5\u667a\u80fd\u76ee\u524d\u4ecd\u662f\u4e00\u4e2a\u7406\u8bba\u6982\u5ff5\uff0c\u8fd8\u6ca1\u6709AI\u7cfb\u7edf\u8fbe\u5230\u8fd9\u79cd\u901a\u7528\u667a\u80fd\u6c34\u5e73\u3002 <p>\u6709\u5173\u66f4\u591a\u4fe1\u606f\uff0c\u8bf7\u53c2\u9605 \u4eba\u5de5\u901a\u7528\u667a\u80fd (AGI)\u3002</p>"},{"location":"lessons/1-Intro/README_chs/#_4","title":"\u667a\u529b\u5b9a\u4e49\u4e0e\u56fe\u7075\u6d4b\u8bd5","text":"<p>\u5904\u7406 \u667a\u529b \u672f\u8bed\u65f6\uff0c\u5176\u4e2d\u4e00\u4e2a\u95ee\u9898\u662f\u6ca1\u6709\u660e\u786e\u7684\u5b9a\u4e49\u3002\u53ef\u4ee5\u8bf4\u667a\u529b\u4e0e \u62bd\u8c61\u601d\u7ef4 \u6216 \u81ea\u6211\u610f\u8bc6 \u76f8\u5173\uff0c\u4f46\u6211\u4eec\u65e0\u6cd5\u51c6\u786e\u5b9a\u4e49\u5b83\u3002</p> <p></p> <p>\u7167\u7247 \u7531 Amber Kipp \u63d0\u4f9b\uff0c\u6765\u81eaUnsplash</p> <p>\u4e3a\u4e86\u770b\u5230\u201c\u667a\u529b\u201d\u8fd9\u4e00\u672f\u8bed\u7684\u6a21\u7cca\u6027\uff0c\u8bd5\u56de\u7b54\u8fd9\u4e2a\u95ee\u9898\uff1a\u201c\u732b\u662f\u667a\u80fd\u7684\u5417\uff1f\u201d\u4e0d\u540c\u7684\u4eba\u5f80\u5f80\u5bf9\u6b64\u7ed9\u51fa\u4e0d\u540c\u7b54\u6848\uff0c\u56e0\u4e3a\u6ca1\u6709\u666e\u904d\u63a5\u53d7\u7684\u6d4b\u8bd5\u80fd\u8bc1\u660e\u8fd9\u4e00\u65ad\u8a00\u662f\u771f\u6216\u5047\u7684\u3002\u5982\u679c\u4f60\u8ba4\u4e3a\u6709\u2014\u2014\u90a3\u5c31\u8bd5\u7740\u8ba9\u4f60\u7684\u732b\u901a\u8fc7\u667a\u5546\u6d4b\u8bd5\u5427...</p> <p>\u2705 \u82b1\u4e00\u5206\u949f\u601d\u8003\u4e00\u4e0b\u4f60\u5982\u4f55\u5b9a\u4e49\u667a\u529b\u3002\u4e00\u53ea\u53ef\u4ee5\u89e3\u8ff7\u5bab\u53d6\u5f97\u98df\u7269\u7684\u4e4c\u9e26\u667a\u80fd\u5417\uff1f\u4e00\u4e2a\u5b69\u5b50\u806a\u660e\u5417\uff1f</p> <p>\u5728\u8c08\u8bbaAGI\u65f6\uff0c\u6211\u4eec\u9700\u8981\u4e00\u79cd\u65b9\u6cd5\u6765\u5224\u65ad\u6211\u4eec\u662f\u5426\u521b\u5efa\u4e86\u771f\u6b63\u7684\u667a\u80fd\u7cfb\u7edf\u3002\u827e\u4f26\u00b7\u56fe\u7075 \u63d0\u51fa\u4e86\u4e00\u79cd\u65b9\u6cd5\uff0c\u79f0\u4e3a \u56fe\u7075\u6d4b\u8bd5\uff0c\u8fd9\u4e5f\u50cf\u662f\u5bf9\u667a\u529b\u7684\u5b9a\u4e49\u3002\u8be5\u6d4b\u8bd5\u5c06\u7ed9\u5b9a\u7cfb\u7edf\u4e0e\u5185\u5728\u667a\u80fd\u2014\u2014\u771f\u5b9e\u4eba\u7c7b\u8fdb\u884c\u6bd4\u8f83\uff0c\u56e0\u4e3a\u4efb\u4f55\u81ea\u52a8\u6bd4\u8f83\u90fd\u53ef\u80fd\u88ab\u8ba1\u7b97\u673a\u7a0b\u5e8f\u7ed5\u8fc7\uff0c\u6240\u4ee5\u6211\u4eec\u4f7f\u7528\u4eba\u5de5\u5ba1\u8baf\u8005\u3002\u56e0\u6b64\uff0c\u5982\u679c\u4e00\u4e2a\u4eba\u65e0\u6cd5\u533a\u5206\u771f\u5b9e\u7684\u4eba\u4e0e\u8ba1\u7b97\u673a\u7cfb\u7edf\u5728\u57fa\u4e8e\u6587\u672c\u7684\u5bf9\u8bdd\u4e2d\u7684\u533a\u522b\u2014\u2014\u8be5\u7cfb\u7edf\u5c31\u88ab\u8ba4\u4e3a\u662f\u667a\u80fd\u7684\u3002</p> <p>\u4e00\u4e2a\u540d\u4e3a Eugene Goostman \u7684\u804a\u5929\u673a\u5668\u4eba\u4e8e2014\u5e74\u5728\u5723\u5f7c\u5f97\u5821\u63a5\u8fd1\u901a\u8fc7\u56fe\u7075\u6d4b\u8bd5\uff0c\u91c7\u7528\u4e86\u4e00\u79cd\u806a\u660e\u7684\u6027\u683c\u8be1\u8ba1\u3002\u5b83\u63d0\u524d\u5ba3\u5e03\u81ea\u5df1\u662f\u4e00\u4e2a13\u5c81\u7684\u4e4c\u514b\u5170\u7537\u5b69\uff0c\u8fd9\u89e3\u91ca\u4e86\u77e5\u8bc6\u7f3a\u4e4f\u548c\u6587\u672c\u4e2d\u7684\u4e00\u4e9b\u5dee\u5f02\u3002\u8fd9\u4f4d\u673a\u5668\u4eba\u57285\u5206\u949f\u7684\u5bf9\u8bdd\u4e2d\u8bf4\u670d30%\u7684\u8bc4\u59d4\u8ba4\u4e3a\u5b83\u662f\u4eba\u7c7b\uff0c\u56fe\u7075\u76f8\u4fe1\u673a\u5668\u52302000\u5e74\u53ef\u4ee5\u901a\u8fc7\u8fd9\u4e00\u6307\u6807\u3002\u7136\u800c\uff0c\u9700\u8981\u7406\u89e3\u7684\u662f\uff0c\u8fd9\u5e76\u4e0d\u8868\u793a\u6211\u4eec\u521b\u9020\u4e86\u667a\u80fd\u7cfb\u7edf\uff0c\u6216\u8ba1\u7b97\u673a\u7cfb\u7edf\u6b3a\u9a97\u4e86\u4eba\u7c7b\u5ba1\u8baf\u8005\u2014\u2014\u7cfb\u7edf\u5e76\u6ca1\u6709\u6b3a\u9a97\u771f\u4eba\uff0c\u800c\u662f\u673a\u5668\u4eba\u7684\u521b\u9020\u8005\u638c\u63e1\u4e86\u6280\u5de7\uff01</p> <p>\u2705 \u4f60\u662f\u5426\u66fe\u88ab\u4e00\u4e2a\u804a\u5929\u673a\u5668\u4eba\u6b3a\u9a97\uff0c\u8ba4\u4e3a\u4f60\u5728\u548c\u4eba\u7c7b\u8bf4\u8bdd\uff1f\u5b83\u662f\u5982\u4f55\u8ba9\u4f60\u76f8\u4fe1\u7684\uff1f</p>"},{"location":"lessons/1-Intro/README_chs/#_5","title":"\u4eba\u5de5\u667a\u80fd\u7684\u4e0d\u540c\u65b9\u6cd5","text":"<p>\u5982\u679c\u6211\u4eec\u5e0c\u671b\u8ba1\u7b97\u673a\u50cf\u4eba\u7c7b\u4e00\u6837\u884c\u52a8\uff0c\u6211\u4eec\u9700\u8981\u67d0\u79cd\u65b9\u5f0f\u5728\u8ba1\u7b97\u673a\u5185\u90e8\u5efa\u6a21\u6211\u4eec\u7684\u601d\u7ef4\u65b9\u5f0f\u3002\u56e0\u6b64\uff0c\u6211\u4eec\u9700\u8981\u5c1d\u8bd5\u7406\u89e3\u662f\u4ec0\u4e48\u8ba9\u4eba\u7c7b\u806a\u660e\u3002</p> <p>\u8981\u80fd\u5c06\u667a\u80fd\u7f16\u7a0b\u5230\u673a\u5668\u4e2d\uff0c\u6211\u4eec\u9700\u8981\u7406\u89e3\u81ea\u5df1\u7684\u51b3\u7b56\u8fc7\u7a0b\u3002\u5982\u679c\u8fdb\u884c\u81ea\u6211\u5185\u7701\uff0c\u4f60\u4f1a\u610f\u8bc6\u5230\u6709\u4e9b\u8fc7\u7a0b\u662f\u4e0b\u610f\u8bc6\u53d1\u751f\u7684\u2014\u2014\u4f8b\u5982\uff0c\u6211\u4eec\u53ef\u4ee5\u4e0d\u52a0\u601d\u7d22\u5730\u5206\u8fa8\u51fa\u732b\u548c\u72d7\u2014\u2014\u800c\u6709\u4e9b\u8fc7\u7a0b\u5219\u6d89\u53ca\u63a8\u7406\u3002</p> <p>\u89e3\u51b3\u8fd9\u4e00\u95ee\u9898\u6709\u4e24\u79cd\u53ef\u80fd\u7684\u65b9\u6cd5\uff1a</p> \u81ea\u4e0a\u800c\u4e0b\u65b9\u6cd5\uff08\u7b26\u53f7\u63a8\u7406\uff09 \u81ea\u4e0b\u800c\u4e0a\u65b9\u6cd5\uff08\u795e\u7ecf\u7f51\u7edc\uff09 \u81ea\u4e0a\u800c\u4e0b\u7684\u65b9\u6cd5\u6a21\u62df\u4eba\u7c7b\u89e3\u51b3\u95ee\u9898\u7684\u63a8\u7406\u65b9\u5f0f\u3002 \u5b83\u5305\u62ec\u4ece\u4eba\u7c7b\u4e2d\u63d0\u53d6 \u77e5\u8bc6\uff0c\u5e76\u5c06\u5176\u8868\u793a\u4e3a\u8ba1\u7b97\u673a\u53ef\u8bfb\u7684\u5f62\u5f0f\u3002 \u6211\u4eec\u8fd8\u9700\u8981\u5f00\u53d1\u4e00\u79cd\u5728\u8ba1\u7b97\u673a\u5185\u90e8\u5efa\u6a21 \u63a8\u7406 \u7684\u65b9\u6cd5\u3002 \u81ea\u4e0b\u800c\u4e0a\u65b9\u6cd5\u6a21\u62df\u4eba\u8111\u7684\u7ed3\u6784\uff0c\u5305\u62ec\u5927\u91cf\u79f0\u4e3a \u795e\u7ecf\u5143 \u7684\u7b80\u5355\u5355\u5143\u3002 \u6bcf\u4e2a\u795e\u7ecf\u5143\u7684\u4f5c\u7528\u7c7b\u4f3c\u4e8e\u5176\u8f93\u5165\u7684\u52a0\u6743\u5e73\u5747\u503c\uff0c\u5e76\u4e14\u901a\u8fc7\u63d0\u4f9b \u8bad\u7ec3\u6570\u636e\uff0c\u6211\u4eec\u53ef\u4ee5\u8bad\u7ec3\u795e\u7ecf\u5143\u7f51\u7edc\u6765\u89e3\u51b3\u6709\u7528\u7684\u95ee\u9898\u3002 <p>\u6b64\u5916\uff0c\u8fd8\u6709\u5176\u4ed6\u4e00\u4e9b\u53ef\u80fd\u7684\u667a\u80fd\u65b9\u6cd5\uff1a</p> <ul> <li> <p>\u6d8c\u73b0\u3001\u534f\u540c\u6216 \u591a\u4ee3\u7406\u65b9\u6cd5 \u57fa\u4e8e\u8fd9\u6837\u4e00\u4e2a\u4e8b\u5b9e\uff0c\u5373\u901a\u8fc7\u5927\u91cf\u7b80\u5355\u4ee3\u7406\u4e4b\u95f4\u7684\u76f8\u4e92\u4f5c\u7528\u53ef\u4ee5\u83b7\u5f97\u590d\u6742\u7684\u667a\u80fd\u884c\u4e3a\u3002\u6839\u636e \u8fdb\u5316\u63a7\u5236\u8bba\uff0c\u667a\u80fd\u53ef\u4ee5\u901a\u8fc7\u5728 \u5143\u7cfb\u7edf\u8fc7\u6e21 \u8fc7\u7a0b\u4e2d\u66f4\u7b80\u5355\u7684\u53cd\u5e94\u884c\u4e3a \u6d8c\u73b0 \u51fa\u6765\u3002</p> </li> <li> <p>\u8fdb\u5316\u65b9\u6cd5\uff0c\u6216 \u9057\u4f20\u7b97\u6cd5 \u662f\u4e00\u79cd\u57fa\u4e8e\u8fdb\u5316\u539f\u7406\u7684\u4f18\u5316\u8fc7\u7a0b\u3002</p> </li> </ul> <p>\u6211\u4eec\u5c06\u5728\u8bfe\u7a0b\u540e\u7eed\u8003\u8651\u8fd9\u4e9b\u65b9\u6cd5\uff0c\u4f46\u76ee\u524d\u6211\u4eec\u5c06\u91cd\u70b9\u5173\u6ce8\u4e24\u79cd\u4e3b\u8981\u65b9\u5411\uff1a\u81ea\u4e0a\u800c\u4e0b\u548c\u81ea\u4e0b\u800c\u4e0a\u3002</p>"},{"location":"lessons/1-Intro/README_chs/#_6","title":"\u81ea\u4e0a\u800c\u4e0b\u65b9\u6cd5","text":"<p>\u5728 \u81ea\u4e0a\u800c\u4e0b\u65b9\u6cd5 \u4e2d\uff0c\u6211\u4eec\u5c1d\u8bd5\u6a21\u578b\u5316\u6211\u4eec\u7684\u63a8\u7406\u3002\u56e0\u4e3a\u6211\u4eec\u53ef\u4ee5\u5728\u63a8\u7406\u65f6\u8ddf\u8e2a\u6211\u4eec\u7684\u601d\u7ef4\uff0c\u5c1d\u8bd5\u5c06\u8fd9\u4e00\u8fc7\u7a0b\u5f62\u5f0f\u5316\u5e76\u7f16\u7a0b\u5230\u8ba1\u7b97\u673a\u4e2d\u3002\u8fd9\u88ab\u79f0\u4e3a \u7b26\u53f7\u63a8\u7406\u3002</p> <p>\u4eba\u4eec\u503e\u5411\u4e8e\u5728\u8111\u6d77\u4e2d\u6709\u4e00\u4e9b\u6307\u5bfc\u51b3\u7b56\u8fc7\u7a0b\u7684\u89c4\u5219\u3002\u4f8b\u5982\uff0c\u5f53\u533b\u751f\u8bca\u65ad\u60a3\u8005\u65f6\uff0c\u53ef\u80fd\u4f1a\u610f\u8bc6\u5230\u4eba\u6709\u53d1\u70e7\u75c7\u72b6\uff0c\u56e0\u6b64\u4f53\u5185\u53ef\u80fd\u6709\u4e00\u4e9b\u708e\u75c7\u3002\u901a\u8fc7\u5c06\u5927\u91cf\u89c4\u5219\u5e94\u7528\u4e8e\u5177\u4f53\u95ee\u9898\uff0c\u533b\u751f\u53ef\u80fd\u80fd\u591f\u5f97\u51fa\u6700\u7ec8\u8bca\u65ad\u3002</p> <p>\u8fd9\u79cd\u65b9\u6cd5\u4e25\u91cd\u4f9d\u8d56 \u77e5\u8bc6\u8868\u793a \u548c \u63a8\u7406\u3002\u4ece\u4eba\u7c7b\u4e13\u5bb6\u63d0\u53d6\u77e5\u8bc6\u53ef\u80fd\u662f\u6700\u56f0\u96be\u7684\u90e8\u5206\uff0c\u56e0\u4e3a\u8bb8\u591a\u60c5\u51b5\u4e0b\u533b\u751f\u81ea\u5df1\u90fd\u4e0d\u77e5\u9053\u4e3a\u4f55\u5f97\u51fa\u4e86\u7279\u5b9a\u8bca\u65ad\u3002\u6709\u65f6\u89e3\u51b3\u65b9\u6848\u5728\u4ed6\u7684\u8111\u6d77\u4e2d\u81ea\u52a8\u5f62\u6210\u800c\u65e0\u9700\u660e\u786e\u601d\u8003\u3002\u4e00\u4e9b\u4efb\u52a1\uff0c\u4f8b\u5982\u4ece\u7167\u7247\u4e2d\u786e\u5b9a\u4e00\u4e2a\u4eba\u7684\u5e74\u9f84\uff0c\u5b8c\u5168\u65e0\u6cd5\u901a\u8fc7\u64cd\u4f5c\u77e5\u8bc6\u6765\u8fdb\u884c\u3002</p>"},{"location":"lessons/1-Intro/README_chs/#_7","title":"\u81ea\u4e0b\u800c\u4e0a\u65b9\u6cd5","text":"<p>\u6216\u8005\uff0c\u6211\u4eec\u53ef\u4ee5\u5c1d\u8bd5\u5bf9\u5927\u8111\u4e2d\u7684\u6700\u7b80\u5355\u5143\u7d20\u2014\u2014\u795e\u7ecf\u5143\u8fdb\u884c\u5efa\u6a21\u3002\u6211\u4eec\u53ef\u4ee5\u5728\u8ba1\u7b97\u673a\u4e2d\u6784\u5efa\u4e00\u4e2a\u6240\u8c13\u7684 \u4eba\u5de5\u795e\u7ecf\u7f51\u7edc\uff0c\u7136\u540e\u5c1d\u8bd5\u901a\u8fc7\u63d0\u4f9b\u793a\u4f8b\u6765\u6559\u5b83\u89e3\u51b3\u95ee\u9898\u3002\u8fd9\u4e00\u8fc7\u7a0b\u7c7b\u4f3c\u4e8e\u4e00\u4e2a\u65b0\u751f\u513f\u901a\u8fc7\u89c2\u5bdf\u5468\u56f4\u73af\u5883\u5b66\u4e60\u7684\u65b9\u6cd5\u3002</p> <p>\u2705 \u505a\u4e00\u4e9b\u5173\u4e8e\u5a74\u513f\u5982\u4f55\u5b66\u4e60\u7684\u7814\u7a76\u3002\u5a74\u513f\u5927\u8111\u7684\u57fa\u672c\u5143\u7d20\u662f\u4ec0\u4e48\uff1f</p> \u5173\u4e8e\u673a\u5668\u5b66\u4e60\u5462\uff1f \u57fa\u4e8e\u8ba1\u7b97\u673a\u5b66\u4e60\u4ee5\u89e3\u51b3\u95ee\u9898\u7684\u4e00\u90e8\u5206\u4eba\u5de5\u667a\u80fd\u88ab\u79f0\u4e3a \u673a\u5668\u5b66\u4e60\u3002 \u6211\u4eec\u5728\u672c\u8bfe\u7a0b\u4e2d\u4e0d\u4f1a\u8003\u8651\u4f20\u7edf\u673a\u5668\u5b66\u4e60\u2014\u2014\u8bf7\u53c2\u9605\u5355\u72ec\u7684 \u521d\u5b66\u8005\u7684\u673a\u5668\u5b66\u4e60 \u8bfe\u7a0b\u3002"},{"location":"lessons/1-Intro/README_chs/#_8","title":"\u4eba\u5de5\u667a\u80fd\u7b80\u53f2","text":"<p>\u4eba\u5de5\u667a\u80fd\u4f5c\u4e3a\u4e00\u4e2a\u9886\u57df\u59cb\u4e8e20\u4e16\u7eaa\u4e2d\u671f\u3002\u6700\u521d\uff0c\u7b26\u53f7\u63a8\u7406\u662f\u4e00\u79cd\u666e\u904d\u7684\u65b9\u6cd5\uff0c\u5e76\u53d6\u5f97\u4e86\u4e00\u4e9b\u91cd\u8981\u7684\u6210\u529f\uff0c\u5982\u4e13\u5bb6\u7cfb\u7edf\u2014\u2014\u80fd\u591f\u5728\u6709\u9650\u95ee\u9898\u9886\u57df\u5185\u5145\u5f53\u4e13\u5bb6\u7684\u8ba1\u7b97\u673a\u7a0b\u5e8f\u3002\u7136\u800c\uff0c\u5f88\u5feb\u5c31\u663e\u9732\u51fa\u8fd9\u79cd\u65b9\u6cd5\u7684\u5c40\u9650\u6027\u3002\u5c06\u77e5\u8bc6\u4ece\u4e13\u5bb6\u63d0\u53d6\u51fa\u6765\uff0c\u5728\u8ba1\u7b97\u673a\u4e2d\u8868\u793a\u51fa\u6765\uff0c\u5e76\u4fdd\u6301\u77e5\u8bc6\u5e93\u7684\u51c6\u786e\u6027\uff0c\u7ed3\u679c\u53d1\u73b0\u8fd9\u662f\u4e00\u4e2a\u975e\u5e38\u590d\u6742\u7684\u4efb\u52a1\uff0c\u5e76\u4e14\u5728\u5f88\u591a\u60c5\u51b5\u4e0b\u6210\u672c\u8fc7\u9ad8\u800c\u4e0d\u5b9e\u9645\u3002\u8fd9\u5bfc\u81f4\u4e861970\u5e74\u4ee3\u7684\u6240\u8c13 AI\u51ac\u5929\u3002</p> <p></p> <p>\u56fe\u7247\u7531 Dmitry Soshnikov \u63d0\u4f9b</p> <p>\u968f\u7740\u65f6\u95f4\u7684\u63a8\u79fb\uff0c\u8ba1\u7b97\u8d44\u6e90\u53d8\u5f97\u66f4\u52a0\u4fbf\u5b9c\uff0c\u4e14\u53ef\u4ee5\u83b7\u5f97\u66f4\u591a\u6570\u636e\uff0c\u56e0\u6b64\u795e\u7ecf\u7f51\u7edc\u65b9\u6cd5\u5728\u8ba1\u7b97\u673a\u89c6\u89c9\u6216\u8bed\u97f3\u7406\u89e3\u7b49\u8bb8\u591a\u9886\u57df\u4e2d\u8868\u73b0\u51fa\u5353\u8d8a\u7684\u6027\u80fd\u3002\u5728\u8fc7\u53bb\u7684\u5341\u5e74\u4e2d\uff0c\u4eba\u5de5\u667a\u80fd\u8fd9\u4e2a\u672f\u8bed\u5927\u591a\u4f5c\u4e3a\u795e\u7ecf\u7f51\u7edc\u7684\u540c\u4e49\u8bcd\u51fa\u73b0\uff0c\u56e0\u4e3a\u6211\u4eec\u542c\u5230\u7684\u5927\u591a\u6570AI\u6210\u529f\u90fd\u57fa\u4e8e\u795e\u7ecf\u7f51\u7edc\u3002</p> <p>\u6211\u4eec\u53ef\u4ee5\u89c2\u5bdf\u5230\uff0c\u5728\u521b\u5efa\u8c61\u68cb\u7a0b\u5e8f\u65b9\u9762\u7684\u65b9\u6cd5\u662f\u5982\u4f55\u53d8\u5316\u7684\uff1a</p> <ul> <li>\u65e9\u671f\u7684\u8c61\u68cb\u7a0b\u5e8f\u57fa\u4e8e\u641c\u7d22\u2014\u2014\u7a0b\u5e8f\u663e\u5f0f\u8bd5\u56fe\u8bc4\u4f30\u5bf9\u624b\u5728\u63a5\u4e0b\u6765\u51e0\u6b65\u7684\u53ef\u80fd\u8d70\u6cd5\uff0c\u5e76\u6839\u636e\u51e0\u6b65\u5185\u53ef\u4ee5\u8fbe\u5230\u7684\u6700\u4f73\u4f4d\u7f6e\u9009\u62e9\u6700\u4f73\u8d70\u6cd5\u3002 \u8fd9\u5bfc\u81f4\u4e86\u6240\u8c13 alpha-beta\u526a\u679d \u641c\u7d22\u7b97\u6cd5\u7684\u53d1\u5c55\u3002</li> <li>\u641c\u7d22\u7b56\u7565\u5728\u6e38\u620f\u540e\u671f\u6548\u679c\u5f88\u597d\uff0c\u56e0\u4e3a\u641c\u7d22\u7a7a\u95f4\u53d7\u5230\u5c11\u6570\u53ef\u80fd\u8d70\u6cd5\u7684\u9650\u5236\u3002\u7136\u800c\u5728\u6e38\u620f\u5f00\u59cb\u65f6\uff0c\u641c\u7d22\u7a7a\u95f4\u5e9e\u5927\uff0c\u53ef\u4ee5\u901a\u8fc7\u5b66\u4e60\u4eba\u7c7b\u73a9\u5bb6\u4e4b\u95f4\u7684\u73b0\u6709\u6bd4\u8d5b\u6765\u6539\u8fdb\u7b97\u6cd5\u3002 \u6b64\u540e\u7684\u4e00\u4e9b\u5b9e\u9a8c\u91c7\u7528\u6240\u8c13\u7684 \u57fa\u4e8e\u6848\u4f8b\u63a8\u7406\uff0c \u7a0b\u5e8f\u4f1a\u5728\u77e5\u8bc6\u5e93\u4e2d\u67e5\u627e\u4e0e\u5f53\u524d\u68cb\u5c40\u975e\u5e38\u76f8\u4f3c\u7684\u6848\u4f8b\u3002</li> <li>\u83b7\u5f97\u5bf9\u4eba\u7c7b\u73a9\u5bb6\u80dc\u5229\u7684\u73b0\u4ee3\u7a0b\u5e8f\u57fa\u4e8e\u795e\u7ecf\u7f51\u7edc\u548c \u5f3a\u5316\u5b66\u4e60\uff0c \u8fd9\u4e9b\u7a0b\u5e8f\u901a\u8fc7\u957f\u65f6\u95f4\u81ea\u6211\u5bf9\u5f08\u5e76\u4ece\u81ea\u5df1\u7684\u9519\u8bef\u4e2d\u5b66\u4e60\u6765\u5b66\u4f1a\u4e0b\u68cb\u2014\u2014\u8fd9\u4e0e\u4eba\u7c7b\u5b66\u4e60\u4e0b\u68cb\u975e\u5e38\u76f8\u4f3c\u3002 \u7136\u800c\uff0c\u8ba1\u7b97\u673a\u7a0b\u5e8f\u53ef\u4ee5\u5728\u66f4\u77ed\u7684\u65f6\u95f4\u5185\u73a9\u66f4\u591a\u7684\u6e38\u620f\uff0c\u56e0\u6b64\u5b66\u4e60\u901f\u5ea6\u66f4\u5feb\u3002</li> </ul> <p>\u2705 \u505a\u4e00\u4e9b\u7814\u7a76\uff0c\u4e86\u89e3\u5176\u4ed6\u7531AI\u73a9\u7684\u6e38\u620f\u3002</p> <p>\u7c7b\u4f3c\u5730\uff0c\u6211\u4eec\u53ef\u4ee5\u770b\u5230\u521b\u5efa\u201c\u4f1a\u8bf4\u8bdd\u7684\u7a0b\u5e8f\u201d\uff08\u53ef\u80fd\u901a\u8fc7\u56fe\u7075\u6d4b\u8bd5\uff09\u7684\u65b9\u6cd5\u662f\u5982\u4f55\u53d8\u5316\u7684\uff1a</p> <ul> <li>\u65e9\u671f\u7684\u8fd9\u7c7b\u7a0b\u5e8f\u5982 Eliza\uff0c\u57fa\u4e8e\u975e\u5e38\u7b80\u5355\u7684\u8bed\u6cd5\u89c4\u5219\u548c\u5c06\u8f93\u5165\u53e5\u5b50\u91cd\u65b0\u516c\u5f0f\u5316\u4e3a\u95ee\u9898\u3002</li> <li>\u73b0\u4ee3\u7684\u52a9\u624b\u5982 Cortana\u3001Siri \u6216 Google Assistant \u90fd\u662f\u6df7\u5408\u7cfb\u7edf\uff0c\u4f7f\u7528\u795e\u7ecf\u7f51\u7edc\u5c06\u8bed\u97f3\u8f6c\u6362\u4e3a\u6587\u672c\u5e76\u8bc6\u522b\u7528\u6237\u610f\u56fe\uff0c\u7136\u540e\u4f7f\u7528\u4e00\u4e9b\u63a8\u7406\u6216\u663e\u5f0f\u7b97\u6cd5\u6267\u884c\u6240\u9700\u64cd\u4f5c\u3002</li> <li>\u672a\u6765\uff0c\u6211\u4eec\u53ef\u80fd\u671f\u671b\u4e00\u4e2a\u5b8c\u5168\u57fa\u4e8e\u795e\u7ecf\u7f51\u7edc\u7684\u6a21\u578b\u80fd\u591f\u81ea\u884c\u5904\u7406\u5bf9\u8bdd\u3002 \u6700\u8fd1\u7684 GPT \u548c Turing-NLG \u4e00\u7cfb\u5217\u7684\u795e\u7ecf\u7f51\u7edc\u5728\u8fd9\u65b9\u9762\u663e\u793a\u4e86\u5de8\u5927\u7684\u6210\u529f\u3002</li> </ul> <p></p> <p>\u56fe\u7247\u7531 Dmitry Soshnikov \u63d0\u4f9b\uff0c\u7167\u7247 \u7531 Marina Abrosimova \u63d0\u4f9b\uff0c\u6765\u81eaUnsplash</p>"},{"location":"lessons/1-Intro/README_chs/#ai","title":"\u6700\u8fd1\u7684AI\u7814\u7a76","text":"<p>\u7ea6\u57282010\u5e74\u5de6\u53f3\uff0c\u795e\u7ecf\u7f51\u7edc\u7814\u7a76\u7684\u5927\u53d1\u5c55\u5f97\u76ca\u4e8e\u5927\u91cf\u516c\u5f00\u6570\u636e\u96c6\u7684\u5f00\u653e\u3002\u4e00\u5927\u6279\u5305\u542b\u5927\u7ea61400\u4e07\u5f20\u5e26\u6ce8\u91ca\u7684\u56fe\u50cf\u79f0\u4e3a ImageNet\uff0c\u50ac\u751f\u4e86 ImageNet\u5927\u578b\u56fe\u50cf\u8bc6\u522b\u6311\u6218\u8d5b\u3002</p> <p></p> <p>\u56fe\u7247\u7531 Dmitry Soshnikov \u63d0\u4f9b</p> <p>2012\u5e74\uff0c\u9996\u6b21\u5728\u56fe\u50cf\u5206\u7c7b\u4e2d\u4f7f\u7528 \u5377\u79ef\u795e\u7ecf\u7f51\u7edc\uff0c\u4f7f\u5206\u7c7b\u9519\u8bef\u660e\u663e\u4e0b\u964d\uff08\u4ece\u63a5\u8fd130%\u964d\u4f4e\u523016.4%\uff09\u30022015\u5e74\uff0c\u5fae\u8f6f\u7814\u7a76\u9662\u7684 ResNet \u67b6\u6784 \u8fbe\u5230\u4e86\u4eba\u7c7b\u6c34\u5e73\u7684\u51c6\u786e\u7387\u3002</p> <p>\u81ea\u90a3\u65f6\u8d77\uff0c\u795e\u7ecf\u7f51\u7edc\u5728\u8bb8\u591a\u4efb\u52a1\u4e2d\u8868\u73b0\u51fa\u4e86\u975e\u5e38\u6210\u529f\u7684\u884c\u4e3a\uff1a</p> \u5e74\u4efd \u8fbe\u5230\u4eba\u7c7b\u6c34\u5e73 2015 \u56fe\u50cf\u5206\u7c7b 2016 \u4f1a\u8bdd\u8bed\u97f3\u8bc6\u522b 2018 \u81ea\u52a8\u673a\u5668\u7ffb\u8bd1\uff08\u4e2d\u82f1\u4e4b\u95f4\uff09 2020 \u56fe\u50cf\u63cf\u8ff0 <p>\u5728\u8fc7\u53bb\u51e0\u5e74\u4e2d\uff0c\u6211\u4eec\u89c1\u8bc1\u4e86\u5927\u8bed\u8a00\u6a21\u578b\u5de8\u5927\u7684\u6210\u529f\uff0c\u5982 BERT \u548c GPT-3\u3002 \u8fd9\u4e3b\u8981\u662f\u56e0\u4e3a\u6709\u5927\u91cf\u7684\u901a\u7528\u6587\u672c\u6570\u636e\u53ef\u4f9b\u4f7f\u7528\uff0c\u6211\u4eec\u53ef\u4ee5\u8bad\u7ec3\u6a21\u578b\u6355\u6349\u6587\u672c\u7684\u7ed3\u6784\u548c\u610f\u4e49\uff0c\u5728\u666e\u901a\u6587\u672c\u96c6\u5408\u4e0a\u8fdb\u884c\u9884\u8bad\u7ec3\uff0c\u7136\u540e\u5c06\u8fd9\u4e9b\u6a21\u578b\u4e13\u95e8\u5316\u7528\u4e8e\u66f4\u5177\u4f53\u7684\u4efb\u52a1\u3002 \u6211\u4eec\u5c06\u5728\u672c\u8bfe\u7a0b\u7684 \u81ea\u7136\u8bed\u8a00\u5904\u7406 \u90e8\u5206\u4e2d\u5b66\u4e60\u66f4\u591a\u76f8\u5173\u5185\u5bb9\u3002</p>"},{"location":"lessons/1-Intro/README_chs/#_9","title":"\ud83d\ude80 \u6311\u6218","text":"<p>\u5728\u4e92\u8054\u7f51\u4e0a\u5de1\u6e38\u4e00\u4e0b\uff0c\u786e\u5b9a\u4f60\u8ba4\u4e3aAI\u5728\u54ea\u4e9b\u9886\u57df\u6700\u6709\u6548\u5730\u88ab\u4f7f\u7528\u3002 \u662f\u5728\u5730\u56fe\u5e94\u7528\u4e2d\uff0c\u8fd8\u662f\u67d0\u4e9b\u8bed\u97f3\u8f6c\u6587\u672c\u670d\u52a1\u6216\u662f\u7535\u5b50\u6e38\u620f\u4e2d\uff1f\u7814\u7a76\u4e86\u89e3\u7cfb\u7edf\u662f\u5982\u4f55\u88ab\u5efa\u7acb\u7684\u3002</p>"},{"location":"lessons/1-Intro/README_chs/#_10","title":"\u8bfe\u540e\u6d4b\u9a8c","text":""},{"location":"lessons/1-Intro/README_chs/#_11","title":"\u590d\u4e60\u4e0e\u81ea\u5b66","text":"<p>\u901a\u8fc7\u9605\u8bfb \u8fd9\u8282\u8bfe \u6765\u590d\u4e60AI\u548cML\u7684\u5386\u53f2\u3002\u4ece\u8fd9\u8282\u8bfe\u6216\u4e0a\u9762\u6d82\u9e26\u7b14\u8bb0\u4e2d\u9009\u62e9\u4e00\u4e2a\u5143\u7d20\uff0c\u6df1\u5165\u7814\u7a76\u5b83\u4ee5\u4e86\u89e3\u5176\u6f14\u53d8\u7684\u6587\u5316\u80cc\u666f\u3002</p> <p>\u4f5c\u4e1a\uff1a\u6e38\u620f\u8bbe\u8ba1\u6bd4\u8d5b</p>"},{"location":"lessons/1-Intro/assignment/","title":"Game Jam","text":"<p>Games are an area that have been heavily influence by developments in AI and ML. In this assignment, write a short paper on a game that you like that has been influenced by the evolution of AI. It should be an old enough game to have been influenced by several types of computer processing systems. A good example is Chess or Go, but also take a look at video games like pong or Pac-Man. Write an essay that discusses the game's past, present, and AI future.</p>"},{"location":"lessons/1-Intro/assignment_chs/","title":"\u6e38\u620f\u5f00\u53d1\u9a6c\u62c9\u677e","text":"<p>\u6e38\u620f\u9886\u57df\u53d7\u5230\u4e86AI\u548cML\u53d1\u5c55\u7684\u6df1\u523b\u5f71\u54cd\u3002\u5728\u8fd9\u4e2a\u4f5c\u4e1a\u4e2d\uff0c\u8bf7\u64b0\u5199\u4e00\u7bc7\u5173\u4e8e\u4f60\u559c\u6b22\u7684\u3001\u53d7AI\u6f14\u53d8\u5f71\u54cd\u7684\u6e38\u620f\u7684\u77ed\u6587\u3002\u5b83\u5e94\u8be5\u662f\u4e00\u4e2a\u53d7\u591a\u79cd\u8ba1\u7b97\u673a\u5904\u7406\u7cfb\u7edf\u5f71\u54cd\u7684\u8f83\u8001\u7684\u6e38\u620f\u3002\u56fd\u9645\u8c61\u68cb\u6216\u56f4\u68cb\u662f\u5f88\u597d\u7684\u4f8b\u5b50\uff0c\u4f46\u4e5f\u53ef\u4ee5\u770b\u770b\u50cf\u4e52\u4e53\u6216\u5403\u8c46\u4eba\u8fd9\u6837\u7684\u7535\u5b50\u6e38\u620f\u3002\u5199\u4e00\u7bc7\u8ba8\u8bba\u8be5\u6e38\u620f\u7684\u8fc7\u53bb\u3001\u73b0\u5728\u548cAI\u672a\u6765\u7684\u6587\u7ae0\u3002</p>"},{"location":"lessons/2-Symbolic/","title":"Knowledge Representation and Expert Systems","text":"<p>Sketchnote by Tomomi Imura</p> <p>The quest for artificial intelligence is based on a search for knowledge, to make sense of the world similar to how humans do. But how can you go about doing this?</p>"},{"location":"lessons/2-Symbolic/#pre-lecture-quiz","title":"Pre-lecture quiz","text":"<p>In the early days of AI, the top-down approach to creating intelligent systems (discussed in the previous lesson) was popular. The idea was to extract the knowledge from people into some machine-readable form, and then use it to automatically solve problems. This approach was based on two big ideas:</p> <ul> <li>Knowledge Representation</li> <li>Reasoning</li> </ul>"},{"location":"lessons/2-Symbolic/#knowledge-representation","title":"Knowledge Representation","text":"<p>One of the important concepts in Symbolic AI is knowledge. It is important to differentiate knowledge from information or data. For example, one can say that books contain knowledge, because one can study books and become an expert. However, what books contain is actually called data, and by reading books and integrating this data into our world model we convert this data to knowledge.</p> <p>\u2705 Knowledge is something which is contained in our head and represents our understanding of the world. It is obtained by an active learning process, which integrates pieces of information that we receive into our active model of the world.</p> <p>Most often, we do not strictly define knowledge, but we align it with other related concepts using DIKW Pyramid. It contains the following concepts:</p> <ul> <li>Data is something represented in physical media, such as written text or spoken words. Data exists independently of human beings and can be passed between people.</li> <li>Information is how we interpret data in our head. For example, when we hear the word computer, we have some understanding of what it is.</li> <li>Knowledge is information being integrated into our world model. For example, once we learn what a computer is, we start having some ideas about how it works, how much it costs, and what it can be used for. This network of interrelated concepts forms our knowledge.</li> <li>Wisdom is yet one more level of our understanding of the world, and it represents meta-knowledge, eg. some notion on how and when the knowledge should be used.</li> </ul> <p></p> <p>Image from Wikipedia, By Longlivetheux - Own work, CC BY-SA 4.0</p> <p>Thus, the problem of knowledge representation is to find some effective way to represent knowledge inside a computer in the form of data, to make it automatically usable. This can be seen as a spectrum:</p> <p></p> <p>Image by Dmitry Soshnikov</p> <ul> <li>On the left, there are very simple types of knowledge representations that can be effectively used by computers. The simplest one is algorithmic, when knowledge is represented by a computer program. This, however, is not the best way to represent knowledge, because it is not flexible. Knowledge inside our head is often non-algorithmic.</li> <li>On the right, there are representations such as natural text. It is the most powerful, but cannot be used for automatic reasoning.</li> </ul> <p>\u2705 Think for a minute about how you represent knowledge in your head and convert it to notes. Is there a particular format that works well for you to aid in retention?</p>"},{"location":"lessons/2-Symbolic/#classifying-computer-knowledge-representations","title":"Classifying Computer Knowledge Representations","text":"<p>We can classify different computer knowledge representation methods in the following categories:</p> <ul> <li> <p>Network representations are based on the fact that we have a network of interrelated concepts inside our head. We can try to reproduce the same networks as a graph inside a computer - a so-called semantic network.</p> </li> <li> <p>Object-Attribute-Value triplets or attribute-value pairs. Since a graph can be represented inside a computer as a list of nodes and edges, we can represent a semantic network by a list of triplets, containing objects, attributes, and values. For example, we build the following triplets about programming languages:</p> </li> </ul> Object Attribute Value Python is Untyped-Language Python invented-by Guido van Rossum Python block-syntax indentation Untyped-Language doesn't have type definitions <p>\u2705 Think how triplets can be used to represent other types of knowledge.</p> <ol> <li> <p>Hierarchical representations emphasize the fact that we often create a hierarchy of objects inside our head. For example, we know that canary is a bird, and all birds have wings. We also have some idea about what colour a canary usually is, and what is their flight speed.</p> </li> <li> <p>Frame representation is based on representing each object or class of objects as a frame which contains slots. Slots have possible default values, value restrictions, or stored procedures that can be called to obtain the value of a slot. All frames form a hierarchy similar to an object hierarchy in object-oriented programming languages.</p> </li> <li>Scenarios are special kind of frames that represent complex situations that can unfold in time.</li> </ol> <p>Python</p> Slot Value Default value Interval Name Python Is-A Untyped-Language Variable Case CamelCase Program Length 5-5000 lines Block Syntax Indent <ol> <li>Procedural representations are based on representing knowledge by a list of actions that can be executed when a certain condition occurs.</li> <li>Production rules are if-then statements that allow us to draw conclusions. For example, a doctor can have a rule saying that IF a patient has high fever OR high level of C-reactive protein in blood test THEN he has an inflammation. Once we encounter one of the conditions, we can make a conclusion about inflammation, and then use it in further reasoning.</li> <li> <p>Algorithms can be considered another form of procedural representation, although they are almost never used directly in knowledge-based systems.</p> </li> <li> <p>Logic was originally proposed by Aristotle as a way to represent universal human knowledge.</p> </li> <li>Predicate Logic as a mathematical theory is too rich to be computable, therefore some subset of it is normally used, such as Horn clauses used in Prolog.</li> <li>Descriptive Logic is a family of logical systems used to represent and reason about hierarchies of objects distributed knowledge representations such as semantic web.</li> </ol>"},{"location":"lessons/2-Symbolic/#expert-systems","title":"Expert Systems","text":"<p>One of the early successes of symbolic AI were so-called expert systems - computer systems that were designed to act as an expert in some limited problem domain. They were based on a knowledge base extracted from one or more human experts, and they contained an inference engine that performed some reasoning on top of it.</p> Simplified structure of a human neural system Architecture of a knowledge-based system <p>Expert systems are built like the human reasoning system, which contains short-term memory and long-term memory. Similarly, in knowledge-based systems we distinguish the following components:</p> <ul> <li>Problem memory: contains the knowledge about the problem being currently solved, i.e. the temperature or blood pressure of a patient, whether he has inflammation or not, etc. This knowledge is also called static knowledge, because it contains a snapshot of what we currently know about the problem - the so-called problem state.</li> <li>Knowledge base: represents long-term knowledge about a problem domain. It is extracted manually from human experts, and does not change from consultation to consultation. Because it allows us to navigate from one problem state to another, it is also called dynamic knowledge.</li> <li>Inference engine: orchestrates the whole process of searching in the problem state space, asking questions of the user when necessary. It is also responsible for finding the right rules to be applied to each state.</li> </ul> <p>As an example, let's consider the following expert system of determining an animal based on its physical characteristics:</p> <p></p> <p>Image by Dmitry Soshnikov</p> <p>This diagram is called an AND-OR tree, and it is a graphical representation of a set of production rules. Drawing a tree is useful at the beginning of extracting knowledge from the expert. To represent the knowledge inside the computer it is more convenient to use rules:</p> <pre><code>IF the animal eats meat\nOR (animal has sharp teeth\n    AND animal has claws\n    AND animal has forward-looking eyes\n) \nTHEN the animal is a carnivore\n</code></pre> <p>You can notice that each condition on the left-hand-side of the rule and the action are essentially object-attribute-value (OAV) triplets. Working memory contains the set of OAV triplets that correspond to the problem currently being solved. A rules engine looks for rules for which a condition is satisfied and applies them, adding another triplet to the working memory.</p> <p>\u2705 Write your own AND-OR tree on a topic you like!</p>"},{"location":"lessons/2-Symbolic/#forward-vs-backward-inference","title":"Forward vs. Backward Inference","text":"<p>The process described above is called forward inference. It starts with some initial data about the problem available in the working memory, and then executes the following reasoning loop:</p> <ol> <li>If the target attribute is present in the working memory - stop and give the result</li> <li>Look for all the rules whose condition is currently satisfied - obtain conflict set of rules.</li> <li>Perform conflict resolution - select one rule that will be executed on this step. There could be different conflict resolution strategies:</li> <li>Select the first applicable rule in the knowledge base</li> <li>Select a random rule</li> <li>Select a more specific rule, i.e. the one meeting the most conditions in the \"left-hand-side\" (LHS)</li> <li>Apply selected rule and insert new piece of knowledge into the problem state</li> <li>Repeat from step 1.</li> </ol> <p>However, in some cases we might want to start with an empty knowledge about the problem, and ask questions that will help us arrive to the conclusion. For example, when doing medical diagnosis, we usually do not perform all medical analyses in advance before starting diagnosing the patient. We rather want to perform analyses when a decision needs to be made.</p> <p>This process can be modeled using backward inference. It is driven by the goal - the attribute value that we are looking to find:</p> <ol> <li>Select all rules that can give us the value of a goal (i.e. with the goal on the RHS (\"right-hand-side\")) - a conflict set</li> <li>If there are no rules for this attribute, or there is a rule saying that we should ask the value from the user - ask for it, otherwise:</li> <li>Use conflict resolution strategy to select one rule that we will use as hypothesis - we will try to prove it</li> <li>Recurrently repeat the process for all attributes in the LHS of the rule, trying to prove them as goals</li> <li>If at any point the process fails - use another rule at step 3.</li> </ol> <p>\u2705 In which situations is forward inference more appropriate? How about backward inference?</p>"},{"location":"lessons/2-Symbolic/#implementing-expert-systems","title":"Implementing Expert Systems","text":"<p>Expert systems can be implemented using different tools:</p> <ul> <li>Programming them directly in some high level programming language. This is not the best idea, because the main advantage of a knowledge-based system is that knowledge is separated from inference, and potentially a problem domain expert should be able to write rules without understanding the details of the inference process</li> <li>Using expert systems shell, i.e. a system specifically designed to be populated by knowledge using some knowledge representation language.</li> </ul>"},{"location":"lessons/2-Symbolic/#exercise-animal-inference","title":"\u270d\ufe0f Exercise: Animal Inference","text":"<p>See Animals.ipynb for an example of implementing forward and backward inference expert system.</p> <p>Note: This example is rather simple, and only gives the idea of how an expert system looks like. Once you start creating such a system, you will only notice some intelligent behaviour from it once you reach certain number of rules, around 200+. At some point, rules become too complex to keep all of them in mind, and at this point you may start wondering why a system makes certain decisions. However, the important characteristics of knowledge-based systems is that you can always explain exactly how any of the decisions were made.</p>"},{"location":"lessons/2-Symbolic/#ontologies-and-the-semantic-web","title":"Ontologies and the Semantic Web","text":"<p>At the end of 20th century there was an initiative to use knowledge representation to annotate Internet resources, so that it would be possible to find resources that correspond to very specific queries. This motion was called Semantic Web, and it relied on several concepts:</p> <ul> <li>A special knowledge representation based on description logics (DL). It is similar to frame knowledge representation, because it builds a hierarchy of objects with properties, but it has formal logical semantics and inference. There is a whole family of DLs which balance between expressiveness and algorithmic complexity of inference.</li> <li>Distributed knowledge representation, where all concepts are represented by a global URI identifier, making it possible to create knowledge hierarchies that span the internet.</li> <li>A family of XML-based languages for knowledge description: RDF (Resource Description Framework), RDFS (RDF Schema), OWL (Ontology Web Language).</li> </ul> <p>A core concept in the Semantic Web is a concept of Ontology. It refers to a explicit specification of a problem domain using some formal knowledge representation. The simplest ontology can be just a hierarchy of objects in a problem domain, but more complex ontologies will include rules that can be used for inference.</p> <p>In the semantic web, all representations are based on triplets. Each object and each relation are uniquely identified by the URI. For example, if we want to state the fact that this AI Curriculum has been developed by Dmitry Soshnikov on Jan 1st, 2022 - here are the triplets we can use:</p> <p></p> <pre><code>http://github.com/microsoft/ai-for-beginners http://www.example.com/terms/creation-date \u201cJan 13, 2007\u201d\nhttp://github.com/microsoft/ai-for-beginners http://purl.org/dc/elements/1.1/creator http://soshnikov.com\n</code></pre> <p>\u2705 Here <code>http://www.example.com/terms/creation-date</code> and <code>http://purl.org/dc/elements/1.1/creator</code> are some well-known and universally accepted URIs to express the concepts of creator and creation date.</p> <p>In a more complex case, if we want to define a list of creators, we can use some data structures defined in RDF.</p> <p></p> <p>Diagrams above by Dmitry Soshnikov</p> <p>The progress of building the Semantic Web was somehow slowed down by the success of search engines and natural language processing techniques, which allow extracting structured data from text. However, in some areas there are still significant efforts to maintain ontologies and knowledge bases. A few projects worth noting:</p> <ul> <li>WikiData is a collection of machine readable knowledge bases associated with Wikipedia. Most of the data is mined from Wikipedia InfoBoxes, pieces of structured content inside Wikipedia pages. You can query wikidata in SPARQL, a special query language for Semantic Web. Here is a sample query that displays most popular eye colors among humans:</li> </ul> <pre><code>#defaultView:BubbleChart\nSELECT ?eyeColorLabel (COUNT(?human) AS ?count)\nWHERE\n{\n  ?human wdt:P31 wd:Q5.       # human instance-of homo sapiens\n  ?human wdt:P1340 ?eyeColor. # human eye-color ?eyeColor\n  SERVICE wikibase:label { bd:serviceParam wikibase:language \"en\". }\n}\nGROUP BY ?eyeColorLabel\n</code></pre> <ul> <li>DBpedia is another effort similar to WikiData.</li> </ul> <p>\u2705 If you want to experiment with building your own ontologies, or opening existing ones, there is a great visual ontology editor called Prot\u00e9g\u00e9. Download it, or use it online.</p> <p></p> <p>Web Prot\u00e9g\u00e9 editor open with the Romanov Family ontology. Screenshot by Dmitry Soshnikov</p>"},{"location":"lessons/2-Symbolic/#exercise-a-family-ontology","title":"\u270d\ufe0f Exercise: A Family Ontology","text":"<p>See FamilyOntology.ipynb for an example of using Semantic Web techniques to reason about family relationships. We will take a family tree represented in common GEDCOM format and an ontology of family relationships and build a graph of all family relationships for given set of individuals.</p>"},{"location":"lessons/2-Symbolic/#microsoft-concept-graph","title":"Microsoft Concept Graph","text":"<p>In most of the cases, ontologies are carefully created by hand. However, it is also possible to mine ontologies from unstructured data, for example, from natural language texts.</p> <p>One such attempt was done by Microsoft Research, and resulted in Microsoft Concept Graph.</p> <p>It is a large collection of entities grouped together using <code>is-a</code> inheritance relationship. It allows answering questions like \"What is Microsoft?\" - the answer being something like \"a company with probability 0.87, and a brand with probability 0.75\".</p> <p>The Graph is available either as REST API, or as a large downloadable text file that lists all entity pairs.</p>"},{"location":"lessons/2-Symbolic/#exercise-a-concept-graph","title":"\u270d\ufe0f Exercise: A Concept Graph","text":"<p>Try the MSConceptGraph.ipynb notebook to see how we can use Microsoft Concept Graph to group news articles into several categories.</p>"},{"location":"lessons/2-Symbolic/#conclusion","title":"Conclusion","text":"<p>Nowadays, AI is often considered to be a synonym for Machine Learning or Neural Networks. However, a human being also exhibits explicit reasoning, which is something currently not being handled by neural networks. In real world projects, explicit reasoning is still used to perform tasks that require explanations, or being able to modify the behavior of the system in a controlled way.</p>"},{"location":"lessons/2-Symbolic/#challenge","title":"\ud83d\ude80 Challenge","text":"<p>In the Family Ontology notebook associated to this lesson, there is an opportunity to experiment with other family relations. Try to discover new connections between people in the family tree.</p>"},{"location":"lessons/2-Symbolic/#post-lecture-quiz","title":"Post-lecture quiz","text":""},{"location":"lessons/2-Symbolic/#review-self-study","title":"Review &amp; Self Study","text":"<p>Do some research on the internet to discover areas where humans have tried to quantify and codify knowledge. Take a look at Bloom's Taxonomy, and go back in history to learn how humans tried to make sense of their world. Explore the work of Linnaeus to create a taxonomy of organisms, and observe the way Dmitri Mendeleev created a way for chemical elements to be described and grouped. What other interesting examples can you find?</p> <p>Assignment: Build an Ontology</p>"},{"location":"lessons/2-Symbolic/README_chs/","title":"\u77e5\u8bc6\u8868\u793a\u4e0e\u4e13\u5bb6\u7cfb\u7edf","text":"<p>\u7531 Tomomi Imura \u7ed8\u5236\u7684\u901f\u8bb0</p> <p>\u5bf9\u4eba\u5de5\u667a\u80fd\u7684\u63a2\u7d22\u57fa\u4e8e\u5bf9\u77e5\u8bc6\u7684\u8ffd\u6c42\uff0c\u5e0c\u671b\u80fd\u591f\u50cf\u4eba\u7c7b\u4e00\u6837\u7406\u89e3\u4e16\u754c\u3002\u4f46\u5982\u4f55\u5b9e\u73b0\u8fd9\u4e00\u76ee\u6807\u5462\uff1f</p>"},{"location":"lessons/2-Symbolic/README_chs/#_2","title":"\u8bfe\u524d\u6d4b\u9a8c","text":"<p>\u5728\u4eba\u5de5\u667a\u80fd\u7684\u65e9\u671f\uff0c\u521b\u5efa\u667a\u80fd\u7cfb\u7edf\u7684\u81ea\u4e0a\u800c\u4e0b\u7684\u65b9\u6cd5\uff08\u5728\u524d\u4e00\u8bfe\u4e2d\u8ba8\u8bba\u8fc7\uff09\u975e\u5e38\u6d41\u884c\u3002\u5176\u601d\u60f3\u662f\u4ece\u4eba\u4eec\u90a3\u91cc\u63d0\u53d6\u77e5\u8bc6\uff0c\u8f6c\u5316\u4e3a\u673a\u5668\u53ef\u8bfb\u7684\u5f62\u5f0f\uff0c\u7136\u540e\u7528\u5b83\u6765\u81ea\u52a8\u89e3\u51b3\u95ee\u9898\u3002\u8fd9\u79cd\u65b9\u6cd5\u57fa\u4e8e\u4e24\u5927\u601d\u60f3\uff1a</p> <ul> <li>\u77e5\u8bc6\u8868\u793a</li> <li>\u63a8\u7406</li> </ul>"},{"location":"lessons/2-Symbolic/README_chs/#_3","title":"\u77e5\u8bc6\u8868\u793a","text":"<p>\u7b26\u53f7 AI \u4e2d\u7684\u91cd\u8981\u6982\u5ff5\u4e4b\u4e00\u662f \u77e5\u8bc6\u3002\u91cd\u8981\u7684\u662f\u5c06\u77e5\u8bc6\u4e0e\u4fe1\u606f\u6216\u6570\u636e\u533a\u5206\u5f00\u3002\u4f8b\u5982\uff0c\u6211\u4eec\u53ef\u4ee5\u8bf4\u4e66\u7c4d\u5305\u542b\u77e5\u8bc6\uff0c\u56e0\u4e3a\u6211\u4eec\u53ef\u4ee5\u901a\u8fc7\u5b66\u4e60\u4e66\u7c4d\u6210\u4e3a\u4e13\u5bb6\u3002\u7136\u800c\uff0c\u4e66\u7c4d\u4e2d\u771f\u6b63\u5305\u542b\u7684\u662f\u6570\u636e\uff0c\u901a\u8fc7\u9605\u8bfb\u4e66\u7c4d\u5e76\u5c06\u8fd9\u4e9b\u6570\u636e\u6574\u5408\u5230\u6211\u4eec\u7684\u4e16\u754c\u6a21\u578b\u4e2d\uff0c\u6211\u4eec\u5c06\u6570\u636e\u8f6c\u5316\u4e3a\u77e5\u8bc6\u3002</p> <p>\u2705 \u77e5\u8bc6 \u662f\u6211\u4eec\u5934\u8111\u4e2d\u5305\u542b\u7684\u5185\u5bb9\uff0c\u4ee3\u8868\u6211\u4eec\u5bf9\u4e16\u754c\u7684\u7406\u89e3\u3002\u5b83\u662f\u901a\u8fc7\u4e00\u4e2a\u4e3b\u52a8\u7684 \u5b66\u4e60 \u8fc7\u7a0b\u83b7\u5f97\u7684\uff0c\u8fd9\u4e2a\u8fc7\u7a0b\u5c06\u6211\u4eec\u63a5\u6536\u5230\u7684\u4fe1\u606f\u7247\u6bb5\u6574\u5408\u5230\u6211\u4eec\u4e16\u754c\u7684\u6d3b\u52a8\u6a21\u578b\u4e2d\u3002</p> <p>\u6211\u4eec\u901a\u5e38\u4e0d\u4f1a\u4e25\u683c\u5b9a\u4e49\u77e5\u8bc6\uff0c\u800c\u662f\u901a\u8fc7 DIKW \u91d1\u5b57\u5854 \u5c06\u5176\u4e0e\u5176\u4ed6\u76f8\u5173\u6982\u5ff5\u5bf9\u9f50\u3002\u5b83\u5305\u542b\u4ee5\u4e0b\u6982\u5ff5\uff1a</p> <ul> <li>\u6570\u636e \u662f\u4ee5\u7269\u7406\u4ecb\u8d28\u8868\u793a\u7684\u5185\u5bb9\uff0c\u4f8b\u5982\u4e66\u9762\u6587\u5b57\u6216\u53e3\u5934\u8bdd\u8bed\u3002\u6570\u636e\u72ec\u7acb\u4e8e\u4eba\u7c7b\u5b58\u5728\uff0c\u5e76\u4e14\u53ef\u4ee5\u5728\u4eba\u4eec\u4e4b\u95f4\u4f20\u9012\u3002</li> <li>\u4fe1\u606f \u662f\u6211\u4eec\u5728\u5934\u8111\u4e2d\u89e3\u8bfb\u6570\u636e\u7684\u65b9\u5f0f\u3002\u4f8b\u5982\uff0c\u5f53\u6211\u4eec\u542c\u5230 \"\u8ba1\u7b97\u673a\" \u8fd9\u4e2a\u8bcd\u65f6\uff0c\u6211\u4eec\u5bf9\u5176\u6709\u4e00\u5b9a\u7684\u7406\u89e3\u3002</li> <li>\u77e5\u8bc6 \u662f\u4fe1\u606f\u6574\u5408\u5230\u6211\u4eec\u7684\u4e16\u754c\u6a21\u578b\u4e2d\u7684\u8fc7\u7a0b\u3002\u4f8b\u5982\uff0c\u4e00\u65e6\u6211\u4eec\u5b66\u4e60\u5230\u4ec0\u4e48\u662f\u8ba1\u7b97\u673a\uff0c\u6211\u4eec\u5c31\u5f00\u59cb\u5bf9\u5176\u5de5\u4f5c\u539f\u7406\u3001\u6210\u672c\u53ca\u7528\u9014\u6709\u4e00\u4e9b\u6982\u5ff5\u3002\u8fd9\u4e9b\u76f8\u4e92\u5173\u8054\u7684\u6982\u5ff5\u7f51\u7edc\u5f62\u6210\u4e86\u6211\u4eec\u7684\u77e5\u8bc6\u3002</li> <li>\u667a\u6167 \u662f\u6211\u4eec\u5bf9\u4e16\u754c\u7406\u89e3\u7684\u66f4\u9ad8\u4e00\u5c42\u6b21\uff0c\u4ee3\u8868\u4e86 \u5143\u77e5\u8bc6\uff0c\u5373\u5173\u4e8e\u5982\u4f55\u53ca\u4f55\u65f6\u4f7f\u7528\u77e5\u8bc6\u7684\u4e00\u4e9b\u6982\u5ff5\u3002</li> </ul> <p></p> <ul> <li>\u56fe\u7247\u6765\u6e90\uff1a\u7ef4\u57fa\u767e\u79d1\uff0c\u4f5c\u8005 Longlivetheux - \u81ea\u4f5c\uff0cCC BY-SA 4.0 *</li> </ul> <p>\u56e0\u6b64\uff0c\u77e5\u8bc6\u8868\u793a \u7684\u95ee\u9898\u5c31\u662f\u8981\u627e\u5230\u4e00\u79cd\u6709\u6548\u7684\u65b9\u6cd5\uff0c\u5c06\u77e5\u8bc6\u4ee5\u6570\u636e\u7684\u5f62\u5f0f\u8868\u793a\u5728\u8ba1\u7b97\u673a\u5185\u90e8\uff0c\u4f7f\u4e4b\u80fd\u591f\u81ea\u52a8\u5316\u4f7f\u7528\u3002\u8fd9\u53ef\u4ee5\u770b\u4f5c\u4e00\u4e2a\u5149\u8c31\uff1a</p> <p></p> <p>\u56fe\u7247\u6765\u6e90\uff1aDmitry Soshnikov</p> <ul> <li>\u5728\u5de6\u8fb9\uff0c\u6709\u975e\u5e38\u7b80\u5355\u7684\u77e5\u8bc6\u8868\u793a\u7c7b\u578b\uff0c\u8ba1\u7b97\u673a\u53ef\u4ee5\u6709\u6548\u4f7f\u7528\u3002\u6700\u7b80\u5355\u7684\u662f\u7b97\u6cd5\u578b\uff0c\u5f53\u77e5\u8bc6\u7528\u8ba1\u7b97\u673a\u7a0b\u5e8f\u8868\u793a\u65f6\u3002\u7136\u800c\uff0c\u8fd9\u4e0d\u662f\u8868\u793a\u77e5\u8bc6\u7684\u6700\u4f73\u65b9\u5f0f\uff0c\u56e0\u4e3a\u5b83\u4e0d\u7075\u6d3b\u3002\u6211\u4eec\u5934\u8111\u4e2d\u7684\u77e5\u8bc6\u901a\u5e38\u662f\u975e\u7b97\u6cd5\u6027\u7684\u3002</li> <li>\u5728\u53f3\u8fb9\uff0c\u6709\u81ea\u7136\u6587\u672c\u7b49\u8868\u793a\u65b9\u5f0f\u3002\u5b83\u662f\u6700\u5f3a\u5927\u7684\uff0c\u4f46\u4e0d\u80fd\u7528\u4e8e\u81ea\u52a8\u63a8\u7406\u3002</li> </ul> <p>\u2705 \u82b1\u4e00\u5206\u949f\u65f6\u95f4\u601d\u8003\u4f60\u5982\u4f55\u5728\u5934\u8111\u4e2d\u8868\u793a\u77e5\u8bc6\u5e76\u5c06\u5176\u8f6c\u5316\u4e3a\u7b14\u8bb0\u3002\u662f\u5426\u6709\u4e00\u79cd\u7279\u5b9a\u7684\u683c\u5f0f\u80fd\u591f\u4fc3\u8fdb\u8bb0\u5fc6\uff1f</p>"},{"location":"lessons/2-Symbolic/README_chs/#_4","title":"\u8ba1\u7b97\u673a\u77e5\u8bc6\u8868\u793a\u7684\u5206\u7c7b","text":"<p>\u6211\u4eec\u53ef\u4ee5\u5c06\u4e0d\u540c\u7684\u8ba1\u7b97\u673a\u77e5\u8bc6\u8868\u793a\u65b9\u6cd5\u5206\u4e3a\u4ee5\u4e0b\u51e0\u7c7b\uff1a</p> <ul> <li> <p>\u7f51\u7edc\u8868\u793a \u57fa\u4e8e\u6211\u4eec\u5934\u8111\u4e2d\u6709\u4e00\u4e2a\u4e92\u76f8\u5173\u8054\u7684\u6982\u5ff5\u7f51\u7edc\u8fd9\u4e00\u4e8b\u5b9e\u3002\u6211\u4eec\u53ef\u4ee5\u5c1d\u8bd5\u5728\u8ba1\u7b97\u673a\u5185\u91cd\u73b0\u76f8\u540c\u7684\u56fe\u7f51\u7edc\u2014\u2014\u4e00\u4e2a\u6240\u8c13\u7684 \u8bed\u4e49\u7f51\u7edc\u3002</p> </li> <li> <p>\u5bf9\u8c61-\u5c5e\u6027-\u503c\u4e09\u5143\u7ec4 \u6216 \u5c5e\u6027-\u503c\u5bf9\u3002\u56e0\u4e3a\u56fe\u53ef\u4ee5\u5728\u8ba1\u7b97\u673a\u5185\u8868\u793a\u4e3a\u8282\u70b9\u548c\u8fb9\u7684\u5217\u8868\uff0c\u6211\u4eec\u53ef\u4ee5\u901a\u8fc7\u4e00\u4e2a\u4e09\u5143\u7ec4\u5217\u8868\u6765\u8868\u793a\u8bed\u4e49\u7f51\u7edc\uff0c\u5305\u542b\u5bf9\u8c61\u3001\u5c5e\u6027\u548c\u503c\u3002\u4f8b\u5982\uff0c\u6211\u4eec\u53ef\u4ee5\u6784\u5efa\u4ee5\u4e0b\u5173\u4e8e\u7f16\u7a0b\u8bed\u8a00\u7684\u4e09\u5143\u7ec4\uff1a</p> </li> </ul> \u5bf9\u8c61 \u5c5e\u6027 \u503c Python \u662f \u975e\u7c7b\u578b\u5316\u8bed\u8a00 Python \u53d1\u660e\u8005\u662f Guido van Rossum Python \u4ee3\u7801\u5757\u8bed\u6cd5 \u7f29\u8fdb \u975e\u7c7b\u578b\u5316\u8bed\u8a00 \u6ca1\u6709 \u7c7b\u578b\u5b9a\u4e49 <p>\u2705 \u60f3\u4e00\u60f3\u4e09\u5143\u7ec4\u5982\u4f55\u7528\u4e8e\u8868\u793a\u5176\u4ed6\u7c7b\u578b\u7684\u77e5\u8bc6\u3002</p> <ol> <li> <p>\u5c42\u6b21\u8868\u793a \u5f3a\u8c03\u6211\u4eec\u5728\u5934\u8111\u4e2d\u7ecf\u5e38\u521b\u5efa\u5bf9\u8c61\u7684\u5c42\u6b21\u7ed3\u6784\u3002\u4f8b\u5982\uff0c\u6211\u4eec\u77e5\u9053\u91d1\u4e1d\u96c0\u662f\u4e00\u79cd\u9e1f\u7c7b\uff0c\u800c\u6240\u6709\u9e1f\u7c7b\u90fd\u6709\u7fc5\u8180\u3002\u6211\u4eec\u8fd8\u5bf9\u91d1\u4e1d\u96c0\u7684\u989c\u8272\u53ca\u5176\u98de\u884c\u901f\u5ea6\u6709\u4e00\u5b9a\u7684\u4e86\u89e3\u3002</p> </li> <li> <p>\u6846\u67b6\u8868\u793a \u57fa\u4e8e\u5c06\u6bcf\u4e2a\u5bf9\u8c61\u6216\u5bf9\u8c61\u7c7b\u8868\u793a\u4e3a\u4e00\u4e2a \u6846\u67b6\uff0c\u5176\u4e2d\u5305\u542b \u69fd\u3002\u69fd\u53ef\u80fd\u6709\u9ed8\u8ba4\u503c\u3001\u503c\u9650\u5236\u6216\u53ef\u4ee5\u8c03\u7528\u7684\u5b58\u50a8\u8fc7\u7a0b\u4ee5\u83b7\u5f97\u69fd\u7684\u503c\u3002\u6240\u6709\u6846\u67b6\u5f62\u6210\u4e00\u4e2a\u7c7b\u4f3c\u4e8e\u9762\u5411\u5bf9\u8c61\u7f16\u7a0b\u8bed\u8a00\u4e2d\u5bf9\u8c61\u5c42\u6b21\u7ed3\u6784\u7684\u5c42\u6b21\u3002</p> </li> <li>\u60c5\u666f \u662f\u4e00\u79cd\u7279\u6b8a\u7684\u6846\u67b6\uff0c\u4ee3\u8868\u53ef\u4ee5\u968f\u65f6\u95f4\u5c55\u5f00\u7684\u590d\u6742\u60c5\u5883\u3002</li> </ol> <p>Python</p> \u69fd \u503c \u9ed8\u8ba4\u503c \u533a\u95f4 \u540d\u79f0 Python \u662f \u975e\u7c7b\u578b\u5316\u8bed\u8a00 \u53d8\u91cf\u547d\u540d\u65b9\u5f0f CamelCase \u7a0b\u5e8f\u957f\u5ea6 5-5000 \u884c \u4ee3\u7801\u5757\u8bed\u6cd5 \u7f29\u8fdb <ol> <li>\u7a0b\u5e8f\u8868\u793a \u57fa\u4e8e\u8868\u793a\u4e00\u7cfb\u5217\u5f53\u67d0\u79cd\u60c5\u51b5\u53d1\u751f\u65f6\u53ef\u4ee5\u6267\u884c\u7684\u52a8\u4f5c\u3002</li> <li>\u751f\u6210\u89c4\u5219\u662f if-then \u8bed\u53e5\uff0c\u5141\u8bb8\u6211\u4eec\u63a8\u65ad\u7ed3\u8bba\u3002\u4f8b\u5982\uff0c\u4e00\u4f4d\u533b\u751f\u53ef\u80fd\u6709\u4e00\u4e2a\u89c4\u5219\u8bf4 \u5982\u679c \u75c5\u4eba\u53d1\u70e7 \u6216 \u8840\u6db2\u6d4b\u8bd5\u4e2d C \u53cd\u5e94\u86cb\u767d\u6c34\u5e73\u9ad8 \u5219 \u75c5\u4eba\u6709\u708e\u75c7\u3002\u4e00\u65e6\u6211\u4eec\u9047\u5230\u5176\u4e2d\u4e00\u4e2a\u6761\u4ef6\uff0c\u6211\u4eec\u53ef\u4ee5\u5f97\u51fa\u5173\u4e8e\u708e\u75c7\u7684\u7ed3\u8bba\uff0c\u7136\u540e\u5728\u8fdb\u4e00\u6b65\u63a8\u7406\u4e2d\u4f7f\u7528\u5b83\u3002</li> <li> <p>\u7b97\u6cd5\u53ef\u4ee5\u88ab\u8ba4\u4e3a\u662f\u53e6\u4e00\u79cd\u5f62\u5f0f\u7684\u7a0b\u5e8f\u8868\u793a\uff0c\u5c3d\u7ba1\u5728\u77e5\u8bc6\u5e93\u7cfb\u7edf\u4e2d\u51e0\u4e4e\u4ece\u672a\u76f4\u63a5\u4f7f\u7528\u3002</p> </li> <li> <p>\u903b\u8f91 \u6700\u521d\u7531\u4e9a\u91cc\u58eb\u591a\u5fb7\u63d0\u51fa\uff0c\u7528\u4e8e\u8868\u793a\u666e\u904d\u7684\u4eba\u7c7b\u77e5\u8bc6\u3002</p> </li> <li>\u8c13\u8bcd\u903b\u8f91\u4f5c\u4e3a\u4e00\u79cd\u6570\u5b66\u7406\u8bba\uff0c\u8fc7\u4e8e\u4e30\u5bcc\u800c\u4e0d\u53ef\u8ba1\u7b97\uff0c\u56e0\u6b64\u901a\u5e38\u4f7f\u7528\u5b83\u7684\u67d0\u4e2a\u5b50\u96c6\uff0c\u5982\u5728 Prolog \u4e2d\u4f7f\u7528\u7684 Horn \u5b50\u53e5\u3002</li> <li>\u63cf\u8ff0\u903b\u8f91\u662f\u4e00\u7cfb\u5217\u903b\u8f91\u7cfb\u7edf\uff0c\u7528\u4e8e\u8868\u793a\u548c\u63a8\u7406\u5173\u4e8e\u5206\u5e03\u77e5\u8bc6\u8868\u793a\u7684\u5bf9\u8c61\u5c42\u6b21\u7ed3\u6784\uff0c\u5982 \u8bed\u4e49\u7f51\u3002</li> </ol>"},{"location":"lessons/2-Symbolic/README_chs/#_5","title":"\u4e13\u5bb6\u7cfb\u7edf","text":"<p>\u7b26\u53f7 AI \u7684\u65e9\u671f\u6210\u529f\u4e4b\u4e00\u662f\u6240\u8c13\u7684 \u4e13\u5bb6\u7cfb\u7edf\u2014\u2014\u8bbe\u8ba1\u4e3a\u5728\u67d0\u4e00\u6709\u9650\u95ee\u9898\u57df\u4e2d\u5145\u5f53\u4e13\u5bb6\u7684\u8ba1\u7b97\u673a\u7cfb\u7edf\u3002\u5b83\u4eec\u57fa\u4e8e\u4ece\u4e00\u4e2a\u6216\u591a\u4e2a\u4eba\u5de5\u4e13\u5bb6\u4e2d\u63d0\u53d6\u7684 \u77e5\u8bc6\u5e93\uff0c\u5e76\u4e14\u5305\u542b\u4e00\u4e2a\u6267\u884c\u63a8\u7406\u7684 \u63a8\u7406\u5f15\u64ce\u3002</p> \u7b80\u5316\u7684\u4eba\u7c7b\u795e\u7ecf\u7cfb\u7edf\u7ed3\u6784 \u57fa\u4e8e\u77e5\u8bc6\u7cfb\u7edf\u7684\u67b6\u6784 <p>\u4e13\u5bb6\u7cfb\u7edf\u7684\u6784\u5efa\u7c7b\u4f3c\u4e8e\u4eba\u7c7b\u63a8\u7406\u7cfb\u7edf\uff0c\u5176\u4e2d\u5305\u542b \u77ed\u671f\u8bb0\u5fc6 \u548c \u957f\u671f\u8bb0\u5fc6\u3002\u540c\u6837\uff0c\u5728\u57fa\u4e8e\u77e5\u8bc6\u7684\u7cfb\u7edf\u4e2d\u6211\u4eec\u533a\u5206\u4ee5\u4e0b\u7ec4\u4ef6\uff1a</p> <ul> <li>\u95ee\u9898\u8bb0\u5fc6\uff1a\u5305\u542b\u5f53\u524d\u89e3\u51b3\u7684\u95ee\u9898\u7684\u77e5\u8bc6\uff0c\u5373\u75c5\u4eba\u7684\u4f53\u6e29\u6216\u8840\u538b\uff0c\u662f\u5426\u6709\u708e\u75c7\u7b49\u3002\u8fd9\u4e9b\u77e5\u8bc6\u4e5f\u79f0\u4e3a \u9759\u6001\u77e5\u8bc6\uff0c\u56e0\u4e3a\u5b83\u5305\u542b\u6211\u4eec\u5f53\u524d\u5bf9\u95ee\u9898\u7684\u4e86\u89e3\u7684\u5feb\u7167\u2014\u2014\u6240\u8c13\u7684 \u95ee\u9898\u72b6\u6001\u3002</li> <li>\u77e5\u8bc6\u5e93\uff1a\u4ee3\u8868\u5173\u4e8e\u95ee\u9898\u57df\u7684\u957f\u671f\u77e5\u8bc6\u3002\u5b83\u4ece\u4eba\u5de5\u4e13\u5bb6\u90a3\u91cc\u624b\u52a8\u63d0\u53d6\uff0c\u5e76\u4e14\u5728\u54a8\u8be2\u4e4b\u95f4\u4e0d\u4f1a\u6539\u53d8\u3002\u56e0\u4e3a\u5b83\u5141\u8bb8\u6211\u4eec\u4ece\u4e00\u4e2a\u95ee\u9898\u72b6\u6001\u5bfc\u822a\u5230\u53e6\u4e00\u4e2a\u95ee\u9898\u72b6\u6001\uff0c\u5b83\u4e5f\u79f0\u4e3a \u52a8\u6001\u77e5\u8bc6\u3002</li> <li>\u63a8\u7406\u5f15\u64ce\uff1a\u534f\u8c03\u6574\u4e2a\u95ee\u9898\u72b6\u6001\u7a7a\u95f4\u4e2d\u7684\u641c\u7d22\u8fc7\u7a0b\uff0c\u5728\u9700\u8981\u65f6\u5411\u7528\u6237\u63d0\u95ee\u3002\u5b83\u8fd8\u8d1f\u8d23\u4e3a\u6bcf\u4e2a\u72b6\u6001\u627e\u5230\u8981\u5e94\u7528\u7684\u6b63\u786e\u89c4\u5219\u3002</li> </ul> <p>\u4f8b\u5982\uff0c\u8ba9\u6211\u4eec\u8003\u8651\u4ee5\u4e0b\u57fa\u4e8e\u52a8\u7269\u5916\u90e8\u7279\u5f81\u786e\u5b9a\u52a8\u7269\u7684\u4e13\u5bb6\u7cfb\u7edf\uff1a</p> <p></p> <p>\u56fe\u7247\u6765\u6e90\uff1aDmitry Soshnikov</p> <p>\u6b64\u56fe\u79f0\u4e3a AND-OR \u6811\uff0c\u5b83\u662f\u751f\u4ea7\u89c4\u5219\u96c6\u7684\u56fe\u5f62\u8868\u793a\u3002\u7ed8\u5236\u6811\u5728\u4ece\u4e13\u5bb6\u63d0\u53d6\u77e5\u8bc6\u7684\u5f00\u59cb\u65f6\u5f88\u6709\u7528\u3002\u4e3a\u4e86\u5728\u8ba1\u7b97\u673a\u5185\u90e8\u8868\u793a\u77e5\u8bc6\uff0c\u4f7f\u7528\u89c4\u5219\u66f4\u52a0\u65b9\u4fbf\uff1a</p> <pre><code>\u5982\u679c\u52a8\u7269\u5403\u8089\n\u6216 (\u52a8\u7269\u6709\u5c16\u7259\n    \u4e14\u52a8\u7269\u6709\u722a\u5b50\n    \u4e14\u52a8\u7269\u6709\u5411\u524d\u770b\u7684\u773c\u775b\n) \n\u5219\u52a8\u7269\u662f\u98df\u8089\u52a8\u7269\n</code></pre> <p>\u4f60\u53ef\u4ee5\u6ce8\u610f\u5230\uff0c\u6bcf\u4e2a\u89c4\u5219\u5de6\u4fa7\u7684\u6761\u4ef6\u548c\u52a8\u4f5c\u672c\u8d28\u4e0a\u90fd\u662f\u5bf9\u8c61-\u5c5e\u6027-\u503c\uff08OAV\uff09\u4e09\u5143\u7ec4\u3002\u5de5\u4f5c\u8bb0\u5fc6 \u5305\u542b\u4e0e\u5f53\u524d\u6b63\u5728\u89e3\u51b3\u7684\u95ee\u9898\u76f8\u5bf9\u5e94\u7684 OAV \u4e09\u5143\u7ec4\u96c6\u3002\u89c4\u5219\u5f15\u64ce \u641c\u7d22\u6ee1\u8db3\u6761\u4ef6\u7684\u89c4\u5219\u5e76\u5e94\u7528\u5b83\u4eec\uff0c\u5c06\u53e6\u4e00\u4e2a\u4e09\u5143\u7ec4\u6dfb\u52a0\u5230\u5de5\u4f5c\u8bb0\u5fc6\u4e2d\u3002</p> <p>\u2705 \u5728\u4f60\u559c\u6b22\u7684\u4e3b\u9898\u4e0a\u7f16\u5199\u4f60\u81ea\u5df1\u7684 AND-OR \u6811\uff01</p>"},{"location":"lessons/2-Symbolic/README_chs/#_6","title":"\u524d\u5411\u63a8\u7406\u4e0e\u540e\u5411\u63a8\u7406","text":"<p>\u4e0a\u8ff0\u8fc7\u7a0b\u79f0\u4e3a \u524d\u5411\u63a8\u7406\u3002\u5b83\u4ece\u5de5\u4f5c\u8bb0\u5fc6\u4e2d\u53ef\u7528\u7684\u4e00\u4e9b\u521d\u59cb\u6570\u636e\u5f00\u59cb\uff0c\u7136\u540e\u6267\u884c\u4ee5\u4e0b\u63a8\u7406\u5faa\u73af\uff1a</p> <ol> <li>\u5982\u679c\u76ee\u6807\u5c5e\u6027\u5b58\u5728\u4e8e\u5de5\u4f5c\u8bb0\u5fc6\u4e2d\uff0c\u5219\u505c\u6b62\u5e76\u7ed9\u51fa\u7ed3\u679c</li> <li>\u67e5\u627e\u6761\u4ef6\u5f53\u524d\u6ee1\u8db3\u7684\u6240\u6709\u89c4\u5219\u2014\u2014\u83b7\u5f97 \u51b2\u7a81\u96c6 \u89c4\u5219\u3002</li> <li>\u6267\u884c \u51b2\u7a81\u89e3\u51b3\u2014\u2014\u9009\u62e9\u4e00\u4e2a\u8981\u5728\u6b64\u6b65\u9aa4\u6267\u884c\u7684\u89c4\u5219\u3002\u53ef\u80fd\u6709\u4e0d\u540c\u7684\u51b2\u7a81\u89e3\u51b3\u7b56\u7565\uff1a</li> <li>\u9009\u62e9\u77e5\u8bc6\u5e93\u4e2d\u7b2c\u4e00\u4e2a\u9002\u7528\u7684\u89c4\u5219</li> <li>\u968f\u673a\u9009\u62e9\u4e00\u4e2a\u89c4\u5219</li> <li>\u9009\u62e9 \u66f4\u5177\u4f53 \u7684\u89c4\u5219\uff0c\u5373\u6ee1\u8db3 \"\u5de6\u4fa7\"\uff08LHS\uff09\u4e2d\u6700\u591a\u6761\u4ef6\u7684\u89c4\u5219</li> <li>\u5e94\u7528\u9009\u62e9\u7684\u89c4\u5219\u5e76\u5c06\u65b0\u77e5\u8bc6\u63d2\u5165\u95ee\u9898\u72b6\u6001</li> <li>\u4ece\u6b65\u9aa41\u91cd\u65b0\u5f00\u59cb\u3002</li> </ol> <p>\u7136\u800c\uff0c\u5728\u67d0\u4e9b\u60c5\u51b5\u4e0b\uff0c\u6211\u4eec\u53ef\u80fd\u5e0c\u671b\u4ece\u4e00\u4e2a\u5173\u4e8e\u95ee\u9898\u7684\u7a7a\u767d\u77e5\u8bc6\u5f00\u59cb\uff0c\u5e76\u63d0\u51fa\u6709\u52a9\u4e8e\u6211\u4eec\u5f97\u51fa\u7ed3\u8bba\u7684\u95ee\u9898\u3002\u4f8b\u5982\uff0c\u5728\u8fdb\u884c\u533b\u5b66\u8bca\u65ad\u65f6\uff0c\u6211\u4eec\u901a\u5e38\u4e0d\u4f1a\u5728\u5f00\u59cb\u8bca\u65ad\u75c5\u4eba\u4e4b\u524d\u8fdb\u884c\u6240\u6709\u533b\u5b66\u5206\u6790\u3002\u6211\u4eec\u5e0c\u671b\u5728\u9700\u8981\u505a\u51fa\u51b3\u7b56\u65f6\u8fdb\u884c\u5206\u6790\u3002</p> <p>\u6b64\u8fc7\u7a0b\u53ef\u4ee5\u7528 \u540e\u5411\u63a8\u7406 \u5efa\u6a21\u3002\u5b83\u7531 \u76ee\u6807 \u9a71\u52a8\u2014\u2014\u6211\u4eec\u6b63\u5728\u5bfb\u627e\u7684\u5c5e\u6027\u503c\uff1a</p> <ol> <li>\u9009\u62e9\u6240\u6709\u53ef\u4ee5\u7ed9\u6211\u4eec\u76ee\u6807\u503c\u7684\u89c4\u5219\uff08\u5373\u5728 RHS\uff08\"\u53f3\u4fa7\"\uff09\u4e2d\u6709\u76ee\u6807\uff09\u2014\u2014\u51b2\u7a81\u96c6</li> <li>\u5982\u679c\u6ca1\u6709\u8be5\u5c5e\u6027\u7684\u89c4\u5219\uff0c\u6216\u8005\u6709\u89c4\u5219\u8868\u793a\u6211\u4eec\u5e94\u8be5\u95ee\u7528\u6237\u8be5\u503c\u2014\u2014\u8be2\u95ee\u5b83\uff0c\u5426\u5219\uff1a</li> <li>\u4f7f\u7528\u51b2\u7a81\u89e3\u51b3\u7b56\u7565\u9009\u62e9\u4e00\u4e2a\u6211\u4eec\u5c06\u7528\u4f5c\u5047\u8bbe\u7684\u89c4\u5219\u2014\u2014\u6211\u4eec\u5c06\u5c1d\u8bd5\u8bc1\u660e\u5b83</li> <li>\u9012\u5f52\u5730\u5bf9\u89c4\u5219 LHS \u4e2d\u7684\u6240\u6709\u5c5e\u6027\u91cd\u590d\u6b64\u8fc7\u7a0b\uff0c\u5c1d\u8bd5\u8bc1\u660e\u5b83\u4eec\u4e3a\u76ee\u6807</li> <li>\u5982\u679c\u5728\u4efb\u4f55\u65f6\u5019\u8fdb\u7a0b\u5931\u8d25\u2014\u2014\u5728\u6b65\u9aa43\u4e2d\u4f7f\u7528\u53e6\u4e00\u4e2a\u89c4\u5219\u3002</li> </ol> <p>\u2705 \u54ea\u4e9b\u60c5\u51b5\u4e0b\u524d\u5411\u63a8\u7406\u66f4\u5408\u9002\uff1f\u540e\u5411\u63a8\u7406\u5462\uff1f</p>"},{"location":"lessons/2-Symbolic/README_chs/#_7","title":"\u5b9e\u73b0\u4e13\u5bb6\u7cfb\u7edf","text":"<p>\u4e13\u5bb6\u7cfb\u7edf\u53ef\u4ee5\u4f7f\u7528\u4e0d\u540c\u7684\u5de5\u5177\u5b9e\u73b0\uff1a</p> <ul> <li>\u76f4\u63a5\u5728\u67d0\u4e9b\u9ad8\u7ea7\u7f16\u7a0b\u8bed\u8a00\u4e2d\u7f16\u5199\u5b83\u4eec\u3002\u8fd9\u4e0d\u662f\u6700\u597d\u7684\u65b9\u6cd5\uff0c\u56e0\u4e3a\u57fa\u4e8e\u77e5\u8bc6\u7684\u7cfb\u7edf\u7684\u4e3b\u8981\u4f18\u70b9\u662f\u77e5\u8bc6\u4e0e\u63a8\u7406\u5206\u79bb\uff0c\u5e76\u4e14\u6f5c\u5728\u95ee\u9898\u57df\u4e13\u5bb6\u5e94\u80fd\u591f\u7f16\u5199\u89c4\u5219\u800c\u65e0\u9700\u7406\u89e3\u63a8\u7406\u8fc7\u7a0b\u7684\u8be6\u7ec6\u4fe1\u606f\u3002</li> <li>\u4f7f\u7528 \u4e13\u5bb6\u7cfb\u7edf\u5916\u58f3\uff0c\u5373\u4e13\u95e8\u8bbe\u8ba1\u4e3a\u901a\u8fc7\u67d0\u79cd\u77e5\u8bc6\u8868\u793a\u8bed\u8a00\u586b\u5145\u77e5\u8bc6\u7684\u7cfb\u7edf\u3002</li> </ul>"},{"location":"lessons/2-Symbolic/README_chs/#_8","title":"\u270d\ufe0f \u7ec3\u4e60\uff1a\u52a8\u7269\u63a8\u7406","text":"<p>\u53c2\u89c1 Animals.ipynb \u83b7\u53d6\u5982\u4f55\u5b9e\u73b0\u524d\u5411\u548c\u540e\u5411\u63a8\u7406\u4e13\u5bb6\u7cfb\u7edf\u7684\u793a\u4f8b\u3002</p> <p>\u6ce8\u610f\uff1a\u8fd9\u4e2a\u793a\u4f8b\u76f8\u5bf9\u7b80\u5355\uff0c\u4ec5\u63d0\u4f9b\u4e13\u5bb6\u7cfb\u7edf\u7684\u5916\u89c2\u6982\u5ff5\u3002\u4e00\u65e6\u4f60\u5f00\u59cb\u521b\u5efa\u8fd9\u6837\u7684\u7cfb\u7edf\uff0c\u4f60\u5c06\u4f1a\u6ce8\u610f\u5230\uff0c\u53ea\u6709\u5f53\u4f60\u8fbe\u5230\u4e00\u5b9a\u6570\u91cf\u7684\u89c4\u5219\uff08\u5927\u7ea6200+\uff09\u65f6\uff0c\u4f60\u624d\u4f1a\u770b\u5230\u4e00\u4e9b \u667a\u80fd \u884c\u4e3a\u3002\u5230\u67d0\u4e00\u65f6\u523b\uff0c\u89c4\u5219\u53d8\u5f97\u8fc7\u4e8e\u590d\u6742\uff0c\u65e0\u6cd5\u5168\u90e8\u8bb0\u4f4f\uff0c\u6b64\u65f6\u4f60\u53ef\u80fd\u4f1a\u60f3\u77e5\u9053\u4e3a\u4ec0\u4e48\u7cfb\u7edf\u505a\u51fa\u67d0\u4e9b\u51b3\u7b56\u3002\u7136\u800c\uff0c\u57fa\u4e8e\u77e5\u8bc6\u7684\u7cfb\u7edf\u7684\u91cd\u8981\u7279\u5f81\u662f\u4f60\u59cb\u7ec8\u53ef\u4ee5 \u89e3\u91ca \u4efb\u4f55\u51b3\u7b56\u662f\u5982\u4f55\u505a\u51fa\u7684\u3002</p>"},{"location":"lessons/2-Symbolic/README_chs/#_9","title":"\u672c\u4f53\u8bba\u4e0e\u8bed\u4e49\u7f51","text":"<p>\u5728\u4e8c\u5341\u4e16\u7eaa\u672b\uff0c\u6709\u4e00\u4e2a\u4f7f\u7528\u77e5\u8bc6\u8868\u793a\u6765\u6ce8\u91ca\u4e92\u8054\u7f51\u8d44\u6e90\u7684\u5021\u8bae\uff0c\u4ee5\u4fbf\u80fd\u591f\u627e\u5230\u5bf9\u5e94\u975e\u5e38\u5177\u4f53\u67e5\u8be2\u7684\u8d44\u6e90\u3002\u8fd9\u4e00\u8fd0\u52a8\u79f0\u4e3a \u8bed\u4e49\u7f51\uff0c\u5b83\u4f9d\u8d56\u4e8e\u51e0\u4e2a\u6982\u5ff5\uff1a</p> <ul> <li>\u57fa\u4e8e \u63cf\u8ff0\u903b\u8f91 (DL) \u7684\u7279\u6b8a\u77e5\u8bc6\u8868\u793a\u3002\u5b83\u7c7b\u4f3c\u4e8e\u6846\u67b6\u77e5\u8bc6\u8868\u793a\uff0c\u56e0\u4e3a\u5b83\u6784\u5efa\u4e86\u5bf9\u8c61\u7684\u5c42\u6b21\u7ed3\u6784\u548c\u5c5e\u6027\uff0c\u4f46\u5177\u6709\u5f62\u5f0f\u903b\u8f91\u8bed\u4e49\u548c\u63a8\u7406\u3002\u6709\u4e00\u6574\u5957\u5e73\u8861\u8868\u8fbe\u80fd\u529b\u548c\u63a8\u7406\u7b97\u6cd5\u590d\u6742\u6027\u7684 DL \u5bb6\u65cf\u3002</li> <li>\u5206\u5e03\u5f0f\u77e5\u8bc6\u8868\u793a\uff0c\u5176\u4e2d\u6240\u6709\u6982\u5ff5\u90fd\u7531\u5168\u5c40 URI \u6807\u8bc6\u7b26\u8868\u793a\uff0c\u4f7f\u5176\u80fd\u591f\u521b\u5efa\u8de8\u8d8a\u4e92\u8054\u7f51\u7684\u77e5\u8bc6\u5c42\u6b21\u3002</li> <li>\u4e00\u65cf\u57fa\u4e8e XML \u7684\u77e5\u8bc6\u63cf\u8ff0\u8bed\u8a00\uff1aRDF\uff08\u8d44\u6e90\u63cf\u8ff0\u6846\u67b6\uff09\u3001RDFS\uff08RDF \u67b6\u6784\uff09\u3001OWL\uff08\u672c\u4f53\u7f51\u8bed\u8a00\uff09\u3002</li> </ul> <p>\u8bed\u4e49\u7f51\u7684\u6838\u5fc3\u6982\u5ff5\u662f \u672c\u4f53 \u7684\u6982\u5ff5\u3002\u5b83\u6307\u7684\u662f\u4f7f\u7528\u67d0\u79cd\u5f62\u5f0f\u77e5\u8bc6\u8868\u793a\u660e\u786e\u6307\u5b9a\u7684\u95ee\u9898\u57df\u3002\u6700\u7b80\u5355\u7684\u672c\u4f53\u53ef\u4ee5\u53ea\u662f\u95ee\u9898\u57df\u4e2d\u7684\u5bf9\u8c61\u5c42\u6b21\u7ed3\u6784\uff0c\u4f46\u66f4\u590d\u6742\u7684\u672c\u4f53\u5c06\u5305\u62ec\u53ef\u7528\u4e8e\u63a8\u7406\u7684\u89c4\u5219\u3002</p> <p>\u5728\u8bed\u4e49\u7f51\u4e2d\uff0c\u6240\u6709\u8868\u793a\u57fa\u4e8e\u4e09\u5143\u7ec4\u3002\u6bcf\u4e2a\u5bf9\u8c61\u548c\u6bcf\u4e2a\u5173\u7cfb\u90fd\u7531 URI \u552f\u4e00\u6807\u8bc6\u3002\u4f8b\u5982\uff0c\u5982\u679c\u6211\u4eec\u60f3\u8981\u58f0\u660e AI \u8bfe\u7a0b\u7531 Dmitry Soshnikov \u4e8e 2022 \u5e74 1 \u6708 1 \u65e5\u5f00\u53d1\u7684\u4e8b\u5b9e\uff0c\u8fd9\u91cc\u662f\u53ef\u4ee5\u4f7f\u7528\u7684\u4e09\u5143\u7ec4\uff1a</p> <p></p> <pre><code>http://github.com/microsoft/ai-for-beginners http://www.example.com/terms/creation-date \"2022-01-01\"\nhttp://github.com/microsoft/ai-for-beginners http://purl.org/dc/elements/1.1/creator http://soshnikov.com\n</code></pre> <p>\u2705 \u8fd9\u91cc <code>http://www.example.com/terms/creation-date</code> \u548c <code>http://purl.org/dc/elements/1.1/creator</code> \u662f\u4e00\u4e9b\u516c\u8ba4\u53ef\u8868\u8fbe \u521b\u9020\u8005 \u548c \u521b\u5efa\u65e5\u671f \u6982\u5ff5\u7684 URI\u3002</p> <p>\u5728\u66f4\u590d\u6742\u7684\u60c5\u51b5\u4e0b\uff0c\u5982\u679c\u6211\u4eec\u60f3\u8981\u5b9a\u4e49\u4e00\u4e2a\u521b\u9020\u8005\u5217\u8868\uff0c\u6211\u4eec\u53ef\u4ee5\u4f7f\u7528 RDF \u4e2d\u5b9a\u4e49\u7684\u4e00\u4e9b\u6570\u636e\u7ed3\u6784\u3002</p> <p></p> <p>\u4e0a\u56fe\u6765\u6e90\uff1aDmitry Soshnikov</p> <p>\u8bed\u4e49\u7f51\u7684\u8fdb\u5c55\u56e0\u641c\u7d22\u5f15\u64ce\u548c\u81ea\u7136\u8bed\u8a00\u5904\u7406\u6280\u672f\u7684\u6210\u529f\u800c\u6709\u6240\u653e\u7f13\uff0c\u8fd9\u4e9b\u6280\u672f\u5141\u8bb8\u4ece\u6587\u672c\u4e2d\u63d0\u53d6\u7ed3\u6784\u5316\u6570\u636e\u3002\u7136\u800c\uff0c\u5728\u67d0\u4e9b\u9886\u57df\u4ecd\u6709\u663e\u8457\u7684\u52aa\u529b\u6765\u7ef4\u62a4\u672c\u4f53\u8bba\u548c\u77e5\u8bc6\u5e93\u3002\u4e00\u4e9b\u503c\u5f97\u6ce8\u610f\u7684\u9879\u76ee\uff1a</p> <ul> <li>WikiData \u662f\u4e0e\u7ef4\u57fa\u767e\u79d1\u5173\u8054\u7684\u673a\u5668\u53ef\u8bfb\u77e5\u8bc6\u5e93\u7684\u96c6\u5408\u3002\u5927\u591a\u6570\u6570\u636e\u4ece\u7ef4\u57fa\u767e\u79d1 \u4fe1\u606f\u6846 \u4e2d\u6316\u6398\u51fa\u6765\uff0c\u8fd9\u4e9b\u4fe1\u606f\u6846\u662f\u7ef4\u57fa\u767e\u79d1\u9875\u9762\u4e2d\u7684\u7ed3\u6784\u5316\u5185\u5bb9\u3002\u4f60\u53ef\u4ee5\u7528 SPARQL\uff08\u8bed\u4e49\u7f51\u7684\u7279\u6b8a\u67e5\u8be2\u8bed\u8a00\uff09\u67e5\u8be2 Wikidata\u3002\u8fd9\u662f\u4e00\u4e2a\u663e\u793a\u4eba\u7c7b\u4e2d\u6700\u6d41\u884c\u7684\u773c\u775b\u989c\u8272\u7684\u793a\u4f8b\u67e5\u8be2\uff1a</li> </ul> <pre><code>#defaultView:BubbleChart\nSELECT ?eyeColorLabel (COUNT(?human) AS ?count)\nWHERE\n{\n  ?human wdt:P31 wd:Q5.       # human instance-of homo sapiens\n  ?human wdt:P1340 ?eyeColor. # human eye-color ?eyeColor\n  SERVICE wikibase:label { bd:serviceParam wikibase:language \"en\". }\n}\nGROUP BY ?eyeColorLabel\n</code></pre> <ul> <li>DBpedia \u662f\u53e6\u4e00\u4e2a\u7c7b\u4f3c WikiData \u7684\u52aa\u529b\u3002</li> </ul> <p>\u2705 \u5982\u679c\u4f60\u60f3\u4f53\u9a8c\u6784\u5efa\u81ea\u5df1\u7684\u672c\u4f53\u8bba\u6216\u6253\u5f00\u73b0\u6709\u7684\u672c\u4f53\u8bba\uff0c\u6709\u4e00\u4e2a\u5f88\u68d2\u7684\u89c6\u89c9\u672c\u4f53\u7f16\u8f91\u5668\u53eb\u505a Prot\u00e9g\u00e9\u3002\u4e0b\u8f7d\u5b83\uff0c\u6216\u8005\u5728\u7ebf\u4f7f\u7528\u3002</p> <p></p> <p>Web Prot\u00e9g\u00e9 \u7f16\u8f91\u5668\u6253\u5f00\u4e86\u7f57\u66fc\u8bfa\u592b\u5bb6\u5ead\u7684\u672c\u4f53\u3002\u622a\u56fe\u7531 Dmitry Soshnikov \u63d0\u4f9b</p>"},{"location":"lessons/2-Symbolic/README_chs/#_10","title":"\u270d\ufe0f \u7ec3\u4e60\uff1a\u4e00\u4e2a\u5bb6\u5ead\u672c\u4f53\u8bba","text":"<p>\u53c2\u89c1 FamilyOntology.ipynb \u83b7\u53d6\u4e00\u4e2a\u4f7f\u7528\u8bed\u4e49\u7f51\u6280\u672f\u6765\u63a8\u7406\u5bb6\u65cf\u5173\u7cfb\u7684\u793a\u4f8b\u3002\u6211\u4eec\u5c06\u4f7f\u7528\u901a\u7528 GEDCOM \u683c\u5f0f\u8868\u793a\u7684\u5bb6\u8c31\u548c\u5bb6\u5ead\u5173\u7cfb\u672c\u4f53\uff0c\u4e3a\u7ed9\u5b9a\u7684\u4e00\u7ec4\u4e2a\u4eba\u6784\u5efa\u6240\u6709\u5bb6\u5ead\u5173\u7cfb\u7684\u56fe\u3002</p>"},{"location":"lessons/2-Symbolic/README_chs/#microsoft-concept-graph","title":"Microsoft Concept Graph","text":"<p>\u5728\u5927\u591a\u6570\u60c5\u51b5\u4e0b\uff0c\u672c\u4f53\u8bba\u662f\u7531\u4eba\u5de5\u7ec6\u5fc3\u521b\u5efa\u7684\u3002\u7136\u800c\uff0c\u4e5f\u6709\u53ef\u80fd\u4ece\u975e\u7ed3\u6784\u5316\u6570\u636e\u4e2d \u6316\u6398 \u672c\u4f53\u8bba\uff0c\u4f8b\u5982\uff0c\u4ece\u81ea\u7136\u8bed\u8a00\u6587\u672c\u4e2d\u3002</p> <p>\u5fae\u8f6f\u7814\u7a76\u9662\u505a\u4e86\u4e00\u6b21\u8fd9\u6837\u7684\u5c1d\u8bd5\uff0c\u5e76\u5f97\u51fa\u4e86 Microsoft Concept Graph\u3002</p> <p>\u5b83\u662f\u4e00\u4e2a\u4f7f\u7528 <code>is-a</code> \u7ee7\u627f\u5173\u7cfb\u5c06\u5b9e\u4f53\u5206\u7ec4\u5728\u4e00\u8d77\u7684\u5927\u578b\u96c6\u5408\u3002\u5b83\u5141\u8bb8\u56de\u7b54\u8bf8\u5982 \"\u4ec0\u4e48\u662f\u5fae\u8f6f\u516c\u53f8\uff1f\" \u8fd9\u6837\u7684\u95ee\u9898\u2014\u2014\u7b54\u6848\u7c7b\u4f3c\u4e8e \"\u4e00\u4e2a\u516c\u53f8\uff0c\u6982\u7387\u4e3a 0.87\uff0c\u4e00\u4e2a\u54c1\u724c\uff0c\u6982\u7387\u4e3a 0.75\"\u3002</p> <p>\u8be5\u56fe\u53ef\u4ee5\u4f5c\u4e3a REST API \u4f7f\u7528\uff0c\u6216\u8005\u4f5c\u4e3a\u4e00\u4e2a\u5305\u542b\u6240\u6709\u5b9e\u4f53\u5bf9\u7684\u5927\u578b\u53ef\u4e0b\u8f7d\u6587\u672c\u6587\u4ef6\u3002</p>"},{"location":"lessons/2-Symbolic/README_chs/#_11","title":"\u270d\ufe0f \u7ec3\u4e60\uff1a\u6982\u5ff5\u56fe","text":"<p>\u5c1d\u8bd5 MSConceptGraph.ipynb \u7b14\u8bb0\u672c\uff0c\u4e86\u89e3\u5982\u4f55\u4f7f\u7528 Microsoft Concept Graph \u5c06\u65b0\u95fb\u6587\u7ae0\u5206\u7ec4\u5230\u591a\u4e2a\u7c7b\u522b\u4e2d\u3002</p>"},{"location":"lessons/2-Symbolic/README_chs/#_12","title":"\u7ed3\u8bba","text":"<p>\u5982\u4eca\uff0cAI \u7ecf\u5e38\u88ab\u8ba4\u4e3a\u662f \u673a\u5668\u5b66\u4e60 \u6216 \u795e\u7ecf\u7f51\u7edc \u7684\u540c\u4e49\u8bcd\u3002\u7136\u800c\uff0c\u4eba\u7c7b\u8fd8\u5c55\u73b0\u51fa\u660e\u786e\u7684\u63a8\u7406\u80fd\u529b\uff0c\u800c\u8fd9\u662f\u5f53\u524d\u795e\u7ecf\u7f51\u7edc\u5c1a\u672a\u5904\u7406\u7684\u5185\u5bb9\u3002\u5728\u5b9e\u9645\u9879\u76ee\u4e2d\uff0c\u660e\u786e\u63a8\u7406\u4ecd\u7136\u88ab\u7528\u6765\u5b8c\u6210\u9700\u8981\u89e3\u91ca\u6216\u80fd\u591f\u4ee5\u53ef\u63a7\u65b9\u5f0f\u4fee\u6539\u7cfb\u7edf\u884c\u4e3a\u7684\u4efb\u52a1\u3002</p>"},{"location":"lessons/2-Symbolic/README_chs/#_13","title":"\ud83d\ude80 \u6311\u6218","text":"<p>\u5728\u4e0e\u672c\u8bfe\u76f8\u5173\u7684\u201c\u5bb6\u65cf\u672c\u4f53\u201d\u7b14\u8bb0\u672c\u4e2d\uff0c\u53ef\u4ee5\u5c1d\u8bd5\u63a2\u7d22\u5176\u4ed6\u5bb6\u5ead\u5173\u7cfb\u3002\u8bd5\u7740\u53d1\u73b0\u5bb6\u8c31\u4e2d\u4eba\u4e0e\u4eba\u4e4b\u95f4\u7684\u65b0\u8fde\u63a5\u3002</p>"},{"location":"lessons/2-Symbolic/README_chs/#_14","title":"\u8bfe\u540e\u6d4b\u9a8c","text":""},{"location":"lessons/2-Symbolic/README_chs/#_15","title":"\u590d\u4e60\u4e0e\u81ea\u5b66","text":"<p>\u901a\u8fc7\u4e92\u8054\u7f51\u8fdb\u884c\u7814\u7a76\uff0c\u53d1\u73b0\u4eba\u7c7b\u5c1d\u8bd5\u91cf\u5316\u548c\u7f16\u7801\u77e5\u8bc6\u7684\u9886\u57df\u3002\u4e86\u89e3\u5e03\u9c81\u59c6\u5206\u7c7b\u6cd5\uff08Bloom's Taxonomy\uff09\uff0c\u5e76\u56de\u987e\u5386\u53f2\uff0c\u4e86\u89e3\u4eba\u7c7b\u5982\u4f55\u5c1d\u8bd5\u7406\u89e3\u4ed6\u4eec\u7684\u4e16\u754c\u3002\u63a2\u7d22\u6797\u5948\uff08Linnaeus\uff09\u5bf9\u751f\u7269\u8fdb\u884c\u5206\u7c7b\u7684\u5de5\u4f5c\uff0c\u5e76\u89c2\u5bdf\u5fb7\u7c73\u7279\u91cc\u00b7\u95e8\u6377\u5217\u592b\uff08Dmitri Mendeleev\uff09\u5982\u4f55\u4e3a\u5316\u5b66\u5143\u7d20\u521b\u5efa\u63cf\u8ff0\u548c\u5206\u7ec4\u7684\u65b9\u6cd5\u3002\u4f60\u8fd8\u80fd\u627e\u5230\u54ea\u4e9b\u6709\u8da3\u7684\u4f8b\u5b50\uff1f</p> <p>\u4f5c\u4e1a: \u6784\u5efa\u672c\u4f53</p>"},{"location":"lessons/2-Symbolic/assignment/","title":"Build an Ontology","text":"<p>Building a knowledge base is all about categorizing a model representing facts about a topic. Pick a topic - like a person, a place, or a thing - and then build a model of that topic. Use some of the techniques and model-building strategies described in this lesson. An example would be creating an ontology of a living room with furniture, lights, and so on. How does the living room differ from the kitchen? The bathroom? How do you know it's a living room and not a dining room? Use Prot\u00e9g\u00e9 to build your ontology.</p>"},{"location":"lessons/2-Symbolic/assignment_chs/","title":"\u6784\u5efa\u4e00\u4e2a\u672c\u4f53","text":"<p>\u6784\u5efa\u4e00\u4e2a\u77e5\u8bc6\u5e93\u662f\u5173\u4e8e\u4e3a\u67d0\u4e2a\u4e3b\u9898\u6784\u5efa\u4e00\u4e2a\u53cd\u6620\u4e8b\u5b9e\u7684\u6a21\u578b\u3002\u9009\u62e9\u4e00\u4e2a\u4e3b\u9898 - \u6bd4\u5982\u4e00\u4e2a\u4eba\u3001\u4e00\u4e2a\u5730\u65b9\u6216\u4e00\u4e2a\u4e8b\u7269 - \u7136\u540e\u4e3a\u8be5\u4e3b\u9898\u6784\u5efa\u4e00\u4e2a\u6a21\u578b\u3002\u4f7f\u7528\u672c\u8bfe\u4e2d\u4ecb\u7ecd\u7684\u4e00\u4e9b\u6280\u672f\u548c\u6a21\u578b\u6784\u5efa\u7b56\u7565\u3002\u4e00\u4e2a\u4f8b\u5b50\u662f\u521b\u5efa\u4e00\u4e2a\u5e26\u6709\u5bb6\u5177\u3001\u706f\u5177\u7b49\u7684\u5ba2\u5385\u672c\u4f53\u3002\u5ba2\u5385\u4e0e\u53a8\u623f\u6709\u4f55\u4e0d\u540c\uff1f\u4e0e\u6d74\u5ba4\u6709\u4ec0\u4e48\u4e0d\u540c\uff1f\u4f60\u5982\u4f55\u77e5\u9053\u8fd9\u662f\u4e00\u4e2a\u5ba2\u5385\u800c\u4e0d\u662f\u9910\u5385\uff1f\u4f7f\u7528 Prot\u00e9g\u00e9 \u6765\u6784\u5efa\u4f60\u7684\u672c\u4f53\u3002</p>"},{"location":"lessons/3-NeuralNetworks/","title":"Introduction to Neural Networks","text":"<p>As we discussed in the introduction, one of the ways to achieve intelligence is to train a computer model or an artificial brain. Since the middle of 20th century, researchers tried different mathematical models, until in recent years this direction proved to by hugely successful. Such mathematical models of the brain are called neural networks.</p> <p>Sometimes neural networks are called Artificial Neural Networks, ANNs, in order to indicate that we are talking about models, not real networks of neurons.</p>"},{"location":"lessons/3-NeuralNetworks/#machine-learning","title":"Machine Learning","text":"<p>Neural Networks are a part of a larger discipline called Machine Learning, whose goal is to use data to train computer models that are able to solve problems. Machine Learning constitutes a large part of Artificial Intelligence, however, we do not cover classical ML in this curricula.</p> <p>Visit our separate Machine Learning for Beginners curriculum to learn more about classic Machine Learning.</p> <p>In Machine Learning, we assume that we have some dataset of examples X, and corresponding output values Y. Examples are often N-dimensional vectors that consist of features, and outputs are called labels.</p> <p>We will consider the two most common machine learning problems:</p> <ul> <li>Classification, where we need to classify an input object into two or more classes.</li> <li>Regression, where we need to predict a numerical number for each of the input samples.</li> </ul> <p>When representing inputs and outputs as tensors, the input dataset is a matrix of size M\u00d7N, where M is number of samples and N is the number of features. Output labels Y is the vector of size M.</p> <p>In this curriculum, we will only focus on neural network models.</p>"},{"location":"lessons/3-NeuralNetworks/#a-model-of-a-neuron","title":"A Model of a Neuron","text":"<p>From biology we know that our brain consists of neural cells, each of them having multiple \"inputs\" (axons), and an output (dendrite). Axons and dendrites can conduct electrical signals, and connections between axons and dendrites can exhibit different degrees of conductivity (controlled by neuromediators).</p> Real Neuron (Image from Wikipedia) Artificial Neuron (Image by Author) <p>Thus, the simplest mathematical model of a neuron contains several inputs X<sub>1</sub>, ..., X<sub>N</sub> and an output Y, and a series of weights W<sub>1</sub>, ..., W<sub>N</sub>. An output is calculated as:</p> <p></p> <p>where f is some non-linear activation function.</p> <p>Early models of neuron were described in the classical paper A logical calculus of the ideas immanent in nervous activity by Warren McCullock and Walter Pitts in 1943. Donald Hebb in his book \"The Organization of Behavior: A Neuropsychological Theory\" proposed the way those networks can be trained.</p>"},{"location":"lessons/3-NeuralNetworks/#in-this-section","title":"In this Section","text":"<p>In this section we will learn about: * Perceptron, one of the earliest neural network models for two-class classification * Multi-layered networks with a paired notebook how to build our own framework * Neural Network Frameworks, with these notebooks: PyTorch and Keras/Tensorflow * Overfitting</p>"},{"location":"lessons/3-NeuralNetworks/README_chs/","title":"\u795e\u7ecf\u7f51\u7edc\u4ecb\u7ecd","text":"<p>\u5982\u6211\u4eec\u5728\u4ecb\u7ecd\u4e2d\u8ba8\u8bba\u7684\u90a3\u6837\uff0c\u5b9e\u73b0\u667a\u80fd\u7684\u4e00\u79cd\u65b9\u5f0f\u662f\u8bad\u7ec3\u4e00\u4e2a\u8ba1\u7b97\u673a\u6a21\u578b\u6216\u4e00\u4e2a\u4eba\u5de5\u5927\u8111\u3002\u81ea20\u4e16\u7eaa\u4e2d\u53f6\u4ee5\u6765\uff0c\u7814\u7a76\u4eba\u5458\u5c1d\u8bd5\u4e86\u4e0d\u540c\u7684\u6570\u5b66\u6a21\u578b\uff0c\u76f4\u5230\u6700\u8fd1\u51e0\u5e74\u8fd9\u79cd\u65b9\u5411\u624d\u88ab\u8bc1\u660e\u662f\u975e\u5e38\u6210\u529f\u7684\u3002\u8fd9\u4e9b\u5927\u8111\u7684\u6570\u5b66\u6a21\u578b\u79f0\u4e3a\u795e\u7ecf\u7f51\u7edc\u3002</p> <p>\u6709\u65f6\u795e\u7ecf\u7f51\u7edc\u88ab\u79f0\u4e3a\u4eba\u5de5\u795e\u7ecf\u7f51\u7edc\uff0c\u5373ANNs\uff0c\u7528\u4ee5\u8868\u660e\u6211\u4eec\u8ba8\u8bba\u7684\u6a21\u578b\uff0c\u800c\u4e0d\u662f\u771f\u6b63\u7684\u795e\u7ecf\u5143\u7f51\u7edc\u3002</p>"},{"location":"lessons/3-NeuralNetworks/README_chs/#_2","title":"\u673a\u5668\u5b66\u4e60","text":"<p>\u795e\u7ecf\u7f51\u7edc\u5c5e\u4e8e\u4e00\u4e2a\u66f4\u5927\u7684\u5b66\u79d1\uff0c\u79f0\u4e3a\u673a\u5668\u5b66\u4e60\uff0c\u5176\u76ee\u6807\u662f\u4f7f\u7528\u6570\u636e\u8bad\u7ec3\u80fd\u591f\u89e3\u51b3\u95ee\u9898\u7684\u8ba1\u7b97\u673a\u6a21\u578b\u3002\u673a\u5668\u5b66\u4e60\u6784\u6210\u4e86\u4eba\u5de5\u667a\u80fd\u7684\u5f88\u5927\u4e00\u90e8\u5206\uff0c\u7136\u800c\uff0c\u6211\u4eec\u5728\u672c\u8bfe\u7a0b\u4e2d\u4e0d\u6db5\u76d6\u7ecf\u5178\u7684\u673a\u5668\u5b66\u4e60\u3002</p> <p>\u8bbf\u95ee\u6211\u4eec\u7684\u72ec\u7acb\u8bfe\u7a0b \u521d\u5b66\u8005\u7684\u673a\u5668\u5b66\u4e60 \u4ee5\u4e86\u89e3\u66f4\u591a\u5173\u4e8e\u7ecf\u5178\u673a\u5668\u5b66\u4e60\u7684\u4fe1\u606f\u3002</p> <p>\u5728\u673a\u5668\u5b66\u4e60\u4e2d\uff0c\u6211\u4eec\u5047\u8bbe\u6709\u4e00\u4e9b\u4f8b\u5b50\u6570\u636e\u96c6X\u548c\u76f8\u5e94\u7684\u8f93\u51fa\u503cY\u3002\u4f8b\u5b50\u901a\u5e38\u662f\u7531\u7279\u5f81\u7ec4\u6210\u7684N\u7ef4\u5411\u91cf\uff0c\u800c\u8f93\u51fa\u79f0\u4e3a\u6807\u7b7e\u3002</p> <p>\u6211\u4eec\u5c06\u8003\u8651\u4e24\u79cd\u6700\u5e38\u89c1\u7684\u673a\u5668\u5b66\u4e60\u95ee\u9898\uff1a</p> <ul> <li>\u5206\u7c7b\uff0c\u6211\u4eec\u9700\u8981\u5c06\u8f93\u5165\u5bf9\u8c61\u5206\u7c7b\u4e3a\u4e24\u4e2a\u6216\u591a\u4e2a\u7c7b\u522b\u3002</li> <li>\u56de\u5f52\uff0c\u6211\u4eec\u9700\u8981\u9884\u6d4b\u6bcf\u4e2a\u8f93\u5165\u6837\u672c\u7684\u6570\u503c\u3002</li> </ul> <p>\u5f53\u5c06\u8f93\u5165\u548c\u8f93\u51fa\u8868\u793a\u4e3a\u5f20\u91cf\u65f6\uff0c\u8f93\u5165\u6570\u636e\u96c6\u662f\u5927\u5c0f\u4e3aM\u00d7N\u7684\u77e9\u9635\uff0c\u5176\u4e2dM\u662f\u6837\u672c\u6570\uff0cN\u662f\u7279\u5f81\u6570\u3002\u8f93\u51fa\u6807\u7b7eY\u662f\u5927\u5c0f\u4e3aM\u7684\u5411\u91cf\u3002</p> <p>\u5728\u672c\u8bfe\u7a0b\u4e2d\uff0c\u6211\u4eec\u5c06\u53ea\u5173\u6ce8\u795e\u7ecf\u7f51\u7edc\u6a21\u578b\u3002</p>"},{"location":"lessons/3-NeuralNetworks/README_chs/#_3","title":"\u795e\u7ecf\u5143\u6a21\u578b","text":"<p>\u4ece\u751f\u7269\u5b66\u6211\u4eec\u77e5\u9053\uff0c\u5927\u8111\u7531\u795e\u7ecf\u7ec6\u80de\u7ec4\u6210\uff0c\u6bcf\u4e2a\u795e\u7ecf\u7ec6\u80de\u5177\u6709\u591a\u4e2a\u201c\u8f93\u5165\u201d\uff08\u8f74\u7a81\uff09\u548c\u4e00\u4e2a\u8f93\u51fa\uff08\u6811\u7a81\uff09\u3002\u8f74\u7a81\u548c\u6811\u7a81\u53ef\u4ee5\u4f20\u5bfc\u7535\u4fe1\u53f7\uff0c\u4e14\u5b83\u4eec\u4e4b\u95f4\u7684\u8fde\u63a5\u53ef\u4ee5\u8868\u73b0\u51fa\u4e0d\u540c\u7a0b\u5ea6\u7684\u4f20\u5bfc\u6027\uff08\u7531\u795e\u7ecf\u9012\u8d28\u63a7\u5236\uff09\u3002</p> \u771f\u5b9e\u795e\u7ecf\u5143 \uff08\u56fe\u7247\u6765\u81ea\u7ef4\u57fa\u767e\u79d1\uff09 \u4eba\u5de5\u795e\u7ecf\u5143 \uff08\u56fe\u7247\u6765\u81ea\u4f5c\u8005\uff09 <p>\u56e0\u6b64\uff0c\u795e\u7ecf\u5143\u7684\u6700\u7b80\u5355\u6570\u5b66\u6a21\u578b\u5305\u542b\u591a\u4e2a\u8f93\u5165X<sub>1</sub>, ..., X<sub>N</sub> \u548c\u4e00\u4e2a\u8f93\u51faY\uff0c\u4ee5\u53ca\u4e00\u7cfb\u5217\u6743\u91cdW<sub>1</sub>, ..., W<sub>N</sub>\u3002\u8f93\u51fa\u7684\u8ba1\u7b97\u5982\u4e0b\uff1a</p> <p> \u5176\u4e2df\u662f\u67d0\u79cd\u975e\u7ebf\u6027\u6fc0\u6d3b\u51fd\u6570\u3002</p> <p>\u65e9\u671f\u7684\u795e\u7ecf\u5143\u6a21\u578b\u57281943\u5e74\u7531Warren McCullock\u548cWalter Pitts\u7684\u7ecf\u5178\u8bba\u6587 \u300a\u795e\u7ecf\u6d3b\u52a8\u4e2d\u7684\u903b\u8f91\u6f14\u7b97\u300b \u4e2d\u8fdb\u884c\u4e86\u63cf\u8ff0\u3002Donald Hebb\u5728\u4ed6\u7684\u4e66 \"\u884c\u4e3a\u7684\u7ec4\u7ec7\uff1a\u795e\u7ecf\u5fc3\u7406\u5b66\u7406\u8bba\" \u4e2d\u63d0\u51fa\u4e86\u8fd9\u4e9b\u7f51\u7edc\u7684\u8bad\u7ec3\u65b9\u6cd5\u3002</p>"},{"location":"lessons/3-NeuralNetworks/README_chs/#_4","title":"\u672c\u7ae0\u8282\u5185\u5bb9","text":"<p>\u5728\u672c\u7ae0\u8282\u4e2d\u6211\u4eec\u5c06\u5b66\u4e60\uff1a * \u611f\u77e5\u5668\uff0c\u4e00\u79cd\u6700\u65e9\u7684\u4e24\u7c7b\u5206\u7c7b\u795e\u7ecf\u7f51\u7edc\u6a21\u578b * \u591a\u5c42\u7f51\u7edc \u548c\u914d\u5957\u7b14\u8bb0\u672c \u5982\u4f55\u6784\u5efa\u6211\u4eec\u81ea\u5df1\u7684\u6846\u67b6 * \u795e\u7ecf\u7f51\u7edc\u6846\u67b6\uff0c\u5305\u62ec\u4ee5\u4e0b\u7b14\u8bb0\u672c\uff1aPyTorch \u548c Keras/Tensorflow * \u8fc7\u62df\u5408</p>"},{"location":"lessons/3-NeuralNetworks/03-Perceptron/","title":"Introduction to Neural Networks: Perceptron","text":""},{"location":"lessons/3-NeuralNetworks/03-Perceptron/#pre-lecture-quiz","title":"Pre-lecture quiz","text":"<p>One of the first attempts to implement something similar to a modern neural network was done by Frank Rosenblatt from Cornell Aeronautical Laboratory in 1957. It was a hardware implementation called \"Mark-1\", designed to recognize primitive geometric figures, such as triangles, squares and circles.</p> <p>Images from Wikipedia</p> <p>An input image was represented by 20x20 photocell array, so the neural network had 400 inputs and one binary output. A simple network contained one neuron, also called a threshold logic unit. Neural network weights acted like potentiometers that required manual adjustment during the training phase.</p> <p>\u2705 A potentiometer is a device that allows the user to adjust the resistance of a circuit.</p> <p>The New York Times wrote about perceptron at that time: the embryo of an electronic computer that [the Navy] expects will be able to walk, talk, see, write, reproduce itself and be conscious of its existence.</p>"},{"location":"lessons/3-NeuralNetworks/03-Perceptron/#perceptron-model","title":"Perceptron Model","text":"<p>Suppose we have N features in our model, in which case the input vector would be a vector of size N. A perceptron is a binary classification model, i.e. it can distinguish between two classes of input data. We will assume that for each input vector x the output of our perceptron would be either +1 or -1, depending on the class. The output will be computed using the formula:</p> <p>y(x) = f(w<sup>T</sup>x)</p> <p>where f is a step activation function</p> <p></p>"},{"location":"lessons/3-NeuralNetworks/03-Perceptron/#training-the-perceptron","title":"Training the Perceptron","text":"<p>To train a perceptron we need to find a weights vector w that classifies most of the values correctly, i.e. results in the smallest error. This error E is defined by perceptron criterion in the following manner:</p> <p>E(w) = -\u2211w<sup>T</sup>x<sub>i</sub>t<sub>i</sub></p> <p>where:</p> <ul> <li>the sum is taken on those training data points i that result in the wrong classification</li> <li>x<sub>i</sub> is the input data, and t<sub>i</sub> is either -1 or +1 for negative and positive examples accordingly.</li> </ul> <p>This criteria is considered as a function of weights w, and we need to minimize it. Often, a method called gradient descent is used, in which we start with some initial weights w<sup>(0)</sup>, and then at each step update the weights according to the formula:</p> <p>w<sup>(t+1)</sup> = w<sup>(t)</sup> - \u03b7\u2207E(w)</p> <p>Here \u03b7 is the so-called learning rate, and \u2207E(w) denotes the gradient of E. After we calculate the gradient, we end up with</p> <p>w<sup>(t+1)</sup> = w<sup>(t)</sup> + \u2211\u03b7x<sub>i</sub>t<sub>i</sub></p> <p>The algorithm in Python looks like this:</p> <pre><code>def train(positive_examples, negative_examples, num_iterations = 100, eta = 1):\n\n    weights = [0,0,0] # Initialize weights (almost randomly :)\n\n    for i in range(num_iterations):\n        pos = random.choice(positive_examples)\n        neg = random.choice(negative_examples)\n\n        z = np.dot(pos, weights) # compute perceptron output\n        if z &lt; 0: # positive example classified as negative\n            weights = weights + eta*weights.shape\n\n        z  = np.dot(neg, weights)\n        if z &gt;= 0: # negative example classified as positive\n            weights = weights - eta*weights.shape\n\n    return weights\n</code></pre>"},{"location":"lessons/3-NeuralNetworks/03-Perceptron/#conclusion","title":"Conclusion","text":"<p>In this lesson, you learned about a perceptron, which is a binary classification model, and how to train it by using a weights vector.</p>"},{"location":"lessons/3-NeuralNetworks/03-Perceptron/#challenge","title":"\ud83d\ude80 Challenge","text":"<p>If you'd like to try to build your own perceptron, try this lab on Microsoft Learn which uses the Azure ML designer.</p>"},{"location":"lessons/3-NeuralNetworks/03-Perceptron/#post-lecture-quiz","title":"Post-lecture quiz","text":""},{"location":"lessons/3-NeuralNetworks/03-Perceptron/#review-self-study","title":"Review &amp; Self Study","text":"<p>To see how we can use perceptron to solve a toy problem as well as real-life problems, and to continue learning - go to Perceptron notebook.</p> <p>Here's an interesting article about perceptrons as well.</p>"},{"location":"lessons/3-NeuralNetworks/03-Perceptron/#assignment","title":"Assignment","text":"<p>In this lesson, we have implemented a perceptron for binary classification task, and we have used it to classify between two handwritten digits. In this lab, you are asked to solve the problem of digit classification entirely, i.e. determine which digit is most likely to correspond to a given image.</p> <ul> <li>Instructions</li> <li>Notebook</li> </ul>"},{"location":"lessons/3-NeuralNetworks/03-Perceptron/README_chs/","title":"\u795e\u7ecf\u7f51\u7edc\u5165\u95e8\uff1a\u611f\u77e5\u5668","text":""},{"location":"lessons/3-NeuralNetworks/03-Perceptron/README_chs/#_2","title":"\u8bfe\u524d\u6d4b\u9a8c","text":"<p>1957\u5e74\uff0c\u5eb7\u5948\u5c14\u822a\u7a7a\u5b9e\u9a8c\u5ba4\u7684Frank Rosenblatt\u9996\u6b21\u5c1d\u8bd5\u5b9e\u73b0\u7c7b\u4f3c\u4e8e\u73b0\u4ee3\u795e\u7ecf\u7f51\u7edc\u7684\u4e1c\u897f\u3002\u8fd9\u662f\u4e00\u79cd\u540d\u4e3a\"Mark-1\"\u7684\u786c\u4ef6\u5b9e\u73b0\uff0c\u65e8\u5728\u8bc6\u522b\u539f\u59cb\u51e0\u4f55\u56fe\u5f62\uff0c\u5982\u4e09\u89d2\u5f62\u3001\u6b63\u65b9\u5f62\u548c\u5706\u5f62\u3002</p> <p>\u56fe\u7247\u6765\u6e90 \u7ef4\u57fa\u767e\u79d1</p> <p>\u8f93\u5165\u56fe\u50cf\u753120\u00d720\u5149\u7535\u6c60\u9635\u5217\u8868\u793a\uff0c\u56e0\u6b64\u795e\u7ecf\u7f51\u7edc\u6709400\u4e2a\u8f93\u5165\u548c\u4e00\u4e2a\u4e8c\u8fdb\u5236\u8f93\u51fa\u3002\u4e00\u4e2a\u7b80\u5355\u7684\u7f51\u7edc\u5305\u542b\u4e00\u4e2a\u795e\u7ecf\u5143\uff0c\u4e5f\u79f0\u4e3a\u4e00\u4e2a\u9608\u503c\u903b\u8f91\u5355\u5143\u3002\u795e\u7ecf\u7f51\u7edc\u7684\u6743\u91cd\u50cf\u7535\u4f4d\u5668\u4e00\u6837\u5728\u8bad\u7ec3\u9636\u6bb5\u9700\u8981\u624b\u52a8\u8c03\u6574\u3002</p> <p>\u2705 \u7535\u4f4d\u5668\u662f\u4e00\u79cd\u5141\u8bb8\u7528\u6237\u8c03\u6574\u7535\u8def\u7535\u963b\u7684\u88c5\u7f6e\u3002</p> <p>\u300a\u7ebd\u7ea6\u65f6\u62a5\u300b\u5f53\u65f6\u5199\u9053\u611f\u77e5\u5668\uff1a\u6d77\u519b\u671f\u671b\u7684\u7535\u5b50\u8ba1\u7b97\u673a\u7684\u80da\u80ce\uff0c\u5c06\u80fd\u591f\u884c\u8d70\u3001\u8c08\u8bdd\u3001\u770b\u89c1\u3001\u5199\u5b57\u3001\u590d\u5236\u81ea\u5df1\u5e76\u610f\u8bc6\u5230\u81ea\u5df1\u7684\u5b58\u5728\u3002</p>"},{"location":"lessons/3-NeuralNetworks/03-Perceptron/README_chs/#_3","title":"\u611f\u77e5\u5668\u6a21\u578b","text":"<p>\u5047\u8bbe\u6211\u4eec\u7684\u6a21\u578b\u4e2d\u6709N\u4e2a\u7279\u5f81\uff0c\u5728\u8fd9\u79cd\u60c5\u51b5\u4e0b\uff0c\u8f93\u5165\u5411\u91cf\u5c06\u662f\u5927\u5c0f\u4e3aN\u7684\u5411\u91cf\u3002\u611f\u77e5\u5668\u662f\u4e00\u4e2a\u4e8c\u5206\u7c7b\u6a21\u578b\uff0c\u5373\u5b83\u53ef\u4ee5\u533a\u5206\u4e24\u7c7b\u8f93\u5165\u6570\u636e\u3002\u6211\u4eec\u5c06\u5047\u8bbe\u5bf9\u4e8e\u6bcf\u4e2a\u8f93\u5165\u5411\u91cfx\uff0c\u611f\u77e5\u5668\u7684\u8f93\u51fa\u5c06\u6839\u636e\u7c7b\u522b\u4e3a+1\u6216-1\u3002\u8f93\u51fa\u5c06\u4f7f\u7528\u4ee5\u4e0b\u516c\u5f0f\u8ba1\u7b97\uff1a</p> <p>y(x) = f(w<sup>T</sup>x)</p> <p>\u5176\u4e2df\u662f\u4e00\u4e2a\u9636\u8dc3\u6fc0\u6d3b\u51fd\u6570</p> <p></p>"},{"location":"lessons/3-NeuralNetworks/03-Perceptron/README_chs/#_4","title":"\u8bad\u7ec3\u611f\u77e5\u5668","text":"<p>\u8981\u8bad\u7ec3\u4e00\u4e2a\u611f\u77e5\u5668\uff0c\u6211\u4eec\u9700\u8981\u627e\u5230\u4e00\u4e2a\u6743\u91cd\u5411\u91cfw\uff0c\u8be5\u5411\u91cf\u53ef\u4ee5\u6b63\u786e\u5206\u7c7b\u5927\u591a\u6570\u503c\uff0c\u5373\u4f7f\u9519\u8bef\u6700\u5c0f\u5316\u3002\u8fd9\u4e2a\u9519\u8befE\u7531\u4ee5\u4e0b\u65b9\u5f0f\u5b9a\u4e49\u7684\u611f\u77e5\u5668\u51c6\u5219\u6765\u5b9a\u4e49\uff1a</p> <p>E(w) = -\u2211w<sup>T</sup>x<sub>i</sub>t<sub>i</sub></p> <p>\u5176\u4e2d\uff1a</p> <ul> <li>\u6c42\u548c\u5728\u90a3\u4e9b\u5bfc\u81f4\u9519\u8bef\u5206\u7c7b\u7684\u8bad\u7ec3\u6570\u636e\u70b9i\u4e0a\u8fdb\u884c</li> <li>x<sub>i</sub>\u662f\u8f93\u5165\u6570\u636e\uff0ct<sub>i</sub>\u5206\u522b\u5bf9\u8d1f\u4f8b\u548c\u6b63\u4f8b\u4e3a-1\u6216+1\u3002</li> </ul> <p>\u8fd9\u4e2a\u51c6\u5219\u88ab\u8ba4\u4e3a\u662f\u6743\u91cdw\u7684\u51fd\u6570\uff0c\u56e0\u6b64\u6211\u4eec\u9700\u8981\u6700\u5c0f\u5316\u5b83\u3002\u901a\u5e38\u4f7f\u7528\u4e00\u79cd\u79f0\u4e3a\u68af\u5ea6\u4e0b\u964d\u7684\u65b9\u6cd5\uff0c\u6211\u4eec\u4ece\u67d0\u4e9b\u521d\u59cb\u6743\u91cdw<sup>(0)</sup>\u5f00\u59cb\uff0c\u7136\u540e\u5728\u6bcf\u4e00\u6b65\u4e2d\u6839\u636e\u4ee5\u4e0b\u516c\u5f0f\u66f4\u65b0\u6743\u91cd\uff1a</p> <p>w<sup>(t+1)</sup> = w<sup>(t)</sup> - \u03b7\u2207E(w)</p> <p>\u8fd9\u91cc\u7684\u03b7\u662f\u6240\u8c13\u7684\u5b66\u4e60\u7387\uff0c\u2207E(w)\u8868\u793aE\u7684\u68af\u5ea6\u3002\u5728\u8ba1\u7b97\u68af\u5ea6\u4e4b\u540e\uff0c\u6211\u4eec\u5f97\u5230</p> <p>w<sup>(t+1)</sup> = w<sup>(t)</sup> + \u2211\u03b7x<sub>i</sub>t<sub>i</sub></p> <p>Python\u4e2d\u7684\u7b97\u6cd5\u5982\u4e0b\u6240\u793a\uff1a</p> <pre><code>def train(positive_examples, negative_examples, num_iterations = 100, eta = 1):\n\n    weights = [0,0,0] # \u521d\u59cb\u5316\u6743\u91cd\uff08\u51e0\u4e4e\u662f\u968f\u673a\u7684 :)\n\n    for i in range(num_iterations):\n        pos = random.choice(positive_examples)\n        neg = random.choice(negative_examples)\n\n        z = np.dot(pos, weights) # \u8ba1\u7b97\u611f\u77e5\u5668\u8f93\u51fa\n        if z &lt; 0: # \u5c06\u6b63\u4f8b\u5206\u7c7b\u4e3a\u8d1f\u4f8b\n            weights = weights + eta*weights.shape\n\n        z = np.dot(neg, weights)\n        if z &gt;= 0: # \u5c06\u8d1f\u4f8b\u5206\u7c7b\u4e3a\u6b63\u4f8b\n            weights = weights - eta*weights.shape\n\n    return weights\n</code></pre>"},{"location":"lessons/3-NeuralNetworks/03-Perceptron/README_chs/#_5","title":"\u7ed3\u8bba","text":"<p>\u5728\u672c\u8bfe\u4e2d\uff0c\u4f60\u5b66\u4e60\u4e86\u611f\u77e5\u5668\uff0c\u8fd9\u662f\u4e00\u79cd\u4e8c\u5206\u7c7b\u6a21\u578b\uff0c\u4ee5\u53ca\u5982\u4f55\u901a\u8fc7\u4f7f\u7528\u6743\u91cd\u5411\u91cf\u6765\u8bad\u7ec3\u5b83\u3002</p>"},{"location":"lessons/3-NeuralNetworks/03-Perceptron/README_chs/#_6","title":"\ud83d\ude80 \u6311\u6218","text":"<p>\u5982\u679c\u4f60\u60f3\u5c1d\u8bd5\u6784\u5efa\u4f60\u81ea\u5df1\u7684\u611f\u77e5\u5668\uff0c\u8bf7\u8bd5\u8bd5\u5fae\u8f6f\u5b66\u4e60\u4e2d\u7684\u8fd9\u4e2a\u5b9e\u9a8c\uff0c\u5b83\u4f7f\u7528\u4e86Azure ML designer\u3002</p>"},{"location":"lessons/3-NeuralNetworks/03-Perceptron/README_chs/#_7","title":"\u8bfe\u540e\u6d4b\u9a8c","text":""},{"location":"lessons/3-NeuralNetworks/03-Perceptron/README_chs/#_8","title":"\u590d\u4e60\u4e0e\u81ea\u5b66","text":"<p>\u8981\u67e5\u770b\u6211\u4eec\u5982\u4f55\u4f7f\u7528\u611f\u77e5\u5668\u6765\u89e3\u51b3\u73a9\u5177\u95ee\u9898\u4ee5\u53ca\u5b9e\u9645\u95ee\u9898\uff0c\u5e76\u7ee7\u7eed\u5b66\u4e60\uff0c\u8bf7\u8bbf\u95ee\u611f\u77e5\u5668\u7b14\u8bb0\u672c\u3002</p> <p>\u8fd9\u91cc\u6709\u4e00\u7bc7\u6709\u8da3\u7684\u5173\u4e8e\u611f\u77e5\u5668\u7684\u6587\u7ae0\u3002</p>"},{"location":"lessons/3-NeuralNetworks/03-Perceptron/README_chs/#_9","title":"\u4f5c\u4e1a","text":"<p>\u5728\u672c\u8bfe\u4e2d\uff0c\u6211\u4eec\u5b9e\u73b0\u4e86\u4e00\u4e2a\u7528\u4e8e\u4e8c\u5206\u7c7b\u4efb\u52a1\u7684\u611f\u77e5\u5668\uff0c\u5e76\u7528\u5b83\u6765\u533a\u5206\u7c7b\u4f3c\u4e8e\u624b\u5199\u6570\u5b57\u7684\u4e24\u7c7b\u3002\u5728\u8fd9\u4e2a\u5b9e\u9a8c\u4e2d\uff0c\u4f60\u9700\u8981\u5b8c\u6574\u5730\u89e3\u51b3\u6570\u5b57\u5206\u7c7b\u95ee\u9898\uff0c\u5373\u786e\u5b9a\u7ed9\u5b9a\u56fe\u50cf\u6700\u6709\u53ef\u80fd\u5bf9\u5e94\u7684\u6570\u5b57\u3002</p> <ul> <li>\u8bf4\u660e</li> <li>\u7b14\u8bb0\u672c</li> </ul>"},{"location":"lessons/3-NeuralNetworks/03-Perceptron/lab/","title":"Multi-Class Classification with Perceptron","text":"<p>Lab Assignment from AI for Beginners Curriculum.</p>"},{"location":"lessons/3-NeuralNetworks/03-Perceptron/lab/#task","title":"Task","text":"<p>Using the code we have developed in this lesson for binary classification of MNIST handwritten digits, create a multi-class classified that would be able to recognize any digit. Compute the classification accuracy on the train and test dataset, and print out the confusion matrix.</p>"},{"location":"lessons/3-NeuralNetworks/03-Perceptron/lab/#hints","title":"Hints","text":"<ol> <li>For each digit, create a dataset for binary classifier of \"this digit vs. all other digits\"</li> <li>Train 10 different perceptrons for binary classification (one for each digit)</li> <li>Define a function that will classify an input digit</li> </ol> <p>Hint: If we combine weights of all 10 perceptrons into one matrix, we should be able to apply all 10 perceptrons to the input digits by one matrix multiplication. Most probable digit can then be found just by applying <code>argmax</code> operation on the output.</p>"},{"location":"lessons/3-NeuralNetworks/03-Perceptron/lab/#stating-notebook","title":"Stating Notebook","text":"<p>Start the lab by opening PerceptronMultiClass.ipynb</p>"},{"location":"lessons/3-NeuralNetworks/03-Perceptron/lab/README_chs/","title":"\u4f7f\u7528\u611f\u77e5\u673a\u8fdb\u884c\u591a\u7c7b\u5206\u7c7b","text":"<p>\u6765\u81ea\u521d\u5b66\u8005 AI \u8bfe\u7a0b\u7684\u5b9e\u9a8c\u4f5c\u4e1a\u3002</p>"},{"location":"lessons/3-NeuralNetworks/03-Perceptron/lab/README_chs/#_2","title":"\u4efb\u52a1","text":"<p>\u4f7f\u7528\u6211\u4eec\u5728\u672c\u8bfe\u4e2d\u4e3a MNIST \u624b\u5199\u6570\u5b57\u7684\u4e8c\u5206\u7c7b\u6240\u5f00\u53d1\u7684\u4ee3\u7801\uff0c\u521b\u5efa\u4e00\u4e2a\u80fd\u591f\u8bc6\u522b\u4efb\u610f\u6570\u5b57\u7684\u591a\u7c7b\u5206\u7c7b\u5668\u3002\u8ba1\u7b97\u8bad\u7ec3\u6570\u636e\u96c6\u548c\u6d4b\u8bd5\u6570\u636e\u96c6\u4e0a\u7684\u5206\u7c7b\u51c6\u786e\u7387\uff0c\u5e76\u6253\u5370\u51fa\u6df7\u6dc6\u77e9\u9635\u3002</p>"},{"location":"lessons/3-NeuralNetworks/03-Perceptron/lab/README_chs/#_3","title":"\u63d0\u793a","text":"<ol> <li>\u5bf9\u4e8e\u6bcf\u4e2a\u6570\u5b57\uff0c\u4e3a\u201c\u8fd9\u4e2a\u6570\u5b57 vs. \u5176\u4ed6\u6240\u6709\u6570\u5b57\u201d\u7684\u4e8c\u5206\u7c7b\u5668\u521b\u5efa\u4e00\u4e2a\u6570\u636e\u96c6</li> <li>\u8bad\u7ec3 10 \u4e2a\u4e0d\u540c\u7684\u611f\u77e5\u673a\u8fdb\u884c\u4e8c\u5206\u7c7b\uff08\u6bcf\u4e2a\u6570\u5b57\u4e00\u4e2a\uff09</li> <li>\u5b9a\u4e49\u4e00\u4e2a\u51fd\u6570\u6765\u5206\u7c7b\u8f93\u5165\u7684\u6570\u5b57</li> </ol> <p>\u63d0\u793a\uff1a\u5982\u679c\u6211\u4eec\u5c06\u6240\u6709 10 \u4e2a\u611f\u77e5\u673a\u7684\u6743\u91cd\u7ec4\u5408\u6210\u4e00\u4e2a\u77e9\u9635\uff0c\u6211\u4eec\u5e94\u8be5\u80fd\u591f\u901a\u8fc7\u4e00\u6b21\u77e9\u9635\u4e58\u6cd5\u5c06\u6240\u6709 10 \u4e2a\u611f\u77e5\u673a\u5e94\u7528\u5230\u8f93\u5165\u7684\u6570\u5b57\u4e0a\u3002\u7136\u540e\u53ef\u4ee5\u901a\u8fc7\u5bf9\u8f93\u51fa\u5e94\u7528 <code>argmax</code> \u64cd\u4f5c\u6765\u627e\u5230\u6700\u53ef\u80fd\u7684\u6570\u5b57\u3002</p>"},{"location":"lessons/3-NeuralNetworks/03-Perceptron/lab/README_chs/#_4","title":"\u8d77\u59cb\u7b14\u8bb0\u672c","text":"<p>\u901a\u8fc7\u6253\u5f00 PerceptronMultiClass.ipynb \u5f00\u59cb\u5b9e\u9a8c\u3002</p>"},{"location":"lessons/3-NeuralNetworks/04-OwnFramework/","title":"Introduction to Neural Networks. Multi-Layered Perceptron","text":"<p>In the previous section, you learned about the simplest neural network model - one-layered perceptron, a linear two-class classification model.</p> <p>In this section we will extend this model into a more flexible framework, allowing us to:</p> <ul> <li>perform multi-class classification in addition to two-class</li> <li>solve regression problems in addition to classification</li> <li>separate classes that are not linearly separable</li> </ul> <p>We will also develop our own modular framework in Python that will allow us to construct different neural network architectures.</p>"},{"location":"lessons/3-NeuralNetworks/04-OwnFramework/#pre-lecture-quiz","title":"Pre-lecture quiz","text":""},{"location":"lessons/3-NeuralNetworks/04-OwnFramework/#formalization-of-machine-learning","title":"Formalization of Machine Learning","text":"<p>Let's start with formalizing the Machine Learning problem. Suppose we have a training dataset X with labels Y, and we need to build a model f that will make most accurate predictions. The quality of predictions is measured by Loss function \u2112. The following loss functions are often used:</p> <ul> <li>For regression problem, when we need to predict a number, we can use absolute error \u2211<sub>i</sub>|f(x<sup>(i)</sup>)-y<sup>(i)</sup>|, or squared error \u2211<sub>i</sub>(f(x<sup>(i)</sup>)-y<sup>(i)</sup>)<sup>2</sup></li> <li>For classification, we use 0-1 loss (which is essentially the same as accuracy of the model), or logistic loss.</li> </ul> <p>For one-level perceptron, function f was defined as a linear function f(x)=wx+b (here w is the weight matrix, x is the vector of input features, and b is bias vector). For different neural network architectures, this function can take more complex form.</p> <p>In the case of classification, it is often desirable to get probabilities of corresponding classes as network output. To convert arbitrary numbers to probabilities (eg. to normalize the output), we often use softmax function \u03c3, and the function f becomes f(x)=\u03c3(wx+b)</p> <p>In the definition of f above, w and b are called parameters \u03b8=\u27e8w,b\u27e9. Given the dataset \u27e8X,Y\u27e9, we can compute an overall error on the whole dataset as a function of parameters \u03b8.</p> <p>\u2705 The goal of neural network training is to minimize the error by varying parameters \u03b8</p>"},{"location":"lessons/3-NeuralNetworks/04-OwnFramework/#gradient-descent-optimization","title":"Gradient Descent Optimization","text":"<p>There is a well-known method of function optimization called gradient descent. The idea is that we can compute a derivative (in multi-dimensional case called gradient) of loss function with respect to parameters, and vary parameters in such a way that the error would decrease. This can be formalized as follows:</p> <ul> <li>Initialize parameters by some random values w<sup>(0)</sup>, b<sup>(0)</sup></li> <li>Repeat the following step many times:<ul> <li>w<sup>(i+1)</sup> = w<sup>(i)</sup>-\u03b7\u2202\u2112/\u2202w</li> <li>b<sup>(i+1)</sup> = b<sup>(i)</sup>-\u03b7\u2202\u2112/\u2202b</li> </ul> </li> </ul> <p>During training, the optimization steps are supposed to be calculated considering the whole dataset (remember that loss is calculated as a sum through all training samples). However, in real life we take small portions of the dataset called minibatches, and calculate gradients based on a subset of data. Because subset is taken randomly each time, such method is called stochastic gradient descent (SGD).</p>"},{"location":"lessons/3-NeuralNetworks/04-OwnFramework/#multi-layered-perceptrons-and-backpropagation","title":"Multi-Layered Perceptrons and Backpropagation","text":"<p>One-layer network, as we have seen above, is capable of classifying linearly separable classes. To build a richer model, we can combine several layers of the network. Mathematically it would mean that the function f would have a more complex form, and will be computed in several steps: * z<sub>1</sub>=w<sub>1</sub>x+b<sub>1</sub> * z<sub>2</sub>=w<sub>2</sub>\u03b1(z<sub>1</sub>)+b<sub>2</sub> * f = \u03c3(z<sub>2</sub>)</p> <p>Here, \u03b1 is a non-linear activation function, \u03c3 is a softmax function, and parameters \u03b8=&lt;w<sub>1</sub>,b<sub>1</sub>,w<sub>2</sub>,b<sub>2</sub>&gt;.</p> <p>The gradient descent algorithm would remain the same, but it would be more difficult to calculate gradients. Given the chain differentiation rule, we can calculate derivatives as:</p> <ul> <li>\u2202\u2112/\u2202w<sub>2</sub> = (\u2202\u2112/\u2202\u03c3)(\u2202\u03c3/\u2202z<sub>2</sub>)(\u2202z<sub>2</sub>/\u2202w<sub>2</sub>)</li> <li>\u2202\u2112/\u2202w<sub>1</sub> = (\u2202\u2112/\u2202\u03c3)(\u2202\u03c3/\u2202z<sub>2</sub>)(\u2202z<sub>2</sub>/\u2202\u03b1)(\u2202\u03b1/\u2202z<sub>1</sub>)(\u2202z<sub>1</sub>/\u2202w<sub>1</sub>)</li> </ul> <p>\u2705 The chain differentiation rule is used to calculate derivatives of the loss function with respect to parameters.</p> <p>Note that the left-most part of all those expressions is the same, and thus we can effectively calculate derivatives starting from the loss function and going \"backwards\" through the computational graph. Thus the method of training a multi-layered perceptron is called backpropagation, or 'backprop'.</p> <p></p> <p>TODO: image citation</p> <p>\u2705 We will cover backprop in much more detail in our notebook example.  </p>"},{"location":"lessons/3-NeuralNetworks/04-OwnFramework/#conclusion","title":"Conclusion","text":"<p>In this lesson, we have built our own neural network library, and we have used it for a simple two-dimensional classification task.</p>"},{"location":"lessons/3-NeuralNetworks/04-OwnFramework/#challenge","title":"\ud83d\ude80 Challenge","text":"<p>In the accompanying notebook, you will implement your own framework for building and training multi-layered perceptrons. You will be able to see in detail how modern neural networks operate.</p> <p>Proceed to the OwnFramework notebook and work through it.</p>"},{"location":"lessons/3-NeuralNetworks/04-OwnFramework/#post-lecture-quiz","title":"Post-lecture quiz","text":""},{"location":"lessons/3-NeuralNetworks/04-OwnFramework/#review-self-study","title":"Review &amp; Self Study","text":"<p>Backpropagation is a common algorithm used in AI and ML, worth studying in more detail</p>"},{"location":"lessons/3-NeuralNetworks/04-OwnFramework/#assignment","title":"Assignment","text":"<p>In this lab, you are asked to use the framework you constructed in this lesson to solve MNIST handwritten digit classification.</p> <ul> <li>Instructions</li> <li>Notebook</li> </ul>"},{"location":"lessons/3-NeuralNetworks/04-OwnFramework/README_chs/","title":"\u795e\u7ecf\u7f51\u7edc\u4ecb\u7ecd. \u591a\u5c42\u611f\u77e5\u5668","text":"<p>\u5728\u4e0a\u4e00\u8282\u4e2d\uff0c\u4f60\u4e86\u89e3\u4e86\u6700\u7b80\u5355\u7684\u795e\u7ecf\u7f51\u7edc\u6a21\u578b - \u5355\u5c42\u611f\u77e5\u5668\uff0c\u8fd9\u662f\u4e00\u4e2a\u7ebf\u6027\u53cc\u7c7b\u5206\u7c7b\u6a21\u578b\u3002</p> <p>\u5728\u672c\u8282\u4e2d\uff0c\u6211\u4eec\u5c06\u6269\u5c55\u8fd9\u4e2a\u6a21\u578b\u5230\u4e00\u4e2a\u66f4\u7075\u6d3b\u7684\u6846\u67b6\uff0c\u5141\u8bb8\u6211\u4eec\uff1a</p> <ul> <li>\u9664\u4e86\u53cc\u7c7b\u4e4b\u5916\uff0c\u8fd8\u80fd\u6267\u884c\u591a\u7c7b\u5206\u7c7b</li> <li>\u9664\u4e86\u5206\u7c7b\u4e4b\u5916\uff0c\u8fd8\u80fd\u89e3\u51b3\u56de\u5f52\u95ee\u9898</li> <li>\u5206\u79bb\u90a3\u4e9b\u4e0d\u662f\u7ebf\u6027\u53ef\u5206\u7684\u7c7b</li> </ul> <p>\u6211\u4eec\u8fd8\u5c06\u5f00\u53d1\u6211\u4eec\u81ea\u5df1\u7684 Python \u6a21\u5757\u5316\u6846\u67b6\uff0c\u5141\u8bb8\u6211\u4eec\u6784\u5efa\u4e0d\u540c\u7684\u795e\u7ecf\u7f51\u7edc\u67b6\u6784\u3002</p>"},{"location":"lessons/3-NeuralNetworks/04-OwnFramework/README_chs/#_2","title":"\u8bfe\u524d\u6d4b\u9a8c","text":""},{"location":"lessons/3-NeuralNetworks/04-OwnFramework/README_chs/#_3","title":"\u673a\u5668\u5b66\u4e60\u5f62\u5f0f\u5316","text":"<p>\u8ba9\u6211\u4eec\u5148\u5f62\u5f0f\u5316\u673a\u5668\u5b66\u4e60\u95ee\u9898\u3002\u5047\u8bbe\u6211\u4eec\u6709\u4e00\u4e2a\u5e26\u6709\u6807\u7b7e Y \u7684\u8bad\u7ec3\u6570\u636e\u96c6 X\uff0c\u6211\u4eec\u9700\u8981\u6784\u5efa\u4e00\u4e2a\u6a21\u578b f\uff0c\u4ee5\u4f7f\u5176\u9884\u6d4b\u6700\u51c6\u786e\u3002\u9884\u6d4b\u8d28\u91cf\u7531\u635f\u5931\u51fd\u6570 \u2112 \u6d4b\u91cf\u3002\u4ee5\u4e0b\u635f\u5931\u51fd\u6570\u7ecf\u5e38\u4f7f\u7528\uff1a</p> <ul> <li>\u5bf9\u4e8e\u56de\u5f52\u95ee\u9898\uff0c\u5f53\u6211\u4eec\u9700\u8981\u9884\u6d4b\u4e00\u4e2a\u6570\u503c\u65f6\uff0c\u6211\u4eec\u53ef\u4ee5\u4f7f\u7528\u7edd\u5bf9\u8bef\u5dee \u2211<sub>i</sub>|f(x<sup>(i)</sup>)-y<sup>(i)</sup>| \u6216\u5e73\u65b9\u8bef\u5dee \u2211<sub>i</sub>(f(x<sup>(i)</sup>)-y<sup>(i)</sup>)<sup>2</sup></li> <li>\u5bf9\u4e8e\u5206\u7c7b\uff0c\u6211\u4eec\u4f7f\u75280-1\u635f\u5931\uff08\u5b9e\u9645\u4e0a\u4e0e\u6a21\u578b\u7684\u51c6\u786e\u5ea6\u76f8\u540c\uff09\u6216\u903b\u8f91\u635f\u5931\u3002</li> </ul> <p>\u5bf9\u4e8e\u5355\u5c42\u611f\u77e5\u5668\uff0c\u51fd\u6570 f \u88ab\u5b9a\u4e49\u4e3a\u7ebf\u6027\u51fd\u6570 f(x)=wx+b\uff08\u8fd9\u91cc w \u662f\u6743\u91cd\u77e9\u9635\uff0cx \u662f\u8f93\u5165\u7279\u5f81\u5411\u91cf\uff0cb \u662f\u504f\u7f6e\u5411\u91cf\uff09\u3002\u5bf9\u4e8e\u4e0d\u540c\u7684\u795e\u7ecf\u7f51\u7edc\u67b6\u6784\uff0c\u8fd9\u4e2a\u51fd\u6570\u53ef\u4ee5\u91c7\u7528\u66f4\u590d\u6742\u7684\u5f62\u5f0f\u3002</p> <p>\u5728\u5206\u7c7b\u7684\u60c5\u51b5\u4e0b\uff0c\u901a\u5e38\u5e0c\u671b\u83b7\u5f97\u5bf9\u5e94\u7c7b\u522b\u7684\u6982\u7387\u4f5c\u4e3a\u7f51\u7edc\u8f93\u51fa\u3002\u4e3a\u4e86\u5c06\u4efb\u610f\u6570\u503c\u8f6c\u6362\u4e3a\u6982\u7387\uff08\u4f8b\u5982\u89c4\u8303\u5316\u8f93\u51fa\uff09\uff0c\u6211\u4eec\u901a\u5e38\u4f7f\u7528softmax \u51fd\u6570 \u03c3\uff0c\u51fd\u6570 f \u53d8\u4e3a f(x)=\u03c3(wx+b)</p> <p>\u5728\u4e0a\u8ff0 f \u7684\u5b9a\u4e49\u4e2d\uff0cw \u548c b \u88ab\u79f0\u4e3a\u53c2\u6570 \u03b8=\u27e8w,b\u27e9\u3002\u7ed9\u5b9a\u6570\u636e\u96c6\u27e8X,Y\u27e9\uff0c\u6211\u4eec\u53ef\u4ee5\u8ba1\u7b97\u6574\u4e2a\u6570\u636e\u96c6\u4e0a\u7684\u603b\u4f53\u8bef\u5dee\u4f5c\u4e3a\u53c2\u6570 \u03b8 \u7684\u51fd\u6570\u3002</p> <p>\u2705 \u795e\u7ecf\u7f51\u7edc\u8bad\u7ec3\u7684\u76ee\u6807\u662f\u901a\u8fc7\u6539\u53d8\u53c2\u6570 \u03b8 \u6765\u6700\u5c0f\u5316\u8bef\u5dee</p>"},{"location":"lessons/3-NeuralNetworks/04-OwnFramework/README_chs/#_4","title":"\u68af\u5ea6\u4e0b\u964d\u4f18\u5316","text":"<p>\u6709\u4e00\u79cd\u4f17\u6240\u5468\u77e5\u7684\u51fd\u6570\u4f18\u5316\u65b9\u6cd5\u79f0\u4e3a\u68af\u5ea6\u4e0b\u964d\u3002\u5176\u601d\u60f3\u662f\u6211\u4eec\u53ef\u4ee5\u8ba1\u7b97\u635f\u5931\u51fd\u6570\u76f8\u5bf9\u4e8e\u53c2\u6570\u7684\u5bfc\u6570\uff08\u5728\u591a\u7ef4\u60c5\u51b5\u4e0b\u79f0\u4e3a\u68af\u5ea6\uff09\uff0c\u5e76\u4ee5\u8fd9\u79cd\u65b9\u5f0f\u6539\u53d8\u53c2\u6570\uff0c\u4f7f\u5f97\u8bef\u5dee\u51cf\u5c11\u3002\u8fd9\u53ef\u4ee5\u5f62\u5f0f\u5316\u5982\u4e0b\uff1a</p> <ul> <li>\u901a\u8fc7\u4e00\u4e9b\u968f\u673a\u503c w<sup>(0)</sup>, b<sup>(0)</sup> \u521d\u59cb\u5316\u53c2\u6570</li> <li>\u91cd\u590d\u4ee5\u4e0b\u6b65\u9aa4\u591a\u6b21\uff1a<ul> <li>w<sup>(i+1)</sup> = w<sup>(i)</sup>-\u03b7\u2202\u2112/\u2202w</li> <li>b<sup>(i+1)</sup> = b<sup>(i)</sup>-\u03b7\u2202\u2112/\u2202b</li> </ul> </li> </ul> <p>\u5728\u8bad\u7ec3\u8fc7\u7a0b\u4e2d\uff0c\u5047\u8bbe\u4f18\u5316\u6b65\u9aa4\u662f\u8003\u8651\u6574\u4e2a\u6570\u636e\u96c6\u6765\u8ba1\u7b97\u7684\uff08\u8bb0\u4f4f\uff0c\u635f\u5931\u662f\u6839\u636e\u6240\u6709\u8bad\u7ec3\u6837\u672c\u7684\u603b\u548c\u8ba1\u7b97\u7684\uff09\u3002\u7136\u800c\uff0c\u5728\u5b9e\u9645\u751f\u6d3b\u4e2d\uff0c\u6211\u4eec\u53d6\u79f0\u4e3a\u5c0f\u6279\u91cf\u7684\u5c0f\u90e8\u5206\u6570\u636e\u96c6\uff0c\u5e76\u57fa\u4e8e\u6570\u636e\u5b50\u96c6\u8ba1\u7b97\u68af\u5ea6\u3002\u56e0\u4e3a\u6bcf\u6b21\u5b50\u96c6\u662f\u968f\u673a\u53d6\u7684\uff0c\u8fd9\u79cd\u65b9\u6cd5\u79f0\u4e3a\u968f\u673a\u68af\u5ea6\u4e0b\u964d\uff08SGD\uff09\u3002</p>"},{"location":"lessons/3-NeuralNetworks/04-OwnFramework/README_chs/#_5","title":"\u591a\u5c42\u611f\u77e5\u5668\u548c\u53cd\u5411\u4f20\u64ad","text":"<p>\u6b63\u5982\u6211\u4eec\u4e0a\u9762\u6240\u89c1\u7684\uff0c\u4e00\u4e2a\u5c42\u7684\u7f51\u7edc\u80fd\u591f\u5bf9\u7ebf\u6027\u53ef\u5206\u7684\u7c7b\u8fdb\u884c\u5206\u7c7b\u3002\u4e3a\u4e86\u6784\u5efa\u4e00\u4e2a\u66f4\u4e30\u5bcc\u7684\u6a21\u578b\uff0c\u6211\u4eec\u53ef\u4ee5\u5c06\u7f51\u7edc\u7684\u51e0\u5c42\u7ec4\u5408\u8d77\u6765\u3002\u6570\u5b66\u4e0a\uff0c\u8fd9\u610f\u5473\u7740\u51fd\u6570 f \u5c06\u5177\u6709\u66f4\u590d\u6742\u7684\u5f62\u5f0f\uff0c\u5e76\u5c06\u5728\u51e0\u4e2a\u6b65\u9aa4\u4e2d\u8ba1\u7b97\uff1a * z<sub>1</sub>=w<sub>1</sub>x+b<sub>1</sub> * z<sub>2</sub>=w<sub>2</sub>\u03b1(z<sub>1</sub>)+b<sub>2</sub> * f = \u03c3(z<sub>2</sub>)</p> <p>\u8fd9\u91cc\uff0c\u03b1 \u662f\u4e00\u4e2a\u975e\u7ebf\u6027\u6fc0\u6d3b\u51fd\u6570\uff0c\u03c3 \u662f\u4e00\u4e2a softmax \u51fd\u6570\uff0c\u53c2\u6570 \u03b8=&lt;w<sub>1</sub>,b<sub>1</sub>,w<sub>2</sub>,b<sub>2</sub>&gt;</p> <p>\u68af\u5ea6\u4e0b\u964d\u7b97\u6cd5\u5c06\u4fdd\u6301\u4e0d\u53d8\uff0c\u4f46\u662f\u8ba1\u7b97\u68af\u5ea6\u4f1a\u66f4\u56f0\u96be\u3002\u6839\u636e\u94fe\u5f0f\u6c42\u5bfc\u6cd5\u5219\uff0c\u6211\u4eec\u53ef\u4ee5\u8ba1\u7b97\u5bfc\u6570\u4e3a\uff1a</p> <ul> <li>\u2202\u2112/\u2202w<sub>2</sub> = (\u2202\u2112/\u2202\u03c3)(\u2202\u03c3/\u2202z<sub>2</sub>)(\u2202z<sub>2</sub>/\u2202w<sub>2</sub>)</li> <li>\u2202\u2112/\u2202w<sub>1</sub> = (\u2202\u2112/\u2202\u03c3)(\u2202\u03c3/\u2202z<sub>2</sub>)(\u2202z<sub>2</sub>/\u2202\u03b1)(\u2202\u03b1/\u2202z<sub>1</sub>)(\u2202z<sub>1</sub>/\u2202w<sub>1</sub>)</li> </ul> <p>\u2705 \u94fe\u5f0f\u6c42\u5bfc\u6cd5\u5219\u7528\u4e8e\u8ba1\u7b97\u635f\u5931\u51fd\u6570\u76f8\u5bf9\u4e8e\u53c2\u6570\u7684\u5bfc\u6570\u3002</p> <p>\u8bf7\u6ce8\u610f\uff0c\u8fd9\u4e9b\u8868\u8fbe\u5f0f\u6700\u5de6\u8fb9\u7684\u90e8\u5206\u662f\u76f8\u540c\u7684\uff0c\u56e0\u6b64\u6211\u4eec\u53ef\u4ee5\u6709\u6548\u5730\u4ece\u635f\u5931\u51fd\u6570\u5f00\u59cb\u8ba1\u7b97\u5bfc\u6570\uff0c\u5e76\u901a\u8fc7\u8ba1\u7b97\u56fe \"\u5411\u540e\" \u8ba1\u7b97\u3002\u56e0\u6b64\uff0c\u591a\u5c42\u611f\u77e5\u5668\u7684\u8bad\u7ec3\u65b9\u6cd5\u79f0\u4e3a\u53cd\u5411\u4f20\u64ad\uff0c\u6216 'backprop'\u3002</p> <p></p> <p>TODO: \u56fe\u7247\u5f15\u7528</p> <p>\u2705 \u6211\u4eec\u5c06\u5728\u6211\u4eec\u7684\u7b14\u8bb0\u672c\u793a\u4f8b\u4e2d\u66f4\u8be6\u7ec6\u5730\u4ecb\u7ecd\u53cd\u5411\u4f20\u64ad\u3002</p>"},{"location":"lessons/3-NeuralNetworks/04-OwnFramework/README_chs/#_6","title":"\u7ed3\u8bba","text":"<p>\u5728\u672c\u8bfe\u4e2d\uff0c\u6211\u4eec\u6784\u5efa\u4e86\u81ea\u5df1\u7684\u795e\u7ecf\u7f51\u7edc\u5e93\uff0c\u5e76\u5c06\u5176\u7528\u4e8e\u4e00\u4e2a\u7b80\u5355\u7684\u4e8c\u7ef4\u5206\u7c7b\u4efb\u52a1\u3002</p>"},{"location":"lessons/3-NeuralNetworks/04-OwnFramework/README_chs/#_7","title":"\ud83d\ude80 \u6311\u6218","text":"<p>\u5728\u914d\u5957\u7684\u7b14\u8bb0\u672c\u4e2d\uff0c\u4f60\u5c06\u5b9e\u73b0\u4f60\u81ea\u5df1\u7684\u6784\u5efa\u548c\u8bad\u7ec3\u591a\u5c42\u611f\u77e5\u5668\u7684\u6846\u67b6\u3002\u4f60\u5c06\u80fd\u591f\u8be6\u7ec6\u4e86\u89e3\u73b0\u4ee3\u795e\u7ecf\u7f51\u7edc\u5982\u4f55\u8fd0\u884c\u3002</p> <p>\u8fdb\u5165 OwnFramework \u7b14\u8bb0\u672c\u5e76\u5b8c\u6210\u5b83\u3002</p>"},{"location":"lessons/3-NeuralNetworks/04-OwnFramework/README_chs/#_8","title":"\u8bfe\u540e\u6d4b\u9a8c","text":""},{"location":"lessons/3-NeuralNetworks/04-OwnFramework/README_chs/#_9","title":"\u590d\u4e60\u4e0e\u81ea\u5b66","text":"<p>\u53cd\u5411\u4f20\u64ad\u662f AI \u548c ML \u4e2d\u5e38\u7528\u7684\u7b97\u6cd5\uff0c\u503c\u5f97\u66f4\u8be6\u7ec6\u5730\u7814\u7a76</p>"},{"location":"lessons/3-NeuralNetworks/04-OwnFramework/README_chs/#_10","title":"\u4f5c\u4e1a","text":"<p>\u5728\u672c\u6b21\u5b9e\u9a8c\u4e2d\uff0c\u4f60\u9700\u8981\u4f7f\u7528\u672c\u8282\u8bfe\u4e2d\u6784\u5efa\u7684\u6846\u67b6\u6765\u89e3\u51b3 MNIST \u624b\u5199\u6570\u5b57\u5206\u7c7b\u95ee\u9898\u3002</p> <ul> <li>\u8bf4\u660e</li> <li>\u7b14\u8bb0\u672c</li> </ul>"},{"location":"lessons/3-NeuralNetworks/04-OwnFramework/lab/","title":"MNIST Classification with Our Own Framework","text":"<p>Lab Assignment from AI for Beginners Curriculum.</p>"},{"location":"lessons/3-NeuralNetworks/04-OwnFramework/lab/#task","title":"Task","text":"<p>Solve the MNIST handwritten digit classification problem using 1-, 2- and 3-layered perceptron. Use the neural network framework we have developed in the lesson.</p>"},{"location":"lessons/3-NeuralNetworks/04-OwnFramework/lab/#stating-notebook","title":"Stating Notebook","text":"<p>Start the lab by opening MyFW_MNIST.ipynb</p>"},{"location":"lessons/3-NeuralNetworks/04-OwnFramework/lab/#questions","title":"Questions","text":"<p>As a result of this lab, try to answer the following questions:</p> <ul> <li>Does the inter-layer activation function affect network performance?</li> <li>Do we need 2- or 3-layered network for this task?</li> <li>Did you experience any problems training the network? Especially as the number of layers increased.</li> <li>How do weights of the network behave during training? You may plot max abs value of weights vs. epoch to understand the relation.</li> </ul>"},{"location":"lessons/3-NeuralNetworks/04-OwnFramework/lab/README_chs/","title":"\u7528\u6211\u4eec\u81ea\u5df1\u7684\u6846\u67b6\u8fdb\u884cMNIST\u5206\u7c7b","text":"<p>\u5b9e\u9a8c\u4efb\u52a1\u6765\u81eaAI for Beginners Curriculum\u3002</p>"},{"location":"lessons/3-NeuralNetworks/04-OwnFramework/lab/README_chs/#_1","title":"\u4efb\u52a1","text":"<p>\u4f7f\u75281\u5c42\u30012\u5c42\u548c3\u5c42\u611f\u77e5\u5668\u89e3\u51b3MNIST\u624b\u5199\u6570\u5b57\u5206\u7c7b\u95ee\u9898\u3002\u4f7f\u7528\u6211\u4eec\u5728\u8bfe\u7a0b\u4e2d\u5f00\u53d1\u7684\u795e\u7ecf\u7f51\u7edc\u6846\u67b6\u3002</p>"},{"location":"lessons/3-NeuralNetworks/04-OwnFramework/lab/README_chs/#_2","title":"\u5f00\u59cb","text":"<p>\u901a\u8fc7\u6253\u5f00MyFW_MNIST.ipynb\u6765\u5f00\u59cb\u5b9e\u9a8c\u3002</p>"},{"location":"lessons/3-NeuralNetworks/04-OwnFramework/lab/README_chs/#_3","title":"\u95ee\u9898","text":"<p>\u901a\u8fc7\u672c\u6b21\u5b9e\u9a8c\uff0c\u5c1d\u8bd5\u56de\u7b54\u4ee5\u4e0b\u95ee\u9898\uff1a</p> <ul> <li>\u5c42\u95f4\u6fc0\u6d3b\u51fd\u6570\u662f\u5426\u5f71\u54cd\u7f51\u7edc\u6027\u80fd\uff1f</li> <li>\u5bf9\u4e8e\u8fd9\u4e2a\u4efb\u52a1\uff0c\u6211\u4eec\u9700\u89812\u5c42\u62163\u5c42\u7f51\u7edc\u5417\uff1f</li> <li>\u5728\u8bad\u7ec3\u7f51\u7edc\u65f6\uff0c\u60a8\u662f\u5426\u9047\u5230\u4efb\u4f55\u95ee\u9898\uff1f\u5c24\u5176\u662f\u5728\u5c42\u6570\u589e\u52a0\u65f6\u3002</li> <li>\u5728\u8bad\u7ec3\u671f\u95f4\uff0c\u7f51\u7edc\u7684\u6743\u91cd\u662f\u5982\u4f55\u53d8\u5316\u7684\uff1f\u60a8\u53ef\u4ee5\u7ed8\u5236\u6743\u91cd\u7684\u6700\u5927\u7edd\u5bf9\u503c\u4e0eepoch\u7684\u5173\u7cfb\u56fe\u6765\u7406\u89e3\u8fd9\u79cd\u5173\u7cfb\u3002</li> </ul>"},{"location":"lessons/3-NeuralNetworks/05-Frameworks/","title":"Neural Network Frameworks","text":"<p>As we have learned already, to be able to train neural networks efficiently we need to do two things:</p> <ul> <li>To operate on tensors, eg. to multiply, add, and compute some functions such as sigmoid or softmax</li> <li>To compute gradients of all expressions, in order to perform gradient descent optimization</li> </ul>"},{"location":"lessons/3-NeuralNetworks/05-Frameworks/#pre-lecture-quiz","title":"Pre-lecture quiz","text":"<p>While the <code>numpy</code> library can do the first part, we need some mechanism to compute gradients. In our framework that we have developed in the previous section we had to manually program all derivative functions inside the <code>backward</code> method, which does backpropagation. Ideally, a framework should give us the opportunity to compute gradients of any expression that we can define.</p> <p>Another important thing is to be able to perform computations on GPU, or any other specialized compute units, such as TPU. Deep neural network training requires a lot of computations, and to be able to parallelize those computations on GPUs is very important.</p> <p>\u2705 The term 'parallelize' means to distribute the computations over multiple devices.</p> <p>Currently, the two most popular neural frameworks are: TensorFlow and PyTorch. Both provide a low-level API to operate with tensors on both CPU and GPU. On top of the low-level API, there is also higher-level API, called Keras and PyTorch Lightning correspondingly.</p> Low-Level API TensorFlow PyTorch High-level API Keras PyTorch Lightning <p>Low-level APIs in both frameworks allow you to build so-called computational graphs. This graph defines how to compute the output (usually the loss function) with given input parameters, and can be pushed for computation on GPU, if it is available. There are functions to differentiate this computational graph and compute gradients, which can then be used for optimizing model parameters.</p> <p>High-level APIs pretty much consider neural networks as a sequence of layers, and make constructing most of the neural networks much easier. Training the model usually requires preparing the data and then calling a <code>fit</code> function to do the job.</p> <p>The high-level API allows you to construct typical neural networks very quickly without worrying about lots of details. At the same time, low-level API offer much more control over the training process, and thus they are used a lot in research, when you are dealing with new neural network architectures.</p> <p>It is also important to understand that you can use both APIs together, eg. you can develop your own network layer architecture using low-level API, and then use it inside the larger network constructed and trained with the high-level API. Or you can define a network using the high-level API as a sequence of layers, and then use your own low-level training loop to perform optimization. Both APIs use the same basic underlying concepts, and they are designed to work well together.</p>"},{"location":"lessons/3-NeuralNetworks/05-Frameworks/#learning","title":"Learning","text":"<p>In this course, we offer most of the content both for PyTorch and TensorFlow. You can choose your preferred framework and only go through the corresponding notebooks. If you are not sure which framework to choose, read some discussions on the internet regarding PyTorch vs. TensorFlow. You can also have a look at both frameworks to get better understanding.</p> <p>Where possible, we will use High-Level APIs for simplicity. However, we believe it is important to understand how neural networks work from the ground up, thus in the beginning we start by working with low-level API and tensors. However, if you want to get going fast and do not want to spend a lot of time on learning these details, you can skip those and go straight into high-level API notebooks.</p>"},{"location":"lessons/3-NeuralNetworks/05-Frameworks/#exercises-frameworks","title":"\u270d\ufe0f Exercises: Frameworks","text":"<p>Continue your learning in the following notebooks:</p> Low-Level API TensorFlow+Keras Notebook PyTorch High-level API Keras PyTorch Lightning <p>After mastering the frameworks, let's recap the notion of overfitting.</p>"},{"location":"lessons/3-NeuralNetworks/05-Frameworks/#overfitting","title":"Overfitting","text":"<p>Overfitting is an extremely important concept in machine learning, and it is very important to get it right!</p> <p>Consider the following problem of approximating 5 dots (represented by <code>x</code> on the graphs below):</p> Linear model, 2 parameters Non-linear model, 7 parameters Training error = 5.3 Training error = 0 Validation error = 5.1 Validation error = 20 <ul> <li>On the left, we see a good straight line approximation. Because the number of parameters is adequate, the model gets the idea behind point distribution right.</li> <li>On the right, the model is too powerful. Because we only have 5 points and the model has 7 parameters, it can adjust in such a way as to pass through all points, making training the error to be 0. However, this prevents the model from understanding the correct pattern behind data, thus the validation error is very high.</li> </ul> <p>It is very important to strike a correct balance between the richness of the model (number of parameters) and the number of training samples.</p>"},{"location":"lessons/3-NeuralNetworks/05-Frameworks/#why-overfitting-occurs","title":"Why overfitting occurs","text":"<ul> <li>Not enough training data</li> <li>Too powerful model</li> <li>Too much noise in input data</li> </ul>"},{"location":"lessons/3-NeuralNetworks/05-Frameworks/#how-to-detect-overfitting","title":"How to detect overfitting","text":"<p>As you can see from the graph above, overfitting can be detected by a very low training error, and a high validation error. Normally during training we will see both training and validation errors starting to decrease, and then at some point validation error might stop decreasing and start rising. This will be a sign of overfitting, and the indicator that we should probably stop training at this point (or at least make a snapshot of the model).</p> <p></p>"},{"location":"lessons/3-NeuralNetworks/05-Frameworks/#how-to-prevent-overfitting","title":"How to prevent overfitting","text":"<p>If you can see that overfitting occurs, you can do one of the following:</p> <ul> <li>Increase the amount of training data</li> <li>Decrease the complexity of the model</li> <li>Use some regularization technique, such as Dropout, which we will consider later.</li> </ul>"},{"location":"lessons/3-NeuralNetworks/05-Frameworks/#overfitting-and-bias-variance-tradeoff","title":"Overfitting and Bias-Variance Tradeoff","text":"<p>Overfitting is actually a case of a more generic problem in statistics called Bias-Variance Tradeoff. If we consider the possible sources of error in our model, we can see two types of errors:</p> <ul> <li>Bias errors are caused by our algorithm not being able to capture the relationship between training data correctly. It can result from the fact that our model is not powerful enough (underfitting).</li> <li>Variance errors, which are caused by the model approximating noise in the input data instead of meaningful relationship (overfitting).</li> </ul> <p>During training, bias error decreases (as our model learns to approximate the data), and variance error increases. It is important to stop training - either manually (when we detect overfitting) or automatically (by introducing regularization) - to prevent overfitting.</p>"},{"location":"lessons/3-NeuralNetworks/05-Frameworks/#conclusion","title":"Conclusion","text":"<p>In this lesson, you learned about the differences between the various APIs for the two most popular AI frameworks, TensorFlow and PyTorch. In addition, you learned about a very important topic, overfitting.</p>"},{"location":"lessons/3-NeuralNetworks/05-Frameworks/#challenge","title":"\ud83d\ude80 Challenge","text":"<p>In the accompanying notebooks, you will find 'tasks' at the bottom; work through the notebooks and complete the tasks.</p>"},{"location":"lessons/3-NeuralNetworks/05-Frameworks/#post-lecture-quiz","title":"Post-lecture quiz","text":""},{"location":"lessons/3-NeuralNetworks/05-Frameworks/#review-self-study","title":"Review &amp; Self Study","text":"<p>Do some research on the following topics:</p> <ul> <li>TensorFlow</li> <li>PyTorch</li> <li>Overfitting</li> </ul> <p>Ask yourself the following questions:</p> <ul> <li>What is the difference between TensorFlow and PyTorch?</li> <li>What is the difference between overfitting and underfitting?</li> </ul>"},{"location":"lessons/3-NeuralNetworks/05-Frameworks/#assignment","title":"Assignment","text":"<p>In this lab, you are asked to solve two classification problems using single- and multi-layered fully-connected networks using PyTorch or TensorFlow.</p> <ul> <li>Instructions</li> <li>Notebook</li> </ul>"},{"location":"lessons/3-NeuralNetworks/05-Frameworks/README_chs/","title":"\u795e\u7ecf\u7f51\u7edc\u6846\u67b6","text":"<p>\u6b63\u5982\u6211\u4eec\u5df2\u7ecf\u5b66\u4e60\u5230\u7684\uff0c\u8981\u80fd\u591f\u9ad8\u6548\u5730\u8bad\u7ec3\u795e\u7ecf\u7f51\u7edc\uff0c\u6211\u4eec\u9700\u8981\u505a\u4e24\u4ef6\u4e8b\uff1a</p> <ul> <li>\u64cd\u4f5c\u5f20\u91cf\uff0c\u4f8b\u5982\u76f8\u4e58\u3001\u76f8\u52a0\u548c\u8ba1\u7b97\u4e00\u4e9b\u51fd\u6570\u5982sigmoid\u6216softmax</li> <li>\u8ba1\u7b97\u6240\u6709\u8868\u8fbe\u5f0f\u7684\u68af\u5ea6\uff0c\u4ee5\u4fbf\u6267\u884c\u68af\u5ea6\u4e0b\u964d\u4f18\u5316</li> </ul>"},{"location":"lessons/3-NeuralNetworks/05-Frameworks/README_chs/#_2","title":"\u8bfe\u524d\u6d4b\u9a8c","text":"<p>\u5c3d\u7ba1<code>numpy</code>\u5e93\u53ef\u4ee5\u5b8c\u6210\u7b2c\u4e00\u90e8\u5206\uff0c\u4f46\u6211\u4eec\u4ecd\u9700\u8981\u67d0\u79cd\u673a\u5236\u6765\u8ba1\u7b97\u68af\u5ea6\u3002\u5728\u5148\u524d\u7ae0\u8282\u5f00\u53d1\u7684\u6211\u4eec\u7684\u6846\u67b6\u4e2d\uff0c\u6211\u4eec\u4e0d\u5f97\u4e0d\u5728<code>backward</code>\u65b9\u6cd5\u5185\u624b\u52a8\u7f16\u7a0b\u6240\u6709\u7684\u5bfc\u6570\u51fd\u6570\u6765\u8fdb\u884c\u53cd\u5411\u4f20\u64ad\u3002\u7406\u60f3\u60c5\u51b5\u4e0b\uff0c\u4e00\u4e2a\u6846\u67b6\u5e94\u8ba9\u6211\u4eec\u80fd\u591f\u8ba1\u7b97\u4efb\u4f55\u8868\u8fbe\u5f0f\u7684\u68af\u5ea6\u3002</p> <p>\u53e6\u4e00\u4e2a\u91cd\u8981\u7684\u4e8b\u60c5\u662f\u80fd\u591f\u5728GPU\u6216\u4efb\u4f55\u5176\u4ed6\u4e13\u7528\u8ba1\u7b97\u5355\u5143\uff08\u5982TPU\uff09\u4e0a\u6267\u884c\u8ba1\u7b97\u3002\u6df1\u5ea6\u795e\u7ecf\u7f51\u7edc\u8bad\u7ec3\u9700\u8981\u5927\u91cf\u7684\u8ba1\u7b97\uff0c\u5e76\u4e14\u80fd\u591f\u5728GPU\u4e0a\u5e76\u884c\u8fd9\u4e9b\u8ba1\u7b97\u662f\u975e\u5e38\u91cd\u8981\u7684\u3002</p> <p>\u2705 \u672f\u8bed'\u5e76\u884c\u5316'\u610f\u5473\u7740\u5c06\u8ba1\u7b97\u5206\u914d\u5230\u591a\u4e2a\u8bbe\u5907\u4e0a\u3002</p> <p>\u76ee\u524d\uff0c\u6700\u6d41\u884c\u7684\u4e24\u4e2a\u795e\u7ecf\u7f51\u7edc\u6846\u67b6\u662f\uff1aTensorFlow\u548cPyTorch\u3002\u4e24\u8005\u90fd\u63d0\u4f9b\u4e86\u4e00\u4e2a\u4f4e\u7ea7API\uff0c\u5728CPU\u548cGPU\u4e0a\u64cd\u4f5c\u5f20\u91cf\u3002\u5728\u4f4e\u7ea7API\u4e4b\u4e0a\uff0c\u8fd8\u6709\u9ad8\u7ea7API\uff0c\u5206\u522b\u79f0\u4e3aKeras\u548cPyTorch Lightning\u3002</p> \u4f4e\u7ea7API TensorFlow PyTorch \u9ad8\u7ea7API Keras PyTorch Lightning <p>\u4f4e\u7ea7API\u5141\u8bb8\u4f60\u6784\u5efa\u6240\u8c13\u7684\u8ba1\u7b97\u56fe\u3002\u6b64\u56fe\u5b9a\u4e49\u4e86\u5982\u4f55\u5229\u7528\u7ed9\u5b9a\u7684\u8f93\u5165\u53c2\u6570\u8ba1\u7b97\u8f93\u51fa\uff08\u901a\u5e38\u662f\u635f\u5931\u51fd\u6570\uff09\uff0c\u5e76\u4e14\u5982\u679c\u6709GPU\u53ef\u7528\uff0c\u53ef\u4ee5\u5c06\u5176\u63a8\u9001\u5230GPU\u4e0a\u8fdb\u884c\u8ba1\u7b97\u3002\u8fd8\u6709\u4e00\u4e9b\u51fd\u6570\u7528\u4e8e\u6c42\u5bfc\u8fd9\u4e2a\u8ba1\u7b97\u56fe\u5e76\u8ba1\u7b97\u68af\u5ea6\uff0c\u8fd9\u4e9b\u68af\u5ea6\u968f\u540e\u53ef\u7528\u4e8e\u4f18\u5316\u6a21\u578b\u53c2\u6570\u3002</p> <p>\u9ad8\u7ea7API\u57fa\u672c\u4e0a\u5c06\u795e\u7ecf\u7f51\u7edc\u89c6\u4e3a\u4e00\u4e2a\u5c42\u7684\u5e8f\u5217\uff0c\u4f7f\u5927\u591a\u6570\u795e\u7ecf\u7f51\u7edc\u7684\u6784\u5efa\u53d8\u5f97\u66f4\u5bb9\u6613\u3002\u8bad\u7ec3\u6a21\u578b\u901a\u5e38\u9700\u8981\u51c6\u5907\u6570\u636e\uff0c\u7136\u540e\u8c03\u7528<code>fit</code>\u51fd\u6570\u6765\u5b8c\u6210\u8fd9\u9879\u5de5\u4f5c\u3002</p> <p>\u9ad8\u7ea7API\u5141\u8bb8\u4f60\u975e\u5e38\u5feb\u901f\u5730\u6784\u5efa\u5178\u578b\u7684\u795e\u7ecf\u7f51\u7edc\uff0c\u800c\u4e0d\u5fc5\u62c5\u5fc3\u8bb8\u591a\u7ec6\u8282\u3002\u540c\u65f6\uff0c\u4f4e\u7ea7API\u63d0\u4f9b\u4e86\u5bf9\u8bad\u7ec3\u8fc7\u7a0b\u66f4\u5927\u7684\u63a7\u5236\uff0c\u56e0\u6b64\u5728\u7814\u7a76\u65b0\u795e\u7ecf\u7f51\u7edc\u67b6\u6784\u65f6\u7ecf\u5e38\u4f7f\u7528\u3002</p> <p>\u8fd8\u9700\u8981\u7406\u89e3\u7684\u662f\uff0c\u4f60\u53ef\u4ee5\u5171\u540c\u4f7f\u7528\u4e24\u79cdAPI\uff0c\u4f8b\u5982\uff0c\u4f7f\u7528\u4f4e\u7ea7API\u5f00\u53d1\u81ea\u5df1\u7684\u7f51\u7edc\u5c42\u67b6\u6784\uff0c\u7136\u540e\u5728\u7528\u9ad8\u7ea7API\u6784\u5efa\u548c\u8bad\u7ec3\u7684\u5927\u578b\u7f51\u7edc\u4e2d\u4f7f\u7528\u5b83\u3002\u6216\u8005\u4f60\u53ef\u4ee5\u4f7f\u7528\u9ad8\u7ea7API\u4f5c\u4e3a\u5c42\u7684\u5e8f\u5217\u6765\u5b9a\u4e49\u7f51\u7edc\uff0c\u7136\u540e\u4f7f\u7528\u81ea\u5df1\u7684\u4f4e\u7ea7\u8bad\u7ec3\u5faa\u73af\u6765\u6267\u884c\u4f18\u5316\u3002\u4e24\u79cdAPI\u4f7f\u7528\u76f8\u540c\u7684\u57fa\u672c\u6982\u5ff5\uff0c\u5e76\u4e14\u8bbe\u8ba1\u4e3a\u80fd\u591f\u5f88\u597d\u5730\u534f\u4f5c\u3002</p>"},{"location":"lessons/3-NeuralNetworks/05-Frameworks/README_chs/#_3","title":"\u5b66\u4e60","text":"<p>\u5728\u672c\u8bfe\u7a0b\u4e2d\uff0c\u6211\u4eec\u63d0\u4f9b\u4e86\u5927\u90e8\u5206\u5185\u5bb9\u540c\u65f6\u9002\u7528\u4e8ePyTorch\u548cTensorFlow\u3002\u60a8\u53ef\u4ee5\u9009\u62e9\u9996\u9009\u7684\u6846\u67b6\uff0c\u5e76\u4ec5\u5b66\u4e60\u76f8\u5e94\u7684\u7b14\u8bb0\u672c\u3002\u5982\u679c\u60a8\u4e0d\u786e\u5b9a\u9009\u62e9\u54ea\u4e2a\u6846\u67b6\uff0c\u53ef\u4ee5\u9605\u8bfb\u4e00\u4e9b\u5173\u4e8ePyTorch vs. TensorFlow\u7684\u8ba8\u8bba\u3002\u60a8\u4e5f\u53ef\u4ee5\u67e5\u770b\u8fd9\u4e24\u4e2a\u6846\u67b6\u4ee5\u83b7\u5f97\u66f4\u597d\u7684\u7406\u89e3\u3002</p> <p>\u5c3d\u53ef\u80fd\u60c5\u51b5\u4e0b\uff0c\u6211\u4eec\u5c06\u4f7f\u7528\u9ad8\u7ea7API\u4ee5\u6c42\u7b80\u5355\u3002\u7136\u800c\uff0c\u6211\u4eec\u8ba4\u4e3a\u7406\u89e3\u4ece\u57fa\u7840\u5230\u9ad8\u7ea7\u7684\u795e\u7ecf\u7f51\u7edc\u5de5\u4f5c\u539f\u7406\u975e\u5e38\u91cd\u8981\uff0c\u56e0\u6b64\u4e00\u5f00\u59cb\u6211\u4eec\u5c06\u4f7f\u7528\u4f4e\u7ea7API\u548c\u5f20\u91cf\u8fdb\u884c\u5de5\u4f5c\u3002\u7136\u800c\uff0c\u5982\u679c\u60a8\u5e0c\u671b\u5feb\u901f\u5165\u95e8\u5e76\u4e0d\u60f3\u82b1\u592a\u591a\u65f6\u95f4\u5b66\u4e60\u8fd9\u4e9b\u7ec6\u8282\uff0c\u60a8\u53ef\u4ee5\u8df3\u8fc7\u8fd9\u4e9b\u76f4\u63a5\u8fdb\u5165\u9ad8\u7ea7API\u7b14\u8bb0\u672c\u3002</p>"},{"location":"lessons/3-NeuralNetworks/05-Frameworks/README_chs/#_4","title":"\u270d\ufe0f \u7ec3\u4e60\uff1a\u6846\u67b6","text":"<p>\u5728\u4ee5\u4e0b\u7b14\u8bb0\u672c\u4e2d\u7ee7\u7eed\u60a8\u7684\u5b66\u4e60\uff1a</p> \u4f4e\u7ea7API TensorFlow+Keras \u7b14\u8bb0\u672c PyTorch \u9ad8\u7ea7API Keras PyTorch Lightning <p>\u5728\u638c\u63e1\u6846\u67b6\u4e4b\u540e\uff0c\u8ba9\u6211\u4eec\u56de\u987e\u4e00\u4e0b\u8fc7\u62df\u5408\u7684\u6982\u5ff5\u3002</p>"},{"location":"lessons/3-NeuralNetworks/05-Frameworks/README_chs/#_5","title":"\u8fc7\u62df\u5408","text":"<p>\u8fc7\u62df\u5408\u662f\u673a\u5668\u5b66\u4e60\u4e2d\u4e00\u4e2a\u6781\u5176\u91cd\u8981\u7684\u6982\u5ff5\uff0c\u638c\u63e1\u5b83\u975e\u5e38\u91cd\u8981\uff01</p> <p>\u8003\u8651\u4ee5\u4e0b\u8fd1\u4f3c5\u4e2a\u70b9\uff08\u5728\u4e0b\u56fe\u4e2d\u7531<code>x</code>\u8868\u793a\uff09\u7684\u95ee\u9898\uff1a</p> \u7ebf\u6027\u6a21\u578b\uff0c2\u4e2a\u53c2\u6570 \u975e\u7ebf\u6027\u6a21\u578b\uff0c7\u4e2a\u53c2\u6570 \u8bad\u7ec3\u8bef\u5dee = 5.3 \u8bad\u7ec3\u8bef\u5dee = 0 \u9a8c\u8bc1\u8bef\u5dee = 5.1 \u9a8c\u8bc1\u8bef\u5dee = 20 <ul> <li>\u5de6\u8fb9\uff0c\u6211\u4eec\u770b\u5230\u4e00\u4e2a\u5f88\u597d\u7684\u76f4\u7ebf\u8fd1\u4f3c\u3002\u56e0\u4e3a\u53c2\u6570\u6570\u91cf\u662f\u6070\u5f53\u7684\uff0c\u6a21\u578b\u6b63\u786e\u7406\u89e3\u4e86\u70b9\u7684\u5206\u5e03\u3002</li> <li>\u53f3\u8fb9\uff0c\u6a21\u578b\u592a\u5f3a\u5927\u4e86\u3002\u56e0\u4e3a\u6211\u4eec\u53ea\u67095\u4e2a\u70b9\uff0c\u800c\u6a21\u578b\u67097\u4e2a\u53c2\u6570\uff0c\u5b83\u53ef\u4ee5\u8c03\u6574\u4ee5\u901a\u8fc7\u6240\u6709\u70b9\uff0c\u4f7f\u5f97\u8bad\u7ec3\u8bef\u5dee\u4e3a0\u3002\u7136\u800c\uff0c\u8fd9\u963b\u6b62\u4e86\u6a21\u578b\u7406\u89e3\u6570\u636e\u80cc\u540e\u7684\u6b63\u786e\u6a21\u5f0f\uff0c\u56e0\u6b64\u9a8c\u8bc1\u8bef\u5dee\u975e\u5e38\u9ad8\u3002</li> </ul> <p>\u5728\u6a21\u578b\u7684\u590d\u6742\u5ea6\uff08\u53c2\u6570\u6570\u91cf\uff09\u548c\u8bad\u7ec3\u6837\u672c\u6570\u91cf\u4e4b\u95f4\u627e\u5230\u6b63\u786e\u7684\u5e73\u8861\u975e\u5e38\u91cd\u8981\u3002</p>"},{"location":"lessons/3-NeuralNetworks/05-Frameworks/README_chs/#_6","title":"\u4e3a\u4ec0\u4e48\u4f1a\u53d1\u751f\u8fc7\u62df\u5408","text":"<ul> <li>\u8bad\u7ec3\u6570\u636e\u4e0d\u8db3</li> <li>\u6a21\u578b\u592a\u5f3a\u5927</li> <li>\u8f93\u5165\u6570\u636e\u4e2d\u566a\u97f3\u8fc7\u591a</li> </ul>"},{"location":"lessons/3-NeuralNetworks/05-Frameworks/README_chs/#_7","title":"\u5982\u4f55\u68c0\u6d4b\u8fc7\u62df\u5408","text":"<p>\u6b63\u5982\u4e0a\u56fe\u6240\u793a\uff0c\u8fc7\u62df\u5408\u53ef\u4ee5\u901a\u8fc7\u975e\u5e38\u4f4e\u7684\u8bad\u7ec3\u8bef\u5dee\u548c\u9ad8\u7684\u9a8c\u8bc1\u8bef\u5dee\u6765\u68c0\u6d4b\u3002\u901a\u5e38\u5728\u8bad\u7ec3\u8fc7\u7a0b\u4e2d\uff0c\u6211\u4eec\u4f1a\u770b\u5230\u8bad\u7ec3\u8bef\u5dee\u548c\u9a8c\u8bc1\u8bef\u5dee\u90fd\u5728\u51cf\u5c11\uff0c\u7136\u540e\u67d0\u4e2a\u65f6\u5019\u9a8c\u8bc1\u8bef\u5dee\u53ef\u80fd\u505c\u6b62\u51cf\u5c11\u5e76\u5f00\u59cb\u4e0a\u5347\u3002\u8fd9\u5c06\u662f\u8fc7\u62df\u5408\u7684\u4fe1\u53f7\uff0c\u8868\u660e\u6211\u4eec\u5e94\u8be5\u505c\u6b62\u8bad\u7ec3\uff08\u6216\u81f3\u5c11\u4fdd\u5b58\u6a21\u578b\u7684\u5feb\u7167\uff09\u3002</p> <p></p>"},{"location":"lessons/3-NeuralNetworks/05-Frameworks/README_chs/#_8","title":"\u5982\u4f55\u9632\u6b62\u8fc7\u62df\u5408","text":"<p>\u5982\u679c\u4f60\u53d1\u73b0\u8fc7\u62df\u5408\u53d1\u751f\u4e86\uff0c\u4f60\u53ef\u4ee5\u91c7\u53d6\u4ee5\u4e0b\u63aa\u65bd\u4e4b\u4e00\uff1a</p> <ul> <li>\u589e\u52a0\u8bad\u7ec3\u6570\u636e\u91cf</li> <li>\u51cf\u5c11\u6a21\u578b\u7684\u590d\u6742\u5ea6</li> <li>\u4f7f\u7528\u67d0\u79cd\u6b63\u5219\u5316\u6280\u672f\uff0c\u4f8b\u5982Dropout\uff0c\u6211\u4eec\u7a0d\u540e\u4f1a\u8003\u8651\u8fd9\u4e9b\u6280\u672f\u3002</li> </ul>"},{"location":"lessons/3-NeuralNetworks/05-Frameworks/README_chs/#-","title":"\u8fc7\u62df\u5408\u548c\u504f\u5dee-\u65b9\u5dee\u6743\u8861","text":"<p>\u8fc7\u62df\u5408\u5b9e\u9645\u4e0a\u662f\u7edf\u8ba1\u5b66\u4e2d\u7684\u4e00\u79cd\u66f4\u901a\u7528\u7684\u95ee\u9898\uff0c\u79f0\u4e3a\u504f\u5dee-\u65b9\u5dee\u6743\u8861\u3002\u5982\u679c\u6211\u4eec\u8003\u8651\u6a21\u578b\u4e2d\u53ef\u80fd\u7684\u9519\u8bef\u6765\u6e90\uff0c\u6211\u4eec\u53ef\u4ee5\u770b\u5230\u4e24\u79cd\u7c7b\u578b\u7684\u9519\u8bef\uff1a</p> <ul> <li>\u504f\u5dee\u9519\u8bef\uff0c\u7531\u6211\u4eec\u7684\u7b97\u6cd5\u672a\u80fd\u6b63\u786e\u6355\u6349\u8bad\u7ec3\u6570\u636e\u4e4b\u95f4\u7684\u5173\u7cfb\u5f15\u8d77\u3002\u5b83\u53ef\u80fd\u662f\u7531\u4e8e\u6211\u4eec\u7684\u6a21\u578b\u4e0d\u591f\u5f3a\u5927\uff08\u6b20\u62df\u5408\uff09\u9020\u6210\u7684\u3002</li> <li>\u65b9\u5dee\u9519\u8bef\uff0c\u7531\u6a21\u578b\u8fd1\u4f3c\u8f93\u5165\u6570\u636e\u4e2d\u7684\u566a\u58f0\u800c\u4e0d\u662f\u6709\u610f\u4e49\u7684\u5173\u7cfb\u5f15\u8d77\uff08\u8fc7\u62df\u5408\uff09\u3002</li> </ul> <p>\u5728\u8bad\u7ec3\u8fc7\u7a0b\u4e2d\uff0c\u504f\u5dee\u9519\u8bef\u51cf\u5c11\uff08\u56e0\u4e3a\u6211\u4eec\u7684\u6a21\u578b\u5b66\u4f1a\u8fd1\u4f3c\u6570\u636e\uff09\uff0c\u800c\u65b9\u5dee\u9519\u8bef\u589e\u52a0\u3002\u91cd\u8981\u7684\u662f\u5728\u53d1\u73b0\u8fc7\u62df\u5408\u65f6\u505c\u6b62\u8bad\u7ec3 - \u65e0\u8bba\u662f\u624b\u52a8\u8fd8\u662f\u81ea\u52a8\uff08\u901a\u8fc7\u5f15\u5165\u6b63\u5219\u5316\uff09 - \u4ee5\u9632\u6b62\u8fc7\u62df\u5408\u3002</p>"},{"location":"lessons/3-NeuralNetworks/05-Frameworks/README_chs/#_9","title":"\u7ed3\u8bba","text":"<p>\u5728\u672c\u8bfe\u4e2d\uff0c\u60a8\u4e86\u89e3\u4e86\u4e24\u4e2a\u6700\u6d41\u884c\u7684AI\u6846\u67b6TensorFlow\u548cPyTorch\u7684\u4e0d\u540cAPI\u3002\u6b64\u5916\uff0c\u60a8\u8fd8\u4e86\u89e3\u4e86\u4e00\u4e2a\u975e\u5e38\u91cd\u8981\u7684\u4e3b\u9898\uff0c\u8fc7\u62df\u5408\u3002</p>"},{"location":"lessons/3-NeuralNetworks/05-Frameworks/README_chs/#_10","title":"\ud83d\ude80 \u6311\u6218","text":"<p>\u5728\u914d\u5957\u7684\u7b14\u8bb0\u672c\u4e2d\uff0c\u60a8\u5c06\u5728\u5e95\u90e8\u627e\u5230\u201c\u4efb\u52a1\u201d\uff1b\u8bf7\u5b8c\u6210\u7b14\u8bb0\u672c\u4e2d\u7684\u4efb\u52a1\u3002</p>"},{"location":"lessons/3-NeuralNetworks/05-Frameworks/README_chs/#_11","title":"\u8bfe\u540e\u6d4b\u9a8c","text":""},{"location":"lessons/3-NeuralNetworks/05-Frameworks/README_chs/#_12","title":"\u590d\u4e60\u4e0e\u81ea\u5b66","text":"<p>\u5bf9\u4ee5\u4e0b\u4e3b\u9898\u8fdb\u884c\u4e00\u4e9b\u7814\u7a76\uff1a</p> <ul> <li>TensorFlow</li> <li>PyTorch</li> <li>\u8fc7\u62df\u5408</li> </ul> <p>\u95ee\u81ea\u5df1\u4ee5\u4e0b\u95ee\u9898\uff1a</p> <ul> <li>TensorFlow\u548cPyTorch\u7684\u533a\u522b\u662f\u4ec0\u4e48\uff1f</li> <li>\u8fc7\u62df\u5408\u548c\u6b20\u62df\u5408\u7684\u533a\u522b\u662f\u4ec0\u4e48\uff1f</li> </ul>"},{"location":"lessons/3-NeuralNetworks/05-Frameworks/README_chs/#_13","title":"\u4f5c\u4e1a","text":"<p>\u5728\u672c\u5b9e\u9a8c\u4e2d\uff0c\u60a8\u9700\u8981\u4f7f\u7528PyTorch\u6216TensorFlow\u89e3\u51b3\u4e24\u4e2a\u5206\u7c7b\u95ee\u9898\uff0c\u4f7f\u7528\u5355\u5c42\u548c\u591a\u5c42\u5b8c\u5168\u8fde\u63a5\u7684\u7f51\u7edc\u3002</p> <ul> <li>\u8bf4\u660e</li> <li>\u7b14\u8bb0\u672c</li> </ul>"},{"location":"lessons/3-NeuralNetworks/05-Frameworks/lab/","title":"Classification with PyTorch/TensorFlow","text":"<p>Lab Assignment from AI for Beginners Curriculum.</p>"},{"location":"lessons/3-NeuralNetworks/05-Frameworks/lab/#task","title":"Task","text":"<p>Solve two classification problems using single and multi-layered fully-connected networks using PyTorch or TensorFlow:</p> <ol> <li>Iris classification problem - an example of problem with tabular input data, which can be handled by classical machine learning. You goal would be to classify irises into 3 classes, based on 4 numeric parameters.</li> <li>MNIST handwritten digit classification problem which we have seen before.</li> </ol> <p>Try different network architectures to achieve the best accuracy you can get.</p>"},{"location":"lessons/3-NeuralNetworks/05-Frameworks/lab/#stating-notebook","title":"Stating Notebook","text":"<p>Start the lab by opening LabFrameworks.ipynb</p>"},{"location":"lessons/3-NeuralNetworks/05-Frameworks/lab/README_chs/","title":"\u4f7f\u7528 PyTorch/TensorFlow \u8fdb\u884c\u5206\u7c7b","text":"<p>\u6765\u81ea AI \u521d\u5b66\u8005\u8bfe\u7a0b \u7684\u5b9e\u9a8c\u4f5c\u4e1a\u3002</p>"},{"location":"lessons/3-NeuralNetworks/05-Frameworks/lab/README_chs/#_1","title":"\u4efb\u52a1","text":"<p>\u4f7f\u7528 PyTorch \u6216 TensorFlow \u7684\u5355\u5c42\u548c\u591a\u5c42\u5168\u8fde\u63a5\u7f51\u7edc\u89e3\u51b3\u4e24\u4e2a\u5206\u7c7b\u95ee\u9898\uff1a</p> <ol> <li>Iris \u5206\u7c7b \u95ee\u9898 - \u4e00\u4e2a\u5177\u6709\u8868\u683c\u8f93\u5165\u6570\u636e\u7684\u95ee\u9898\u793a\u4f8b\uff0c\u53ef\u4ee5\u901a\u8fc7\u7ecf\u5178\u7684\u673a\u5668\u5b66\u4e60\u6765\u5904\u7406\u3002\u4f60\u7684\u76ee\u6807\u662f\u57fa\u4e8e 4 \u4e2a\u6570\u503c\u53c2\u6570\u5c06\u9e22\u5c3e\u82b1\u5206\u7c7b\u4e3a 3 \u7c7b\u3002</li> <li>MNIST \u624b\u5199\u6570\u5b57\u5206\u7c7b\u95ee\u9898\uff0c\u8fd9\u4e2a\u95ee\u9898\u6211\u4eec\u4e4b\u524d\u5df2\u7ecf\u89c1\u8fc7\u3002</li> </ol> <p>\u5c1d\u8bd5\u4e0d\u540c\u7684\u7f51\u7edc\u67b6\u6784\uff0c\u4ee5\u83b7\u5f97\u6700\u4f73\u51c6\u786e\u6027\u3002</p>"},{"location":"lessons/3-NeuralNetworks/05-Frameworks/lab/README_chs/#_2","title":"\u5f00\u59cb\u8bb0\u4e8b\u672c","text":"<p>\u901a\u8fc7\u6253\u5f00 LabFrameworks.ipynb \u6765\u5f00\u59cb\u5b9e\u9a8c\u3002</p>"},{"location":"lessons/4-ComputerVision/","title":"Computer Vision","text":"<p>In this section we will learn about:</p> <ul> <li>Intro to Computer Vision and OpenCV</li> <li>Convolutional Neural Networks</li> <li>Pre-trained Networks and Transfer Learning </li> <li>Autoencoders</li> <li>Generative Adversarial Networks</li> <li>Object Detection</li> <li>Semantic Segmentation</li> </ul>"},{"location":"lessons/4-ComputerVision/README_chs/","title":"\u8ba1\u7b97\u673a\u89c6\u89c9","text":"<p>\u5728\u672c\u8282\u4e2d\u6211\u4eec\u5c06\u5b66\u4e60\uff1a</p> <ul> <li>\u8ba1\u7b97\u673a\u89c6\u89c9\u548cOpenCV\u5165\u95e8</li> <li>\u5377\u79ef\u795e\u7ecf\u7f51\u7edc</li> <li>\u9884\u8bad\u7ec3\u7f51\u7edc\u548c\u8fc1\u79fb\u5b66\u4e60</li> <li>\u81ea\u7f16\u7801\u5668</li> <li>\u751f\u6210\u5bf9\u6297\u7f51\u7edc</li> <li>\u7269\u4f53\u68c0\u6d4b</li> <li>\u8bed\u4e49\u5206\u5272</li> </ul>"},{"location":"lessons/4-ComputerVision/06-IntroCV/","title":"Introduction to Computer Vision","text":"<p>Computer Vision is a discipline whose aim is to allow computers to gain high-level understanding of digital images. This is quite a broad definition, because understanding can mean many different things, including finding an object on a picture (object detection), understanding what is happening (event detection), describing a picture in text, or reconstructing a scene in 3D. There are also special tasks related to human images: age and emotion estimation, face detection and identification, and 3D pose estimation, to name a few.</p>"},{"location":"lessons/4-ComputerVision/06-IntroCV/#pre-lecture-quiz","title":"Pre-lecture quiz","text":"<p>One of the simplest tasks of computer vision is image classification.</p> <p>Computer vision is often considered to be a branch of AI. Nowadays, most of computer vision tasks are solved using neural networks. We will learn more about the special type of neural networks used for computer vision, convolutional neural networks, throughout this section.</p> <p>However, before you pass the image to a neural network, in many cases it makes sense to use some algorithmic techniques to enhance the image.</p> <p>There are several Python libraries available for image processing:</p> <ul> <li>imageio can be used for reading/writing different image formats. It also support ffmpeg, a useful tool to convert video frames to images.</li> <li>Pillow (also known as PIL) is a bit more powerful, and also supports some image manipulation such as morphing, palette adjustments, and more.</li> <li>OpenCV is a powerful image processing library written in C++, which has become the de facto standard for image processing. It has a convenient Python interface.</li> <li>dlib is a C++ library that implements many machine learning algorithms, including some of the Computer Vision algorithms. It also has a Python interface, and can be used for challenging tasks such as face and facial landmark detection.</li> </ul>"},{"location":"lessons/4-ComputerVision/06-IntroCV/#opencv","title":"OpenCV","text":"<p>OpenCV is considered to be the de facto standard for image processing. It contains a lot of useful algorithms, implemented in C++. You can call OpenCV from Python as well.</p> <p>A good place to learn OpenCV is this Learn OpenCV course. In our curriculum, our goal is not to learn OpenCV, but to show you some examples when it can be used, and how.</p>"},{"location":"lessons/4-ComputerVision/06-IntroCV/#loading-images","title":"Loading Images","text":"<p>Images in Python can be conveniently represented by NumPy arrays. For example, grayscale images with the size of 320x200 pixels would be stored in a 200x320 array, and color images of the same dimension would have shape of 200x320x3 (for 3 color channels). To load an image, you can use the following code:</p> <pre><code>import cv2\nimport matplotlib.pyplot as plt\n\nim = cv2.imread('image.jpeg')\nplt.imshow(im)\n</code></pre> <p>Traditionally, OpenCV uses BGR (Blue-Green-Red) encoding for color images, while the rest of Python tools use the more traditional RGB (Red-Green-Blue). For the image to look right, you need to convert it to the RGB color space, either by swapping dimensions in the NumPy array, or by calling an OpenCV function:</p> <pre><code>im = cv2.cvtColor(im,cv2.COLOR_BGR2RGB)\n</code></pre> <p>The same <code>cvtColor</code> function can be used to perform other color space transformations such as converting an image to grayscale or to the HSV (Hue-Saturation-Value) color space.</p> <p>You can also use OpenCV to load video frame-by-frame - an example is given in the exercise OpenCV Notebook.</p>"},{"location":"lessons/4-ComputerVision/06-IntroCV/#image-processing","title":"Image Processing","text":"<p>Before feeding an image to a neural network, you may want to apply several pre-processing steps. OpenCV can do many things, including:</p> <ul> <li>Resizing the image using <code>im = cv2.resize(im, (320,200),interpolation=cv2.INTER_LANCZOS)</code></li> <li>Blurring the image using <code>im = cv2.medianBlur(im,3)</code> or <code>im = cv2.GaussianBlur(im, (3,3), 0)</code></li> <li>Changing the brightness and contrast of the image can be done by NumPy array manipulations, as described in this Stackoverflow note.</li> <li>Using thresholding by calling <code>cv2.threshold</code>/<code>cv2.adaptiveThreshold</code> functions, which is often preferable to adjusting brightness or contrast.</li> <li>Applying different transformations to the image:<ul> <li>Affine transformations can be useful if you need to combine rotation, resizing and skewing to the image and you know the source and destination location of three points in the image. Affine transformations keep parallel lines parallel.</li> <li>Perspective transformations can be useful when you know the source and destination positions of 4 points in the image. For example, if you take a picture of a rectangular document via a smartphone camera from some angle, and you want to make a rectangular image of the document itself.</li> </ul> </li> <li>Understanding movement inside the image by using optical flow.</li> </ul>"},{"location":"lessons/4-ComputerVision/06-IntroCV/#examples-of-using-computer-vision","title":"Examples of using Computer Vision","text":"<p>In our OpenCV Notebook, we give some examples of when computer vision can be used to perform specific tasks:</p> <ul> <li>Pre-processing a photograph of a Braille book. We focus on how we can use thresholding, feature detection, perspective transformation and NumPy manipulations to separate individual Braille symbols for further classification by a neural network.</li> </ul> <p>Image from OpenCV.ipynb</p> <ul> <li>Detecting motion in video using frame difference. If the camera is fixed, then frames from the camera feed should be pretty similar to each other. Since frames are represented as arrays, just by subtracting those arrays for two subsequent frames we will get the pixel difference, which should be low for static frames, and become higher once there is substantial motion in the image.</li> </ul> <p></p> <p>Image from OpenCV.ipynb</p> <ul> <li> <p>Detecting motion using Optical Flow. Optical flow allows us to understand how individual pixels on video frames move. There are two types of optical flow:</p> </li> <li> <p>Dense Optical Flow computes the vector field that shows for each pixel where is it moving</p> </li> <li>Sparse Optical Flow is based on taking some distinctive features in the image (eg. edges), and building their trajectory from frame to frame.</li> </ul> <p></p> <p>Image from OpenCV.ipynb</p>"},{"location":"lessons/4-ComputerVision/06-IntroCV/#example-notebooks-opencv-try-opencv-in-action","title":"\u270d\ufe0f Example Notebooks: OpenCV try OpenCV in Action","text":"<p>Let's do some experiments with OpenCV by exploring OpenCV Notebook</p>"},{"location":"lessons/4-ComputerVision/06-IntroCV/#conclusion","title":"Conclusion","text":"<p>Sometimes, relatively complex tasks such as movement detection or fingertip detection can be solved purely by computer vision. Thus, it is very helpful to know the basic techniques of computer vision, and what libraries like OpenCV can do.</p>"},{"location":"lessons/4-ComputerVision/06-IntroCV/#challenge","title":"\ud83d\ude80 Challenge","text":"<p>Watch this video from the AI show to learn about the Cortic Tigers project and how they built a block-based solution to democratize computer vision tasks via a robot. Do some research on other projects like this that help onboard new learners into the field.</p>"},{"location":"lessons/4-ComputerVision/06-IntroCV/#post-lecture-quiz","title":"Post-lecture quiz","text":""},{"location":"lessons/4-ComputerVision/06-IntroCV/#review-self-study","title":"Review &amp; Self Study","text":"<p>Read more on optical flow in this great tutorial.</p>"},{"location":"lessons/4-ComputerVision/06-IntroCV/#assignment","title":"Assignment","text":"<p>In this lab, you will take a video with simple gestures, and your goal is to extract up/down/left/right movements using optical flow.</p> <p></p>"},{"location":"lessons/4-ComputerVision/06-IntroCV/README_chs/","title":"\u8ba1\u7b97\u673a\u89c6\u89c9\u7b80\u4ecb","text":"<p>\u8ba1\u7b97\u673a\u89c6\u89c9 \u662f\u4e00\u4e2a\u5b66\u79d1\uff0c\u5176\u76ee\u6807\u662f\u4f7f\u8ba1\u7b97\u673a\u80fd\u591f\u5bf9\u6570\u5b57\u56fe\u50cf\u8fdb\u884c\u9ad8\u6c34\u5e73\u7684\u7406\u89e3\u3002\u8fd9\u662f\u4e00\u4e2a\u76f8\u5f53\u5e7f\u6cdb\u7684\u5b9a\u4e49\uff0c\u56e0\u4e3a\u7406\u89e3\u53ef\u4ee5\u610f\u5473\u7740\u8bb8\u591a\u4e0d\u540c\u7684\u4e8b\u60c5\uff0c\u5305\u62ec\u5728\u56fe\u7247\u4e2d\u627e\u5230\u4e00\u4e2a\u7269\u4f53\uff08\u7269\u4f53\u68c0\u6d4b\uff09\uff0c\u7406\u89e3\u6b63\u5728\u53d1\u751f\u7684\u4e8b\u60c5\uff08\u4e8b\u4ef6\u68c0\u6d4b\uff09\uff0c\u7528\u6587\u672c\u63cf\u8ff0\u56fe\u7247\uff0c\u6216\u8005\u57283D\u4e2d\u91cd\u5efa\u573a\u666f\u3002\u8fd8\u6709\u4e00\u4e9b\u4e0e\u4eba\u7c7b\u56fe\u50cf\u76f8\u5173\u7684\u7279\u6b8a\u4efb\u52a1\uff1a\u5e74\u9f84\u548c\u60c5\u7eea\u4f30\u8ba1\u3001\u9762\u90e8\u68c0\u6d4b\u548c\u8bc6\u522b\uff0c\u4ee5\u53ca3D\u59ff\u6001\u4f30\u8ba1\uff0c\u7b49\u7b49\u3002</p>"},{"location":"lessons/4-ComputerVision/06-IntroCV/README_chs/#_2","title":"\u8bfe\u524d\u5c0f\u6d4b\u9a8c","text":"<p>\u8ba1\u7b97\u673a\u89c6\u89c9\u6700\u7b80\u5355\u7684\u4efb\u52a1\u4e4b\u4e00\u662f\u56fe\u50cf\u5206\u7c7b\u3002</p> <p>\u8ba1\u7b97\u673a\u89c6\u89c9\u901a\u5e38\u88ab\u8ba4\u4e3a\u662f\u4eba\u5de5\u667a\u80fd\u7684\u4e00\u4e2a\u5206\u652f\u3002\u5982\u4eca\uff0c\u5927\u591a\u6570\u8ba1\u7b97\u673a\u89c6\u89c9\u4efb\u52a1\u90fd\u662f\u901a\u8fc7\u795e\u7ecf\u7f51\u7edc\u6765\u89e3\u51b3\u7684\u3002\u6211\u4eec\u5c06\u5728\u672c\u8282\u4e2d\u8be6\u7ec6\u5b66\u4e60\u7528\u4e8e\u8ba1\u7b97\u673a\u89c6\u89c9\u7684\u7279\u6b8a\u7c7b\u578b\u795e\u7ecf\u7f51\u7edc\u5377\u79ef\u795e\u7ecf\u7f51\u7edc\u3002</p> <p>\u7136\u800c\uff0c\u5728\u5c06\u56fe\u50cf\u4f20\u9012\u7ed9\u795e\u7ecf\u7f51\u7edc\u4e4b\u524d\uff0c\u5728\u8bb8\u591a\u60c5\u51b5\u4e0b\u4f7f\u7528\u4e00\u4e9b\u7b97\u6cd5\u6280\u672f\u6765\u589e\u5f3a\u56fe\u50cf\u662f\u6709\u610f\u4e49\u7684\u3002</p> <p>\u6709\u51e0\u4e2a\u7528\u4e8e\u56fe\u50cf\u5904\u7406\u7684Python\u5e93\uff1a</p> <ul> <li>imageio \u53ef\u7528\u4e8e\u8bfb\u5199\u4e0d\u540c\u7684\u56fe\u50cf\u683c\u5f0f\u3002\u5b83\u8fd8\u652f\u6301 ffmpeg\uff0c\u4e00\u4e2a\u5c06\u89c6\u9891\u5e27\u8f6c\u6362\u4e3a\u56fe\u50cf\u7684\u6709\u7528\u5de5\u5177\u3002</li> <li>Pillow\uff08\u4e5f\u79f0\u4e3a PIL\uff09\u66f4\u5f3a\u5927\u4e00\u4e9b\uff0c\u8fd8\u652f\u6301\u4e00\u4e9b\u56fe\u50cf\u64cd\u4f5c\uff0c\u5982\u53d8\u5f62\u3001\u8c03\u8272\u677f\u8c03\u6574\u7b49\u3002</li> <li>OpenCV \u662f\u4e00\u4e2a\u7528 C++ \u7f16\u5199\u7684\u5f3a\u5927\u56fe\u50cf\u5904\u7406\u5e93\uff0c\u5df2\u6210\u4e3a\u56fe\u50cf\u5904\u7406\u7684\u4e8b\u5b9e\u6807\u51c6\u3002\u5b83\u6709\u4e00\u4e2a\u65b9\u4fbf\u7684 Python \u63a5\u53e3\u3002</li> <li>dlib \u662f\u4e00\u4e2a\u5b9e\u73b0\u4e86\u8bb8\u591a\u673a\u5668\u5b66\u4e60\u7b97\u6cd5\u7684 C++ \u5e93\uff0c\u5305\u62ec\u4e00\u4e9b\u8ba1\u7b97\u673a\u89c6\u89c9\u7b97\u6cd5\u3002\u5b83\u4e5f\u6709\u4e00\u4e2a Python \u63a5\u53e3\uff0c\u53ef\u4ee5\u7528\u4e8e\u9762\u90e8\u548c\u9762\u90e8\u7279\u5f81\u68c0\u6d4b\u7b49\u5177\u6709\u6311\u6218\u6027\u7684\u4efb\u52a1\u3002</li> </ul>"},{"location":"lessons/4-ComputerVision/06-IntroCV/README_chs/#opencv","title":"OpenCV","text":"<p>OpenCV \u88ab\u8ba4\u4e3a\u662f\u56fe\u50cf\u5904\u7406\u7684\u4e8b\u5b9e\u6807\u51c6\u3002\u5b83\u5305\u542b\u8bb8\u591a\u6709\u7528\u7684\u7b97\u6cd5\uff0c\u7528 C++ \u5b9e\u73b0\u3002\u4f60\u4e5f\u53ef\u4ee5\u4ece Python \u8c03\u7528 OpenCV\u3002</p> <p>\u5b66\u4e60 OpenCV \u7684\u4e00\u4e2a\u597d\u5730\u65b9\u662f\u8fd9\u4e2a Learn OpenCV \u8bfe\u7a0b\u3002\u5728\u6211\u4eec\u7684\u8bfe\u7a0b\u4e2d\uff0c\u6211\u4eec\u7684\u76ee\u6807\u4e0d\u662f\u5b66\u4e60 OpenCV\uff0c\u800c\u662f\u5411\u4f60\u5c55\u793a\u5b83\u53ef\u4ee5\u5728\u4f55\u65f6\u548c\u5982\u4f55\u4f7f\u7528\u7684\u4e00\u4e9b\u793a\u4f8b\u3002</p>"},{"location":"lessons/4-ComputerVision/06-IntroCV/README_chs/#_3","title":"\u52a0\u8f7d\u56fe\u50cf","text":"<p>\u5728Python\u4e2d\uff0c\u56fe\u50cf\u53ef\u4ee5\u65b9\u4fbf\u5730\u7528 NumPy \u6570\u7ec4\u8868\u793a\u3002\u4f8b\u5982\uff0c320x200 \u50cf\u7d20\u5927\u5c0f\u7684\u7070\u5ea6\u56fe\u50cf\u5c06\u5b58\u50a8\u5728 200x320 \u6570\u7ec4\u4e2d\uff0c\u800c\u76f8\u540c\u5c3a\u5bf8\u7684\u5f69\u8272\u56fe\u50cf\u5c06\u5177\u6709 200x320x3 \u7684\u5f62\u72b6\uff083 \u4e2a\u989c\u8272\u901a\u9053\uff09\u3002\u8981\u52a0\u8f7d\u56fe\u50cf\uff0c\u53ef\u4ee5\u4f7f\u7528\u4ee5\u4e0b\u4ee3\u7801\uff1a</p> <pre><code>import cv2\nimport matplotlib.pyplot as plt\n\nim = cv2.imread('image.jpeg')\nplt.imshow(im)\n</code></pre> <p>\u4f20\u7edf\u4e0a\uff0cOpenCV \u4f7f\u7528 BGR\uff08\u84dd-\u7eff-\u7ea2\uff09\u7f16\u7801\u5f69\u8272\u56fe\u50cf\uff0c\u800c\u5176\u4f59\u7684 Python \u5de5\u5177\u4f7f\u7528\u66f4\u4f20\u7edf\u7684 RGB\uff08\u7ea2-\u7eff-\u84dd\uff09\u3002\u4e3a\u4e86\u8ba9\u56fe\u50cf\u770b\u8d77\u6765\u6b63\u786e\uff0c\u4f60\u9700\u8981\u5c06\u5176\u8f6c\u6362\u4e3a RGB \u989c\u8272\u7a7a\u95f4\uff0c\u53ef\u4ee5\u901a\u8fc7\u4ea4\u6362 NumPy \u6570\u7ec4\u4e2d\u7684\u7ef4\u5ea6\uff0c\u6216\u8005\u8c03\u7528\u4e00\u4e2a OpenCV \u51fd\u6570\uff1a</p> <pre><code>im = cv2.cvtColor(im,cv2.COLOR_BGR2RGB)\n</code></pre> <p>\u540c\u6837\u7684 <code>cvtColor</code> \u51fd\u6570\u53ef\u4ee5\u7528\u4e8e\u6267\u884c\u5176\u4ed6\u989c\u8272\u7a7a\u95f4\u8f6c\u6362\uff0c\u4f8b\u5982\u5c06\u56fe\u50cf\u8f6c\u6362\u4e3a\u7070\u5ea6\u6216 HSV\uff08\u8272\u8c03-\u9971\u548c\u5ea6-\u503c\uff09\u989c\u8272\u7a7a\u95f4\u3002</p> <p>\u4f60\u8fd8\u53ef\u4ee5\u4f7f\u7528 OpenCV \u4e00\u5e27\u4e00\u5e27\u5730\u52a0\u8f7d\u89c6\u9891 - \u793a\u4f8b\u5728\u7ec3\u4e60 OpenCV Notebook \u4e2d\u63d0\u4f9b\u3002</p>"},{"location":"lessons/4-ComputerVision/06-IntroCV/README_chs/#_4","title":"\u56fe\u50cf\u5904\u7406","text":"<p>\u5728\u5c06\u56fe\u50cf\u4f20\u9012\u7ed9\u795e\u7ecf\u7f51\u7edc\u4e4b\u524d\uff0c\u4f60\u53ef\u80fd\u60f3\u8981\u8fdb\u884c\u51e0\u4e2a\u9884\u5904\u7406\u6b65\u9aa4\u3002OpenCV \u53ef\u4ee5\u505a\u8bb8\u591a\u4e8b\u60c5\uff0c\u5305\u62ec\uff1a</p> <ul> <li>\u4f7f\u7528 <code>im = cv2.resize(im, (320,200),interpolation=cv2.INTER_LANCZOS)</code> \u8c03\u6574\u56fe\u50cf\u5927\u5c0f</li> <li>\u4f7f\u7528 <code>im = cv2.medianBlur(im,3)</code> \u6216 <code>im = cv2.GaussianBlur(im, (3,3), 0)</code> \u6a21\u7cca\u56fe\u50cf</li> <li>\u53ef\u4ee5\u901a\u8fc7 NumPy \u6570\u7ec4\u64cd\u4f5c\u6539\u53d8\u56fe\u50cf\u7684\u4eae\u5ea6\u548c\u5bf9\u6bd4\u5ea6\uff0c\u5982\u8fd9\u4e2a Stackoverflow \u7b14\u8bb0\u4e2d\u63cf\u8ff0\u7684\u90a3\u6837\u3002</li> <li>\u901a\u8fc7\u8c03\u7528 <code>cv2.threshold</code> / <code>cv2.adaptiveThreshold</code> \u51fd\u6570\u4f7f\u7528\u9608\u503c\u5904\u7406\uff0c\u8fd9\u901a\u5e38\u6bd4\u8c03\u6574\u4eae\u5ea6\u6216\u5bf9\u6bd4\u5ea6\u66f4\u53ef\u53d6\u3002</li> <li>\u5e94\u7528\u4e0d\u540c\u7684\u53d8\u6362\u5230\u56fe\u50cf\uff1a<ul> <li>\u4eff\u5c04\u53d8\u6362 \u5982\u679c\u4f60\u9700\u8981\u5bf9\u56fe\u50cf\u8fdb\u884c\u65cb\u8f6c\u3001\u8c03\u6574\u5927\u5c0f\u548c\u503e\u659c\u5e76\u4e14\u4f60\u77e5\u9053\u56fe\u50cf\u4e2d\u4e09\u70b9\u7684\u6e90\u4f4d\u7f6e\u548c\u76ee\u6807\u4f4d\u7f6e\u65f6\u4f1a\u5f88\u6709\u7528\u3002\u4eff\u5c04\u53d8\u6362\u4fdd\u6301\u5e73\u884c\u7ebf\u5e73\u884c\u3002</li> <li>\u900f\u89c6\u53d8\u6362 \u5f53\u4f60\u77e5\u9053\u56fe\u50cf\u4e2d\u56db\u4e2a\u70b9\u7684\u6e90\u4f4d\u7f6e\u548c\u76ee\u6807\u4f4d\u7f6e\u65f6\u4f1a\u5f88\u6709\u7528\u3002\u4f8b\u5982\uff0c\u5982\u679c\u4f60\u7528\u667a\u80fd\u624b\u673a\u4ece\u67d0\u4e2a\u89d2\u5ea6\u62cd\u6444\u77e9\u5f62\u6587\u6863\uff0c\u5e76\u4e14\u4f60\u60f3\u4f7f\u6587\u6863\u672c\u8eab\u7684\u56fe\u50cf\u6210\u4e3a\u77e9\u5f62\u3002</li> </ul> </li> <li>\u4f7f\u7528\u5149\u6d41 \u7406\u89e3\u56fe\u50cf\u4e2d\u5185\u90e8\u7684\u8fd0\u52a8\u3002</li> </ul>"},{"location":"lessons/4-ComputerVision/06-IntroCV/README_chs/#_5","title":"\u4f7f\u7528\u8ba1\u7b97\u673a\u89c6\u89c9\u7684\u793a\u4f8b","text":"<p>\u5728\u6211\u4eec\u7684OpenCV Notebook\u4e2d\uff0c\u6211\u4eec\u63d0\u4f9b\u4e86\u4e00\u4e9b\u8ba1\u7b97\u673a\u89c6\u89c9\u53ef\u4ee5\u7528\u4e8e\u6267\u884c\u7279\u5b9a\u4efb\u52a1\u7684\u793a\u4f8b\uff1a</p> <ul> <li>\u9884\u5904\u7406\u76f2\u6587\u4e66\u7684\u7167\u7247\u3002\u6211\u4eec\u91cd\u70b9\u8ba8\u8bba\u5982\u4f55\u4f7f\u7528\u9608\u503c\u5904\u7406\u3001\u7279\u5f81\u68c0\u6d4b\u3001\u900f\u89c6\u53d8\u6362\u548c NumPy \u64cd\u4f5c\u6765\u5206\u79bb\u5355\u72ec\u7684\u76f2\u6587\u7b26\u53f7\uff0c\u4ee5\u4fbf\u795e\u7ecf\u7f51\u7edc\u8fdb\u4e00\u6b65\u5206\u7c7b\u3002</li> </ul> <p>\u56fe\u7247\u6765\u81ea OpenCV.ipynb</p> <ul> <li>\u4f7f\u7528\u5e27\u5dee\u5f02\u68c0\u6d4b\u89c6\u9891\u4e2d\u7684\u8fd0\u52a8\u3002\u5982\u679c\u6444\u50cf\u673a\u662f\u56fa\u5b9a\u7684\uff0c\u90a3\u4e48\u4ece\u6444\u50cf\u673a\u63d0\u4f9b\u7684\u5e27\u5e94\u8be5\u5f7c\u6b64\u975e\u5e38\u76f8\u4f3c\u3002\u7531\u4e8e\u5e27\u8868\u793a\u4e3a\u6570\u7ec4\uff0c\u53ea\u9700\u51cf\u53bb\u4e24\u4e2a\u8fde\u7eed\u5e27\u7684\u6570\u7ec4\uff0c\u6211\u4eec\u5c31\u4f1a\u5f97\u5230\u50cf\u7d20\u5dee\u5f02\uff0c\u9759\u6001\u5e27\u7684\u5dee\u5f02\u5e94\u8be5\u8f83\u5c0f\uff0c\u5f53\u56fe\u50cf\u4e2d\u6709\u660e\u663e\u8fd0\u52a8\u65f6\uff0c\u5dee\u5f02\u4f1a\u589e\u52a0\u3002</li> </ul> <p></p> <p>\u56fe\u7247\u6765\u81ea OpenCV.ipynb</p> <ul> <li> <p>\u4f7f\u7528\u5149\u6d41\u68c0\u6d4b\u8fd0\u52a8\u3002 \u5149\u6d41 \u5141\u8bb8\u6211\u4eec\u7406\u89e3\u89c6\u9891\u5e27\u4e0a\u5355\u4e2a\u50cf\u7d20\u7684\u79fb\u52a8\u65b9\u5f0f\u3002\u5149\u6d41\u6709\u4e24\u79cd\u7c7b\u578b\uff1a</p> </li> <li> <p>\u5bc6\u96c6\u5149\u6d41 \u8ba1\u7b97\u77e2\u91cf\u573a\uff0c\u663e\u793a\u6bcf\u4e2a\u50cf\u7d20\u7684\u8fd0\u52a8\u65b9\u5411</p> </li> <li>\u7a00\u758f\u5149\u6d41 \u57fa\u4e8e\u6355\u6349\u56fe\u50cf\u4e2d\u7684\u4e00\u4e9b\u660e\u663e\u7279\u5f81\uff08\u4f8b\u5982\u8fb9\u7f18\uff09\uff0c\u5e76\u5efa\u7acb\u5b83\u4eec\u4ece\u5e27\u5230\u5e27\u7684\u8f68\u8ff9\u3002</li> </ul> <p></p> <p>\u56fe\u7247\u6765\u81ea OpenCV.ipynb</p>"},{"location":"lessons/4-ComputerVision/06-IntroCV/README_chs/#opencv-opencv","title":"\u270d\ufe0f \u793a\u4f8b\u7b14\u8bb0\u672c\uff1aOpenCV \u5c1d\u8bd5 OpenCV \u52a8\u4f5c\u6f14\u793a","text":"<p>\u8ba9\u6211\u4eec\u901a\u8fc7\u63a2\u7d22 OpenCV \u7b14\u8bb0\u672c \u6765\u505a\u4e00\u4e9b OpenCV \u7684\u5b9e\u9a8c</p>"},{"location":"lessons/4-ComputerVision/06-IntroCV/README_chs/#_6","title":"\u7ed3\u8bba","text":"<p>\u6709\u65f6\uff0c\u50cf\u8fd0\u52a8\u68c0\u6d4b\u6216\u6307\u5c16\u68c0\u6d4b\u8fd9\u6837\u7684\u590d\u6742\u4efb\u52a1\u53ef\u4ee5\u7eaf\u7cb9\u901a\u8fc7\u8ba1\u7b97\u673a\u89c6\u89c9\u6765\u89e3\u51b3\u3002\u56e0\u6b64\uff0c\u4e86\u89e3\u8ba1\u7b97\u673a\u89c6\u89c9\u7684\u57fa\u672c\u6280\u672f\u4ee5\u53ca\u50cf OpenCV \u8fd9\u6837\u7684\u5e93\u80fd\u505a\u4ec0\u4e48\u662f\u975e\u5e38\u6709\u5e2e\u52a9\u7684\u3002</p>"},{"location":"lessons/4-ComputerVision/06-IntroCV/README_chs/#_7","title":"\ud83d\ude80 \u6311\u6218","text":"<p>\u89c2\u770b \u8fd9\u6bb5\u89c6\u9891\uff0c\u4e86\u89e3 Cortic Tigers \u9879\u76ee\u4ee5\u53ca\u4ed6\u4eec\u5982\u4f55\u6784\u5efa\u57fa\u4e8e\u5757\u7684\u89e3\u51b3\u65b9\u6848\u6765\u6c11\u4e3b\u5316\u901a\u8fc7\u673a\u5668\u4eba\u6267\u884c\u7684\u8ba1\u7b97\u673a\u89c6\u89c9\u4efb\u52a1\u3002\u7814\u7a76\u5176\u4ed6\u7c7b\u4f3c\u7684\u9879\u76ee\uff0c\u8fd9\u4e9b\u9879\u76ee\u6709\u52a9\u4e8e\u65b0\u5b66\u4e60\u8005\u8fdb\u5165\u8fd9\u4e2a\u9886\u57df\u3002</p>"},{"location":"lessons/4-ComputerVision/06-IntroCV/README_chs/#_8","title":"\u8bfe\u540e\u5c0f\u6d4b\u9a8c","text":""},{"location":"lessons/4-ComputerVision/06-IntroCV/README_chs/#_9","title":"\u590d\u4e60\u4e0e\u81ea\u5b66","text":"<p>\u5728\u8fd9\u4e2a\u51fa\u8272\u7684\u6559\u7a0b\u4e2d\u9605\u8bfb\u66f4\u591a\u5173\u4e8e\u5149\u6d41\u7684\u4fe1\u606f\u3002</p>"},{"location":"lessons/4-ComputerVision/06-IntroCV/README_chs/#_10","title":"\u4f5c\u4e1a","text":"<p>\u5728\u8fd9\u4e2a\u5b9e\u9a8c\u4e2d\uff0c\u4f60\u5c06\u5f55\u5236\u4e00\u4e2a\u5305\u542b\u7b80\u5355\u624b\u52bf\u7684\u89c6\u9891\uff0c\u4f60\u7684\u76ee\u6807\u662f\u4f7f\u7528\u5149\u6d41\u63d0\u53d6\u4e0a/\u4e0b/\u5de6/\u53f3\u7684\u8fd0\u52a8\u3002</p> <p></p>"},{"location":"lessons/4-ComputerVision/06-IntroCV/lab/","title":"Detecting Movements using Optical Flow","text":"<p>Lab Assignment from AI for Beginners Curriculum.</p>"},{"location":"lessons/4-ComputerVision/06-IntroCV/lab/#task","title":"Task","text":"<p>Consider this video, in which a person's palm moves left/right/up/down on the stable background.</p> <p></p> <p>Your goal would be able to use Optical Flow to determine, which parts of video contain up/down/left/right movements.</p> <p>Stretch goal would be to actually track the palm/finger movement using skin tone, as described in this blog post or here.</p>"},{"location":"lessons/4-ComputerVision/06-IntroCV/lab/#starting-notebook","title":"Starting Notebook","text":"<p>Start the lab by opening MovementDetection.ipynb</p>"},{"location":"lessons/4-ComputerVision/06-IntroCV/lab/#takeaway","title":"Takeaway","text":"<p>Sometimes, relatively complex tasks such as movement detection or fingertip detection can be solved purely by computer vision. Thus, it is very helpful to know what libraries like OpenCV can do.</p>"},{"location":"lessons/4-ComputerVision/06-IntroCV/lab/README_chs/","title":"\u4f7f\u7528\u5149\u6d41\u68c0\u6d4b\u8fd0\u52a8","text":"<p>\u6765\u81ea\u9762\u5411\u521d\u5b66\u8005\u7684AI\u8bfe\u7a0b\u7684\u5b9e\u9a8c\u4efb\u52a1\u3002</p>"},{"location":"lessons/4-ComputerVision/06-IntroCV/lab/README_chs/#_2","title":"\u4efb\u52a1","text":"<p>\u8003\u8651\u8fd9\u4e2a\u89c6\u9891\uff0c\u89c6\u9891\u4e2d\uff0c\u4e00\u4e2a\u4eba\u7684\u624b\u638c\u5728\u7a33\u5b9a\u7684\u80cc\u666f\u4e0b\u5411\u5de6/\u5411\u53f3/\u5411\u4e0a/\u5411\u4e0b\u79fb\u52a8\u3002</p> <p></p> <p>\u4f60\u7684\u76ee\u6807\u662f\u80fd\u591f\u4f7f\u7528\u5149\u6d41\u6cd5\u6765\u786e\u5b9a\u89c6\u9891\u4e2d\u7684\u54ea\u4e9b\u90e8\u5206\u5305\u542b\u5411\u4e0a/\u5411\u4e0b/\u5411\u5de6/\u5411\u53f3\u7684\u8fd0\u52a8\u3002</p> <p>\u6269\u5c55\u76ee\u6807\u662f\u5b9e\u9645\u4f7f\u7528\u80a4\u8272\u8ddf\u8e2a\u624b\u638c/\u624b\u6307\u7684\u8fd0\u52a8\uff0c\u5982\u8fd9\u7bc7\u535a\u5ba2\u6587\u7ae0\u6216\u8fd9\u91cc\u6240\u63cf\u8ff0\u7684\u90a3\u6837\u3002</p>"},{"location":"lessons/4-ComputerVision/06-IntroCV/lab/README_chs/#_3","title":"\u8d77\u59cb\u7b14\u8bb0\u672c","text":"<p>\u6253\u5f00MovementDetection.ipynb\u5f00\u59cb\u5b9e\u9a8c\u3002</p>"},{"location":"lessons/4-ComputerVision/06-IntroCV/lab/README_chs/#_4","title":"\u6536\u83b7","text":"<p>\u6709\u65f6\uff0c\u8bf8\u5982\u8fd0\u52a8\u68c0\u6d4b\u6216\u6307\u5c16\u68c0\u6d4b\u4e4b\u7c7b\u7684\u76f8\u5bf9\u590d\u6742\u7684\u4efb\u52a1\u53ef\u4ee5\u7eaf\u7cb9\u901a\u8fc7\u8ba1\u7b97\u673a\u89c6\u89c9\u6765\u89e3\u51b3\u3002\u56e0\u6b64\uff0c\u4e86\u89e3\u50cfOpenCV\u8fd9\u6837\u7684\u5e93\u80fd\u591f\u505a\u4ec0\u4e48\u662f\u975e\u5e38\u6709\u5e2e\u52a9\u7684\u3002</p>"},{"location":"lessons/4-ComputerVision/07-ConvNets/","title":"Convolutional Neural Networks","text":"<p>We have seen before that neural networks are quite good at dealing with images, and even one-layer perceptron is able to recognize handwritten digits from MNIST dataset with reasonable accuracy. However, the MNIST dataset is very special, and all digits are centered inside the image, which makes the task simpler.</p>"},{"location":"lessons/4-ComputerVision/07-ConvNets/#pre-lecture-quiz","title":"Pre-lecture quiz","text":"<p>In real life, we want to be able to recognize objects on a picture regardless of their exact location in the image. Computer vision is different from generic classification, because when we are trying to find a certain object in the picture, we are scanning the image looking for some specific patterns and their combinations. For example, when looking for a cat, we first may look for horizontal lines, which can form whiskers, and then certain a combination of whiskers can tell us that it is actually a picture of a cat. Relative position and presence of certain patterns is important, and not their exact position on the image.</p> <p>To extract patterns, we will use the notion of convolutional filters. As you know, an image is represented by a 2D-matrix, or a 3D-tensor with color depth. Applying a filter means that we take relatively small filter kernel matrix, and for each pixel in the original image we compute the weighted average with neighboring points. We can view this like a small window sliding over the whole image, and averaging out all pixels according to the weights in the filter kernel matrix.</p> <p>Image by Dmitry Soshnikov</p> <p>For example, if we apply 3x3 vertical edge and horizontal edge filters to the MNIST digits, we can get highlights (e.g. high values) where there are vertical and horizontal edges in our original image. Thus those two filters can be used to \"look for\" edges. Similarly, we can design different filters to look for other low-level patterns:</p> <p></p> <p>Image of Leung-Malik Filter Bank</p> <p>However, while we can design the filters to extract some patterns manually, we can also design the network in such a way that it will learn the patterns automatically. It is one of the main ideas behind the CNN.</p>"},{"location":"lessons/4-ComputerVision/07-ConvNets/#main-ideas-behind-cnn","title":"Main ideas behind CNN","text":"<p>The way CNNs work is based on the following important ideas:</p> <ul> <li>Convolutional filters can extract patterns</li> <li>We can design the network in such a way that filters are trained automatically</li> <li>We can use the same approach to find patterns in high-level features, not only in the original image. Thus CNN feature extraction work on a hierarchy of features, starting from low-level pixel combinations, up to higher level combination of picture parts.</li> </ul> <p></p> <p>Image from a paper by Hislop-Lynch, based on their research</p>"},{"location":"lessons/4-ComputerVision/07-ConvNets/#exercises-convolutional-neural-networks","title":"\u270d\ufe0f Exercises: Convolutional Neural Networks","text":"<p>Let's continue exploring how convolutional neural networks work, and how we can achieve trainable filters, by working through the corresponding notebooks:</p> <ul> <li>Convolutional Neural Networks - PyTorch</li> <li>Convolutional Neural Networks - TensorFlow</li> </ul>"},{"location":"lessons/4-ComputerVision/07-ConvNets/#pyramid-architecture","title":"Pyramid Architecture","text":"<p>Most of the CNNs used for image processing follow a so-called pyramid architecture. The first convolutional layer applied to the original images typically has a relatively low number of filters (8-16), which correspond to different pixel combinations, such as horizontal/vertical lines of strokes. At the next level, we reduce the spatial dimension of the network, and increase the number of filters, which corresponds to more possible combinations of simple features. With each layer, as we move towards the final classifier, spatial dimensions of the image decrease, and the number of filters grow.</p> <p>As an example, let's look at the architecture of VGG-16, a network that achieved 92.7% accuracy in ImageNet's top-5 classification in 2014:</p> <p></p> <p></p> <p>Image from Researchgate</p>"},{"location":"lessons/4-ComputerVision/07-ConvNets/#best-known-cnn-architectures","title":"Best-Known CNN Architectures","text":"<p>Continue your study about the best-known CNN architectures</p>"},{"location":"lessons/4-ComputerVision/07-ConvNets/CNN_Architectures/","title":"Well-Known CNN Architectures","text":""},{"location":"lessons/4-ComputerVision/07-ConvNets/CNN_Architectures/#vgg-16","title":"VGG-16","text":"<p>VGG-16 is a network that achieved 92.7% accuracy in ImageNet top-5 classification in 2014. It has the following layer structure:</p> <p></p> <p>As you can see, VGG follows a traditional pyramid architecture, which is a sequence of convolution-pooling layers.</p> <p></p> <p>Image from Researchgate</p>"},{"location":"lessons/4-ComputerVision/07-ConvNets/CNN_Architectures/#resnet","title":"ResNet","text":"<p>ResNet is a family of models proposed by Microsoft Research in 2015. The main idea of ResNet is to use residual blocks:</p> <p></p> <p>Image from this paper</p> <p>The reason for using identity pass-through is to have our layer predict the difference between the result of a previous layer and the output of the residual block - hence the name residual. Those blocks are much easier to train, and one can construct networks with several hundreds of those blocks (most common variants are ResNet-52, ResNet-101 and ResNet-152).</p> <p>You can also think of this network as being able to adjust its complexity to the dataset. Initially, when you are starting to train the network, the weights values are small, and most of the signal goes through passthrough identity layers. As training progresses and weights become larger, the significance of network parameters grow, and the networks adjusts to accommodate required expressive power to correctly classify training images.</p>"},{"location":"lessons/4-ComputerVision/07-ConvNets/CNN_Architectures/#google-inception","title":"Google Inception","text":"<p>Google Inception architecture takes this idea one step further, and builds each network layer as a combination of several different paths:</p> <p></p> <p>Image from Researchgate</p> <p>Here, we need to emphasize the role of 1x1 convolutions, because at first they do not make sense. Why would we need to run through the image with 1x1 filter? However, you need to remember that convolution filters also work with several depth channels (originally - RGB colors, in subsequent layers - channels for different filters), and 1x1 convolution is used to mix those input channels together using different trainable weights. It can be also viewed as downsampling (pooling) over channel dimension.</p> <p>Here is a good blog post on the subject, and the original paper.</p>"},{"location":"lessons/4-ComputerVision/07-ConvNets/CNN_Architectures/#mobilenet","title":"MobileNet","text":"<p>MobileNet is a family of models with reduced size, suitable for mobile devices. Use them if you are short in resources, and can sacrifice a little bit of accuracy. The main idea behind them is so-called depthwise separable convolution, which allows representing convolution filters by a composition of spatial convolutions and 1x1 convolution over depth channels. This significantly reduces the number of parameters, making the network smaller in size, and also easier to train with less data.</p> <p>Here is a good blog post on MobileNet.</p>"},{"location":"lessons/4-ComputerVision/07-ConvNets/CNN_Architectures/#conclusion","title":"Conclusion","text":"<p>In this unit, you have learned the main concept behind computer vision neural networks - convolutional networks. Real-life architectures that power image classification, object detection, and even image generation networks are all based on CNNs, just with more layers and some additional training tricks.</p>"},{"location":"lessons/4-ComputerVision/07-ConvNets/CNN_Architectures/#challenge","title":"\ud83d\ude80 Challenge","text":"<p>In the accompanying notebooks, there are notes at the bottom about how to obtain greater accuracy. Do some experiments to see if you can achieve higher accuracy.</p>"},{"location":"lessons/4-ComputerVision/07-ConvNets/CNN_Architectures/#post-lecture-quiz","title":"Post-lecture quiz","text":""},{"location":"lessons/4-ComputerVision/07-ConvNets/CNN_Architectures/#review-self-study","title":"Review &amp; Self Study","text":"<p>While CNNs are most often used for Computer Vision tasks, they are generally good for extracting fixed-sized patterns. For example, if we are dealing with sounds, we may also want to use CNNs to look for some specific patterns in audio signal - in which case filters would be 1-dimensional (and this CNN would be called 1D-CNN). Also, sometimes 3D-CNN is used to extract features in multi-dimensional space, such as certain events occurring on video - CNN can capture certain patterns of feature changing over time. Do some review and self-study about other tasks that can be done with CNNs.</p>"},{"location":"lessons/4-ComputerVision/07-ConvNets/CNN_Architectures/#assignment","title":"Assignment","text":"<p>In this lab, you are tasked with classifying different cat and dog breeds. These images are more complex than the MNIST dataset and of higher dimensions, and there are more than 10 classes.</p>"},{"location":"lessons/4-ComputerVision/07-ConvNets/CNN_Architectures_chs/","title":"\u8457\u540d\u7684 CNN \u67b6\u6784","text":""},{"location":"lessons/4-ComputerVision/07-ConvNets/CNN_Architectures_chs/#vgg-16","title":"VGG-16","text":"<p>VGG-16 \u662f\u4e00\u4e2a\u5728 2014 \u5e74 ImageNet top-5 \u5206\u7c7b\u4e2d\u8fbe\u5230\u4e86 92.7% \u51c6\u786e\u7387\u7684\u7f51\u7edc\u3002\u5b83\u7684\u5c42\u7ed3\u6784\u5982\u4e0b\uff1a</p> <p></p> <p>\u5982\u4f60\u6240\u89c1\uff0cVGG \u9075\u5faa\u4f20\u7edf\u7684\u91d1\u5b57\u5854\u67b6\u6784\uff0c\u8fd9\u662f\u4e00\u4e2a\u5377\u79ef-\u6c60\u5316\u5c42\u7684\u5e8f\u5217\u3002</p> <p></p> <p>\u56fe\u7247\u6765\u81ea Researchgate</p>"},{"location":"lessons/4-ComputerVision/07-ConvNets/CNN_Architectures_chs/#resnet","title":"ResNet","text":"<p>ResNet \u662f\u5fae\u8f6f\u7814\u7a76\u9662\u5728 2015 \u5e74\u63d0\u51fa\u7684\u4e00\u7cfb\u5217\u6a21\u578b\u3002ResNet \u7684\u4e3b\u8981\u601d\u60f3\u662f\u4f7f\u7528\u6b8b\u5dee\u5757\uff1a</p> <p></p> <p>\u56fe\u7247\u6765\u81ea \u8fd9\u7bc7\u8bba\u6587</p> <p>\u4f7f\u7528\u6052\u7b49\u4f20\u9012\u7684\u539f\u56e0\u662f\u8ba9\u6211\u4eec\u7684\u5c42\u9884\u6d4b\u524d\u4e00\u5c42\u7ed3\u679c\u4e0e\u6b8b\u5dee\u5757\u8f93\u51fa\u4e4b\u95f4\u7684\u5dee\u5f02\uff0c\u56e0\u6b64\u5f97\u540d\u6b8b\u5dee\u5757\u3002\u8fd9\u4e9b\u5757\u66f4\u5bb9\u6613\u8bad\u7ec3\uff0c\u53ef\u4ee5\u6784\u5efa\u5305\u542b\u6570\u767e\u4e2a\u8fd9\u79cd\u5757\u7684\u7f51\u7edc\uff08\u6700\u5e38\u89c1\u7684\u53d8\u4f53\u6709 ResNet-52, ResNet-101 \u548c ResNet-152\uff09\u3002</p> <p>\u4f60\u8fd8\u53ef\u4ee5\u5c06\u8fd9\u4e2a\u7f51\u7edc\u60f3\u8c61\u4e3a\u80fd\u591f\u6839\u636e\u6570\u636e\u96c6\u8c03\u6574\u5176\u590d\u6742\u6027\u3002\u6700\u521d\uff0c\u5f53\u4f60\u5f00\u59cb\u8bad\u7ec3\u7f51\u7edc\u65f6\uff0c\u6743\u91cd\u503c\u8f83\u5c0f\uff0c\u5927\u90e8\u5206\u4fe1\u53f7\u901a\u8fc7\u900f\u4f20\u7684\u6052\u7b49\u5c42\u3002\u968f\u7740\u8bad\u7ec3\u7684\u8fdb\u884c\u548c\u6743\u91cd\u53d8\u5927\uff0c\u7f51\u7edc\u53c2\u6570\u7684\u91cd\u8981\u6027\u589e\u52a0\uff0c\u7f51\u7edc\u4e5f\u8c03\u6574\u4ee5\u9002\u5e94\u6240\u9700\u7684\u8868\u8fbe\u80fd\u529b\uff0c\u4ece\u800c\u6b63\u786e\u5206\u7c7b\u8bad\u7ec3\u56fe\u50cf\u3002</p>"},{"location":"lessons/4-ComputerVision/07-ConvNets/CNN_Architectures_chs/#google-inception","title":"Google Inception","text":"<p>Google Inception \u67b6\u6784\u66f4\u8fdb\u4e00\u6b65\uff0c\u5c06\u6bcf\u4e2a\u7f51\u7edc\u5c42\u6784\u5efa\u4e3a\u591a\u4e2a\u4e0d\u540c\u8def\u5f84\u7684\u7ec4\u5408\uff1a</p> <p></p> <p>\u56fe\u7247\u6765\u81ea Researchgate</p> <p>\u5728\u8fd9\u91cc\uff0c\u6211\u4eec\u9700\u8981\u5f3a\u8c03 1x1 \u5377\u79ef\u7684\u4f5c\u7528\uff0c\u56e0\u4e3a\u4e4d\u770b\u4e4b\u4e0b\u5b83\u4eec\u6ca1\u6709\u610f\u4e49\u3002\u4e3a\u4ec0\u4e48\u6211\u4eec\u9700\u8981\u7528 1x1 \u6ee4\u6ce2\u5668\u904d\u5386\u56fe\u50cf\uff1f\u7136\u800c\uff0c\u4f60\u9700\u8981\u8bb0\u4f4f\u5377\u79ef\u6ee4\u6ce2\u5668\u8fd8\u4f1a\u4e0e\u591a\u4e2a\u6df1\u5ea6\u901a\u9053\uff08\u6700\u521d\u662f RGB \u989c\u8272\uff0c\u5728\u540e\u7eed\u5c42\u662f\u4e0d\u540c\u6ee4\u6ce2\u5668\u7684\u901a\u9053\uff09\u4e00\u8d77\u5de5\u4f5c\uff0c\u800c 1x1 \u5377\u79ef\u7528\u6765\u7528\u4e0d\u540c\u7684\u53ef\u8bad\u7ec3\u6743\u91cd\u5c06\u8fd9\u4e9b\u8f93\u5165\u901a\u9053\u6df7\u5408\u5728\u4e00\u8d77\u3002\u5b83\u4e5f\u53ef\u4ee5\u88ab\u89c6\u4e3a\u5728\u901a\u9053\u7ef4\u5ea6\u4e0a\u7684\u4e0b\u91c7\u6837\uff08\u6c60\u5316\uff09\u3002</p> <p>\u8fd9\u662f \u4e00\u4e2a\u5173\u4e8e\u8fd9\u4e2a\u4e3b\u9898\u7684\u597d\u535a\u5ba2\uff0c\u4ee5\u53ca \u539f\u59cb\u8bba\u6587\u3002</p>"},{"location":"lessons/4-ComputerVision/07-ConvNets/CNN_Architectures_chs/#mobilenet","title":"MobileNet","text":"<p>MobileNet \u662f\u4e00\u7cfb\u5217\u51cf\u5c11\u4f53\u79ef\u7684\u6a21\u578b\uff0c\u9002\u7528\u4e8e\u79fb\u52a8\u8bbe\u5907\u3002\u5982\u679c\u8d44\u6e90\u6709\u9650\u5e76\u53ef\u4ee5\u727a\u7272\u4e00\u4e9b\u51c6\u786e\u6027\uff0c\u8bf7\u4f7f\u7528\u5b83\u4eec\u3002\u5176\u4e3b\u8981\u601d\u60f3\u662f\u6240\u8c13\u7684\u6df1\u5ea6\u53ef\u5206\u79bb\u5377\u79ef\uff0c\u8fd9\u5141\u8bb8\u901a\u8fc7\u7a7a\u95f4\u5377\u79ef\u548c\u6df1\u5ea6\u901a\u9053\u4e0a\u7684 1x1 \u5377\u79ef\u7684\u7ec4\u5408\u8868\u793a\u5377\u79ef\u6ee4\u6ce2\u5668\u3002\u8fd9\u6781\u5927\u5730\u51cf\u5c11\u4e86\u53c2\u6570\u6570\u91cf\uff0c\u4f7f\u7f51\u7edc\u4f53\u79ef\u66f4\u5c0f\uff0c\u5e76\u4e14\u4e5f\u66f4\u5bb9\u6613\u7528\u8f83\u5c11\u7684\u6570\u636e\u8fdb\u884c\u8bad\u7ec3\u3002</p> <p>\u8fd9\u662f \u4e00\u4e2a\u5173\u4e8e MobileNet \u7684\u597d\u535a\u5ba2\u3002</p>"},{"location":"lessons/4-ComputerVision/07-ConvNets/CNN_Architectures_chs/#_1","title":"\u7ed3\u8bba","text":"<p>\u5728\u8fd9\u4e2a\u5355\u5143\u4e2d\uff0c\u4f60\u5df2\u7ecf\u5b66\u4e60\u4e86\u8ba1\u7b97\u673a\u89c6\u89c9\u795e\u7ecf\u7f51\u7edc \u2014\u2014 \u5377\u79ef\u7f51\u7edc\u7684\u4e3b\u8981\u6982\u5ff5\u3002\u7528\u4e8e\u56fe\u50cf\u5206\u7c7b\u3001\u76ee\u6807\u68c0\u6d4b\uff0c\u751a\u81f3\u56fe\u50cf\u751f\u6210\u7f51\u7edc\u7684\u73b0\u5b9e\u4e16\u754c\u67b6\u6784\u90fd\u57fa\u4e8e CNN\uff0c\u53ea\u662f\u5c42\u6570\u66f4\u591a\uff0c\u8fd8\u6709\u4e00\u4e9b\u989d\u5916\u7684\u8bad\u7ec3\u6280\u5de7\u3002</p>"},{"location":"lessons/4-ComputerVision/07-ConvNets/CNN_Architectures_chs/#_2","title":"\ud83d\ude80 \u6311\u6218","text":"<p>\u5728\u968f\u9644\u7684\u7b14\u8bb0\u672c\u4e2d\uff0c\u5e95\u90e8\u6709\u5173\u4e8e\u5982\u4f55\u83b7\u5f97\u66f4\u9ad8\u51c6\u786e\u7387\u7684\u6ce8\u91ca\u3002\u505a\u4e00\u4e9b\u5b9e\u9a8c\uff0c\u770b\u4f60\u662f\u5426\u80fd\u8fbe\u5230\u66f4\u9ad8\u7684\u51c6\u786e\u7387\u3002</p>"},{"location":"lessons/4-ComputerVision/07-ConvNets/CNN_Architectures_chs/#_3","title":"\u8bb2\u8bfe\u540e\u6d4b\u9a8c","text":""},{"location":"lessons/4-ComputerVision/07-ConvNets/CNN_Architectures_chs/#_4","title":"\u590d\u4e60\u4e0e\u81ea\u5b66","text":"<p>\u867d\u7136 CNN \u6700\u5e38\u7528\u4e8e\u8ba1\u7b97\u673a\u89c6\u89c9\u4efb\u52a1\uff0c\u4f46\u5b83\u4eec\u901a\u5e38\u9002\u5408\u63d0\u53d6\u56fa\u5b9a\u5927\u5c0f\u7684\u6a21\u5f0f\u3002\u4f8b\u5982\uff0c\u5982\u679c\u6211\u4eec\u5904\u7406\u7684\u662f\u58f0\u97f3\uff0c\u6211\u4eec\u53ef\u80fd\u4e5f\u5e0c\u671b\u4f7f\u7528 CNN \u6765\u5bfb\u627e\u97f3\u9891\u4fe1\u53f7\u4e2d\u7684\u67d0\u4e9b\u7279\u5b9a\u6a21\u5f0f \u2014\u2014 \u5728\u8fd9\u79cd\u60c5\u51b5\u4e0b\u6ee4\u6ce2\u5668\u5c06\u662f\u4e00\u7ef4\u7684\uff08\u8fd9\u79cd CNN \u79f0\u4e3a 1D-CNN\uff09\u3002\u6b64\u5916\uff0c\u6709\u65f6 3D-CNN \u7528\u4e8e\u5728\u591a\u7ef4\u7a7a\u95f4\u4e2d\u63d0\u53d6\u7279\u5f81\uff0c\u4f8b\u5982\u5728\u89c6\u9891\u4e2d\u53d1\u751f\u67d0\u4e9b\u4e8b\u4ef6 \u2014\u2014 CNN \u53ef\u4ee5\u6355\u6349\u5230\u968f\u65f6\u95f4\u53d8\u5316\u7684\u7279\u5f81\u6a21\u5f0f\u3002\u8bf7\u590d\u4e60\u548c\u81ea\u5b66\u5176\u4ed6\u53ef\u4ee5\u7528 CNN \u5b8c\u6210\u7684\u4efb\u52a1\u3002</p>"},{"location":"lessons/4-ComputerVision/07-ConvNets/CNN_Architectures_chs/#_5","title":"\u4f5c\u4e1a","text":"<p>\u5728\u8fd9\u4e2a\u5b9e\u9a8c\u4e2d\uff0c\u4f60\u7684\u4efb\u52a1\u662f\u5206\u7c7b\u4e0d\u540c\u7684\u732b\u72d7\u54c1\u79cd\u3002\u8fd9\u4e9b\u56fe\u50cf\u6bd4 MNIST \u6570\u636e\u96c6\u66f4\u590d\u6742\u4e14\u7ef4\u5ea6\u66f4\u9ad8\uff0c\u5e76\u4e14\u7c7b\u522b\u8d85\u8fc7 10 \u4e2a\u3002</p>"},{"location":"lessons/4-ComputerVision/07-ConvNets/README_chs/","title":"\u5377\u79ef\u795e\u7ecf\u7f51\u7edc","text":"<p>\u6211\u4eec\u4e4b\u524d\u5df2\u7ecf\u770b\u5230\u795e\u7ecf\u7f51\u7edc\u5728\u5904\u7406\u56fe\u50cf\u65b9\u9762\u76f8\u5f53\u4e0d\u9519\uff0c\u751a\u81f3\u5355\u5c42\u611f\u77e5\u5668\u4e5f\u80fd\u591f\u4ee5\u5408\u7406\u7684\u51c6\u786e\u7387\u8bc6\u522bMNIST\u6570\u636e\u96c6\u4e2d\u624b\u5199\u7684\u6570\u5b57\u3002\u7136\u800c\uff0cMNIST\u6570\u636e\u96c6\u975e\u5e38\u7279\u6b8a\uff0c\u6240\u6709\u7684\u6570\u5b57\u90fd\u5728\u56fe\u50cf\u4e2d\u5c45\u4e2d\uff0c\u8fd9\u4f7f\u5f97\u4efb\u52a1\u53d8\u5f97\u66f4\u7b80\u5355\u3002</p>"},{"location":"lessons/4-ComputerVision/07-ConvNets/README_chs/#_2","title":"\u8bfe\u524d\u6d4b\u9a8c","text":"<p>\u5728\u73b0\u5b9e\u751f\u6d3b\u4e2d\uff0c\u6211\u4eec\u5e0c\u671b\u80fd\u591f\u8bc6\u522b\u56fe\u50cf\u4e2d\u7684\u7269\u4f53\uff0c\u800c\u4e0d\u7ba1\u5b83\u4eec\u5728\u56fe\u50cf\u4e2d\u7684\u786e\u5207\u4f4d\u7f6e\u3002\u8ba1\u7b97\u673a\u89c6\u89c9\u4e0d\u540c\u4e8e\u4e00\u822c\u7684\u5206\u7c7b\uff0c\u56e0\u4e3a\u5f53\u6211\u4eec\u8bd5\u56fe\u5728\u56fe\u50cf\u4e2d\u627e\u5230\u67d0\u4e2a\u7279\u5b9a\u7269\u4f53\u65f6\uff0c\u6211\u4eec\u662f\u5728\u626b\u63cf\u56fe\u50cf\u4ee5\u5bfb\u627e\u67d0\u4e9b\u7279\u5b9a\u6a21\u5f0f\u53ca\u5176\u7ec4\u5408\u3002\u4f8b\u5982\uff0c\u5728\u5bfb\u627e\u4e00\u53ea\u732b\u65f6\uff0c\u6211\u4eec\u53ef\u80fd\u9996\u5148\u5bfb\u627e\u6c34\u5e73\u7ebf\uff0c\u8fd9\u4e9b\u7ebf\u53ef\u4ee5\u5f62\u6210\u80e1\u987b\uff0c\u7136\u540e\u67d0\u79cd\u80e1\u987b\u7684\u7ec4\u5408\u53ef\u4ee5\u544a\u8bc9\u6211\u4eec\u8fd9\u5b9e\u9645\u4e0a\u662f\u4e00\u5f20\u732b\u7684\u7167\u7247\u3002\u76f8\u5bf9\u4f4d\u7f6e\u548c\u67d0\u4e9b\u6a21\u5f0f\u7684\u5b58\u5728\u662f\u91cd\u8981\u7684\uff0c\u800c\u4e0d\u662f\u5b83\u4eec\u5728\u56fe\u50cf\u4e2d\u7684\u786e\u5207\u4f4d\u7f6e\u3002</p> <p>\u4e3a\u4e86\u63d0\u53d6\u6a21\u5f0f\uff0c\u6211\u4eec\u5c06\u4f7f\u7528\u5377\u79ef\u6ee4\u6ce2\u5668\u7684\u6982\u5ff5\u3002\u5982\u60a8\u6240\u77e5\uff0c\u56fe\u50cf\u7531\u4e00\u4e2a\u4e8c\u7ef4\u77e9\u9635\u6216\u4e00\u4e2a\u5e26\u6709\u989c\u8272\u6df1\u5ea6\u7684\u4e09\u7ef4\u5f20\u91cf\u8868\u793a\u3002\u5e94\u7528\u6ee4\u6ce2\u5668\u610f\u5473\u7740\u6211\u4eec\u53d6\u4e00\u4e2a\u76f8\u5bf9\u8f83\u5c0f\u7684\u6ee4\u6ce2\u5668\u6838\u77e9\u9635\uff0c\u5bf9\u4e8e\u539f\u59cb\u56fe\u50cf\u4e2d\u7684\u6bcf\u4e2a\u50cf\u7d20\uff0c\u6211\u4eec\u8ba1\u7b97\u5176\u4e0e\u90bb\u8fd1\u70b9\u7684\u52a0\u6743\u5e73\u5747\u503c\u3002\u6211\u4eec\u53ef\u4ee5\u5c06\u5176\u89c6\u4e3a\u4e00\u4e2a\u5728\u6574\u4e2a\u56fe\u50cf\u4e0a\u6ed1\u52a8\u7684\u5c0f\u7a97\u53e3\uff0c\u6839\u636e\u6ee4\u6ce2\u5668\u6838\u77e9\u9635\u4e2d\u7684\u6743\u91cd\u5bf9\u6240\u6709\u50cf\u7d20\u8fdb\u884c\u5e73\u5747\u3002</p> <p>\u56fe\u7247\u7531 Dmitry Soshnikov \u63d0\u4f9b</p> <p>\u4f8b\u5982\uff0c\u5982\u679c\u6211\u4eec\u5c063x3\u7684\u7eb5\u5411\u8fb9\u7f18\u548c\u6a2a\u5411\u8fb9\u7f18\u6ee4\u6ce2\u5668\u5e94\u7528\u4e8eMNIST\u6570\u5b57\uff0c\u6211\u4eec\u53ef\u4ee5\u5728\u539f\u59cb\u56fe\u50cf\u4e2d\u5b58\u5728\u7eb5\u5411\u548c\u6a2a\u5411\u8fb9\u7f18\u7684\u4f4d\u7f6e\u83b7\u5f97\u9ad8\u4eae\u5ea6\uff08\u4f8b\u5982\u9ad8\u503c\uff09\u3002\u56e0\u6b64\uff0c\u8fd9\u4e24\u4e2a\u6ee4\u6ce2\u5668\u53ef\u4ee5\u7528\u6765\u201c\u67e5\u627e\u201d\u8fb9\u7f18\u3002\u540c\u6837\uff0c\u6211\u4eec\u53ef\u4ee5\u8bbe\u8ba1\u4e0d\u540c\u7684\u6ee4\u6ce2\u5668\u6765\u67e5\u627e\u5176\u4ed6\u4f4e\u7ea7\u6a21\u5f0f\uff1a</p> <p></p> <p>Leung-Malik\u6ee4\u6ce2\u5668\u7ec4\u56fe\u50cf</p> <p>\u7136\u800c\uff0c\u867d\u7136\u6211\u4eec\u53ef\u4ee5\u624b\u52a8\u8bbe\u8ba1\u6ee4\u6ce2\u5668\u4ee5\u63d0\u53d6\u4e00\u4e9b\u6a21\u5f0f\uff0c\u4f46\u6211\u4eec\u4e5f\u53ef\u4ee5\u8bbe\u8ba1\u7f51\u7edc\uff0c\u4ee5\u4fbf\u5b83\u81ea\u52a8\u5b66\u4e60\u8fd9\u4e9b\u6a21\u5f0f\u3002\u8fd9\u662fCNN\u80cc\u540e\u7684\u4e3b\u8981\u601d\u60f3\u4e4b\u4e00\u3002</p>"},{"location":"lessons/4-ComputerVision/07-ConvNets/README_chs/#cnn","title":"CNN\u7684\u4e3b\u8981\u601d\u60f3","text":"<p>CNN\u7684\u5de5\u4f5c\u65b9\u5f0f\u57fa\u4e8e\u4ee5\u4e0b\u51e0\u4e2a\u91cd\u8981\u601d\u60f3\uff1a</p> <ul> <li>\u5377\u79ef\u6ee4\u6ce2\u5668\u53ef\u4ee5\u63d0\u53d6\u6a21\u5f0f</li> <li>\u6211\u4eec\u53ef\u4ee5\u8bbe\u8ba1\u7f51\u7edc\uff0c\u4f7f\u6ee4\u6ce2\u5668\u81ea\u52a8\u8bad\u7ec3</li> <li>\u6211\u4eec\u53ef\u4ee5\u4f7f\u7528\u76f8\u540c\u7684\u65b9\u6cd5\u5728\u9ad8\u7ea7\u7279\u5f81\u4e2d\u627e\u5230\u6a21\u5f0f\uff0c\u800c\u4e0d\u4ec5\u4ec5\u662f\u5728\u539f\u59cb\u56fe\u50cf\u4e2d\u3002\u56e0\u6b64\uff0cCNN\u7279\u5f81\u63d0\u53d6\u5728\u7279\u5f81\u7684\u5c42\u6b21\u7ed3\u6784\u4e0a\u5de5\u4f5c\uff0c\u4ece\u4f4e\u7ea7\u50cf\u7d20\u7ec4\u5408\u5230\u66f4\u9ad8\u7ea7\u7684\u56fe\u50cf\u90e8\u5206\u7ec4\u5408\u3002</li> </ul> <p></p> <p>\u56fe\u7247\u6765\u81ea Hislop-Lynch\u7684\u8bba\u6587\uff0c\u57fa\u4e8e\u4ed6\u4eec\u7684\u7814\u7a76</p>"},{"location":"lessons/4-ComputerVision/07-ConvNets/README_chs/#_3","title":"\u270d\ufe0f \u7ec3\u4e60\uff1a\u5377\u79ef\u795e\u7ecf\u7f51\u7edc","text":"<p>\u8ba9\u6211\u4eec\u7ee7\u7eed\u63a2\u7d22\u5377\u79ef\u795e\u7ecf\u7f51\u7edc\u7684\u5de5\u4f5c\u539f\u7406\uff0c\u4ee5\u53ca\u5982\u4f55\u901a\u8fc7\u7ec3\u4e60\u76f8\u5173\u7b14\u8bb0\u672c\u5b9e\u73b0\u53ef\u8bad\u7ec3\u7684\u6ee4\u6ce2\u5668\uff1a</p> <ul> <li>\u5377\u79ef\u795e\u7ecf\u7f51\u7edc - PyTorch</li> <li>\u5377\u79ef\u795e\u7ecf\u7f51\u7edc - TensorFlow</li> </ul>"},{"location":"lessons/4-ComputerVision/07-ConvNets/README_chs/#_4","title":"\u91d1\u5b57\u5854\u67b6\u6784","text":"<p>\u5927\u591a\u6570\u7528\u4e8e\u56fe\u50cf\u5904\u7406\u7684CNNs\u9075\u5faa\u6240\u8c13\u7684\u91d1\u5b57\u5854\u67b6\u6784\u3002\u5e94\u7528\u4e8e\u539f\u59cb\u56fe\u50cf\u7684\u7b2c\u4e00\u4e2a\u5377\u79ef\u5c42\u901a\u5e38\u5177\u6709\u76f8\u5bf9\u8f83\u5c11\u7684\u6ee4\u6ce2\u5668\uff088-16\u4e2a\uff09\uff0c\u8fd9\u4e9b\u6ee4\u6ce2\u5668\u5bf9\u5e94\u4e8e\u4e0d\u540c\u7684\u50cf\u7d20\u7ec4\u5408\uff0c\u4f8b\u5982\u6c34\u5e73/\u5782\u76f4\u7ebf\u6761\u3002\u5728\u4e0b\u4e00\u4e2a\u5c42\u6b21\uff0c\u6211\u4eec\u51cf\u5c11\u4e86\u7f51\u7edc\u7684\u7a7a\u95f4\u7ef4\u5ea6\uff0c\u5e76\u589e\u52a0\u4e86\u6ee4\u6ce2\u5668\u7684\u6570\u91cf\uff0c\u8fd9\u5bf9\u5e94\u4e8e\u66f4\u591a\u7684\u7b80\u5355\u7279\u5f81\u7ec4\u5408\u3002\u5728\u6bcf\u4e00\u5c42\u4e2d\uff0c\u968f\u7740\u6211\u4eec\u5411\u6700\u7ec8\u5206\u7c7b\u5668\u79fb\u52a8\uff0c\u56fe\u50cf\u7684\u7a7a\u95f4\u7ef4\u5ea6\u51cf\u5c11\uff0c\u800c\u6ee4\u6ce2\u5668\u7684\u6570\u91cf\u589e\u52a0\u3002</p> <p>\u4f8b\u5982\uff0c\u8ba9\u6211\u4eec\u770b\u770bVGG-16\u7684\u67b6\u6784\uff0c\u8fd9\u662f\u4e00\u4e2a\u57282014\u5e74ImageNet\u7684\u524d\u4e94\u5206\u7c7b\u4e2d\u8fbe\u5230\u4e8692.7%\u51c6\u786e\u7387\u7684\u7f51\u7edc\uff1a</p> <p></p> <p></p> <p>\u56fe\u7247\u6765\u81ea Researchgate</p>"},{"location":"lessons/4-ComputerVision/07-ConvNets/README_chs/#cnn_1","title":"\u6700\u8457\u540d\u7684CNN\u67b6\u6784","text":"<p>\u7ee7\u7eed\u5b66\u4e60\u6700\u8457\u540d\u7684CNN\u67b6\u6784</p>"},{"location":"lessons/4-ComputerVision/07-ConvNets/lab/","title":"Classification of Pets Faces","text":"<p>Lab Assignment from AI for Beginners Curriculum.</p>"},{"location":"lessons/4-ComputerVision/07-ConvNets/lab/#task","title":"Task","text":"<p>Imagine you need to develop and application for pet nursery to catalog all pets. One of the great features of such an application would be automatically discovering the breed from a photograph. This can be successfully done using neural networks.</p> <p>You need to train a convolutional neural network to classify different breeds of cats and dogs using Pet Faces dataset.</p>"},{"location":"lessons/4-ComputerVision/07-ConvNets/lab/#the-dataset","title":"The Dataset","text":"<p>We will use the Pet Faces dataset, derived from Oxford-IIIT pets dataset. It contains 35 different breeds of dogs and cats.</p> <p></p> <p>To download the dataset, use this code snippet:</p> <pre><code>!wget https://mslearntensorflowlp.blob.core.windows.net/data/petfaces.tar.gz\n!tar xfz petfaces.tar.gz\n!rm petfaces.tar.gz\n</code></pre>"},{"location":"lessons/4-ComputerVision/07-ConvNets/lab/#stating-notebook","title":"Stating Notebook","text":"<p>Start the lab by opening PetFaces.ipynb</p>"},{"location":"lessons/4-ComputerVision/07-ConvNets/lab/#takeaway","title":"Takeaway","text":"<p>You have solved a relatively complex problem of image classification from scratch! There were quite a lot of classes, and you were still able to get reasonable accuracy! It also makes sense to measure top-k accuracy, because it is easy to confuse some of the classes which are not clearly different even to human beings.</p>"},{"location":"lessons/4-ComputerVision/07-ConvNets/lab/README_chs/","title":"\u5ba0\u7269\u8138\u5206\u7c7b","text":"<p>\u6765\u81ea AI for Beginners Curriculum \u7684\u5b9e\u9a8c\u4efb\u52a1\u3002</p>"},{"location":"lessons/4-ComputerVision/07-ConvNets/lab/README_chs/#_2","title":"\u4efb\u52a1","text":"<p>\u60f3\u8c61\u4e00\u4e0b\uff0c\u60a8\u9700\u8981\u4e3a\u5ba0\u7269\u6258\u513f\u6240\u5f00\u53d1\u4e00\u4e2a\u5e94\u7528\u7a0b\u5e8f\u6765\u5206\u7c7b\u6240\u6709\u7684\u5ba0\u7269\u3002\u8fd9\u6837\u4e00\u4e2a\u5e94\u7528\u7a0b\u5e8f\u7684\u4e00\u4e2a\u7edd\u4f73\u529f\u80fd\u662f\u53ef\u4ee5\u901a\u8fc7\u4e00\u5f20\u7167\u7247\u81ea\u52a8\u8bc6\u522b\u51fa\u5ba0\u7269\u7684\u54c1\u79cd\u3002\u8fd9\u53ef\u4ee5\u901a\u8fc7\u795e\u7ecf\u7f51\u7edc\u6210\u529f\u5730\u5b8c\u6210\u3002</p> <p>\u60a8\u9700\u8981\u8bad\u7ec3\u4e00\u4e2a\u5377\u79ef\u795e\u7ecf\u7f51\u7edc\u6765\u4f7f\u7528 Pet Faces \u6570\u636e\u96c6\u5bf9\u4e0d\u540c\u54c1\u79cd\u7684\u732b\u548c\u72d7\u8fdb\u884c\u5206\u7c7b\u3002</p>"},{"location":"lessons/4-ComputerVision/07-ConvNets/lab/README_chs/#_3","title":"\u6570\u636e\u96c6","text":"<p>\u6211\u4eec\u5c06\u4f7f\u7528 Pet Faces \u6570\u636e\u96c6\uff0c\u5176\u6765\u6e90\u4e8e Oxford-IIIT \u5ba0\u7269\u6570\u636e\u96c6\u3002\u5b83\u5305\u542b35\u79cd\u4e0d\u540c\u54c1\u79cd\u7684\u732b\u548c\u72d7\u3002</p> <p></p> <p>\u8981\u4e0b\u8f7d\u6570\u636e\u96c6\uff0c\u8bf7\u4f7f\u7528\u4ee5\u4e0b\u4ee3\u7801\u7247\u6bb5\uff1a</p> <pre><code>!wget https://mslearntensorflowlp.blob.core.windows.net/data/petfaces.tar.gz\n!tar xfz petfaces.tar.gz\n!rm petfaces.tar.gz\n</code></pre>"},{"location":"lessons/4-ComputerVision/07-ConvNets/lab/README_chs/#_4","title":"\u5f00\u59cb\u7b14\u8bb0\u672c","text":"<p>\u901a\u8fc7\u6253\u5f00 PetFaces.ipynb \u6765\u5f00\u59cb\u8fd9\u6b21\u5b9e\u9a8c\u4efb\u52a1</p>"},{"location":"lessons/4-ComputerVision/07-ConvNets/lab/README_chs/#_5","title":"\u6536\u83b7","text":"<p>\u60a8\u5df2\u7ecf\u4ece\u5934\u89e3\u51b3\u4e86\u4e00\u4e2a\u76f8\u5bf9\u590d\u6742\u7684\u56fe\u50cf\u5206\u7c7b\u95ee\u9898\uff01\u6709\u5f88\u591a\u7c7b\u522b\uff0c\u60a8\u4ecd\u7136\u80fd\u591f\u83b7\u5f97\u5408\u7406\u7684\u51c6\u786e\u6027\uff01\u56e0\u4e3a\u4e00\u4e9b\u5373\u4f7f\u5bf9\u4eba\u7c7b\u6765\u8bf4\u4e5f\u4e0d\u662f\u660e\u663e\u4e0d\u540c\u7684\u7c7b\u522b\u5f88\u5bb9\u6613\u6df7\u6dc6\uff0c\u6240\u4ee5\u8861\u91cf top-k \u51c6\u786e\u7387\u4e5f\u662f\u6709\u610f\u4e49\u7684\u3002</p>"},{"location":"lessons/4-ComputerVision/08-TransferLearning/","title":"Pre-trained Networks and Transfer Learning","text":"<p>Training CNNs can take a lot of time, and a lot of data is required for that task. However, much of the time is spent learning the best low-level filters that a network can use to extract patterns from images. A natural question arises - can we use a neural network trained on one dataset and adapt it to classify different images without requiring a full training process?</p>"},{"location":"lessons/4-ComputerVision/08-TransferLearning/#pre-lecture-quiz","title":"Pre-lecture quiz","text":"<p>This approach is called transfer learning, because we transfer some knowledge from one neural network model to another. In transfer learning, we typically start with a pre-trained model, which has been trained on some large image dataset, such as ImageNet. Those models can already do a good job extracting different features from generic images, and in many cases just building a classifier on top of those extracted features can yield a good result.</p> <p>\u2705 Transfer Learning is a term you find in other academic fields, such as Education. It refers to the process of taking knowledge from one domain and applying it to another.</p>"},{"location":"lessons/4-ComputerVision/08-TransferLearning/#pre-trained-models-as-feature-extractors","title":"Pre-Trained Models as Feature Extractors","text":"<p>The convolutional networks that we have talked about in the previous section contained a number of layers, each of which is supposed to extract some features from the image, starting from low-level pixel combinations (such as horizontal/vertical line or stroke), up to higher level combinations of features, corresponding to things like an eye of a flame. If we train CNN on sufficiently large dataset of generic and diverse images, the network should learn to extract those common features.</p> <p>Both Keras and PyTorch contain functions to easily load pre-trained neural network weights for some common architectures, most of which were trained on ImageNet images. The most often used ones are described on the CNN Architectures page from the prior lesson. In particular, you may want to consider using one of the following:</p> <ul> <li>VGG-16/VGG-19 which are relatively simple models that still give good accuracy. Often using VGG as a first attempt is a good choice to see how transfer learning is working.</li> <li>ResNet is a family of models proposed by Microsoft Research in 2015. They have more layers, and thus take more resources.</li> <li>MobileNet is a family of models with reduced size, suitable for mobile devices. Use them if you are short in resources and can sacrifice a little bit of accuracy.</li> </ul> <p>Here are sample features extracted from a picture of a cat by VGG-16 network:</p> <p></p>"},{"location":"lessons/4-ComputerVision/08-TransferLearning/#cats-vs-dogs-dataset","title":"Cats vs. Dogs Dataset","text":"<p>In this example, we will use a dataset of Cats and Dogs, which is very close to a real-life image classification scenario.</p>"},{"location":"lessons/4-ComputerVision/08-TransferLearning/#exercise-transfer-learning","title":"\u270d\ufe0f Exercise: Transfer Learning","text":"<p>Let's see transfer learning in action in corresponding notebooks:</p> <ul> <li>Transfer Learning - PyTorch</li> <li>Transfer Learning - TensorFlow</li> </ul>"},{"location":"lessons/4-ComputerVision/08-TransferLearning/#visualizing-adversarial-cat","title":"Visualizing Adversarial Cat","text":"<p>Pre-trained neural network contains different patterns inside it's brain, including notions of ideal cat (as well as ideal dog, ideal zebra, etc.). It would be interesting to somehow visualize this image. However, it is not simple, because patterns are spread all over the network weights, and also organized in a hierarchical structure.</p> <p>One approach we can take is to start with a random image, and then try to use gradient descent optimization technique to adjust that image in such a way, that the network starts thinking that it's a cat. </p> <p></p> <p>However, if we do this, we will receive something very similar to a random noise. This is because there are many ways to make network think the input image is a cat, including some that do not make sense visually. While those images contain a lot of patterns typical for a cat, there is nothing to constrain them to be visually distinctive.</p> <p>To improve the result, we can add another term into the loss function, which is called variation loss. It is a metric that shows how similar neighboring pixels of the image are. Minimizing variation loss makes image smoother, and gets rid of noise - thus revealing more visually appealing patterns. Here is an example of such \"ideal\" images, that are classified as cat and as zebra with high probability:</p> Ideal Cat Ideal Zebra <p>Similar approach can be used to perform so-called adversarial attacks on a neural network. Suppose we want to fool a neural network and make a dog look like a cat. If we take dog's image, which is recognized by a network as a dog, we can then tweak it a little but using gradient descent optimization, until the network starts classifying it as a cat:</p> Original picture of a dog Picture of a dog classified as a cat <p>See the code to reproduce the results above in the following notebook:</p> <ul> <li>Ideal and Adversarial Cat - TensorFlow</li> </ul>"},{"location":"lessons/4-ComputerVision/08-TransferLearning/#conclusion","title":"Conclusion","text":"<p>Using transfer learning, you are able to quickly put together a classifier for a custom object classification task and achieve high accuracy. You can see that more complex tasks that we are solving now require higher computational power, and cannot be easily solved on the CPU. In the next unit, we will try to use a more lightweight implementation to train the same model using lower compute resources, which results in just slightly lower accuracy.</p>"},{"location":"lessons/4-ComputerVision/08-TransferLearning/#challenge","title":"\ud83d\ude80 Challenge","text":"<p>In the accompanying notebooks, there are notes at the bottom about how transfer knowledge works best with somewhat similar training data (a new type of animal, perhaps). Do some experimentation with completely new types of images to see how well or poorly your transfer knowledge models perform.</p>"},{"location":"lessons/4-ComputerVision/08-TransferLearning/#post-lecture-quiz","title":"Post-lecture quiz","text":""},{"location":"lessons/4-ComputerVision/08-TransferLearning/#review-self-study","title":"Review &amp; Self Study","text":"<p>Read through TrainingTricks_chs.md to deepen your knowledge of some other way to train your models.</p>"},{"location":"lessons/4-ComputerVision/08-TransferLearning/#assignment","title":"Assignment","text":"<p>In this lab, we will use real-life Oxford-IIIT pets dataset with 35 breeds of cats and dogs, and we will build a transfer learning classifier.</p>"},{"location":"lessons/4-ComputerVision/08-TransferLearning/README_chs/","title":"\u9884\u8bad\u7ec3\u7f51\u7edc\u548c\u8fc1\u79fb\u5b66\u4e60","text":"<p>\u8bad\u7ec3\u5377\u79ef\u795e\u7ecf\u7f51\u7edc\uff08CNN\uff09\u9700\u8981\u5f88\u591a\u65f6\u95f4\uff0c\u800c\u4e14\u9700\u8981\u5927\u91cf\u6570\u636e\u3002\u5927\u90e8\u5206\u65f6\u95f4\u90fd\u82b1\u5728\u5b66\u4e60\u7f51\u7edc\u53ef\u4ee5\u7528\u6765\u4ece\u56fe\u50cf\u4e2d\u63d0\u53d6\u6a21\u5f0f\u7684\u6700\u4f73\u4f4e\u7ea7\u6ee4\u6ce2\u5668\u4e0a\u3002\u4e00\u4e2a\u81ea\u7136\u7684\u95ee\u9898\u51fa\u73b0\u4e86\u2014\u2014\u6211\u4eec\u80fd\u5426\u4f7f\u7528\u4e00\u4e2a\u5728\u4e00\u4e2a\u6570\u636e\u96c6\u4e0a\u8bad\u7ec3\u597d\u7684\u795e\u7ecf\u7f51\u7edc\uff0c\u5e76\u9002\u5e94\u5b83\u6765\u5206\u7c7b\u4e0d\u540c\u7684\u56fe\u50cf\uff0c\u800c\u4e0d\u9700\u8981\u5b8c\u6574\u7684\u8bad\u7ec3\u8fc7\u7a0b\u5462\uff1f</p>"},{"location":"lessons/4-ComputerVision/08-TransferLearning/README_chs/#_2","title":"\u8bfe\u524d\u6d4b\u9a8c","text":"<p>\u8fd9\u79cd\u65b9\u6cd5\u88ab\u79f0\u4e3a\u8fc1\u79fb\u5b66\u4e60\uff0c\u56e0\u4e3a\u6211\u4eec\u5c06\u4e00\u4e9b\u77e5\u8bc6\u4ece\u4e00\u4e2a\u795e\u7ecf\u7f51\u7edc\u6a21\u578b\u8f6c\u79fb\u5230\u53e6\u4e00\u4e2a\u6a21\u578b\u4e2d\u3002\u5728\u8fc1\u79fb\u5b66\u4e60\u4e2d\uff0c\u6211\u4eec\u901a\u5e38\u4ece\u4e00\u4e2a\u9884\u8bad\u7ec3\u6a21\u578b\u5f00\u59cb\uff0c\u8be5\u6a21\u578b\u5df2\u7ecf\u5728\u4e00\u4e9b\u5927\u578b\u56fe\u50cf\u6570\u636e\u96c6\uff08\u5982 ImageNet\uff09\u4e0a\u8fdb\u884c\u4e86\u8bad\u7ec3\u3002\u8fd9\u4e9b\u6a21\u578b\u5df2\u7ecf\u80fd\u591f\u5f88\u597d\u5730\u4ece\u901a\u7528\u56fe\u50cf\u4e2d\u63d0\u53d6\u4e0d\u540c\u7684\u7279\u5f81\uff0c\u5728\u8bb8\u591a\u60c5\u51b5\u4e0b\uff0c\u4ec5\u4ec5\u5728\u8fd9\u4e9b\u63d0\u53d6\u7684\u7279\u5f81\u4e4b\u4e0a\u6784\u5efa\u4e00\u4e2a\u5206\u7c7b\u5668\u5c31\u80fd\u4ea7\u751f\u826f\u597d\u7684\u7ed3\u679c\u3002</p> <p>\u2705 \u8fc1\u79fb\u5b66\u4e60\u662f\u60a8\u5728\u5176\u4ed6\u5b66\u672f\u9886\u57df\uff08\u5982\u6559\u80b2\uff09\u4e2d\u4f1a\u53d1\u73b0\u7684\u672f\u8bed\u3002\u5b83\u6307\u7684\u662f\u5c06\u4e00\u4e2a\u9886\u57df\u7684\u77e5\u8bc6\u5e94\u7528\u5230\u53e6\u4e00\u4e2a\u9886\u57df\u7684\u8fc7\u7a0b\u3002</p>"},{"location":"lessons/4-ComputerVision/08-TransferLearning/README_chs/#_3","title":"\u9884\u8bad\u7ec3\u6a21\u578b\u4f5c\u4e3a\u7279\u5f81\u63d0\u53d6\u5668","text":"<p>\u6211\u4eec\u5728\u524d\u4e00\u90e8\u5206\u4e2d\u8ba8\u8bba\u7684\u5377\u79ef\u7f51\u7edc\u5305\u542b\u591a\u4e2a\u5c42\uff0c\u6bcf\u4e00\u5c42\u90fd\u5e94\u8be5\u4ece\u56fe\u50cf\u4e2d\u63d0\u53d6\u4e00\u4e9b\u7279\u5f81\uff0c\u4ece\u4f4e\u7ea7\u50cf\u7d20\u7ec4\u5408\uff08\u5982\u6c34\u5e73/\u5782\u76f4\u7ebf\u6216\u7b14\u753b\uff09\uff0c\u5230\u66f4\u9ad8\u7ea7\u7684\u7279\u5f81\u7ec4\u5408\uff0c\u7c7b\u4f3c\u4e8e\u706b\u7130\u7684\u773c\u775b\u3002\u5982\u679c\u6211\u4eec\u5728\u8db3\u591f\u5927\u7684\u901a\u7528\u548c\u591a\u6837\u5316\u7684\u56fe\u50cf\u6570\u636e\u96c6\u4e0a\u8bad\u7ec3 CNN\uff0c\u7f51\u7edc\u5e94\u8be5\u80fd\u591f\u5b66\u4e60\u63d0\u53d6\u8fd9\u4e9b\u5e38\u89c1\u7279\u5f81\u3002</p> <p>Keras \u548c PyTorch \u90fd\u5305\u542b\u51fd\u6570\u6765\u8f7b\u677e\u52a0\u8f7d\u4e00\u4e9b\u5e38\u89c1\u67b6\u6784\u7684\u9884\u8bad\u7ec3\u795e\u7ecf\u7f51\u7edc\u6743\u91cd\uff0c\u5176\u4e2d\u5927\u591a\u6570\u662f\u5728 ImageNet \u56fe\u50cf\u4e0a\u8bad\u7ec3\u7684\u3002\u6700\u5e38\u7528\u7684\u6a21\u578b\u5728\u4e0a\u4e00\u8bfe\u7684CNN\u67b6\u6784\u9875\u9762\u8fdb\u884c\u4e86\u63cf\u8ff0\u3002\u7279\u522b\u5730\uff0c\u60a8\u53ef\u80fd\u9700\u8981\u8003\u8651\u4f7f\u7528\u4ee5\u4e0b\u6a21\u578b\u4e4b\u4e00\uff1a</p> <ul> <li>VGG-16/VGG-19 \u662f\u76f8\u5bf9\u7b80\u5355\u7684\u6a21\u578b\uff0c\u4f46\u4ecd\u80fd\u63d0\u4f9b\u826f\u597d\u7684\u51c6\u786e\u6027\u3002\u901a\u5e38\u4f7f\u7528 VGG \u4f5c\u4e3a\u7b2c\u4e00\u4e2a\u5c1d\u8bd5\u662f\u4e00\u4e2a\u597d\u7684\u9009\u62e9\uff0c\u4ee5\u67e5\u770b\u8fc1\u79fb\u5b66\u4e60\u7684\u6548\u679c\u3002</li> <li>ResNet \u662f\u5fae\u8f6f\u7814\u7a76\u9662\u57282015\u5e74\u63d0\u51fa\u7684\u4e00\u7cfb\u5217\u6a21\u578b\u3002\u5b83\u4eec\u6709\u66f4\u591a\u7684\u5c42\uff0c\u56e0\u6b64\u9700\u8981\u66f4\u591a\u7684\u8d44\u6e90\u3002</li> <li>MobileNet \u662f\u4e00\u7cfb\u5217\u5177\u6709\u8f83\u5c0f\u5c3a\u5bf8\u7684\u6a21\u578b\uff0c\u9002\u7528\u4e8e\u79fb\u52a8\u8bbe\u5907\u3002\u5982\u679c\u60a8\u8d44\u6e90\u7d27\u7f3a\u4e14\u80fd\u727a\u7272\u4e00\u70b9\u51c6\u786e\u6027\uff0c\u8bf7\u4f7f\u7528\u5b83\u4eec\u3002</li> </ul> <p>\u4ee5\u4e0b\u662f VGG-16 \u7f51\u7edc\u4ece\u4e00\u5f20\u732b\u7684\u56fe\u7247\u4e2d\u63d0\u53d6\u7684\u7279\u5f81\u793a\u4f8b\uff1a</p> <p></p>"},{"location":"lessons/4-ComputerVision/08-TransferLearning/README_chs/#_4","title":"\u732b\u4e0e\u72d7\u6570\u636e\u96c6","text":"<p>\u5728\u8fd9\u4e2a\u793a\u4f8b\u4e2d\uff0c\u6211\u4eec\u5c06\u4f7f\u7528\u4e00\u4e2a\u732b\u548c\u72d7\u7684\u6570\u636e\u96c6\uff0c\u8fd9\u975e\u5e38\u63a5\u8fd1\u771f\u5b9e\u7684\u56fe\u50cf\u5206\u7c7b\u573a\u666f\u3002</p>"},{"location":"lessons/4-ComputerVision/08-TransferLearning/README_chs/#_5","title":"\u270d\ufe0f \u7ec3\u4e60\uff1a\u8fc1\u79fb\u5b66\u4e60","text":"<p>\u8ba9\u6211\u4eec\u770b\u770b\u5728\u5bf9\u5e94\u7684\u7b14\u8bb0\u672c\u4e2d\u8fc1\u79fb\u5b66\u4e60\u7684\u5b9e\u9645\u5e94\u7528\uff1a</p> <ul> <li>\u8fc1\u79fb\u5b66\u4e60 - PyTorch</li> <li>\u8fc1\u79fb\u5b66\u4e60 - TensorFlow</li> </ul>"},{"location":"lessons/4-ComputerVision/08-TransferLearning/README_chs/#_6","title":"\u53ef\u89c6\u5316\u5bf9\u6297\u6027\u732b","text":"<p>\u9884\u8bad\u7ec3\u7684\u795e\u7ecf\u7f51\u7edc\u5728\u5176\u201c\u8111\u201d\u4e2d\u5305\u542b\u4e0d\u540c\u7684\u6a21\u5f0f\uff0c\u5305\u62ec\u7406\u60f3\u732b\uff08\u4ee5\u53ca\u7406\u60f3\u72d7\u3001\u7406\u60f3\u6591\u9a6c\u7b49\uff09\u7684\u6982\u5ff5\u3002\u4ee5\u67d0\u79cd\u65b9\u5f0f\u53ef\u89c6\u5316\u8fd9\u4e2a\u56fe\u50cf\u5c06\u4f1a\u975e\u5e38\u6709\u8da3\u3002\u7136\u800c\uff0c\u8fd9\u5e76\u4e0d\u7b80\u5355\uff0c\u56e0\u4e3a\u6a21\u5f0f\u5206\u5e03\u5728\u7f51\u7edc\u6743\u91cd\u4e2d\u7684\u5404\u4e2a\u4f4d\u7f6e\uff0c\u8fd8\u7ec4\u7ec7\u6210\u4e00\u4e2a\u5206\u5c42\u7ed3\u6784\u3002</p> <p>\u6211\u4eec\u53ef\u4ee5\u91c7\u53d6\u7684\u4e00\u79cd\u65b9\u6cd5\u662f\u4ece\u4e00\u4e2a\u968f\u673a\u56fe\u50cf\u5f00\u59cb\uff0c\u7136\u540e\u5c1d\u8bd5\u4f7f\u7528\u68af\u5ea6\u4e0b\u964d\u4f18\u5316\u6280\u672f\u6765\u8c03\u6574\u8be5\u56fe\u50cf\uff0c\u4f7f\u7f51\u7edc\u8ba4\u4e3a\u5b83\u662f\u4e00\u53ea\u732b\u3002</p> <p></p> <p>\u7136\u800c\uff0c\u5982\u679c\u6211\u4eec\u8fd9\u6837\u505a\uff0c\u6211\u4eec\u5c06\u5f97\u5230\u4e00\u4e9b\u975e\u5e38\u7c7b\u4f3c\u968f\u673a\u566a\u58f0\u7684\u4e1c\u897f\u3002\u8fd9\u662f\u56e0\u4e3a\u6709\u5f88\u591a\u65b9\u6cd5\u53ef\u4ee5\u8ba9\u7f51\u7edc\u8ba4\u4e3a\u8f93\u5165\u56fe\u50cf\u662f\u4e00\u53ea\u732b\uff0c\u5305\u62ec\u4e00\u4e9b\u5728\u89c6\u89c9\u4e0a\u6ca1\u6709\u610f\u4e49\u7684\u65b9\u6cd5\u3002\u867d\u7136\u8fd9\u4e9b\u56fe\u50cf\u5305\u542b\u4e86\u5f88\u591a\u5178\u578b\u7684\u732b\u7684\u6a21\u5f0f\uff0c\u4f46\u6ca1\u6709\u4ec0\u4e48\u80fd\u7ea6\u675f\u5b83\u4eec\u5728\u89c6\u89c9\u4e0a\u662f\u72ec\u7279\u7684\u3002</p> <p>\u4e3a\u4e86\u6539\u8fdb\u7ed3\u679c\uff0c\u6211\u4eec\u53ef\u4ee5\u5728\u635f\u5931\u51fd\u6570\u4e2d\u52a0\u5165\u53e6\u4e00\u4e2a\u9879\uff0c\u79f0\u4e3a\u53d8\u5f02\u635f\u5931\u3002\u5b83\u662f\u4e00\u79cd\u5ea6\u91cf\uff0c\u663e\u793a\u4e86\u56fe\u50cf\u76f8\u90bb\u50cf\u7d20\u7684\u76f8\u4f3c\u7a0b\u5ea6\u3002\u6700\u5c0f\u5316\u53d8\u5f02\u635f\u5931\u4f7f\u56fe\u50cf\u66f4\u5e73\u6ed1\uff0c\u6d88\u9664\u566a\u58f0\uff0c\u4ece\u800c\u63ed\u793a\u66f4\u5177\u89c6\u89c9\u5438\u5f15\u529b\u7684\u6a21\u5f0f\u3002\u4e0b\u9762\u662f\u4e00\u4e9b \u201c\u7406\u60f3\u201d \u56fe\u50cf\u7684\u4f8b\u5b50\uff0c\u5b83\u4eec\u88ab\u9ad8\u5ea6\u6982\u7387\u5730\u5206\u7c7b\u4e3a\u732b\u548c\u6591\u9a6c\uff1a</p> \u7406\u60f3\u732b \u7406\u60f3\u6591\u9a6c <p>\u7c7b\u4f3c\u7684\u65b9\u6cd5\u53ef\u4ee5\u7528\u6765\u5bf9\u795e\u7ecf\u7f51\u7edc\u8fdb\u884c\u6240\u8c13\u7684\u5bf9\u6297\u6027\u653b\u51fb\u3002\u5047\u8bbe\u6211\u4eec\u60f3\u8981\u6b3a\u9a97\u4e00\u4e2a\u795e\u7ecf\u7f51\u7edc\uff0c\u4f7f\u4e00\u53ea\u72d7\u770b\u8d77\u6765\u50cf\u4e00\u53ea\u732b\u3002\u5982\u679c\u6211\u4eec\u62cd\u4e00\u5f20\u88ab\u7f51\u7edc\u8bc6\u522b\u4e3a\u72d7\u7684\u72d7\u7684\u56fe\u50cf\uff0c\u7136\u540e\u4f7f\u7528\u68af\u5ea6\u4e0b\u964d\u4f18\u5316\u5bf9\u5176\u7a0d\u5fae\u8c03\u6574\u4e00\u4e0b\uff0c\u76f4\u5230\u7f51\u7edc\u5f00\u59cb\u5c06\u5176\u5206\u7c7b\u4e3a\u732b\uff1a</p> \u72d7\u7684\u539f\u59cb\u56fe\u7247 \u88ab\u5206\u7c7b\u4e3a\u732b\u7684\u72d7\u7684\u56fe\u7247 <p>\u53c2\u89c1\u4ee5\u4e0b\u7b14\u8bb0\u672c\u4e2d\u7684\u4ee3\u7801\u4ee5\u91cd\u73b0\u4e0a\u8ff0\u7ed3\u679c\uff1a</p> <ul> <li>\u7406\u60f3\u548c\u5bf9\u6297\u6027\u732b - TensorFlow</li> </ul>"},{"location":"lessons/4-ComputerVision/08-TransferLearning/README_chs/#_7","title":"\u7ed3\u8bba","text":"<p>\u901a\u8fc7\u8fc1\u79fb\u5b66\u4e60\uff0c\u60a8\u53ef\u4ee5\u5feb\u901f\u62fc\u51d1\u51fa\u4e00\u4e2a\u81ea\u5b9a\u4e49\u5bf9\u8c61\u5206\u7c7b\u4efb\u52a1\u7684\u5206\u7c7b\u5668\uff0c\u5e76\u4e14\u8fbe\u5230\u9ad8\u51c6\u786e\u5ea6\u3002\u60a8\u53ef\u4ee5\u770b\u5230\u6211\u4eec\u73b0\u5728\u89e3\u51b3\u7684\u66f4\u590d\u6742\u7684\u4efb\u52a1\u9700\u8981\u66f4\u9ad8\u7684\u8ba1\u7b97\u80fd\u529b\uff0c\u5e76\u4e14\u4e0d\u80fd\u8f7b\u677e\u5730\u5728 CPU \u4e0a\u89e3\u51b3\u3002\u5728\u4e0b\u4e00\u5355\u5143\uff0c\u6211\u4eec\u5c06\u5c1d\u8bd5\u4f7f\u7528\u66f4\u8f7b\u91cf\u7684\u5b9e\u73b0\u6765\u8bad\u7ec3\u76f8\u540c\u7684\u6a21\u578b\uff0c\u4f7f\u7528\u66f4\u4f4e\u7684\u8ba1\u7b97\u8d44\u6e90\uff0c\u5176\u7ed3\u679c\u53ea\u662f\u7565\u4f4e\u7684\u51c6\u786e\u6027\u3002</p>"},{"location":"lessons/4-ComputerVision/08-TransferLearning/README_chs/#_8","title":"\ud83d\ude80 \u6311\u6218","text":"<p>\u5728\u968f\u9644\u7684\u7b14\u8bb0\u672c\u4e2d\uff0c\u5e95\u90e8\u6709\u5173\u4e8e\u5982\u4f55\u6700\u597d\u5730\u5229\u7528\u76f8\u4f3c\u8bad\u7ec3\u6570\u636e\uff08\u4f8b\u5982\u4e00\u79cd\u65b0\u7c7b\u578b\u7684\u52a8\u7269\uff09\u7684\u8fc1\u79fb\u77e5\u8bc6\u7684\u5907\u6ce8\u3002\u8bf7\u8fdb\u884c\u4e00\u4e9b\u5b9e\u9a8c\uff0c\u4f7f\u7528\u5b8c\u5168\u65b0\u7c7b\u578b\u7684\u56fe\u50cf\uff0c\u770b\u770b\u60a8\u7684\u8fc1\u79fb\u77e5\u8bc6\u6a21\u578b\u6267\u884c\u5f97\u5982\u4f55\u3002</p>"},{"location":"lessons/4-ComputerVision/08-TransferLearning/README_chs/#_9","title":"\u8bfe\u540e\u6d4b\u9a8c","text":""},{"location":"lessons/4-ComputerVision/08-TransferLearning/README_chs/#_10","title":"\u590d\u4e60\u4e0e\u81ea\u5b66","text":"<p>\u9605\u8bfb TrainingTricks_chs.md \u4ee5\u52a0\u6df1\u60a8\u5bf9\u5176\u4ed6\u4e00\u4e9b\u8bad\u7ec3\u6a21\u578b\u65b9\u6cd5\u7684\u4e86\u89e3\u3002</p>"},{"location":"lessons/4-ComputerVision/08-TransferLearning/README_chs/#_11","title":"\u4f5c\u4e1a","text":"<p>\u5728\u6b64\u5b9e\u9a8c\u4e2d\uff0c\u6211\u4eec\u5c06\u4f7f\u7528\u771f\u5b9e\u7684 Oxford-IIIT \u5ba0\u7269\u6570\u636e\u96c6\uff0c\u8be5\u6570\u636e\u96c6\u5305\u542b35\u79cd\u732b\u72d7\u54c1\u79cd\uff0c\u5e76\u4e14\u6211\u4eec\u5c06\u6784\u5efa\u4e00\u4e2a\u8fc1\u79fb\u5b66\u4e60\u5206\u7c7b\u5668\u3002</p>"},{"location":"lessons/4-ComputerVision/08-TransferLearning/TrainingTricks/","title":"Deep Learning Training Tricks","text":"<p>As neural networks become deeper, the process of their training becomes more and more challenging. One major problem is so-called vanishing gradients or exploding gradients. This post gives a good introduction into those problems.</p> <p>To make training deep networks more efficient, there are a few techniques that can be used.</p>"},{"location":"lessons/4-ComputerVision/08-TransferLearning/TrainingTricks/#keeping-values-in-reasonable-interval","title":"Keeping values in reasonable interval","text":"<p>To make numerical computations more stable, we want to make sure that all values within our neural network are within reasonable scale, typically [-1..1] or [0..1]. It is not a very strict requirement, but the nature of floating point computations is such that values of different magnitudes cannot be accurately manipulated together. For example, if we add 10<sup>-10</sup> and 10<sup>10</sup>, we are likely to get 10<sup>10</sup>, because smaller value would be \"converted\" to the same order as the larger one, and thus mantissa would be lost.</p> <p>Most activation functions have non-linearities around [-1..1], and thus it makes sense to scale all input data to [-1..1] or [0..1] interval.</p>"},{"location":"lessons/4-ComputerVision/08-TransferLearning/TrainingTricks/#initial-weight-initialization","title":"Initial Weight Initialization","text":"<p>Ideally, we want the values to be in the same range after passing through network layers. Thus it is important to initialize weights in such a way as to preserve the distribution of values.</p> <p>Normal distribution N(0,1) is not a good idea, because if we have n inputs, the standard deviation of output would be n, and values are likely to jump out of [0..1] interval.</p> <p>The following initializations are often used:</p> <ul> <li>Uniform distribution -- <code>uniform</code></li> <li>N(0,1/n) -- <code>gaussian</code></li> <li>N(0,1/\u221an_in) guarantees that for inputs with zero mean and standard deviation of 1 the same mean/standard deviation would remain</li> <li>N(0,\u221a2/(n_in+n_out)) -- so-called Xavier initialization (<code>glorot</code>), it helps to keep the signals in range during both forward and backward propagation</li> </ul>"},{"location":"lessons/4-ComputerVision/08-TransferLearning/TrainingTricks/#batch-normalization","title":"Batch Normalization","text":"<p>Even with proper weight initialization, weights can get arbitrary big or small during the training, and they will bring signals out of proper range. We can bring signals back by using one of normalization techniques. While there are several of them (Weight normalization, Layer Normalization), the most often used is Batch Normalization.</p> <p>The idea of batch normalization is to take into account all values across the minibatch, and perform normalization (i.e. subtract mean and divide by standard deviation) based on those values. It is implemented as a network layer that does this normalization after applying the weights, but before activation function. As a result, we are likely to see higher final accuracy and faster training.</p> <p>Here is the original paper on batch normalization, the explanation on Wikipedia, and a good introductory blog post (and the one in Russian).</p>"},{"location":"lessons/4-ComputerVision/08-TransferLearning/TrainingTricks/#dropout","title":"Dropout","text":"<p>Dropout is an interesting technique that removes a certain percentage of random neurons during training. It is also implemented as a layer with one parameter (percentage of neurons to remove, typically 10%-50%), and during training it zeroes random elements of the input vector, before passing it to the next layer.</p> <p>While this may sound like a strange idea, you can see the effect of dropout on training MNIST digit classifier in <code>Dropout.ipynb</code> notebook. It speeds up training and allows us to achieve higher accuracy in less training epochs.</p> <p>This effect can be explained in several ways:</p> <ul> <li>It can be considered to be a random shocking factor to the model, which takes optimiation out of local minimum</li> <li>It can be considered as implicit model averaging, because we can say that during dropout we are training slightly different model</li> </ul> <p>Some people say that when a drunk person tries to learn something, he will remember this better next morning, comparing to a sober person, because a brain with some malfunctioning neurons tries to adapt better to gasp the meaning. We never tested ourselves if this is true of not</p>"},{"location":"lessons/4-ComputerVision/08-TransferLearning/TrainingTricks/#preventing-overfitting","title":"Preventing overfitting","text":"<p>One of the very important aspect of deep learning is too be able to prevent overfitting. While it might be tempting to use very powerful neural network model, we should always balance the number of model parameters with the number of training samples.</p> <p>Make sure you understand the concept of overfitting we have introduced earlier!</p> <p>There are several ways to prevent overfitting:</p> <ul> <li>Early stopping -- continuously monitor error on validation set and stopping training when validation error starts to increase.</li> <li>Explicit Weight Decay / Regularization -- adding an extra penalty to the loss function for high absolute values of weights, which prevents the model of getting very unstable results</li> <li>Model Averaging -- training several models and then averaging the result. This helps to minimize the variance.</li> <li>Dropout (Implicit Model Averaging)</li> </ul>"},{"location":"lessons/4-ComputerVision/08-TransferLearning/TrainingTricks/#optimizers-training-algorithms","title":"Optimizers / Training Algorithms","text":"<p>Another important aspect of training is to chose good training algorithm. While classical gradient descent is a reasonable choice, it can sometimes be too slow, or result in other problems.</p> <p>In deep learning, we use Stochastic Gradient Descent (SGD), which is a gradient descent applied to minibatches, randomly selected from the training set. Weights are adjusted using this formula:</p> <p>w<sup>t+1</sup> = w<sup>t</sup> - \u03b7\u2207\u2112</p>"},{"location":"lessons/4-ComputerVision/08-TransferLearning/TrainingTricks/#momentum","title":"Momentum","text":"<p>In momentum SGD, we are keeping a portion of a gradient from previous steps. It is similar to when we are moving somewhere with inertia, and we receive a punch in a different direction, our trajectory does not change immediately, but keeps some part of the original movement. Here we introduce another vector v to represent the speed:</p> <ul> <li>v<sup>t+1</sup> = \u03b3 v<sup>t</sup> - \u03b7\u2207\u2112</li> <li>w<sup>t+1</sup> = w<sup>t</sup>+v<sup>t+1</sup></li> </ul> <p>Here parameter \u03b3 indicates the extent to which we take inertia into account: \u03b3=0 corresponds to classical SGD; \u03b3=1 is a pure motion equation.</p>"},{"location":"lessons/4-ComputerVision/08-TransferLearning/TrainingTricks/#adam-adagrad-etc","title":"Adam, Adagrad, etc.","text":"<p>Since in each layer we multiply signals by some matrix W<sub>i</sub>, depending on ||W<sub>i</sub>||, the gradient can either diminish and be close to 0, or rise indefinitely. It is the essence of Exploding/Vanishing Gradients problem.</p> <p>One of the solutions to this problem is to use only direction of the gradient in the equation, and ignore the absolute value, i.e.</p> <p>w<sup>t+1</sup> = w<sup>t</sup> - \u03b7(\u2207\u2112/||\u2207\u2112||), where ||\u2207\u2112|| = \u221a\u2211(\u2207\u2112)<sup>2</sup></p> <p>This algorithm is called Adagrad. Another algorithms that use the same idea: RMSProp, Adam</p> <p>Adam is considered to be a very efficient algorithm for many applications, so if you are not sure which one to use - use Adam.</p>"},{"location":"lessons/4-ComputerVision/08-TransferLearning/TrainingTricks/#gradient-clipping","title":"Gradient clipping","text":"<p>Gradient clipping is an extension the idea above. When the ||\u2207\u2112|| \u2264 \u03b8, we consider the original gradient in the weight optimization, and when ||\u2207\u2112|| &gt; \u03b8 - we divide the gradient by it's norm. Here \u03b8 is a parameter, in most cases we can take \u03b8=1 or \u03b8=10.</p>"},{"location":"lessons/4-ComputerVision/08-TransferLearning/TrainingTricks/#learning-rate-decay","title":"Learning rate decay","text":"<p>Training success often depends on the learning rate parameter \u03b7. It is logical to assume that larger values of \u03b7 result in faster training, which is something we typically want in the beginning of the training, and then smaller value of \u03b7 allow us to fine-tune the network. Thus, in most of the cases we want to decrease \u03b7 in the process of the training.</p> <p>This can be done by multiplying \u03b7 by some number (eg. 0.98) after each epoch of the training, or by using more complicated learning rate schedule.</p>"},{"location":"lessons/4-ComputerVision/08-TransferLearning/TrainingTricks/#different-network-architectures","title":"Different Network Architectures","text":"<p>Selecting right network architecture for your problem can be tricky. Normally, we would take an architecture that has proven to work for our specific task (or similar one). Here is a good overview or neural network architectures for computer vision.</p> <p>It is important to select an architecture that will be powerful enough for the number of training samples that we have. Selecting too powerful model can result in overfitting</p> <p>Another good way would be to use and architecture that will automatically adjust to the required complexity. To some extent, ResNet architecture and Inception are self-adjusting. More on computer vision architectures</p>"},{"location":"lessons/4-ComputerVision/08-TransferLearning/TrainingTricks_chs/","title":"\u6df1\u5ea6\u5b66\u4e60\u8bad\u7ec3\u6280\u5de7","text":"<p>\u968f\u7740\u795e\u7ecf\u7f51\u7edc\u53d8\u5f97\u8d8a\u6765\u8d8a\u6df1\uff0c\u5b83\u4eec\u7684\u8bad\u7ec3\u8fc7\u7a0b\u53d8\u5f97\u8d8a\u6765\u8d8a\u5177\u6709\u6311\u6218\u6027\u3002\u4e00\u4e2a\u4e3b\u8981\u95ee\u9898\u662f\u6240\u8c13\u7684\u68af\u5ea6\u6d88\u5931\u6216\u68af\u5ea6\u7206\u70b8\u3002\u8fd9\u7bc7\u6587\u7ae0\u5bf9\u8fd9\u4e9b\u95ee\u9898\u8fdb\u884c\u4e86\u5f88\u597d\u7684\u4ecb\u7ecd\u3002</p> <p>\u4e3a\u4e86\u63d0\u9ad8\u6df1\u5ea6\u7f51\u7edc\u8bad\u7ec3\u7684\u6548\u7387\uff0c\u6709\u51e0\u79cd\u6280\u5de7\u53ef\u4ee5\u4f7f\u7528\u3002</p>"},{"location":"lessons/4-ComputerVision/08-TransferLearning/TrainingTricks_chs/#_2","title":"\u4fdd\u6301\u503c\u5728\u5408\u7406\u533a\u95f4\u5185","text":"<p>\u4e3a\u4e86\u4f7f\u6570\u503c\u8ba1\u7b97\u66f4\u7a33\u5b9a\uff0c\u6211\u4eec\u5e0c\u671b\u786e\u4fdd\u795e\u7ecf\u7f51\u7edc\u4e2d\u7684\u6240\u6709\u503c\u5728\u5408\u7406\u7684\u8303\u56f4\u5185\uff0c\u901a\u5e38\u4e3a[-1..1]\u6216[0..1]\u3002\u8fd9\u4e0d\u662f\u4e00\u4e2a\u975e\u5e38\u4e25\u683c\u7684\u8981\u6c42\uff0c\u4f46\u6d6e\u70b9\u6570\u8ba1\u7b97\u7684\u6027\u8d28\u5982\u6b64\uff0c\u65e0\u6cd5\u51c6\u786e\u5730\u5904\u7406\u4e0d\u540c\u6570\u91cf\u7ea7\u7684\u503c\u3002\u4f8b\u5982\uff0c\u5982\u679c\u6211\u4eec\u52a0\u4e0a10<sup>-10</sup>\u548c10<sup>10</sup>\uff0c\u6211\u4eec\u53ef\u80fd\u4f1a\u5f97\u523010<sup>10</sup>\uff0c\u56e0\u4e3a\u8f83\u5c0f\u7684\u503c\u5c06\u88ab\u201c\u8f6c\u6362\u201d\u5230\u4e0e\u8f83\u5927\u7684\u503c\u76f8\u540c\u7684\u6570\u91cf\u7ea7\uff0c\u4ece\u800c\u5931\u53bb\u6709\u6548\u6570\u3002</p> <p>\u5927\u591a\u6570\u6fc0\u6d3b\u51fd\u6570\u5728[-1..1]\u9644\u8fd1\u90fd\u6709\u975e\u7ebf\u6027\uff0c\u56e0\u6b64\u5c06\u6240\u6709\u8f93\u5165\u6570\u636e\u7f29\u653e\u5230[-1..1]\u6216[0..1]\u533a\u95f4\u662f\u6709\u610f\u4e49\u7684\u3002</p>"},{"location":"lessons/4-ComputerVision/08-TransferLearning/TrainingTricks_chs/#_3","title":"\u521d\u59cb\u6743\u503c\u521d\u59cb\u5316","text":"<p>\u7406\u60f3\u60c5\u51b5\u662f\uff0c\u7ecf\u8fc7\u7f51\u7edc\u5c42\u540e\uff0c\u503c\u4fdd\u6301\u5728\u540c\u4e00\u8303\u56f4\u5185\u3002\u56e0\u6b64\uff0c\u91cd\u8981\u7684\u662f\u4ee5\u4fdd\u6301\u503c\u5206\u5e03\u7684\u65b9\u5f0f\u521d\u59cb\u5316\u6743\u91cd\u3002</p> <p>\u6b63\u6001\u5206\u5e03 N(0,1) \u4e0d\u662f\u4e00\u4e2a\u597d\u4e3b\u610f\uff0c\u56e0\u4e3a\u5982\u679c\u6211\u4eec\u6709 n \u4e2a\u8f93\u5165\uff0c\u8f93\u51fa\u7684\u6807\u51c6\u5dee\u5c06\u4e3a n\uff0c\u4ece\u800c\u5bfc\u81f4\u503c\u53ef\u80fd\u8df3\u51fa [0..1] \u533a\u95f4\u3002</p> <p>\u4ee5\u4e0b\u521d\u59cb\u5316\u65b9\u6cd5\u7ecf\u5e38\u4f7f\u7528\uff1a</p> <ul> <li>\u5747\u5300\u5206\u5e03 -- <code>uniform</code></li> <li>N(0,1/n) -- <code>gaussian</code></li> <li>N(0,1/\u221an_in) \u4fdd\u8bc1\u5bf9\u4e8e\u5747\u503c\u4e3a\u96f6\u3001\u6807\u51c6\u5dee\u4e3a1\u7684\u8f93\u5165\uff0c\u540c\u6837\u7684\u5747\u503c/\u6807\u51c6\u5dee\u4fdd\u6301\u4e0d\u53d8</li> <li>N(0,\u221a2/(n_in+n_out)) -- \u6240\u8c13\u7684 Xavier \u521d\u59cb\u5316 (<code>glorot</code>)\uff0c\u5b83\u6709\u52a9\u4e8e\u5728\u524d\u5411\u548c\u540e\u5411\u4f20\u64ad\u671f\u95f4\u4fdd\u6301\u4fe1\u53f7\u5728\u8303\u56f4\u5185</li> </ul>"},{"location":"lessons/4-ComputerVision/08-TransferLearning/TrainingTricks_chs/#_4","title":"\u6279\u91cf\u5f52\u4e00\u5316","text":"<p>\u5373\u4f7f\u6709\u4e86\u5408\u9002\u7684\u6743\u91cd\u521d\u59cb\u5316\uff0c\u6743\u91cd\u5728\u8bad\u7ec3\u8fc7\u7a0b\u4e2d\u4ecd\u53ef\u80fd\u53d8\u5f97\u4efb\u610f\u5927\u6216\u5c0f\uff0c\u8fd9\u5c06\u4f7f\u4fe1\u53f7\u8d85\u51fa\u9002\u5f53\u7684\u8303\u56f4\u3002\u901a\u8fc7\u4f7f\u7528\u4e00\u79cd\u5f52\u4e00\u5316\u6280\u672f\u53ef\u4ee5\u5c06\u4fe1\u53f7\u62c9\u56de\u5230\u5408\u9002\u7684\u8303\u56f4\u3002\u867d\u7136\u6709\u51e0\u79cd (\u6743\u91cd\u5f52\u4e00\u5316\u3001\u5c42\u5f52\u4e00\u5316)\uff0c\u4f46\u6700\u5e38\u7528\u7684\u662f\u6279\u91cf\u5f52\u4e00\u5316\u3002</p> <p>\u6279\u91cf\u5f52\u4e00\u5316 \u7684\u60f3\u6cd5\u662f\u8003\u8651\u5c0f\u6279\u91cf\u4e2d\u7684\u6240\u6709\u503c\uff0c\u5e76\u57fa\u4e8e\u8fd9\u4e9b\u503c\u6267\u884c\u5f52\u4e00\u5316\uff08\u5373\u51cf\u53bb\u5747\u503c\u5e76\u9664\u4ee5\u6807\u51c6\u5dee\uff09\u3002\u5b83\u5b9e\u73b0\u4e3a\u4e00\u4e2a\u7f51\u7edc\u5c42\uff0c\u5728\u5e94\u7528\u6743\u91cd\u4e4b\u540e\u3001\u6fc0\u6d3b\u51fd\u6570\u4e4b\u524d\u8fdb\u884c\u5f52\u4e00\u5316\u3002\u7ed3\u679c\u662f\uff0c\u6211\u4eec\u5f88\u53ef\u80fd\u4f1a\u770b\u5230\u66f4\u9ad8\u7684\u6700\u7ec8\u51c6\u786e\u6027\u548c\u66f4\u5feb\u7684\u8bad\u7ec3\u901f\u5ea6\u3002</p> <p>\u8fd9\u91cc\u662f\u5173\u4e8e\u6279\u91cf\u5f52\u4e00\u5316\u7684\u539f\u59cb\u8bba\u6587\uff0c\u7ef4\u57fa\u767e\u79d1\u7684\u89e3\u91ca\uff0c\u4ee5\u53ca\u4e00\u4e2a\u5f88\u597d\u7684\u4ecb\u7ecd\u6027\u535a\u5ba2\u6587\u7ae0\uff08\u8fd8\u6709\u4e00\u4e2a\u4fc4\u6587\u7248\uff09\u3002</p>"},{"location":"lessons/4-ComputerVision/08-TransferLearning/TrainingTricks_chs/#_5","title":"\u968f\u673a\u5931\u6d3b","text":"<p>\u968f\u673a\u5931\u6d3b \u662f\u4e00\u79cd\u6709\u8da3\u7684\u6280\u672f\uff0c\u5728\u8bad\u7ec3\u8fc7\u7a0b\u4e2d\u79fb\u9664\u4e00\u5b9a\u6bd4\u4f8b\u7684\u968f\u673a\u795e\u7ecf\u5143\u3002\u5b83\u4e5f\u5b9e\u73b0\u4e3a\u4e00\u4e2a\u5e26\u6709\u4e00\u4e2a\u53c2\u6570\uff08\u8981\u79fb\u9664\u7684\u795e\u7ecf\u5143\u7684\u767e\u5206\u6bd4\uff0c\u901a\u5e38\u4e3a10%-50%\uff09\u7684\u5c42\uff0c\u5728\u8bad\u7ec3\u671f\u95f4\u5b83\u4f1a\u5c06\u8f93\u5165\u5411\u91cf\u7684\u968f\u673a\u5143\u7d20\u7f6e\u4e3a\u96f6\uff0c\u7136\u540e\u4f20\u9012\u5230\u4e0b\u4e00\u5c42\u3002</p> <p>\u867d\u7136\u8fd9\u542c\u8d77\u6765\u50cf\u662f\u4e00\u4e2a\u5947\u602a\u7684\u4e3b\u610f\uff0c\u4f46\u4f60\u53ef\u4ee5\u5728 <code>Dropout.ipynb</code> \u7b14\u8bb0\u672c\u4e2d\u770b\u5230\u8fd9\u5bf9\u8bad\u7ec3 MNIST \u6570\u5b57\u5206\u7c7b\u5668\u7684\u6548\u679c\u3002\u5b83\u52a0\u5feb\u4e86\u8bad\u7ec3\u901f\u5ea6\uff0c\u5e76\u4f7f\u6211\u4eec\u80fd\u591f\u5728\u8f83\u5c11\u7684\u8bad\u7ec3\u5468\u671f\u5185\u8fbe\u5230\u66f4\u9ad8\u7684\u51c6\u786e\u6027\u3002</p> <p>\u8fd9\u79cd\u6548\u679c\u53ef\u4ee5\u901a\u8fc7\u51e0\u79cd\u65b9\u5f0f\u89e3\u91ca\uff1a</p> <ul> <li>\u8fd9\u53ef\u4ee5\u88ab\u89c6\u4e3a\u5bf9\u6a21\u578b\u7684\u968f\u673a\u51b2\u51fb\u56e0\u7d20\uff0c\u5c06\u4f18\u5316\u4ece\u5c40\u90e8\u6700\u5c0f\u503c\u4e2d\u5e26\u51fa\u3002</li> <li>\u8fd9\u53ef\u4ee5\u88ab\u89c6\u4e3a\u9690\u5f0f\u6a21\u578b\u5e73\u5747\uff0c\u56e0\u4e3a\u6211\u4eec\u53ef\u4ee5\u8bf4\u5728\u968f\u673a\u5931\u6d3b\u671f\u95f4\uff0c\u6211\u4eec\u5728\u8bad\u7ec3\u7565\u6709\u4e0d\u540c\u7684\u6a21\u578b\u3002</li> </ul> <p>\u6709\u4e9b\u4eba\u8bf4\uff0c\u5f53\u4e00\u4e2a\u9189\u9152\u7684\u4eba\u5c1d\u8bd5\u5b66\u4e60\u4e00\u4e9b\u4e1c\u897f\u65f6\uff0c\u4ed6\u4f1a\u5728\u7b2c\u4e8c\u5929\u65e9\u4e0a\u6bd4\u4e00\u4e2a\u6e05\u9192\u7684\u4eba\u8bb0\u5f97\u66f4\u597d\uff0c\u56e0\u4e3a\u8111\u4e2d\u7684\u4e00\u4e9b\u5931\u7075\u795e\u7ecf\u5143\u4f1a\u66f4\u597d\u5730\u9002\u5e94\u4ee5\u6293\u4f4f\u610f\u4e49\u3002\u6211\u4eec\u81ea\u5df1\u4ece\u672a\u6d4b\u8bd5\u8fc7\u8fd9\u662f\u5426\u5c5e\u5b9e</p>"},{"location":"lessons/4-ComputerVision/08-TransferLearning/TrainingTricks_chs/#_6","title":"\u9632\u6b62\u8fc7\u62df\u5408","text":"<p>\u6df1\u5ea6\u5b66\u4e60\u7684\u4e00\u4e2a\u975e\u5e38\u91cd\u8981\u7684\u65b9\u9762\u662f\u80fd\u591f\u9632\u6b62\u8fc7\u62df\u5408\u3002\u867d\u7136\u4f7f\u7528\u975e\u5e38\u5f3a\u5927\u7684\u795e\u7ecf\u7f51\u7edc\u6a21\u578b\u53ef\u80fd\u5f88\u8bf1\u4eba\uff0c\u4f46\u6211\u4eec\u5e94\u8be5\u59cb\u7ec8\u5728\u6a21\u578b\u53c2\u6570\u6570\u91cf\u548c\u8bad\u7ec3\u6837\u672c\u6570\u91cf\u4e4b\u95f4\u627e\u5230\u5e73\u8861\u3002</p> <p>\u786e\u4fdd\u4f60\u7406\u89e3\u6211\u4eec\u65e9\u5148\u4ecb\u7ecd\u7684\u8fc7\u62df\u5408\u6982\u5ff5\uff01</p> <p>\u6709\u51e0\u79cd\u9632\u6b62\u8fc7\u62df\u5408\u7684\u65b9\u6cd5\uff1a</p> <ul> <li>\u63d0\u524d\u505c\u6b62 -- \u8fde\u7eed\u76d1\u63a7\u9a8c\u8bc1\u96c6\u4e0a\u7684\u9519\u8bef\uff0c\u5e76\u5728\u9a8c\u8bc1\u9519\u8bef\u5f00\u59cb\u589e\u52a0\u65f6\u505c\u6b62\u8bad\u7ec3\u3002</li> <li>\u663e\u793a\u6743\u91cd\u8870\u51cf / \u6b63\u5219\u5316 -- \u4e3a\u6743\u503c\u7684\u9ad8\u7edd\u5bf9\u503c\u6dfb\u52a0\u989d\u5916\u7684\u60e9\u7f5a\u9879\uff0c\u9632\u6b62\u6a21\u578b\u5f97\u5230\u975e\u5e38\u4e0d\u7a33\u5b9a\u7684\u7ed3\u679c\u3002</li> <li>\u6a21\u578b\u5e73\u5747 -- \u8bad\u7ec3\u591a\u4e2a\u6a21\u578b\u7136\u540e\u5e73\u5747\u7ed3\u679c\uff0c\u8fd9\u6709\u52a9\u4e8e\u6700\u5c0f\u5316\u65b9\u5dee\u3002</li> <li>\u968f\u673a\u5931\u6d3b (\u9690\u5f0f\u6a21\u578b\u5e73\u5747)</li> </ul>"},{"location":"lessons/4-ComputerVision/08-TransferLearning/TrainingTricks_chs/#_7","title":"\u4f18\u5316\u5668 / \u8bad\u7ec3\u7b97\u6cd5","text":"<p>\u8bad\u7ec3\u7684\u53e6\u4e00\u4e2a\u91cd\u8981\u65b9\u9762\u662f\u9009\u62e9\u597d\u7684\u8bad\u7ec3\u7b97\u6cd5\u3002\u867d\u7136\u7ecf\u5178\u7684\u68af\u5ea6\u4e0b\u964d\u662f\u4e00\u4e2a\u5408\u7406\u7684\u9009\u62e9\uff0c\u4f46\u5b83\u6709\u65f6\u53ef\u80fd\u592a\u6162\uff0c\u6216\u8005\u5bfc\u81f4\u5176\u4ed6\u95ee\u9898\u3002</p> <p>\u5728\u6df1\u5ea6\u5b66\u4e60\u4e2d\uff0c\u6211\u4eec\u4f7f\u7528\u968f\u673a\u68af\u5ea6\u4e0b\u964d\uff08SGD\uff09\uff0c\u5b83\u662f\u5e94\u7528\u4e8e\u968f\u673a\u9009\u62e9\u7684\u5c0f\u6279\u91cf\u8bad\u7ec3\u96c6\u7684\u68af\u5ea6\u4e0b\u964d\u3002\u4f7f\u7528\u4ee5\u4e0b\u516c\u5f0f\u8c03\u6574\u6743\u91cd\uff1a</p> <p>w<sup>t+1</sup> = w<sup>t</sup> - \u03b7\u2207\u2112</p>"},{"location":"lessons/4-ComputerVision/08-TransferLearning/TrainingTricks_chs/#_8","title":"\u52a8\u91cf","text":"<p>\u5728\u52a8\u91cf SGD\u4e2d\uff0c\u6211\u4eec\u4fdd\u7559\u4e0a\u4e00\u6b65\u9aa4\u7684\u90e8\u5206\u68af\u5ea6\u3002\u8fd9\u7c7b\u4f3c\u4e8e\u6211\u4eec\u671d\u67d0\u4e2a\u65b9\u5411\u79fb\u52a8\u5e26\u6709\u60ef\u6027\u5e76\u5728\u53d7\u5230\u4e0d\u540c\u65b9\u5411\u7684\u51b2\u51fb\u65f6\uff0c\u6211\u4eec\u7684\u8f68\u8ff9\u4e0d\u4f1a\u7acb\u5373\u6539\u53d8\uff0c\u800c\u662f\u4fdd\u7559\u90e8\u5206\u539f\u59cb\u8fd0\u52a8\u3002\u8fd9\u91cc\u6211\u4eec\u5f15\u5165\u53e6\u4e00\u4e2a\u5411\u91cf v \u8868\u793a\u901f\u5ea6\uff1a</p> <ul> <li>v<sup>t+1</sup> = \u03b3 v<sup>t</sup> - \u03b7\u2207\u2112</li> <li>w<sup>t+1</sup> = w<sup>t</sup>+v<sup>t+1</sup></li> </ul> <p>\u53c2\u6570 \u03b3 \u8868\u793a\u6211\u4eec\u8003\u8651\u60ef\u6027\u7684\u7a0b\u5ea6\uff1a\u03b3=0 \u5bf9\u5e94\u7ecf\u5178 SGD\uff1b\u03b3=1 \u662f\u7eaf\u7cb9\u7684\u8fd0\u52a8\u65b9\u7a0b\u3002</p>"},{"location":"lessons/4-ComputerVision/08-TransferLearning/TrainingTricks_chs/#adamadagrad","title":"Adam\uff0cAdagrad \u7b49","text":"<p>\u7531\u4e8e\u5728\u6bcf\u4e00\u5c42\u4e2d\u6211\u4eec\u5c06\u4fe1\u53f7\u4e58\u4ee5\u67d0\u4e2a\u77e9\u9635 W<sub>i</sub>\uff0c\u6839\u636e ||W<sub>i</sub>||\uff0c\u68af\u5ea6\u8981\u4e48\u4f1a\u7f29\u5c0f\u63a5\u8fd1 0\uff0c\u8981\u4e48\u65e0\u9650\u4e0a\u5347\u3002\u8fd9\u5c31\u662f\u68af\u5ea6\u7206\u70b8/\u6d88\u5931\u95ee\u9898\u7684\u672c\u8d28\u3002</p> <p>\u89e3\u51b3\u8fd9\u4e2a\u95ee\u9898\u7684\u4e00\u4e2a\u65b9\u6cd5\u662f\u53ea\u5728\u65b9\u7a0b\u4e2d\u4f7f\u7528\u68af\u5ea6\u7684\u65b9\u5411\uff0c\u5e76\u5ffd\u7565\u7edd\u5bf9\u503c\uff0c\u5373</p> <p>w<sup>t+1</sup> = w<sup>t</sup> - \u03b7(\u2207\u2112/||\u2207\u2112||)\uff0c\u5176\u4e2d ||\u2207\u2112|| = \u221a\u2211(\u2207\u2112)<sup>2</sup></p> <p>\u8fd9\u4e2a\u7b97\u6cd5\u79f0\u4e3aAdagrad\u3002\u5176\u4ed6\u4f7f\u7528\u76f8\u540c\u601d\u8def\u7684\u7b97\u6cd5\uff1aRMSProp\u3001Adam</p> <p>Adam \u88ab\u8ba4\u4e3a\u662f\u8bb8\u591a\u5e94\u7528\u4e2d\u975e\u5e38\u6709\u6548\u7684\u7b97\u6cd5\uff0c\u6240\u4ee5\u5982\u679c\u4f60\u4e0d\u786e\u5b9a\u7528\u54ea\u4e2a - \u7528 Adam\u3002</p>"},{"location":"lessons/4-ComputerVision/08-TransferLearning/TrainingTricks_chs/#_9","title":"\u68af\u5ea6\u526a\u88c1","text":"<p>\u68af\u5ea6\u526a\u88c1\u662f\u4e0a\u9762\u601d\u60f3\u7684\u6269\u5c55\u3002\u5f53 ||\u2207\u2112|| \u2264 \u03b8 \u65f6\uff0c\u6211\u4eec\u5728\u6743\u91cd\u4f18\u5316\u4e2d\u8003\u8651\u539f\u59cb\u68af\u5ea6\uff1b\u5f53 ||\u2207\u2112|| &gt; \u03b8 \u65f6\uff0c\u6211\u4eec\u5c06\u68af\u5ea6\u9664\u4ee5\u5176\u8303\u6570\u3002\u8fd9\u91cc \u03b8 \u662f\u4e00\u4e2a\u53c2\u6570\uff0c\u5728\u5927\u591a\u6570\u60c5\u51b5\u4e0b\u6211\u4eec\u53ef\u4ee5\u53d6 \u03b8=1 \u6216 \u03b8=10\u3002</p>"},{"location":"lessons/4-ComputerVision/08-TransferLearning/TrainingTricks_chs/#_10","title":"\u5b66\u4e60\u7387\u8870\u51cf","text":"<p>\u8bad\u7ec3\u6210\u529f\u901a\u5e38\u53d6\u51b3\u4e8e\u5b66\u4e60\u7387\u53c2\u6570 \u03b7\u3002\u5408\u7406\u5730\u5047\u8bbe\u8f83\u5927\u7684 \u03b7 \u503c\u4f1a\u5bfc\u81f4\u66f4\u5feb\u7684\u8bad\u7ec3\uff0c\u8fd9\u662f\u6211\u4eec\u901a\u5e38\u5e0c\u671b\u5728\u8bad\u7ec3\u5f00\u59cb\u65f6\u53d1\u751f\u7684\uff0c\u7136\u540e\u8f83\u5c0f\u7684 \u03b7 \u503c\u5141\u8bb8\u6211\u4eec\u5fae\u8c03\u7f51\u7edc\u3002\u56e0\u6b64\uff0c\u5728\u5927\u591a\u6570\u60c5\u51b5\u4e0b\uff0c\u6211\u4eec\u5e0c\u671b\u5728\u8bad\u7ec3\u8fc7\u7a0b\u4e2d\u51cf\u5c11 \u03b7\u3002</p> <p>\u8fd9\u53ef\u4ee5\u901a\u8fc7\u5728\u6bcf\u4e2a\u8bad\u7ec3\u5468\u671f\u4e4b\u540e\u5c06 \u03b7 \u4e58\u4ee5\u67d0\u4e2a\u6570\uff08\u4f8b\u5982 0.98\uff09\u6765\u5b9e\u73b0\uff0c\u6216\u8005\u4f7f\u7528\u66f4\u590d\u6742\u7684\u5b66\u4e60\u7387\u8c03\u5ea6\u3002</p>"},{"location":"lessons/4-ComputerVision/08-TransferLearning/TrainingTricks_chs/#_11","title":"\u4e0d\u540c\u7684\u7f51\u7edc\u67b6\u6784","text":"<p>\u4e3a\u4f60\u7684\u95ee\u9898\u9009\u62e9\u5408\u9002\u7684\u7f51\u7edc\u67b6\u6784\u53ef\u80fd\u5f88\u68d8\u624b\u3002\u901a\u5e38\u7684\u505a\u6cd5\u662f\u9009\u62e9\u5df2\u88ab\u9a8c\u8bc1\u53ef\u4ee5\u7528\u4e8e\u7279\u5b9a\u4efb\u52a1\uff08\u6216\u7c7b\u4f3c\u4efb\u52a1\uff09\u7684\u67b6\u6784\u3002\u8fd9\u91cc\u6709\u4e00\u7bc7\u795e\u7ecf\u7f51\u7edc\u67b6\u6784\u7b80\u53f2\u7efc\u8ff0\uff0c\u9002\u7528\u4e8e\u8ba1\u7b97\u673a\u89c6\u89c9\u3002</p> <p>\u91cd\u8981\u7684\u662f\u9009\u62e9\u9002\u7528\u4e8e\u6211\u4eec\u62e5\u6709\u7684\u8bad\u7ec3\u6837\u672c\u6570\u91cf\u7684\u5f3a\u5927\u67b6\u6784\u3002\u9009\u62e9\u8fc7\u4e8e\u5f3a\u5927\u7684\u6a21\u578b\u53ef\u80fd\u5bfc\u81f4\u8fc7\u62df\u5408</p> <p>\u53e6\u4e00\u79cd\u597d\u7684\u65b9\u6cd5\u662f\u4f7f\u7528\u4e00\u79cd\u5c06\u81ea\u52a8\u8c03\u6574\u5230\u6240\u9700\u590d\u6742\u5ea6\u7684\u67b6\u6784\u3002ResNet \u548c Inception \u67b6\u6784\u5728\u67d0\u79cd\u7a0b\u5ea6\u4e0a\u662f\u81ea\u9002\u5e94\u7684\u3002\u66f4\u591a\u8ba1\u7b97\u673a\u89c6\u89c9\u67b6\u6784</p>"},{"location":"lessons/4-ComputerVision/08-TransferLearning/lab/","title":"Classification of Oxford Pets using Transfer Learning","text":"<p>Lab Assignment from AI for Beginners Curriculum.</p>"},{"location":"lessons/4-ComputerVision/08-TransferLearning/lab/#task","title":"Task","text":"<p>Imagine you need to develop and application for pet nursery to catalog all pets. One of the great features of such an application would be automatically discovering the breed from a photograph. In this assignment, we will use transfer learning to classify real-life pet images from Oxford-IIIT pets dataset.</p>"},{"location":"lessons/4-ComputerVision/08-TransferLearning/lab/#the-dataset","title":"The Dataset","text":"<p>We will use the original Oxford-IIIT pets dataset, which contains 35 different breeds of dogs and cats.</p> <p>To download the dataset, use this code snippet:</p> <pre><code>!wget https://www.robots.ox.ac.uk/~vgg/data/pets/data/images.tar.gz\n!tar xfz images.tar.gz\n!rm images.tar.gz\n</code></pre>"},{"location":"lessons/4-ComputerVision/08-TransferLearning/lab/#stating-notebook","title":"Stating Notebook","text":"<p>Start the lab by opening OxfordPets.ipynb</p>"},{"location":"lessons/4-ComputerVision/08-TransferLearning/lab/#takeaway","title":"Takeaway","text":"<p>Transfer learning and pre-trained networks allow us to solve real-world image classification problems relatively easily. However, pre-trained networks work well on images of similar kind, and if we start classifying very different images (eg. medical images), we are likely to get much worse results.</p>"},{"location":"lessons/4-ComputerVision/08-TransferLearning/lab/README_chs/","title":"\u4f7f\u7528\u8fc1\u79fb\u5b66\u4e60\u5bf9\u725b\u6d25\u5ba0\u7269\u8fdb\u884c\u5206\u7c7b","text":"<p>AI for Beginners Curriculum \u7684\u5b9e\u9a8c\u4f5c\u4e1a\u3002</p>"},{"location":"lessons/4-ComputerVision/08-TransferLearning/lab/README_chs/#_2","title":"\u4efb\u52a1","text":"<p>\u60f3\u8c61\u4f60\u9700\u8981\u5f00\u53d1\u4e00\u4e2a\u5ba0\u7269\u6258\u513f\u6240\u5e94\u7528\u7a0b\u5e8f\u6765\u4e3a\u6240\u6709\u5ba0\u7269\u8fdb\u884c\u5206\u7c7b\u3002\u8fd9\u6837\u7684\u5e94\u7528\u7a0b\u5e8f\u7684\u4e00\u4e2a\u91cd\u8981\u529f\u80fd\u5c06\u662f\u4ece\u7167\u7247\u4e2d\u81ea\u52a8\u8bc6\u522b\u5ba0\u7269\u7684\u54c1\u79cd\u3002\u5728\u6b64\u4f5c\u4e1a\u4e2d\uff0c\u6211\u4eec\u5c06\u4f7f\u7528\u8fc1\u79fb\u5b66\u4e60\u6765\u5bf9 Oxford-IIIT \u5ba0\u7269\u6570\u636e\u96c6\u4e2d\u7684\u771f\u5b9e\u5ba0\u7269\u56fe\u50cf\u8fdb\u884c\u5206\u7c7b\u3002</p>"},{"location":"lessons/4-ComputerVision/08-TransferLearning/lab/README_chs/#_3","title":"\u6570\u636e\u96c6","text":"<p>\u6211\u4eec\u5c06\u4f7f\u7528\u539f\u59cb\u7684 Oxford-IIIT \u5ba0\u7269\u6570\u636e\u96c6\uff0c\u8be5\u6570\u636e\u96c6\u4e2d\u5305\u542b35\u79cd\u4e0d\u540c\u54c1\u79cd\u7684\u72d7\u548c\u732b\u3002</p> <p>\u8981\u4e0b\u8f7d\u6570\u636e\u96c6\uff0c\u8bf7\u4f7f\u7528\u4ee5\u4e0b\u4ee3\u7801\u7247\u6bb5:</p> <pre><code>!wget https://www.robots.ox.ac.uk/~vgg/data/pets/data/images.tar.gz\n!tar xfz images.tar.gz\n!rm images.tar.gz\n</code></pre>"},{"location":"lessons/4-ComputerVision/08-TransferLearning/lab/README_chs/#_4","title":"\u542f\u52a8\u7b14\u8bb0\u672c","text":"<p>\u901a\u8fc7\u6253\u5f00 OxfordPets.ipynb \u6765\u542f\u52a8\u5b9e\u9a8c\u3002</p>"},{"location":"lessons/4-ComputerVision/08-TransferLearning/lab/README_chs/#_5","title":"\u6536\u83b7","text":"<p>\u8fc1\u79fb\u5b66\u4e60\u548c\u9884\u8bad\u7ec3\u7f51\u7edc\u4f7f\u6211\u4eec\u80fd\u591f\u76f8\u5bf9\u8f7b\u677e\u5730\u89e3\u51b3\u73b0\u5b9e\u4e16\u754c\u7684\u56fe\u50cf\u5206\u7c7b\u95ee\u9898\u3002\u7136\u800c\uff0c\u9884\u8bad\u7ec3\u7f51\u7edc\u5728\u5904\u7406\u76f8\u4f3c\u7c7b\u578b\u7684\u56fe\u50cf\u6548\u679c\u8f83\u597d\uff0c\u5982\u679c\u6211\u4eec\u5f00\u59cb\u5206\u7c7b\u5b8c\u5168\u4e0d\u540c\u7684\u56fe\u50cf\uff08\u4f8b\u5982\u533b\u7597\u56fe\u50cf\uff09\uff0c\u6211\u4eec\u53ef\u80fd\u4f1a\u5f97\u5230\u66f4\u5dee\u7684\u7ed3\u679c\u3002</p>"},{"location":"lessons/4-ComputerVision/09-Autoencoders/","title":"Autoencoders","text":"<p>When training CNNs, one of the problems is that we need a lot of labeled data. In the case of image classification, we need to separate images into different classes, which is a manual effort.</p>"},{"location":"lessons/4-ComputerVision/09-Autoencoders/#pre-lecture-quiz","title":"Pre-lecture quiz","text":"<p>However, we might want to use raw (unlabeled) data for training CNN feature extractors, which is called self-supervised learning. Instead of labels, we will use training images as both network input and output. The main idea of autoencoder is that we will have an encoder network that converts input image into some latent space (normally it is just a vector of some smaller size), then the decoder network, whose goal would be to reconstruct the original image.</p> <p>\u2705 An autoencoder is \"a type of artificial neural network used to learn efficient codings of unlabeled data.\"</p> <p>Since we are training an autoencoder to capture as much of the information from the original image as possible for accurate reconstruction, the network tries to find the best embedding of input images to capture the meaning.\u043b.</p> <p></p> <p>Image from Keras blog</p>"},{"location":"lessons/4-ComputerVision/09-Autoencoders/#scenarios-for-using-autoencoders","title":"Scenarios for using Autoencoders","text":"<p>While reconstructing original images does not seem useful in its own right, there are a few scenarios where autoencoders are especially useful:</p> <ul> <li>Lowering the dimension of images for visualization or training image embeddings. Usually autoencoders give better results than PCA, because it takes into account spatial nature of images and hierarchical features.</li> <li>Denoising, i.e. removing noise from the image. Because noise carries out a lot of useless information, autoencoder cannot fit it all into relatively small latent space, and thus it captures only important part of the image. When training denoisers, we start with original images, and use images with artificially added noise as input for autoencoder.</li> <li>Super-resolution, increasing image resolution. We start with high-resolution images, and use the image with lower resolution as the autoencoder input.</li> <li>Generative models. Once we train the autoencoder, the decoder part can be used to create new objects starting from random latent vectors.</li> </ul>"},{"location":"lessons/4-ComputerVision/09-Autoencoders/#variational-autoencoders-vae","title":"Variational Autoencoders (VAE)","text":"<p>Traditional autoencoders reduce the dimension of the input data somehow, figuring out the important features of input images. However, latent vectors ofter do not make much sense. In other words, taking MNIST dataset as an example, figuring out which digits correspond to different latent vectors is not an easy task, because close latent vectors would not necessarily correspond to the same digits.</p> <p>On the other hand, to train generative models it is better to have some understanding of the latent space. This idea leads us to variational auto-encoder (VAE).</p> <p>VAE is the autoencoder that learns to predict statistical distribution of the latent parameters, so-called latent distribution. For example, we may want latent vectors to be distributed normally with some mean z<sub>mean</sub> and standard deviation z<sub>sigma</sub> (both mean and standard deviation are vectors of some dimensionality d). Encoder in VAE learns to predict those parameters, and then decoder takes a random vector from this distribution to reconstruct the object.</p> <p>To summarize:</p> <ul> <li>From input vector, we predict <code>z_mean</code> and <code>z_log_sigma</code> (instead of predicting the standard deviation itself, we predict its logarithm)</li> <li>We sample a vector <code>sample</code> from the distribution N(z<sub>mean</sub>,exp(z<sub>log_sigma</sub>))</li> <li>The decoder tries to decode the original image using <code>sample</code> as an input vector</li> </ul> <p></p> <p>Image from this blog post by Isaak Dykeman</p> <p>Variational auto-encoders use a complex loss function that consists of two parts:</p> <ul> <li>Reconstruction loss is the loss function that shows how close a reconstructed image is to the target (it can be Mean Squared Error, or MSE). It is the same loss function as in normal autoencoders.</li> <li>KL loss, which ensures that latent variable distributions stays close to normal distribution. It is based on the notion of Kullback-Leibler divergence - a metric to estimate how similar two statistical distributions are.</li> </ul> <p>One important advantage of VAEs is that they allow us to generate new images relatively easily, because we know which distribution from which to sample latent vectors. For example, if we train VAE with 2D latent vector on MNIST, we can then vary components of the latent vector to get different digits:</p> <p></p> <p>Image by Dmitry Soshnikov</p> <p>Observe how images blend into each other, as we start getting latent vectors from the different portions of the latent parameter space. We can also visualize this space in 2D:</p> <p> </p> <p>Image by Dmitry Soshnikov</p>"},{"location":"lessons/4-ComputerVision/09-Autoencoders/#exercises-autoencoders","title":"\u270d\ufe0f Exercises: Autoencoders","text":"<p>Learn more about autoencoders in these corresponding notebooks:</p> <ul> <li>Autoencoders in TensorFlow</li> <li>Autoencoders in PyTorch</li> </ul>"},{"location":"lessons/4-ComputerVision/09-Autoencoders/#properties-of-autoencoders","title":"Properties of Autoencoders","text":"<ul> <li>Data Specific - they only work well with the type of images they have been trained on. For example, if we train a super-resolution network on flowers, it will not work well on portraits. This is because the network can produce higher resolution image by taking fine details from features learned from the training dataset.</li> <li>Lossy - the reconstructed image is not the same as the original image. The nature of loss is defined by the loss function used during training</li> <li>Works on unlabeled data</li> </ul>"},{"location":"lessons/4-ComputerVision/09-Autoencoders/#post-lecture-quiz","title":"Post-lecture quiz","text":""},{"location":"lessons/4-ComputerVision/09-Autoencoders/#conclusion","title":"Conclusion","text":"<p>In this lesson, you learned about the various types of autoencoders available to the AI scientist. You learned how to build them, and how to use them to reconstruct images. You also learned about the VAE and how to use it to generate new images.</p>"},{"location":"lessons/4-ComputerVision/09-Autoencoders/#challenge","title":"\ud83d\ude80 Challenge","text":"<p>In this lesson, you learned about using autoencoders for images. But they can also be used for music! Check out the Magenta project's MusicVAE project, which uses autoencoders to learn to reconstruct music. Do some experiments with this library to see what you can create.</p>"},{"location":"lessons/4-ComputerVision/09-Autoencoders/#post-lecture-quiz_1","title":"Post-lecture quiz","text":""},{"location":"lessons/4-ComputerVision/09-Autoencoders/#review-self-study","title":"Review &amp; Self Study","text":"<p>For reference, read more about autoencoders in these resources:</p> <ul> <li>Building Autoencoders in Keras</li> <li>Blog post on NeuroHive</li> <li>Variational Autoencoders Explained</li> <li>Conditional Variational Autoencoders</li> </ul>"},{"location":"lessons/4-ComputerVision/09-Autoencoders/#assignment","title":"Assignment","text":"<p>At the end of this notebook using TensorFlow, you will find a 'task' - use this as your assignment.</p>"},{"location":"lessons/4-ComputerVision/09-Autoencoders/README_chs/","title":"\u81ea\u52a8\u7f16\u7801\u5668","text":"<p>\u5728\u8bad\u7ec3 CNN \u65f6\uff0c\u5176\u4e2d\u4e00\u4e2a\u95ee\u9898\u662f\u6211\u4eec\u9700\u8981\u5927\u91cf\u6807\u8bb0\u6570\u636e\u3002\u5728\u56fe\u50cf\u5206\u7c7b\u7684\u60c5\u51b5\u4e0b\uff0c\u6211\u4eec\u9700\u8981\u5c06\u56fe\u50cf\u5206\u4e3a\u4e0d\u540c\u7684\u7c7b\u522b\uff0c\u8fd9\u9700\u8981\u624b\u52a8\u64cd\u4f5c\u3002</p>"},{"location":"lessons/4-ComputerVision/09-Autoencoders/README_chs/#_2","title":"\u8bfe\u524d\u6d4b\u9a8c","text":"<p>\u7136\u800c\uff0c\u6211\u4eec\u53ef\u80fd\u5e0c\u671b\u4f7f\u7528\u539f\u59cb\uff08\u672a\u6807\u8bb0\uff09\u6570\u636e\u6765\u8bad\u7ec3 CNN \u7279\u5f81\u63d0\u53d6\u5668\uff0c\u8fd9\u79f0\u4e3a\u81ea\u76d1\u7763\u5b66\u4e60\u3002\u6211\u4eec\u5c06\u4f7f\u7528\u8bad\u7ec3\u56fe\u50cf\u4f5c\u4e3a\u7f51\u7edc\u7684\u8f93\u5165\u548c\u8f93\u51fa\u3002\u81ea\u52a8\u7f16\u7801\u5668\u7684\u4e3b\u8981\u601d\u60f3\u662f\u6211\u4eec\u5c06\u6709\u4e00\u4e2a\u7f16\u7801\u5668\u7f51\u7edc\uff0c\u5c06\u8f93\u5165\u56fe\u50cf\u8f6c\u6362\u4e3a\u67d0\u79cd\u6f5c\u5728\u7a7a\u95f4\uff08\u901a\u5e38\u5b83\u53ea\u662f\u4e00\u4e2a\u8f83\u5c0f\u5c3a\u5bf8\u7684\u5411\u91cf\uff09\uff0c\u7136\u540e\u89e3\u7801\u5668\u7f51\u7edc\u7684\u76ee\u6807\u662f\u91cd\u5efa\u539f\u59cb\u56fe\u50cf\u3002</p> <p>\u2705 \u81ea\u52a8\u7f16\u7801\u5668 \u662f\u201c\u4e00\u79cd\u7528\u4e8e\u5b66\u4e60\u65e0\u6807\u7b7e\u6570\u636e\u7684\u6709\u6548\u7f16\u7801\u7684\u4eba\u5de5\u795e\u7ecf\u7f51\u7edc\u7c7b\u578b\u3002\u201d</p> <p>\u7531\u4e8e\u6211\u4eec\u8bad\u7ec3\u7684\u662f\u4e00\u4e2a\u81ea\u52a8\u7f16\u7801\u5668\u6765\u5c3d\u53ef\u80fd\u591a\u5730\u6355\u83b7\u539f\u59cb\u56fe\u50cf\u4e2d\u7684\u4fe1\u606f\uff0c\u4ee5\u5b9e\u73b0\u7cbe\u786e\u7684\u91cd\u5efa\uff0c\u7f51\u7edc\u5c1d\u8bd5\u627e\u5230\u8f93\u5165\u56fe\u50cf\u7684\u6700\u4f73\u5d4c\u5165\u6765\u6355\u83b7\u5176\u542b\u4e49\u3002</p> <p></p> <p>\u56fe\u7247\u6765\u81ea Keras \u535a\u5ba2</p>"},{"location":"lessons/4-ComputerVision/09-Autoencoders/README_chs/#_3","title":"\u4f7f\u7528\u81ea\u52a8\u7f16\u7801\u5668\u7684\u573a\u666f","text":"<p>\u5c3d\u7ba1\u91cd\u5efa\u539f\u59cb\u56fe\u50cf\u672c\u8eab\u770b\u8d77\u6765\u6ca1\u6709\u591a\u5927\u7528\u5904\uff0c\u4f46\u5728\u67d0\u4e9b\u60c5\u51b5\u4e0b\uff0c\u81ea\u52a8\u7f16\u7801\u5668\u7279\u522b\u6709\u7528\uff1a</p> <ul> <li>\u964d\u4f4e\u56fe\u50cf\u7684\u7ef4\u5ea6\u7528\u4e8e\u53ef\u89c6\u5316\u6216\u8bad\u7ec3\u56fe\u50cf\u5d4c\u5165\u3002\u901a\u5e38\u81ea\u52a8\u7f16\u7801\u5668\u6bd4 PCA \u7ed3\u679c\u66f4\u597d\uff0c\u56e0\u4e3a\u5b83\u8003\u8651\u4e86\u56fe\u50cf\u7684\u7a7a\u95f4\u6027\u8d28\u548c\u5c42\u6b21\u7279\u5f81\u3002</li> <li>\u53bb\u566a\uff0c\u5373\u53bb\u9664\u56fe\u50cf\u4e2d\u7684\u566a\u70b9\u3002\u56e0\u4e3a\u566a\u70b9\u643a\u5e26\u4e86\u5927\u91cf\u65e0\u7528\u4fe1\u606f\uff0c\u81ea\u52a8\u7f16\u7801\u5668\u65e0\u6cd5\u5c06\u5176\u5168\u90e8\u585e\u5165\u76f8\u5bf9\u8f83\u5c0f\u7684\u6f5c\u5728\u7a7a\u95f4\uff0c\u56e0\u6b64\u5b83\u53ea\u6355\u83b7\u56fe\u50cf\u7684\u91cd\u8981\u90e8\u5206\u3002\u5728\u8bad\u7ec3\u53bb\u566a\u5668\u65f6\uff0c\u6211\u4eec\u4ece\u539f\u59cb\u56fe\u50cf\u5f00\u59cb\uff0c\u5e76\u4f7f\u7528\u4eba\u5de5\u6dfb\u52a0\u566a\u70b9\u7684\u56fe\u50cf\u4f5c\u4e3a\u81ea\u52a8\u7f16\u7801\u5668\u7684\u8f93\u5165\u3002</li> <li>\u8d85\u5206\u8fa8\u7387\uff0c\u589e\u52a0\u56fe\u50cf\u5206\u8fa8\u7387\u3002\u6211\u4eec\u4ece\u9ad8\u5206\u8fa8\u7387\u56fe\u50cf\u5f00\u59cb\uff0c\u4f7f\u7528\u4f4e\u5206\u8fa8\u7387\u56fe\u50cf\u4f5c\u4e3a\u81ea\u52a8\u7f16\u7801\u5668\u7684\u8f93\u5165\u3002</li> <li>\u751f\u6210\u6a21\u578b\u3002\u4e00\u65e6\u6211\u4eec\u8bad\u7ec3\u4e86\u81ea\u52a8\u7f16\u7801\u5668\uff0c\u89e3\u7801\u5668\u90e8\u5206\u53ef\u4ee5\u7528\u4e8e\u4ece\u968f\u673a\u6f5c\u5728\u5411\u91cf\u5f00\u59cb\u521b\u5efa\u65b0\u5bf9\u8c61\u3002</li> </ul>"},{"location":"lessons/4-ComputerVision/09-Autoencoders/README_chs/#vae","title":"\u53d8\u5206\u81ea\u52a8\u7f16\u7801\u5668 (VAE)","text":"<p>\u4f20\u7edf\u7684\u81ea\u52a8\u7f16\u7801\u5668\u4ee5\u67d0\u79cd\u65b9\u5f0f\u964d\u4f4e\u8f93\u5165\u6570\u636e\u7684\u7ef4\u5ea6\uff0c\u627e\u51fa\u8f93\u5165\u56fe\u50cf\u7684\u91cd\u8981\u7279\u5f81\u3002\u7136\u800c\uff0c\u6f5c\u5728\u5411\u91cf\u5f80\u5f80\u6ca1\u6709\u591a\u5927\u610f\u4e49\u3002\u6362\u53e5\u8bdd\u8bf4\uff0c\u4ee5 MNIST \u6570\u636e\u96c6\u4e3a\u4f8b\uff0c\u5f04\u6e05\u695a\u54ea\u4e9b\u6570\u5b57\u5bf9\u5e94\u4e0d\u540c\u7684\u6f5c\u5728\u5411\u91cf\u5e76\u975e\u6613\u4e8b\uff0c\u56e0\u4e3a\u63a5\u8fd1\u7684\u6f5c\u5728\u5411\u91cf\u4e0d\u4e00\u5b9a\u5bf9\u5e94\u4e8e\u76f8\u540c\u7684\u6570\u5b57\u3002</p> <p>\u53e6\u4e00\u65b9\u9762\uff0c\u8981\u8bad\u7ec3\u751f\u6210\u6a21\u578b\uff0c\u4e86\u89e3\u6f5c\u5728\u7a7a\u95f4\u4f1a\u66f4\u6709\u5e2e\u52a9\u3002\u8fd9\u4e00\u60f3\u6cd5\u5f15\u5bfc\u6211\u4eec\u5230 \u53d8\u5206\u81ea\u52a8\u7f16\u7801\u5668 (VAE)\u3002</p> <p>VAE \u662f\u4e00\u79cd\u5b66\u4e60\u9884\u6d4b\u6f5c\u5728\u53c2\u6570\u7684\u7edf\u8ba1\u5206\u5e03\u7684\u81ea\u52a8\u7f16\u7801\u5668\uff0c\u5373\u6240\u8c13\u7684\u6f5c\u5728\u5206\u5e03\u3002\u4f8b\u5982\uff0c\u6211\u4eec\u53ef\u80fd\u5e0c\u671b\u6f5c\u5728\u5411\u91cf\u6309\u7167\u67d0\u79cd\u5747\u503c z<sub>mean</sub> \u548c\u6807\u51c6\u504f\u5dee z<sub>sigma</sub>\uff08\u5747\u503c\u548c\u6807\u51c6\u5dee\u90fd\u662f\u67d0\u4e2a\u7ef4\u5ea6 d \u7684\u5411\u91cf\uff09\u6b63\u5e38\u5206\u5e03\u3002VAE \u4e2d\u7684\u7f16\u7801\u5668\u5b66\u4e60\u9884\u6d4b\u8fd9\u4e9b\u53c2\u6570\uff0c\u7136\u540e\u89e3\u7801\u5668\u4ece\u8fd9\u4e2a\u5206\u5e03\u4e2d\u62bd\u53d6\u4e00\u4e2a\u968f\u673a\u5411\u91cf\u6765\u91cd\u5efa\u5bf9\u8c61\u3002</p> <p>\u603b\u7ed3\uff1a</p> <ul> <li>\u4ece\u8f93\u5165\u5411\u91cf\u4e2d\uff0c\u6211\u4eec\u9884\u6d4b <code>z_mean</code> \u548c <code>z_log_sigma</code>\uff08\u6211\u4eec\u9884\u6d4b\u5176\u5bf9\u6570\u800c\u4e0d\u662f\u6807\u51c6\u504f\u5dee\u672c\u8eab\uff09</li> <li>\u6211\u4eec\u4ece\u5206\u5e03 N(z<sub>mean</sub>,exp(z<sub>log_sigma</sub>)) \u4e2d\u62bd\u53d6\u4e00\u4e2a\u5411\u91cf <code>sample</code></li> <li>\u89e3\u7801\u5668\u5c1d\u8bd5\u4f7f\u7528 <code>sample</code> \u4f5c\u4e3a\u8f93\u5165\u5411\u91cf\u89e3\u7801\u539f\u59cb\u56fe\u50cf</li> </ul> <p></p> <p>\u56fe\u7247\u6765\u81ea \u8fd9\u4e2a\u535a\u5ba2\u5e16\u5b50 \u7531 Isaak Dykeman \u64b0\u5199</p> <p>\u53d8\u5206\u81ea\u52a8\u7f16\u7801\u5668\u4f7f\u7528\u4e00\u4e2a\u7531\u4e24\u4e2a\u90e8\u5206\u7ec4\u6210\u7684\u590d\u6742\u635f\u5931\u51fd\u6570\uff1a</p> <ul> <li>\u91cd\u5efa\u635f\u5931\u662f\u5c55\u793a\u91cd\u5efa\u56fe\u50cf\u4e0e\u76ee\u6807\u56fe\u50cf\u63a5\u8fd1\u7a0b\u5ea6\u7684\u635f\u5931\u51fd\u6570\uff08\u53ef\u4ee5\u662f\u5747\u65b9\u8bef\u5dee\uff0c\u6216 MSE\uff09\u3002\u5b83\u4e0e\u666e\u901a\u81ea\u52a8\u7f16\u7801\u5668\u4e2d\u7684\u635f\u5931\u51fd\u6570\u76f8\u540c\u3002</li> <li>KL \u635f\u5931\u786e\u4fdd\u6f5c\u5728\u53d8\u91cf\u5206\u5e03\u4fdd\u6301\u63a5\u8fd1\u6b63\u6001\u5206\u5e03\u3002\u5b83\u57fa\u4e8e Kullback-Leibler \u6563\u5ea6 \u6982\u5ff5 - \u4e00\u79cd\u4f30\u8ba1\u4e24\u4e2a\u7edf\u8ba1\u5206\u5e03\u76f8\u4f3c\u7a0b\u5ea6\u7684\u5ea6\u91cf\u3002</li> </ul> <p>VAE \u7684\u4e00\u4e2a\u91cd\u8981\u4f18\u70b9\u662f\u6211\u4eec\u53ef\u4ee5\u76f8\u5bf9\u8f7b\u677e\u5730\u751f\u6210\u65b0\u56fe\u50cf\uff0c\u56e0\u4e3a\u6211\u4eec\u77e5\u9053\u4ece\u4f55\u79cd\u5206\u5e03\u4e2d\u62bd\u53d6\u6f5c\u5728\u5411\u91cf\u3002\u4f8b\u5982\uff0c\u5982\u679c\u6211\u4eec\u5728 MNIST \u4e0a\u8bad\u7ec3\u5e26\u6709 2D \u6f5c\u5728\u5411\u91cf\u7684 VAE\uff0c\u6211\u4eec\u53ef\u4ee5\u968f\u7740\u6f5c\u5728\u5411\u91cf\u7ec4\u4ef6\u7684\u53d8\u5316\u5f97\u5230\u4e0d\u540c\u7684\u6570\u5b57\uff1a</p> <p></p> <p>\u56fe\u7247\u7531 Dmitry Soshnikov \u63d0\u4f9b</p> <p>\u89c2\u5bdf\u5982\u4f55\u56fe\u50cf\u76f8\u4e92\u878d\u5408\uff0c\u56e0\u4e3a\u6211\u4eec\u5f00\u59cb\u4ece\u6f5c\u5728\u53c2\u6570\u7a7a\u95f4\u7684\u4e0d\u540c\u90e8\u5206\u83b7\u53d6\u6f5c\u5728\u5411\u91cf\u3002\u6211\u4eec\u8fd8\u53ef\u4ee5\u5728 2D \u4e2d\u53ef\u89c6\u5316\u6b64\u7a7a\u95f4\uff1a</p> <p></p> <p>\u56fe\u7247\u7531 Dmitry Soshnikov \u63d0\u4f9b</p>"},{"location":"lessons/4-ComputerVision/09-Autoencoders/README_chs/#_4","title":"\u270d\ufe0f \u7ec3\u4e60\uff1a\u81ea\u52a8\u7f16\u7801\u5668","text":"<p>\u5728\u8fd9\u4e9b\u76f8\u5e94\u7684\u7b14\u8bb0\u672c\u4e2d\u4e86\u89e3\u66f4\u591a\u5173\u4e8e\u81ea\u52a8\u7f16\u7801\u5668\u7684\u77e5\u8bc6\uff1a</p> <ul> <li>TensorFlow \u4e2d\u7684\u81ea\u52a8\u7f16\u7801\u5668</li> <li>PyTorch \u4e2d\u7684\u81ea\u52a8\u7f16\u7801\u5668</li> </ul>"},{"location":"lessons/4-ComputerVision/09-Autoencoders/README_chs/#_5","title":"\u81ea\u52a8\u7f16\u7801\u5668\u7684\u5c5e\u6027","text":"<ul> <li>\u6570\u636e\u7279\u5b9a\u5316 - \u5b83\u4eec\u53ea\u80fd\u5f88\u597d\u5730\u5904\u7406\u8bad\u7ec3\u8fc7\u7684\u56fe\u50cf\u7c7b\u578b\u3002\u4f8b\u5982\uff0c\u5982\u679c\u6211\u4eec\u5728\u82b1\u5349\u4e0a\u8bad\u7ec3\u4e00\u4e2a\u8d85\u5206\u8fa8\u7387\u7f51\u7edc\uff0c\u5b83\u5728\u8096\u50cf\u4e0a\u6548\u679c\u4e0d\u4f1a\u5f88\u597d\u3002\u8fd9\u662f\u56e0\u4e3a\u7f51\u7edc\u53ef\u4ee5\u901a\u8fc7\u4ece\u8bad\u7ec3\u6570\u636e\u96c6\u4e2d\u5b66\u5f97\u7684\u7279\u5f81\u4e2d\u83b7\u53d6\u7ec6\u8282\u6765\u751f\u6210\u66f4\u9ad8\u5206\u8fa8\u7387\u7684\u56fe\u50cf\u3002</li> <li>\u6709\u635f - \u91cd\u5efa\u7684\u56fe\u50cf\u4e0e\u539f\u59cb\u56fe\u50cf\u4e0d\u540c\u3002\u635f\u5931\u7684\u6027\u8d28\u7531\u8bad\u7ec3\u8fc7\u7a0b\u4e2d\u4f7f\u7528\u7684\u635f\u5931\u51fd\u6570\u51b3\u5b9a</li> <li>\u9002\u7528\u4e8e \u65e0\u6807\u8bb0\u6570\u636e</li> </ul>"},{"location":"lessons/4-ComputerVision/09-Autoencoders/README_chs/#_6","title":"\u8bfe\u540e\u6d4b\u9a8c","text":""},{"location":"lessons/4-ComputerVision/09-Autoencoders/README_chs/#_7","title":"\u603b\u7ed3","text":"<p>\u5728\u672c\u8bfe\u4e2d\uff0c\u60a8\u4e86\u89e3\u4e86 AI \u79d1\u5b66\u5bb6\u53ef\u7528\u7684\u5404\u79cd\u7c7b\u578b\u7684\u81ea\u52a8\u7f16\u7801\u5668\u3002\u60a8\u5b66\u4e60\u4e86\u5982\u4f55\u6784\u5efa\u5b83\u4eec\uff0c\u5e76\u5982\u4f55\u4f7f\u7528\u5b83\u4eec\u91cd\u5efa\u56fe\u50cf\u3002\u60a8\u8fd8\u5b66\u4e60\u4e86 VAE \u4ee5\u53ca\u5982\u4f55\u4f7f\u7528\u5b83\u6765\u751f\u6210\u65b0\u56fe\u50cf\u3002</p>"},{"location":"lessons/4-ComputerVision/09-Autoencoders/README_chs/#_8","title":"\ud83d\ude80 \u6311\u6218","text":"<p>\u5728\u672c\u8bfe\u4e2d\uff0c\u60a8\u5b66\u4e60\u4e86\u5982\u4f55\u4f7f\u7528\u81ea\u52a8\u7f16\u7801\u5668\u5904\u7406\u56fe\u50cf\u3002\u4f46\u5b83\u4eec\u4e5f\u53ef\u4ee5\u7528\u4e8e\u97f3\u4e50\uff01\u67e5\u770b Magenta \u9879\u76ee\u7684 MusicVAE \u9879\u76ee\uff0c\u8be5\u9879\u76ee\u4f7f\u7528\u81ea\u52a8\u7f16\u7801\u5668\u5b66\u4e60\u91cd\u5efa\u97f3\u4e50\u3002\u4f7f\u7528\u6b64\u5e93\u8fdb\u884c\u4e00\u4e9b\u5b9e\u9a8c \u6765\u770b\u770b\u60a8\u80fd\u521b\u4f5c\u51fa\u4ec0\u4e48\u3002</p>"},{"location":"lessons/4-ComputerVision/09-Autoencoders/README_chs/#_9","title":"\u8bfe\u540e\u6d4b\u9a8c","text":""},{"location":"lessons/4-ComputerVision/09-Autoencoders/README_chs/#_10","title":"\u590d\u4e60\u4e0e\u81ea\u5b66","text":"<p>\u4f5c\u4e3a\u53c2\u8003\uff0c\u8bf7\u9605\u8bfb\u66f4\u591a\u5173\u4e8e\u81ea\u52a8\u7f16\u7801\u5668\u7684\u8d44\u6e90\uff1a</p> <ul> <li>\u5728 Keras \u4e2d\u6784\u5efa\u81ea\u52a8\u7f16\u7801\u5668</li> <li>NeuroHive \u4e0a\u7684\u535a\u5ba2\u6587\u7ae0</li> <li>\u53d8\u5206\u81ea\u52a8\u7f16\u7801\u5668\u8be6\u89e3</li> <li>\u6761\u4ef6\u53d8\u5206\u81ea\u52a8\u7f16\u7801\u5668</li> </ul>"},{"location":"lessons/4-ComputerVision/09-Autoencoders/README_chs/#_11","title":"\u4f5c\u4e1a","text":"<p>\u5728 \u6b64\u4f7f\u7528 TensorFlow \u7684\u7b14\u8bb0\u672c \u7684\u672b\u5c3e\uff0c\u60a8\u4f1a\u53d1\u73b0\u4e00\u4e2a\u201c\u4efb\u52a1\u201d - \u4f7f\u7528\u5b83\u4f5c\u4e3a\u60a8\u7684\u4f5c\u4e1a\u3002</p>"},{"location":"lessons/4-ComputerVision/10-GANs/","title":"Generative Adversarial Networks","text":"<p>In the previous section, we learned about generative models: models that can generate new images similar to the ones in the training dataset. VAE was a good example of a generative model.</p>"},{"location":"lessons/4-ComputerVision/10-GANs/#pre-lecture-quiz","title":"Pre-lecture quiz","text":"<p>However, if we try to generate something really meaningful, like a painting at reasonable resolution, with VAE, we will see that training does not converge well. For this use case, we should learn about another architecture specifically targeted at generative models - Generative Adversarial Networks, or GANs.</p> <p>The main idea of a GAN is to have two neural networks that will be trained against each other:</p> <p></p> <p>Image by Dmitry Soshnikov</p> <p>\u2705 A little vocabulary: * Generator is a network that takes some random vector, and produces the image as a result * Discriminator is a network that takes an image, and it should tell whether it is a real image (from training dataset), or it was generated by a generator. It is essentially an image classifier.</p>"},{"location":"lessons/4-ComputerVision/10-GANs/#discriminator","title":"Discriminator","text":"<p>The architecture of discriminator does not differ from an ordinary image classification network. In the simplest case it can be fully-connected classifier, but most probably it will be a convolutional network.</p> <p>\u2705 A GAN based on convolutional networks is called a DCGAN</p> <p>A CNN discriminator consists of the following layers: several convolutions+poolings (with decreasing spatial size) and, one-or-more fully-connected layers to get \"feature vector\", final binary classifier.</p> <p>\u2705 A 'pooling' in this context is a technique that reduces the size of the image. \"Pooling layers reduce the dimensions of data by combining the outputs of neuron clusters at one layer into a single neuron in the next layer.\" - source</p>"},{"location":"lessons/4-ComputerVision/10-GANs/#generator","title":"Generator","text":"<p>A Generator is slightly more tricky. You can consider it to be a reversed discriminator. Starting from a latent vector (in place of a feature vector), it has a fully-connected layer to convert it into the required size/shape, followed by deconvolutions+upscaling. This is similar to decoder part of autoencoder.</p> <p>\u2705 Because the convolution layer is implemented as a linear filter traversing the image, deconvolution is essentially similar to convolution, and can be implemented using the same layer logic.</p> <p></p> <p>Image by Dmitry Soshnikov</p>"},{"location":"lessons/4-ComputerVision/10-GANs/#training-the-gan","title":"Training the GAN","text":"<p>GANs are called adversarial because there is a constant competition between the generator and the discriminator. During this competition, both generator and discriminator improve, thus the network learns to produce better and better pictures.</p> <p>The training happens in two stages:</p> <ul> <li>Training the discriminator. This task is pretty straightforward: we generate a batch of images by the generator, labeling them 0, which stands for fake image, and taking a batch of images from the input dataset (with label 1, real image). We obtain some discriminator loss, and perform backprop.</li> <li>Training the generator. This is slightly more tricky, because we do not know the expected output for the generator directly. We take the whole GAN network consisting of a generator followed by discriminator, feed it with some random vectors, and expect the result to be 1 (corresponding to real images). We then freeze the parameters of the discriminator (we do not want it to be trained at this step), and perform the backprop.</li> </ul> <p>During this process, both the generator and the discriminator losses are not going down significantly. In the ideal situation, they should oscillate, corresponding to both networks improving their performance.</p>"},{"location":"lessons/4-ComputerVision/10-GANs/#exercises-gans","title":"\u270d\ufe0f Exercises: GANs","text":"<ul> <li>GAN Notebook in TensorFlow/Keras</li> <li>GAN Notebook in PyTorch</li> </ul>"},{"location":"lessons/4-ComputerVision/10-GANs/#problems-with-gan-training","title":"Problems with GAN training","text":"<p>GANs are known to be especially difficult to train. Here are a few problems:</p> <ul> <li>Mode Collapse. By this term we mean that the generator learns to produce one successful image that tricks the generator, and not a variety of different images.</li> <li>Sensitivity to hyperparameters. Often you can see that a GAN does not converge at all, and then suddenly decreases in the learning rate leading to convergence.</li> <li>Keeping a balance between the generator and the discriminator. In many cases discriminator loss can drop to zero relatively quickly, which results in the generator being unable to train further. To overcome this, we can try setting different learning rates for the generator and discriminator, or skip discriminator training if the loss is already too low.</li> <li>Training for high resolution. Reflecting the same problem as with autoencoders, this problem is triggered because reconstructing too many layers of convolutional network leads to artifacts. This problem is typically solved with so-called progressive growing, when first a few layers are trained on low-res images, and then layers are \"unblocked\" or added. Another solution would be adding extra connections between layers and training several resolutions at once - see this Multi-Scale Gradient GANs paper for details.</li> </ul>"},{"location":"lessons/4-ComputerVision/10-GANs/#style-transfer","title":"Style Transfer","text":"<p>GANs is a great way to generate artistic images. Another interesting technique is so-called style transfer, which takes one content image, and re-draws it in a different style, applying filters from style image. </p> <p>The way it works is the following: * We start with a random noise image (or with a content image, but for the sake of understanding it is easier to start from random noise) * Our goal would be to create such an image, that would be close to both content image and style image. This would be determined by two loss functions:    - Content loss is computed based on the features extracted by the CNN at some layers from current image and content image    - Style loss is computed between current image and style image in a clever way using Gram matrices (more details in the example notebook) * To make the image smoother and remove noise, we also introduce Variation loss, which computes average distance between neighboring pixels * The main optimization loop adjusts current image using gradient descent (or some other optimization algorithm) to minimize the total loss, which is a weighted sum of all three losses. </p>"},{"location":"lessons/4-ComputerVision/10-GANs/#example-style-transfer","title":"\u270d\ufe0f Example: Style Transfer","text":""},{"location":"lessons/4-ComputerVision/10-GANs/#post-lecture-quiz","title":"Post-lecture quiz","text":""},{"location":"lessons/4-ComputerVision/10-GANs/#conclusion","title":"Conclusion","text":"<p>In this lesson, you learned about GANS and how to train them. You also learned about the special challenges that this type of Neural Network can face, and some strategies on how to move past them.</p>"},{"location":"lessons/4-ComputerVision/10-GANs/#challenge","title":"\ud83d\ude80 Challenge","text":"<p>Run through the Style Transfer notebook using your own images.</p>"},{"location":"lessons/4-ComputerVision/10-GANs/#review-self-study","title":"Review &amp; Self Study","text":"<p>For reference, read more about GANs in these resources:</p> <ul> <li>Marco Pasini, 10 Lessons I Learned Training GANs for one Year</li> <li>StyleGAN, a de facto GAN architecture to consider</li> <li>Creating Generative Art using GANs on Azure ML</li> </ul>"},{"location":"lessons/4-ComputerVision/10-GANs/#assignment","title":"Assignment","text":"<p>Revisit one of the two notebooks associated to this lesson and retrain the GAN on your own images. What can you create?</p>"},{"location":"lessons/4-ComputerVision/10-GANs/README_chs/","title":"\u751f\u6210\u5bf9\u6297\u7f51\u7edc","text":"<p>\u5728\u524d\u4e00\u8282\u4e2d\uff0c\u6211\u4eec\u4e86\u89e3\u4e86\u751f\u6210\u6a21\u578b\uff1a\u53ef\u4ee5\u751f\u6210\u4e0e\u8bad\u7ec3\u6570\u636e\u96c6\u4e2d\u7684\u56fe\u50cf\u76f8\u4f3c\u7684\u65b0\u56fe\u50cf\u7684\u6a21\u578b\u3002VAE \u662f\u751f\u6210\u6a21\u578b\u7684\u4e00\u4e2a\u5f88\u597d\u7684\u4f8b\u5b50\u3002</p>"},{"location":"lessons/4-ComputerVision/10-GANs/README_chs/#_2","title":"\u8bfe\u7a0b\u524d\u6d4b\u9a8c","text":"<p>\u7136\u800c\uff0c\u5982\u679c\u6211\u4eec\u5c1d\u8bd5\u4f7f\u7528 VAE \u751f\u6210\u4e00\u4e9b\u771f\u6b63\u6709\u610f\u4e49\u7684\u4e1c\u897f\uff0c\u6bd4\u5982\u5408\u7406\u5206\u8fa8\u7387\u7684\u7ed8\u753b\uff0c\u6211\u4eec\u4f1a\u53d1\u73b0\u8bad\u7ec3\u5e76\u4e0d\u6536\u655b\u3002\u5bf9\u4e8e\u8fd9\u79cd\u60c5\u51b5\uff0c\u6211\u4eec\u9700\u8981\u5b66\u4e60\u53e6\u4e00\u79cd\u4e13\u95e8\u9488\u5bf9\u751f\u6210\u6a21\u578b\u7684\u67b6\u6784\u2014\u2014\u751f\u6210\u5bf9\u6297\u7f51\u7edc\uff08Generative Adversarial Networks, GANs\uff09\u3002</p> <p>GAN \u7684\u4e3b\u8981\u60f3\u6cd5\u662f\u8ba9\u4e24\u4e2a\u795e\u7ecf\u7f51\u7edc\u76f8\u4e92\u5bf9\u6297\u8fdb\u884c\u8bad\u7ec3\uff1a</p> <p></p> <p>\u56fe\u7247\u6765\u81ea Dmitry Soshnikov</p> <p>\u2705 \u4e00\u4e9b\u672f\u8bed\uff1a * \u751f\u6210\u5668\u662f\u4e00\u4e2a\u7f51\u7edc\uff0c\u5b83\u63a5\u53d7\u4e00\u4e9b\u968f\u673a\u5411\u91cf\uff0c\u5e76\u751f\u6210\u56fe\u50cf\u4f5c\u4e3a\u7ed3\u679c * \u5224\u522b\u5668\u662f\u4e00\u4e2a\u7f51\u7edc\uff0c\u53ef\u4ee5\u5224\u65ad\u8f93\u5165\u7684\u56fe\u50cf\u662f\u771f\u5b9e\u56fe\u50cf\uff08\u6765\u81ea\u8bad\u7ec3\u6570\u636e\u96c6\uff09\u8fd8\u662f\u751f\u6210\u5668\u751f\u6210\u7684\u56fe\u50cf\u3002\u5b83\u672c\u8d28\u4e0a\u662f\u4e00\u4e2a\u56fe\u50cf\u5206\u7c7b\u5668\u3002</p>"},{"location":"lessons/4-ComputerVision/10-GANs/README_chs/#_3","title":"\u5224\u522b\u5668","text":"<p>\u5224\u522b\u5668\u7684\u67b6\u6784\u4e0e\u666e\u901a\u7684\u56fe\u50cf\u5206\u7c7b\u7f51\u7edc\u6ca1\u6709\u533a\u522b\u3002\u5728\u6700\u7b80\u5355\u7684\u60c5\u51b5\u4e0b\uff0c\u5b83\u53ef\u4ee5\u662f\u4e00\u4e2a\u5168\u8fde\u63a5\u5206\u7c7b\u5668\uff0c\u4f46\u66f4\u53ef\u80fd\u7684\u662f\u4e00\u4e2a\u5377\u79ef\u7f51\u7edc\u3002</p> <p>\u2705 \u4e00\u4e2a\u57fa\u4e8e\u5377\u79ef\u7f51\u7edc\u7684 GAN \u88ab\u79f0\u4e3a DCGAN</p> <p>CNN \u5224\u522b\u5668\u7531\u4ee5\u4e0b\u5c42\u7ec4\u6210\uff1a\u51e0\u4e2a\u5377\u79ef+\u6c60\u5316\u5c42\uff08\u5177\u6709\u9012\u51cf\u7684\u7a7a\u95f4\u5c3a\u5bf8\uff09\uff0c\u548c\u4e00\u4e2a\u6216\u591a\u4e2a\u5168\u8fde\u63a5\u5c42\u6765\u83b7\u5f97\u201c\u7279\u5f81\u5411\u91cf\u201d\uff0c\u6700\u7ec8\u7684\u4e8c\u5206\u7c7b\u5668\u3002</p> <p>\u2705 \u5728\u6b64\u4e0a\u4e0b\u6587\u4e2d\u7684\u201c\u6c60\u5316\u201d\u662f\u4e00\u79cd\u51cf\u5c0f\u56fe\u50cf\u5927\u5c0f\u7684\u6280\u672f\u3002\u201c\u6c60\u5316\u5c42\u901a\u8fc7\u5c06\u67d0\u4e00\u5c42\u7684\u795e\u7ecf\u5143\u7c07\u8f93\u51fa\u7ec4\u5408\u6210\u4e0b\u4e00\u5c42\u4e2d\u7684\u4e00\u4e2a\u795e\u7ecf\u5143\uff0c\u6765\u51cf\u5c11\u6570\u636e\u7ef4\u5ea6\u3002\u201d - \u6765\u6e90</p>"},{"location":"lessons/4-ComputerVision/10-GANs/README_chs/#_4","title":"\u751f\u6210\u5668","text":"<p>\u751f\u6210\u5668\u7a0d\u5fae\u6709\u4e9b\u590d\u6742\u3002\u4f60\u53ef\u4ee5\u5c06\u5176\u89c6\u4e3a\u4e00\u4e2a\u53cd\u5411\u7684\u5224\u522b\u5668\u3002\u4ece\u6f5c\u5728\u5411\u91cf\uff08\u4ee3\u66ff\u7279\u5f81\u5411\u91cf\uff09\u5f00\u59cb\uff0c\u5b83\u5177\u6709\u4e00\u4e2a\u5168\u8fde\u63a5\u5c42\uff0c\u5c06\u5176\u8f6c\u6362\u4e3a\u6240\u9700\u7684\u5927\u5c0f/\u5f62\u72b6\uff0c\u968f\u540e\u662f\u53cd\u5377\u79ef+\u4e0a\u91c7\u6837\u3002\u8fd9\u7c7b\u4f3c\u4e8e\u81ea\u7f16\u7801\u5668\u7684\u89e3\u7801\u5668\u90e8\u5206\u3002</p> <p>\u2705 \u56e0\u4e3a\u5377\u79ef\u5c42\u4f5c\u4e3a\u904d\u5386\u56fe\u50cf\u7684\u7ebf\u6027\u6ee4\u6ce2\u5668\u88ab\u5b9e\u73b0\uff0c\u53cd\u5377\u79ef\u672c\u8d28\u4e0a\u7c7b\u4f3c\u4e8e\u5377\u79ef\uff0c\u53ef\u4ee5\u4f7f\u7528\u76f8\u540c\u7684\u5c42\u903b\u8f91\u6765\u5b9e\u73b0\u3002</p> <p></p> <p>\u56fe\u7247\u6765\u81ea Dmitry Soshnikov</p>"},{"location":"lessons/4-ComputerVision/10-GANs/README_chs/#gan","title":"\u8bad\u7ec3GAN","text":"<p>GAN \u88ab\u79f0\u4e3a\u5bf9\u6297\u6027\uff0c\u56e0\u4e3a\u751f\u6210\u5668\u548c\u5224\u522b\u5668\u4e4b\u95f4\u59cb\u7ec8\u5b58\u5728\u7ade\u4e89\u3002\u5728\u8fd9\u79cd\u7ade\u4e89\u4e2d\uff0c\u751f\u6210\u5668\u548c\u5224\u522b\u5668\u90fd\u5728\u4e0d\u65ad\u6539\u8fdb\uff0c\u4ece\u800c\u4f7f\u7f51\u7edc\u5b66\u4f1a\u751f\u6210\u8d8a\u6765\u8d8a\u597d\u7684\u56fe\u7247\u3002</p> <p>\u8bad\u7ec3\u5206\u4e3a\u4e24\u4e2a\u9636\u6bb5\uff1a</p> <ul> <li>\u8bad\u7ec3\u5224\u522b\u5668\u3002\u8fd9\u4e2a\u4efb\u52a1\u76f8\u5f53\u7b80\u5355\uff1a\u6211\u4eec\u7528\u751f\u6210\u5668\u751f\u6210\u4e00\u6279\u56fe\u50cf\uff0c\u6807\u8bb0\u4e3a 0\uff0c\u8868\u793a\u5047\u56fe\u50cf\uff0c\u518d\u4ece\u8f93\u5165\u6570\u636e\u96c6\u4e2d\u53d6\u4e00\u6279\u56fe\u50cf\uff08\u6807\u8bb0\u4e3a 1\uff0c\u771f\u5b9e\u56fe\u50cf\uff09\u3002\u6211\u4eec\u83b7\u5f97\u4e00\u4e9b\u5224\u522b\u5668\u635f\u5931\uff0c\u5e76\u8fdb\u884c\u53cd\u5411\u4f20\u64ad\u3002</li> <li>\u8bad\u7ec3\u751f\u6210\u5668\u3002\u8fd9\u7a0d\u5fae\u6709\u4e9b\u590d\u6742\uff0c\u56e0\u4e3a\u6211\u4eec\u4e0d\u77e5\u9053\u751f\u6210\u5668\u7684\u671f\u671b\u8f93\u51fa\u3002\u6211\u4eec\u53d6\u4e00\u4e2a\u7531\u751f\u6210\u5668\u540e\u8ddf\u5224\u522b\u5668\u7ec4\u6210\u7684\u6574\u4e2a GAN \u7f51\u7edc\uff0c\u7528\u4e00\u4e9b\u968f\u673a\u5411\u91cf\u5582\u7ed9\u5b83\uff0c\u5e76\u671f\u671b\u7ed3\u679c\u4e3a 1\uff08\u5bf9\u5e94\u4e8e\u771f\u5b9e\u56fe\u50cf\uff09\u3002\u7136\u540e\u6211\u4eec\u51bb\u7ed3\u5224\u522b\u5668\u7684\u53c2\u6570\uff08\u4e0d\u5e0c\u671b\u5728\u6b64\u6b65\u9aa4\u5bf9\u5176\u8fdb\u884c\u8bad\u7ec3\uff09\uff0c\u5e76\u8fdb\u884c\u53cd\u5411\u4f20\u64ad\u3002</li> </ul> <p>\u5728\u6b64\u8fc7\u7a0b\u4e2d\uff0c\u751f\u6210\u5668\u548c\u5224\u522b\u5668\u7684\u635f\u5931\u5e76\u4e0d\u4f1a\u663e\u8457\u4e0b\u964d\u3002\u5728\u7406\u60f3\u60c5\u51b5\u4e0b\uff0c\u5b83\u4eec\u5e94\u8be5\u632f\u8361\uff0c\u5bf9\u5e94\u4e8e\u4e24\u4e2a\u7f51\u7edc\u90fd\u5728\u63d0\u9ad8\u5176\u6027\u80fd\u3002</p>"},{"location":"lessons/4-ComputerVision/10-GANs/README_chs/#gans","title":"\u270d\ufe0f \u7ec3\u4e60\uff1aGANs","text":"<ul> <li>TensorFlow/Keras \u4e2d\u7684 GAN \u7b14\u8bb0\u672c</li> <li>PyTorch \u4e2d\u7684 GAN \u7b14\u8bb0\u672c</li> </ul>"},{"location":"lessons/4-ComputerVision/10-GANs/README_chs/#gan_1","title":"GAN\u8bad\u7ec3\u7684\u95ee\u9898","text":"<p>GANs \u7279\u522b\u96be\u4ee5\u8bad\u7ec3\u3002\u4ee5\u4e0b\u662f\u4e00\u4e9b\u95ee\u9898\uff1a</p> <ul> <li>\u6a21\u5f0f\u5d29\u6e83\u3002\u8fd9\u4e2a\u672f\u8bed\u6307\u7684\u662f\u751f\u6210\u5668\u5b66\u4f1a\u751f\u6210\u4e00\u79cd\u6210\u529f\u6b3a\u9a97\u5224\u522b\u5668\u7684\u56fe\u50cf\uff0c\u800c\u4e0d\u662f\u5404\u79cd\u4e0d\u540c\u7684\u56fe\u50cf\u3002</li> <li>\u5bf9\u8d85\u53c2\u6570\u7684\u654f\u611f\u6027\u3002\u4f60\u53ef\u80fd\u4f1a\u53d1\u73b0 GAN \u6839\u672c\u4e0d\u6536\u655b\uff0c\u7136\u540e\u7a81\u7136\u7531\u4e8e\u5b66\u4e60\u7387\u7684\u51cf\u5c11\u800c\u6536\u655b\u3002</li> <li>\u4fdd\u6301\u751f\u6210\u5668\u548c\u5224\u522b\u5668\u4e4b\u95f4\u7684\u5e73\u8861\u3002\u5728\u8bb8\u591a\u60c5\u51b5\u4e0b\uff0c\u5224\u522b\u5668\u7684\u635f\u5931\u53ef\u80fd\u4f1a\u76f8\u5bf9\u8f83\u5feb\u5730\u964d\u5230\u96f6\uff0c\u8fd9\u5bfc\u81f4\u751f\u6210\u5668\u65e0\u6cd5\u8fdb\u4e00\u6b65\u8bad\u7ec3\u3002\u4e3a\u4e86\u89e3\u51b3\u8fd9\u4e2a\u95ee\u9898\uff0c\u6211\u4eec\u53ef\u4ee5\u5c1d\u8bd5\u4e3a\u751f\u6210\u5668\u548c\u5224\u522b\u5668\u8bbe\u7f6e\u4e0d\u540c\u7684\u5b66\u4e60\u7387\uff0c\u6216\u8005\u5982\u679c\u635f\u5931\u5df2\u7ecf\u592a\u4f4e\u5219\u8df3\u8fc7\u5224\u522b\u5668\u8bad\u7ec3\u3002</li> <li>\u8bad\u7ec3\u9ad8\u5206\u8fa8\u7387\u3002\u4e0e\u81ea\u7f16\u7801\u5668\u6709\u76f8\u540c\u7684\u95ee\u9898\uff0c\u5f53\u91cd\u5efa\u5305\u542b\u592a\u591a\u5377\u79ef\u5c42\u7684\u7f51\u7edc\u4f1a\u5bfc\u81f4\u4f2a\u50cf\u3002\u8fd9\u4e2a\u95ee\u9898\u901a\u5e38\u901a\u8fc7\u6240\u8c13\u7684\u9010\u6b65\u751f\u957f\u6765\u89e3\u51b3\uff0c\u9996\u5148\u5728\u4f4e\u5206\u8fa8\u7387\u56fe\u50cf\u4e0a\u8bad\u7ec3\u51e0\u5c42\uff0c\u7136\u540e\u201c\u89e3\u9501\u201d\u6216\u6dfb\u52a0\u5c42\u3002\u53e6\u4e00\u79cd\u89e3\u51b3\u65b9\u6cd5\u662f\u589e\u52a0\u5c42\u4e4b\u95f4\u7684\u989d\u5916\u8fde\u63a5\u5e76\u540c\u65f6\u8bad\u7ec3\u591a\u4e2a\u5206\u8fa8\u7387\uff0c\u8be6\u89c1\u8fd9\u7bc7\u591a\u5c3a\u5ea6\u68af\u5ea6 GANs \u8bba\u6587\u3002</li> </ul>"},{"location":"lessons/4-ComputerVision/10-GANs/README_chs/#_5","title":"\u98ce\u683c\u8fc1\u79fb","text":"<p>GAN\u5bf9\u4e8e\u751f\u6210\u827a\u672f\u56fe\u50cf\u975e\u5e38\u6709\u6548\u3002\u53e6\u4e00\u79cd\u6709\u8da3\u7684\u6280\u672f\u662f\u6240\u8c13\u7684\u98ce\u683c\u8fc1\u79fb\uff0c\u5b83\u5c06\u4e00\u4e2a\u5185\u5bb9\u56fe\u50cf\u91cd\u65b0\u7ed8\u5236\u6210\u4e0d\u540c\u7684\u98ce\u683c\uff0c\u5e94\u7528\u4e8e\u98ce\u683c\u56fe\u50cf\u4e2d\u7684\u6ee4\u955c\u3002</p> <p>\u5b83\u7684\u5de5\u4f5c\u65b9\u5f0f\u5982\u4e0b\uff1a * \u6211\u4eec\u4ece\u4e00\u4e2a\u968f\u673a\u566a\u58f0\u56fe\u50cf\u5f00\u59cb\uff08\u6216\u8005\u4ece\u4e00\u4e2a\u5185\u5bb9\u56fe\u50cf\u5f00\u59cb\uff0c\u4f46\u4e3a\u4e86\u7406\u89e3\uff0c\u6211\u4eec\u66f4\u5bb9\u6613\u4ece\u968f\u673a\u566a\u58f0\u5f00\u59cb\uff09 * \u6211\u4eec\u7684\u76ee\u6807\u662f\u521b\u5efa\u4e00\u4e2a\u65e2\u63a5\u8fd1\u5185\u5bb9\u56fe\u50cf\u53c8\u63a5\u8fd1\u98ce\u683c\u56fe\u50cf\u7684\u56fe\u50cf\u3002\u8fd9\u901a\u8fc7\u4e24\u4e2a\u635f\u5931\u51fd\u6570\u6765\u786e\u5b9a\uff1a    - \u5185\u5bb9\u635f\u5931\u662f\u57fa\u4e8e CNN \u5728\u67d0\u4e9b\u5c42\u7ea7\u4ece\u5f53\u524d\u56fe\u50cf\u548c\u5185\u5bb9\u56fe\u50cf\u4e2d\u63d0\u53d6\u7684\u7279\u5f81\u6765\u8ba1\u7b97\u7684    - \u98ce\u683c\u635f\u5931\u5de7\u5999\u5730\u4f7f\u7528 Gram \u77e9\u9635\u5728\u5f53\u524d\u56fe\u50cf\u548c\u98ce\u683c\u56fe\u50cf\u4e4b\u95f4\u8ba1\u7b97\uff08\u66f4\u591a\u8be6\u60c5\u5728\u793a\u4f8b\u7b14\u8bb0\u672c\u4e2d\uff09 * \u4e3a\u4e86\u4f7f\u56fe\u50cf\u66f4\u5e73\u6ed1\u5e76\u6d88\u9664\u566a\u58f0\uff0c\u6211\u4eec\u8fd8\u5f15\u5165\u4e86\u53d8\u5206\u635f\u5931\uff0c\u5b83\u8ba1\u7b97\u90bb\u8fd1\u50cf\u7d20\u4e4b\u95f4\u7684\u5e73\u5747\u8ddd\u79bb * \u4e3b\u4f18\u5316\u5faa\u73af\u4f7f\u7528\u68af\u5ea6\u4e0b\u964d\uff08\u6216\u5176\u4ed6\u4e00\u4e9b\u4f18\u5316\u7b97\u6cd5\uff09\u8c03\u6574\u5f53\u524d\u56fe\u50cf\uff0c\u4ee5\u6700\u5c0f\u5316\u603b\u635f\u5931\uff0c\u603b\u635f\u5931\u662f\u6240\u6709\u4e09\u79cd\u635f\u5931\u7684\u52a0\u6743\u603b\u548c\u3002</p>"},{"location":"lessons/4-ComputerVision/10-GANs/README_chs/#_6","title":"\u270d\ufe0f \u793a\u4f8b\uff1a\u98ce\u683c\u8fc1\u79fb","text":""},{"location":"lessons/4-ComputerVision/10-GANs/README_chs/#_7","title":"\u8bfe\u7a0b\u540e\u6d4b\u9a8c","text":""},{"location":"lessons/4-ComputerVision/10-GANs/README_chs/#_8","title":"\u7ed3\u8bba","text":"<p>\u5728\u672c\u8bfe\u4e2d\uff0c\u4f60\u4e86\u89e3\u4e86 GAN \u53ca\u5176\u8bad\u7ec3\u65b9\u6cd5\u3002\u4f60\u8fd8\u4e86\u89e3\u4e86\u8fd9\u79cd\u7c7b\u578b\u7684\u795e\u7ecf\u7f51\u7edc\u53ef\u80fd\u9762\u4e34\u7684\u7279\u6b8a\u6311\u6218\uff0c\u4ee5\u53ca\u4e00\u4e9b\u5e94\u5bf9\u7b56\u7565\u3002</p>"},{"location":"lessons/4-ComputerVision/10-GANs/README_chs/#_9","title":"\ud83d\ude80 \u6311\u6218","text":"<p>\u4f7f\u7528\u4f60\u81ea\u5df1\u7684\u56fe\u50cf\u8fd0\u884c\u98ce\u683c\u8fc1\u79fb\u7b14\u8bb0\u672c\u3002</p>"},{"location":"lessons/4-ComputerVision/10-GANs/README_chs/#_10","title":"\u590d\u4e60\u4e0e\u81ea\u5b66","text":"<p>\u6709\u5173 GAN \u7684\u66f4\u591a\u53c2\u8003\uff0c\u8bf7\u9605\u8bfb\u4ee5\u4e0b\u8d44\u6e90\uff1a</p> <ul> <li>Marco Pasini\uff0c \u300a\u6211\u8bad\u7ec3 GAN \u4e00\u5e74\u4e2d\u5b66\u5230\u7684 10 \u4e2a\u6559\u8bad\u300b</li> <li>StyleGAN\uff0c\u4e00\u4e2a\u5b9e\u9645\u53ef\u8003\u8651\u7684 GAN \u67b6\u6784</li> <li>\u5728 Azure ML \u4e0a\u4f7f\u7528 GAN \u521b\u5efa\u751f\u6210\u827a\u672f</li> </ul>"},{"location":"lessons/4-ComputerVision/10-GANs/README_chs/#_11","title":"\u4f5c\u4e1a","text":"<p>\u91cd\u6e29\u4e0e\u672c\u8bfe\u76f8\u5173\u7684\u4e24\u4e2a\u7b14\u8bb0\u672c\u4e4b\u4e00\uff0c\u5e76\u5728\u4f60\u81ea\u5df1\u7684\u56fe\u50cf\u4e0a\u91cd\u65b0\u8bad\u7ec3 GAN\u3002\u4f60\u80fd\u521b\u9020\u4ec0\u4e48\uff1f</p>"},{"location":"lessons/4-ComputerVision/11-ObjectDetection/","title":"Object Detection","text":"<p>The image classification models we have dealt with so far took an image and produced a categorical result, such as the class 'number' in a MNIST problem. However, in many cases we do not want just to know that a picture portrays objects - we want to be able to determine their precise location. This is exactly the point of object detection.</p>"},{"location":"lessons/4-ComputerVision/11-ObjectDetection/#pre-lecture-quiz","title":"Pre-lecture quiz","text":"<p>Image from YOLO v2 web site</p>"},{"location":"lessons/4-ComputerVision/11-ObjectDetection/#a-naive-approach-to-object-detection","title":"A Naive Approach to Object Detection","text":"<p>Assuming we wanted to find a cat on a picture, a very naive approach to object detection would be the following:</p> <ol> <li>Break the picture down to a number of tiles</li> <li>Run image classification on each tile.</li> <li>Those tiles that result in sufficiently high activation can be considered to contain the object in question.</li> </ol> <p></p> <p>Image from Exercise Notebook</p> <p>However, this approach is far from ideal, because it only allows the algorithm to locate the object's bounding box very imprecisely. For more precise location, we need to run some sort of regression to predict the coordinates of bounding boxes - and for that, we need specific datasets.</p>"},{"location":"lessons/4-ComputerVision/11-ObjectDetection/#regression-for-object-detection","title":"Regression for Object Detection","text":"<p>This blog post has a great gentle introduction to detecting shapes.</p>"},{"location":"lessons/4-ComputerVision/11-ObjectDetection/#datasets-for-object-detection","title":"Datasets for Object Detection","text":"<p>You might run across the following datasets for this task:</p> <ul> <li>PASCAL VOC - 20 classes</li> <li>COCO - Common Objects in Context. 80 classes, bounding boxes and segmentation masks</li> </ul> <p></p>"},{"location":"lessons/4-ComputerVision/11-ObjectDetection/#object-detection-metrics","title":"Object Detection Metrics","text":""},{"location":"lessons/4-ComputerVision/11-ObjectDetection/#intersection-over-union","title":"Intersection over Union","text":"<p>While for image classification it is easy to measure how well the algorithm performs, for object detection we need to measure both the correctness of the class, as well as the precision of the inferred bounding box location. For the latter, we use the so-called Intersection over Union (IoU), which measures how well two boxes (or two arbitrary areas) overlap.</p> <p></p> <p>Figure 2 from this excellent blog post on IoU</p> <p>The idea is simple - we divide the area of intersection between two figures by the area of their union. For two identical areas, IoU would be 1, while for completely disjointed areas it will be 0. Otherwise it will vary from 0 to 1. We typically only consider those bounding boxes for which IoU is over a certain value.</p>"},{"location":"lessons/4-ComputerVision/11-ObjectDetection/#average-precision","title":"Average Precision","text":"<p>Suppose we want to measure how well a given class of objects $C$ is recognized. To measure it, we use Average Precision metrics, which is calculated as follows:</p> <ol> <li>Consider Precision-Recall curve shows the accuracy depending on a detection threshold value (from 0 to 1).</li> <li>Depending on the threshold, we will get more or less objects detected in the image, and different values of precision and recall.</li> <li>The curve will look like this:</li> </ol> <p></p> <p>Image from NeuroWorkshop</p> <p>The average Precision for a given class $C$ is the area under this curve. More precisely, Recall axis is typically divided into 10 parts, and Precision is averaged over all those points:</p> <p>$$ AP = {1\\over11}\\sum_{i=0}^{10}\\mbox{Precision}(\\mbox{Recall}={i\\over10}) $$</p>"},{"location":"lessons/4-ComputerVision/11-ObjectDetection/#ap-and-iou","title":"AP and IoU","text":"<p>We shall consider only those detections, for which IoU is above a certain value. For example, in PASCAL VOC dataset typically $\\mbox{IoU Threshold} = 0.5$ is assumed, while in COCO AP is measured for different values of $\\mbox{IoU Threshold}$.</p> <p></p> <p>Image from NeuroWorkshop</p>"},{"location":"lessons/4-ComputerVision/11-ObjectDetection/#mean-average-precision-map","title":"Mean Average Precision - mAP","text":"<p>The main metric for Object Detection is called Mean Average Precision, or mAP. It is the value of Average Precision, average across all object classes, and sometimes also over $\\mbox{IoU Threshold}$. In more detail, the process of calculating mAP is described in this blog post), and also here with code samples.</p>"},{"location":"lessons/4-ComputerVision/11-ObjectDetection/#different-object-detection-approaches","title":"Different Object Detection Approaches","text":"<p>There are two broad classes of object detection algorithms:</p> <ul> <li>Region Proposal Networks (R-CNN, Fast R-CNN, Faster R-CNN). The main idea is to generate Regions of Interests (ROI) and run CNN over them, looking for maximum activation. It is a bit similar to the naive approach, with the exception that ROIs are generated in a more clever way. One of the majors drawbacks of such methods is that they are slow, because we need many passes of the CNN classifier over the image.</li> <li>One-pass (YOLO, SSD, RetinaNet) methods. In those architectures we design the network to predict both classes and ROIs in one pass.</li> </ul>"},{"location":"lessons/4-ComputerVision/11-ObjectDetection/#r-cnn-region-based-cnn","title":"R-CNN: Region-Based CNN","text":"<p>R-CNN uses Selective Search to generate hierarchical structure of ROI regions, which are then passed through CNN feature extractors and SVM-classifiers to determine the object class, and linear regression to determine bounding box coordinates. Official Paper</p> <p></p> <p>Image from van de Sande et al. ICCV\u201911</p> <p></p> <p>*Images from this blog</p>"},{"location":"lessons/4-ComputerVision/11-ObjectDetection/#f-rcnn-fast-r-cnn","title":"F-RCNN - Fast R-CNN","text":"<p>This approach is similar to R-CNN, but regions are defined after convolution layers have been applied.</p> <p></p> <p>Image from the Official Paper, arXiv, 2015</p>"},{"location":"lessons/4-ComputerVision/11-ObjectDetection/#faster-r-cnn","title":"Faster R-CNN","text":"<p>The main idea of this approach is to use neural network to predict ROIs - so-called Region Proposal Network. Paper, 2016</p> <p></p> <p>Image from the official paper</p>"},{"location":"lessons/4-ComputerVision/11-ObjectDetection/#r-fcn-region-based-fully-convolutional-network","title":"R-FCN: Region-Based Fully Convolutional Network","text":"<p>This algorithm is even faster than Faster R-CNN. The main idea is the following:</p> <ol> <li>We extract features using ResNet-101</li> <li>Features are processed by Position-Sensitive Score Map. Each object from $C$ classes is divided by $k\\times k$ regions, and we are training to predict parts of objects.</li> <li>For each part from $k\\times k$ regions all networks vote for object classes, and the object class with maximum vote is selected.</li> </ol> <p></p> <p>Image from official paper</p>"},{"location":"lessons/4-ComputerVision/11-ObjectDetection/#yolo-you-only-look-once","title":"YOLO - You Only Look Once","text":"<p>YOLO is a realtime one-pass algorithm. The main idea is the following:</p> <ul> <li>Image is divided into $S\\times S$ regions</li> <li>For each region, CNN predicts $n$ possible objects, bounding box coordinates and confidence=probability * IoU.</li> </ul> <p></p> <p>Image from official paper</p>"},{"location":"lessons/4-ComputerVision/11-ObjectDetection/#other-algorithms","title":"Other Algorithms","text":"<ul> <li>RetinaNet: official paper</li> <li>PyTorch Implementation in Torchvision</li> <li>Keras Implementation</li> <li>Object Detection with RetinaNet in Keras Samples</li> <li>SSD (Single Shot Detector): official paper</li> </ul>"},{"location":"lessons/4-ComputerVision/11-ObjectDetection/#exercises-object-detection","title":"\u270d\ufe0f Exercises: Object Detection","text":"<p>Continue your learning in the following notebook:</p> <p>ObjectDetection.ipynb</p>"},{"location":"lessons/4-ComputerVision/11-ObjectDetection/#conclusion","title":"Conclusion","text":"<p>In this lesson you took a whirlwind tour of all the various ways that object detection can be accomplished!</p>"},{"location":"lessons/4-ComputerVision/11-ObjectDetection/#challenge","title":"\ud83d\ude80 Challenge","text":"<p>Read through these articles and notebooks about YOLO and try them for yourself</p> <ul> <li>Good blog post describing YOLO</li> <li>Official site</li> <li>Yolo: Keras implementation, step-by-step notebook</li> <li>Yolo v2: Keras implementation, step-by-step notebook</li> </ul>"},{"location":"lessons/4-ComputerVision/11-ObjectDetection/#post-lecture-quiz","title":"Post-lecture quiz","text":""},{"location":"lessons/4-ComputerVision/11-ObjectDetection/#review-self-study","title":"Review &amp; Self Study","text":"<ul> <li>Object Detection by Nikhil Sardana</li> <li>A good comparison of object detection algorithms</li> <li>Review of Deep Learning Algorithms for Object Detection</li> <li>A Step-by-Step Introduction to the Basic Object Detection Algorithms</li> <li>Implementation of Faster R-CNN in Python for Object Detection</li> </ul>"},{"location":"lessons/4-ComputerVision/11-ObjectDetection/#assignment-object-detection","title":"Assignment: Object Detection","text":""},{"location":"lessons/4-ComputerVision/11-ObjectDetection/README_chs/","title":"\u76ee\u6807\u68c0\u6d4b","text":"<p>\u5230\u76ee\u524d\u4e3a\u6b62\u6211\u4eec\u8ba8\u8bba\u7684\u56fe\u50cf\u5206\u7c7b\u6a21\u578b\u90fd\u662f\u5c06\u56fe\u50cf\u8f93\u5165\u5e76\u751f\u6210\u4e00\u4e2a\u5206\u7c7b\u7ed3\u679c\uff0c\u6bd4\u5982\u5728MNIST\u95ee\u9898\u4e2d\u7684\u7c7b\u522b\u201c\u6570\u5b57\u201d\u3002\u7136\u800c\uff0c\u5728\u8bb8\u591a\u60c5\u51b5\u4e0b\uff0c\u6211\u4eec\u4e0d\u4ec5\u5e0c\u671b\u77e5\u9053\u56fe\u7247\u4e2d\u6709\u7269\u4f53\uff0c\u8fd8\u5e0c\u671b\u80fd\u591f\u786e\u5b9a\u5b83\u4eec\u7684\u7cbe\u786e\u4f4d\u7f6e\u3002\u8fd9\u6b63\u662f\u76ee\u6807\u68c0\u6d4b\u7684\u76ee\u7684\u3002</p>"},{"location":"lessons/4-ComputerVision/11-ObjectDetection/README_chs/#_2","title":"\u8bfe\u524d\u6d4b\u9a8c","text":"<p>\u56fe\u7247\u6765\u81ea YOLO v2 \u5b98\u7f51</p>"},{"location":"lessons/4-ComputerVision/11-ObjectDetection/README_chs/#_3","title":"\u4e00\u4e2a\u7b80\u5355\u7684\u76ee\u6807\u68c0\u6d4b\u65b9\u6cd5","text":"<p>\u5047\u8bbe\u6211\u4eec\u60f3\u5728\u4e00\u5f20\u56fe\u7247\u4e2d\u627e\u5230\u4e00\u53ea\u732b\uff0c\u4e00\u4e2a\u975e\u5e38\u7b80\u5355\u7684\u76ee\u6807\u68c0\u6d4b\u65b9\u6cd5\u662f\uff1a</p> <ol> <li>\u5c06\u56fe\u7247\u5206\u89e3\u6210\u82e5\u5e72\u5c0f\u5757</li> <li>\u5728\u6bcf\u4e2a\u5c0f\u5757\u4e0a\u8fd0\u884c\u56fe\u50cf\u5206\u7c7b</li> <li>\u5bf9\u4e8e\u90a3\u4e9b\u83b7\u5f97\u8db3\u591f\u9ad8\u6fc0\u6d3b\u7684\u5c0f\u5757\uff0c\u53ef\u4ee5\u8ba4\u4e3a\u5305\u542b\u4e86\u6211\u4eec\u8981\u627e\u7684\u7269\u4f53</li> </ol> <p></p> <p>\u56fe\u7247\u6765\u81ea \u5b9e\u8df5\u7b14\u8bb0</p> <p>\u7136\u800c\uff0c\u8fd9\u79cd\u65b9\u6cd5\u8fdc\u975e\u7406\u60f3\uff0c\u56e0\u4e3a\u5b83\u53ea\u80fd\u975e\u5e38\u4e0d\u7cbe\u786e\u5730\u5b9a\u4f4d\u7269\u4f53\u7684\u8fb9\u754c\u6846\u3002\u4e3a\u4e86\u66f4\u7cbe\u786e\u5730\u5b9a\u4f4d\uff0c\u6211\u4eec\u9700\u8981\u8fd0\u884c\u67d0\u79cd\u56de\u5f52\u6765\u9884\u6d4b\u8fb9\u754c\u6846\u7684\u5750\u6807\u2014\u2014\u4e3a\u6b64\uff0c\u6211\u4eec\u9700\u8981\u7279\u5b9a\u7684\u6570\u636e\u96c6\u3002</p>"},{"location":"lessons/4-ComputerVision/11-ObjectDetection/README_chs/#_4","title":"\u7528\u56de\u5f52\u8fdb\u884c\u76ee\u6807\u68c0\u6d4b","text":"<p>\u8fd9\u7bc7\u535a\u5ba2\u5bf9\u68c0\u6d4b\u5f62\u72b6\u8fdb\u884c\u4e86\u5f88\u597d\u7684\u5165\u95e8\u4ecb\u7ecd\u3002</p>"},{"location":"lessons/4-ComputerVision/11-ObjectDetection/README_chs/#_5","title":"\u76ee\u6807\u68c0\u6d4b\u7684\u6570\u636e\u96c6","text":"<p>\u4f60\u53ef\u80fd\u4f1a\u9047\u5230\u4ee5\u4e0b\u7528\u4e8e\u6b64\u4efb\u52a1\u7684\u6570\u636e\u96c6\uff1a</p> <ul> <li>PASCAL VOC - 20\u4e2a\u7c7b\u522b</li> <li>COCO - \u5e38\u89c1\u7269\u4f53\u5728\u4e0a\u4e0b\u6587\u4e2d\u300280\u4e2a\u7c7b\u522b\uff0c\u5305\u62ec\u8fb9\u754c\u6846\u548c\u5206\u5272\u63a9\u7801</li> </ul> <p></p>"},{"location":"lessons/4-ComputerVision/11-ObjectDetection/README_chs/#_6","title":"\u76ee\u6807\u68c0\u6d4b\u7684\u5ea6\u91cf\u6807\u51c6","text":""},{"location":"lessons/4-ComputerVision/11-ObjectDetection/README_chs/#iou","title":"\u4ea4\u5e76\u6bd4\uff08IoU\uff09","text":"<p>\u56fe\u50cf\u5206\u7c7b\u5f88\u5bb9\u6613\u8861\u91cf\u7b97\u6cd5\u7684\u8868\u73b0\uff0c\u800c\u5bf9\u4e8e\u76ee\u6807\u68c0\u6d4b\uff0c\u6211\u4eec\u4e0d\u4ec5\u9700\u8981\u8861\u91cf\u7c7b\u522b\u7684\u6b63\u786e\u6027\uff0c\u8fd8\u9700\u8981\u8861\u91cf\u63a8\u65ad\u7684\u8fb9\u754c\u6846\u4f4d\u7f6e\u7684\u7cbe\u5ea6\u3002\u540e\u8005\u4f7f\u7528\u6240\u8c13\u7684\u4ea4\u5e76\u6bd4\uff08IoU\uff09\uff0c\u5373\u8861\u91cf\u4e24\u4e2a\u6846\uff08\u6216\u4efb\u610f\u4e24\u4e2a\u533a\u57df\uff09\u7684\u91cd\u53e0\u7a0b\u5ea6\u3002</p> <p></p> <p>\u56fe2\u6765\u81ea\u8fd9\u7bc7\u5173\u4e8eIoU\u7684\u4f18\u79c0\u535a\u5ba2\u6587\u7ae0</p> <p>\u5176\u601d\u60f3\u5f88\u7b80\u5355\u2014\u2014\u6211\u4eec\u5c06\u4e24\u4e2a\u56fe\u5f62\u4e4b\u95f4\u7684\u4ea4\u96c6\u9762\u79ef\u9664\u4ee5\u5b83\u4eec\u7684\u5e76\u96c6\u9762\u79ef\u3002\u5bf9\u4e8e\u4e24\u4e2a\u76f8\u540c\u7684\u533a\u57df\uff0cIoU\u4e3a1\uff0c\u800c\u5bf9\u4e8e\u5b8c\u5168\u4e0d\u76f8\u4ea4\u7684\u533a\u57df\u5219\u4e3a0\u3002\u5426\u5219\u5b83\u4f1a\u57280\u52301\u4e4b\u95f4\u53d8\u5316\u3002\u6211\u4eec\u901a\u5e38\u4ec5\u8003\u8651\u90a3\u4e9bIoU\u8d85\u8fc7\u67d0\u4e2a\u503c\u7684\u8fb9\u754c\u6846\u3002</p>"},{"location":"lessons/4-ComputerVision/11-ObjectDetection/README_chs/#ap","title":"\u5e73\u5747\u7cbe\u5ea6\uff08AP\uff09","text":"<p>\u5047\u8bbe\u6211\u4eec\u60f3\u8861\u91cf\u67d0\u4e2a\u7ed9\u5b9a\u7c7b\u522b$C$\u7684\u7269\u4f53\u8bc6\u522b\u5f97\u6709\u591a\u597d\u3002\u4e3a\u6b64\uff0c\u6211\u4eec\u4f7f\u7528\u5e73\u5747\u7cbe\u5ea6\u6307\u6807\uff0c\u5176\u8ba1\u7b97\u65b9\u6cd5\u5982\u4e0b\uff1a</p> <ol> <li>\u8003\u8651\u663e\u793a\u68c0\u6d4b\u9608\u503c\uff08\u4ece0\u52301\uff09\u4e0a\u7cbe\u5ea6\u7684\u7cbe\u5ea6-\u53ec\u56de\u7387\u66f2\u7ebf</li> <li>\u6839\u636e\u9608\u503c\uff0c\u6211\u4eec\u5c06\u5728\u56fe\u50cf\u4e2d\u68c0\u6d4b\u5230\u66f4\u591a\u6216\u66f4\u5c11\u7684\u7269\u4f53\uff0c\u5e76\u5f97\u5230\u4e0d\u540c\u7684\u7cbe\u5ea6\u548c\u53ec\u56de\u7387\u503c\u3002</li> <li>\u66f2\u7ebf\u5c06\u5982\u4e0b\u56fe\u6240\u793a\uff1a</li> </ol> <p></p> <p>\u56fe\u7247\u6765\u81eaNeuroWorkshop</p> <p>\u7ed9\u5b9a\u7c7b\u522b$C$\u7684\u5e73\u5747\u7cbe\u5ea6\u662f\u8be5\u66f2\u7ebf\u4e0b\u7684\u9762\u79ef\u3002\u786e\u5207\u5730\u8bf4\uff0c\u53ec\u56de\u8f74\u901a\u5e38\u5206\u4e3a10\u90e8\u5206\uff0c\u5e76\u4e14\u5728\u6240\u6709\u8fd9\u4e9b\u70b9\u4e0a\u5e73\u5747\u7cbe\u5ea6\uff1a</p> <p>$$ AP = {1\\over11}\\sum_{i=0}^{10}\\mbox{Precision}(\\mbox{Recall}={i\\over10}) $$</p>"},{"location":"lessons/4-ComputerVision/11-ObjectDetection/README_chs/#ap-iou","title":"AP \u548c IoU","text":"<p>\u6211\u4eec\u53ea\u8003\u8651\u90a3\u4e9bIoU\u8d85\u8fc7\u67d0\u4e2a\u503c\u7684\u68c0\u6d4b\u3002\u4f8b\u5982\uff0c\u5728PASCAL VOC\u6570\u636e\u96c6\u4e2d\uff0c\u901a\u5e38\u5047\u8bbe$\\mbox{IoU Threshold} = 0.5$\uff0c\u800c\u5728COCO\u4e2d\uff0cAP\u662f\u9488\u5bf9\u4e0d\u540c\u7684$\\mbox{IoU Threshold}$\u503c\u6d4b\u91cf\u7684\u3002</p> <p></p> <p>\u56fe\u7247\u6765\u81eaNeuroWorkshop</p>"},{"location":"lessons/4-ComputerVision/11-ObjectDetection/README_chs/#-map","title":"\u5e73\u5747\u5e73\u5747\u7cbe\u5ea6 - mAP","text":"<p>\u76ee\u6807\u68c0\u6d4b\u7684\u4e3b\u8981\u6307\u6807\u79f0\u4e3a\u5e73\u5747\u5e73\u5747\u7cbe\u5ea6\uff0c\u6216mAP\u3002\u5b83\u662f\u6240\u6709\u7269\u4f53\u7c7b\u522b\u4e0a\u7684\u5e73\u5747\u7cbe\u5ea6\u503c\uff0c\u6709\u65f6\u4e5f\u5305\u62ec$\\mbox{IoU Threshold}$\u3002\u66f4\u8be6\u7ec6\u7684\u8ba1\u7b97mAP\u7684\u8fc7\u7a0b\u5728\u672c\u535a\u5ba2\u6587\u7ae0\u4e2d\u8fdb\u884c\u4e86\u63cf\u8ff0\uff0c\u5e76\u4e14\u5728\u8fd9\u91cc\u6709\u4ee3\u7801\u793a\u4f8b\u3002</p>"},{"location":"lessons/4-ComputerVision/11-ObjectDetection/README_chs/#_7","title":"\u4e0d\u540c\u7684\u76ee\u6807\u68c0\u6d4b\u65b9\u6cd5","text":"<p>\u76ee\u6807\u68c0\u6d4b\u7b97\u6cd5\u5927\u81f4\u53ef\u4ee5\u5206\u4e3a\u4e24\u5927\u7c7b\uff1a</p> <ul> <li>\u533a\u57df\u63d0\u8bae\u7f51\u7edc\uff08R-CNN, Fast R-CNN, Faster R-CNN\uff09\u3002\u4e3b\u8981\u601d\u60f3\u662f\u751f\u6210\u5174\u8da3\u533a\u57df\uff08ROI\uff09\u5e76\u5728\u5176\u4e0a\u8fd0\u884cCNN\uff0c\u5bfb\u627e\u6700\u5927\u6fc0\u6d3b\u3002\u8fd9\u6709\u70b9\u7c7b\u4f3c\u4e8e\u7b80\u5355\u65b9\u6cd5\uff0c\u533a\u522b\u5728\u4e8eROIs\u4ee5\u66f4\u5de7\u5999\u7684\u65b9\u5f0f\u751f\u6210\u3002\u8fd9\u79cd\u65b9\u6cd5\u7684\u4e3b\u8981\u7f3a\u70b9\u4e4b\u4e00\u662f\u901f\u5ea6\u6162\uff0c\u56e0\u4e3a\u6211\u4eec\u9700\u8981\u5bf9\u56fe\u7247\u8fdb\u884c\u591a\u6b21CNN\u5206\u7c7b\u5668\u7684\u4f20\u9012\u3002</li> <li>\u4e00\u901a\u9053\uff08YOLO, SSD, RetinaNet\uff09\u65b9\u6cd5\u3002\u5728\u8fd9\u4e9b\u67b6\u6784\u4e2d\uff0c\u6211\u4eec\u8bbe\u8ba1\u7f51\u7edc\u4ee5\u5728\u4e00\u6b21\u4f20\u9012\u4e2d\u9884\u6d4b\u7c7b\u522b\u548cROIs\u3002</li> </ul>"},{"location":"lessons/4-ComputerVision/11-ObjectDetection/README_chs/#r-cnn-cnn","title":"R-CNN: \u57fa\u4e8e\u533a\u57df\u7684CNN","text":"<p>R-CNN\u4f7f\u7528\u9009\u62e9\u6027\u641c\u7d22\u751f\u6210ROI\u533a\u57df\u7684\u5206\u5c42\u7ed3\u6784\uff0c\u7136\u540e\u901a\u8fc7CNN\u7279\u5f81\u63d0\u53d6\u5668\u548cSVM\u5206\u7c7b\u5668\u786e\u5b9a\u7269\u4f53\u7c7b\u522b\uff0c\u5e76\u901a\u8fc7\u7ebf\u6027\u56de\u5f52\u786e\u5b9a\u8fb9\u754c\u6846\u5750\u6807\u3002\u5b98\u65b9\u8bba\u6587</p> <p></p> <p>\u56fe\u7247\u6765\u81eavan de Sande\u7b49\uff0cICCV\u201911</p> <p></p> <p>\u56fe\u7247\u6765\u81ea\u8fd9\u7bc7\u535a\u5ba2</p>"},{"location":"lessons/4-ComputerVision/11-ObjectDetection/README_chs/#f-rcnn-r-cnn","title":"F-RCNN - \u5feb\u901fR-CNN","text":"<p>\u8fd9\u79cd\u65b9\u6cd5\u7c7b\u4f3c\u4e8eR-CNN\uff0c\u4f46\u533a\u57df\u662f\u5728\u5377\u79ef\u5c42\u4e4b\u540e\u5b9a\u4e49\u7684\u3002</p> <p></p> <p>\u56fe\u7247\u6765\u81ea\u5b98\u65b9\u8bba\u6587\uff0carXiv\uff0c2015</p>"},{"location":"lessons/4-ComputerVision/11-ObjectDetection/README_chs/#r-cnn","title":"\u66f4\u5feb\u7684R-CNN","text":"<p>\u8fd9\u79cd\u65b9\u6cd5\u7684\u4e3b\u8981\u601d\u60f3\u662f\u4f7f\u7528\u795e\u7ecf\u7f51\u7edc\u9884\u6d4bROIs\u2014\u2014\u5373\u6240\u8c13\u7684\u533a\u57df\u63d0\u8bae\u7f51\u7edc\u3002\u8bba\u6587\uff0c2016</p> <p></p> <p>\u56fe\u7247\u6765\u81ea\u5b98\u65b9\u8bba\u6587</p>"},{"location":"lessons/4-ComputerVision/11-ObjectDetection/README_chs/#r-fcn","title":"R-FCN: \u57fa\u4e8e\u533a\u57df\u7684\u5168\u5377\u79ef\u7f51\u7edc","text":"<p>\u8be5\u7b97\u6cd5\u6bd4Faster R-CNN\u66f4\u5feb\u3002\u4e3b\u8981\u601d\u60f3\u5982\u4e0b\uff1a</p> <ol> <li>\u6211\u4eec\u4f7f\u7528ResNet-101\u63d0\u53d6\u7279\u5f81</li> <li>\u7279\u5f81\u7531\u4f4d\u7f6e\u654f\u611f\u5f97\u5206\u56fe\u5904\u7406\u3002\u6bcf\u4e2a$C$\u7c7b\u522b\u7684\u5bf9\u8c61\u5206\u4e3a$k\\times k$\u533a\u57df\uff0c\u6211\u4eec\u8bad\u7ec3\u9884\u6d4b\u5bf9\u8c61\u7684\u90e8\u5206\u3002</li> <li>\u5728$k\\times k$\u533a\u57df\u7684\u6bcf\u4e2a\u90e8\u5206\uff0c\u6240\u6709\u7f51\u7edc\u4e3a\u5bf9\u8c61\u7c7b\u522b\u6295\u7968\uff0c\u9009\u62e9\u6700\u9ad8\u7968\u6570\u7684\u5bf9\u8c61\u7c7b\u522b\u3002</li> </ol> <p></p> <p>\u56fe\u7247\u6765\u81ea\u5b98\u65b9\u8bba\u6587</p>"},{"location":"lessons/4-ComputerVision/11-ObjectDetection/README_chs/#yolo-","title":"YOLO - \u4f60\u53ea\u770b\u4e00\u6b21","text":"<p>YOLO\u662f\u4e00\u79cd\u5b9e\u65f6\u7684\u4e00\u901a\u9053\u7b97\u6cd5\u3002\u4e3b\u8981\u601d\u60f3\u5982\u4e0b\uff1a</p> <ul> <li>\u5c06\u56fe\u50cf\u5206\u4e3a$S\\times S$\u533a\u57df</li> <li>\u5bf9\u6bcf\u4e2a\u533a\u57df\uff0cCNN\u9884\u6d4b$n$\u4e2a\u53ef\u80fd\u5bf9\u8c61\uff0c\u8fb9\u754c\u6846\u5750\u6807\u548c\u7f6e\u4fe1\u5ea6=\u6982\u7387 * IoU\u3002</li> </ul> <p></p> <p>\u56fe\u7247\u6765\u81ea\u5b98\u65b9\u8bba\u6587</p>"},{"location":"lessons/4-ComputerVision/11-ObjectDetection/README_chs/#_8","title":"\u5176\u4ed6\u7b97\u6cd5","text":"<ul> <li>RetinaNet: \u5b98\u65b9\u8bba\u6587</li> <li>Torchvision\u4e2d\u7684PyTorch\u5b9e\u73b0</li> <li>Keras\u5b9e\u73b0</li> <li>Keras\u6837\u4f8b\u4e2d\u7684RetinaNet\u76ee\u6807\u68c0\u6d4b</li> <li>SSD (\u5355\u6b21\u68c0\u6d4b\u5668): \u5b98\u65b9\u8bba\u6587</li> </ul>"},{"location":"lessons/4-ComputerVision/11-ObjectDetection/README_chs/#_9","title":"\u270d\ufe0f \u7ec3\u4e60\uff1a\u76ee\u6807\u68c0\u6d4b","text":"<p>\u7ee7\u7eed\u5728\u4ee5\u4e0b\u7b14\u8bb0\u672c\u4e2d\u5b66\u4e60\uff1a</p> <p>ObjectDetection.ipynb</p>"},{"location":"lessons/4-ComputerVision/11-ObjectDetection/README_chs/#_10","title":"\u7ed3\u8bba","text":"<p>\u5728\u672c\u8bfe\u4e2d\uff0c\u4f60\u5feb\u901f\u6d4f\u89c8\u4e86\u5404\u79cd\u5b8c\u6210\u76ee\u6807\u68c0\u6d4b\u7684\u65b9\u6cd5\uff01</p>"},{"location":"lessons/4-ComputerVision/11-ObjectDetection/README_chs/#_11","title":"\ud83d\ude80 \u6311\u6218","text":"<p>\u9605\u8bfb\u8fd9\u4e9b\u5173\u4e8eYOLO\u7684\u6587\u7ae0\u548c\u7b14\u8bb0\u672c\uff0c\u5e76\u5c1d\u8bd5\u4e00\u4e0b\uff1a</p> <ul> <li>\u597d\u7684\u535a\u5ba2\u6587\u7ae0\u63cf\u8ff0YOLO</li> <li>\u5b98\u65b9\u7ad9\u70b9</li> <li>Yolo: Keras\u5b9e\u73b0\uff0c\u4e00\u6b65\u4e00\u6b65\u7684\u7b14\u8bb0\u672c</li> <li>Yolo v2: Keras\u5b9e\u73b0\uff0c\u4e00\u6b65\u4e00\u6b65\u7684\u7b14\u8bb0\u672c</li> </ul>"},{"location":"lessons/4-ComputerVision/11-ObjectDetection/README_chs/#_12","title":"\u8bfe\u540e\u6d4b\u9a8c","text":""},{"location":"lessons/4-ComputerVision/11-ObjectDetection/README_chs/#_13","title":"\u590d\u4e60\u4e0e\u81ea\u5b66","text":"<ul> <li>\u76ee\u6807\u68c0\u6d4b \u4f5c\u8005\u662fNikhil Sardana</li> <li>\u76ee\u6807\u68c0\u6d4b\u7b97\u6cd5\u7684\u4e00\u4e2a\u597d\u7684\u6bd4\u8f83</li> <li>\u6df1\u5ea6\u5b66\u4e60\u7b97\u6cd5\u76ee\u6807\u68c0\u6d4b\u56de\u987e</li> <li>\u57fa\u7840\u76ee\u6807\u68c0\u6d4b\u7b97\u6cd5\u7684\u9010\u6b65\u4ecb\u7ecd</li> <li>\u5728Python\u4e2d\u5b9e\u73b0Faster R-CNN\u8fdb\u884c\u76ee\u6807\u68c0\u6d4b</li> </ul>"},{"location":"lessons/4-ComputerVision/11-ObjectDetection/README_chs/#_14","title":"\u4f5c\u4e1a\uff1a\u76ee\u6807\u68c0\u6d4b","text":""},{"location":"lessons/4-ComputerVision/11-ObjectDetection/lab/","title":"Head Detection using Hollywood Heads Dataset","text":"<p>Lab Assignment from AI for Beginners Curriculum.</p>"},{"location":"lessons/4-ComputerVision/11-ObjectDetection/lab/#task","title":"Task","text":"<p>Counting number of people on video surveillance camera stream is an important task that will allow us to estimate the number of visitors in a shops, busy hours in a restaurant, etc. To solve this task, we need to be able to detect human heads from different angles. To train object detection model to detect human heads, we can use Hollywood Heads Dataset.</p>"},{"location":"lessons/4-ComputerVision/11-ObjectDetection/lab/#the-dataset","title":"The Dataset","text":"<p>Hollywood Heads Dataset contains 369,846 human heads annotated in 224,740 movie frames from Hollywood movies. It is provided in https://host.robots.ox.ac.uk/pascal/VOC/ format, where for each image there is also an XML description file that looks like this:</p> <pre><code>&lt;annotation&gt;\n    &lt;folder&gt;HollywoodHeads&lt;/folder&gt;\n    &lt;filename&gt;mov_021_149390.jpeg&lt;/filename&gt;\n    &lt;source&gt;\n        &lt;database&gt;HollywoodHeads 2015 Database&lt;/database&gt;\n        &lt;annotation&gt;HollywoodHeads 2015&lt;/annotation&gt;\n        &lt;image&gt;WILLOW&lt;/image&gt;\n    &lt;/source&gt;\n    &lt;size&gt;\n        &lt;width&gt;608&lt;/width&gt;\n        &lt;height&gt;320&lt;/height&gt;\n        &lt;depth&gt;3&lt;/depth&gt;\n    &lt;/size&gt;\n    &lt;segmented&gt;0&lt;/segmented&gt;\n    &lt;object&gt;\n        &lt;name&gt;head&lt;/name&gt;\n        &lt;bndbox&gt;\n            &lt;xmin&gt;201&lt;/xmin&gt;\n            &lt;ymin&gt;1&lt;/ymin&gt;\n            &lt;xmax&gt;480&lt;/xmax&gt;\n            &lt;ymax&gt;263&lt;/ymax&gt;\n        &lt;/bndbox&gt;\n        &lt;difficult&gt;0&lt;/difficult&gt;\n    &lt;/object&gt;\n    &lt;object&gt;\n        &lt;name&gt;head&lt;/name&gt;\n        &lt;bndbox&gt;\n            &lt;xmin&gt;3&lt;/xmin&gt;\n            &lt;ymin&gt;4&lt;/ymin&gt;\n            &lt;xmax&gt;241&lt;/xmax&gt;\n            &lt;ymax&gt;285&lt;/ymax&gt;\n        &lt;/bndbox&gt;\n        &lt;difficult&gt;0&lt;/difficult&gt;\n    &lt;/object&gt;\n&lt;/annotation&gt;\n</code></pre> <p>In this dataset, there is only one class of objects <code>head</code>, and for each head, you get the coordinates of the bounding box. You can parse XML using Python libraries, or use this library to deal directly with PASCAL VOC format.</p>"},{"location":"lessons/4-ComputerVision/11-ObjectDetection/lab/#training-object-detection","title":"Training Object Detection","text":"<p>You can train an object detection model using one of the following ways:</p> <ul> <li>Using Azure Custom Vision and it's Python API to programmatically train the model in the cloud. Custom vision will not be able to use more than a few hundred images for training the model, so you may need to limit the dataset.</li> <li>Using the example from Keras tutorial to train RetunaNet model.</li> <li>Using torchvision.models.detection.RetinaNet build-in module in torchvision.</li> </ul>"},{"location":"lessons/4-ComputerVision/11-ObjectDetection/lab/#takeaway","title":"Takeaway","text":"<p>Object detection is a task that is frequently required in industry. While there are some services that can be used to perform object detection (such as Azure Custom Vision), it is important to understand how object detection works and to be able to train your own models. </p>"},{"location":"lessons/4-ComputerVision/11-ObjectDetection/lab/README_chs/","title":"\u4f7f\u7528Hollywood Heads\u6570\u636e\u96c6\u8fdb\u884c\u5934\u90e8\u68c0\u6d4b","text":"<p>AI for Beginners Curriculum\u7684\u5b9e\u9a8c\u4f5c\u4e1a\u3002</p>"},{"location":"lessons/4-ComputerVision/11-ObjectDetection/lab/README_chs/#_1","title":"\u4efb\u52a1","text":"<p>\u5728\u89c6\u9891\u76d1\u63a7\u6444\u50cf\u673a\u6d41\u4e2d\u8ba1\u7b97\u4eba\u6570\u662f\u4e00\u4e2a\u91cd\u8981\u7684\u4efb\u52a1\uff0c\u5b83\u53ef\u4ee5\u5e2e\u52a9\u6211\u4eec\u4f30\u7b97\u5546\u5e97\u7684\u8bbf\u5ba2\u6570\u91cf\u3001\u9910\u9986\u7684\u7e41\u5fd9\u65f6\u95f4\u7b49\u3002\u8981\u89e3\u51b3\u8fd9\u4e2a\u4efb\u52a1\uff0c\u6211\u4eec\u9700\u8981\u80fd\u591f\u4ece\u4e0d\u540c\u89d2\u5ea6\u68c0\u6d4b\u4eba\u5934\u3002\u4e3a\u4e86\u8bad\u7ec3\u5bf9\u8c61\u68c0\u6d4b\u6a21\u578b\u6765\u68c0\u6d4b\u4eba\u5934\uff0c\u6211\u4eec\u53ef\u4ee5\u4f7f\u7528Hollywood Heads\u6570\u636e\u96c6\u3002</p>"},{"location":"lessons/4-ComputerVision/11-ObjectDetection/lab/README_chs/#_2","title":"\u6570\u636e\u96c6","text":"<p>Hollywood Heads\u6570\u636e\u96c6\u5305\u542b\u5728224,740\u5f20\u597d\u83b1\u575e\u7535\u5f71\u5e27\u4e2d\u7684369,846\u4e2a\u4eba\u5934\u3002\u5b83\u4ee5PASCAL VOC\u683c\u5f0f\u63d0\u4f9b\uff0c\u5bf9\u4e8e\u6bcf\u5f20\u56fe\u7247\u90fd\u6709\u4e00\u4e2aXML\u63cf\u8ff0\u6587\u4ef6\uff0c\u5982\u4e0b\u6240\u793a\uff1a</p> <pre><code>&lt;annotation&gt;\n    &lt;folder&gt;HollywoodHeads&lt;/folder&gt;\n    &lt;filename&gt;mov_021_149390.jpeg&lt;/filename&gt;\n    &lt;source&gt;\n        &lt;database&gt;HollywoodHeads 2015 Database&lt;/database&gt;\n        &lt;annotation&gt;HollywoodHeads 2015&lt;/annotation&gt;\n        &lt;image&gt;WILLOW&lt;/image&gt;\n    &lt;/source&gt;\n    &lt;size&gt;\n        &lt;width&gt;608&lt;/width&gt;\n        &lt;height&gt;320&lt;/height&gt;\n        &lt;depth&gt;3&lt;/depth&gt;\n    &lt;/size&gt;\n    &lt;segmented&gt;0&lt;/segmented&gt;\n    &lt;object&gt;\n        &lt;name&gt;head&lt;/name&gt;\n        &lt;bndbox&gt;\n            &lt;xmin&gt;201&lt;/xmin&gt;\n            &lt;ymin&gt;1&lt;/ymin&gt;\n            &lt;xmax&gt;480&lt;/xmax&gt;\n            &lt;ymax&gt;263&lt;/ymax&gt;\n        &lt;/bndbox&gt;\n        &lt;difficult&gt;0&lt;/difficult&gt;\n    &lt;/object&gt;\n    &lt;object&gt;\n        &lt;name&gt;head&lt;/name&gt;\n        &lt;bndbox&gt;\n            &lt;xmin&gt;3&lt;/xmin&gt;\n            &lt;ymin&gt;4&lt;/xmin&gt;\n            &lt;xmax&gt;241&lt;/xmax&gt;\n            &lt;ymax&gt;285&lt;/ymax&gt;\n        &lt;/bndbox&gt;\n        &lt;difficult&gt;0&lt;/difficult&gt;\n    &lt;/object&gt;\n&lt;/annotation&gt;\n</code></pre> <p>\u5728\u8fd9\u4e2a\u6570\u636e\u96c6\u4e2d\uff0c\u53ea\u6709\u4e00\u7c7b\u5bf9\u8c61<code>head</code>\uff0c\u5bf9\u4e8e\u6bcf\u4e00\u4e2a\u5934\u90e8\uff0c\u4f60\u5c06\u83b7\u5f97\u8fb9\u754c\u6846\u7684\u5750\u6807\u3002\u4f60\u53ef\u4ee5\u4f7f\u7528Python\u5e93\u89e3\u6790XML\uff0c\u6216\u8005\u4f7f\u7528\u8fd9\u4e2a\u5e93\u76f4\u63a5\u5904\u7406PASCAL VOC\u683c\u5f0f\u3002</p>"},{"location":"lessons/4-ComputerVision/11-ObjectDetection/lab/README_chs/#_3","title":"\u8bad\u7ec3\u5bf9\u8c61\u68c0\u6d4b","text":"<p>\u4f60\u53ef\u4ee5\u4f7f\u7528\u4ee5\u4e0b\u51e0\u79cd\u65b9\u5f0f\u6765\u8bad\u7ec3\u4e00\u4e2a\u5bf9\u8c61\u68c0\u6d4b\u6a21\u578b\uff1a</p> <ul> <li>\u4f7f\u7528Azure Custom Vision\u548c\u5b83\u7684Python API\u6765\u7f16\u7a0b\u5316\u5730\u5728\u4e91\u4e2d\u8bad\u7ec3\u6a21\u578b\u3002Custom Vision\u4e0d\u80fd\u4f7f\u7528\u8d85\u8fc7\u51e0\u767e\u5f20\u56fe\u50cf\u6765\u8bad\u7ec3\u6a21\u578b\uff0c\u6240\u4ee5\u4f60\u53ef\u80fd\u9700\u8981\u9650\u5236\u6570\u636e\u96c6\u3002</li> <li>\u4f7f\u7528Keras\u6559\u7a0b\u4e2d\u7684\u4f8b\u5b50\u6765\u8bad\u7ec3RetunaNet\u6a21\u578b\u3002</li> <li>\u4f7f\u7528torchvision.models.detection.RetinaNet\u4e2d\u5185\u7f6e\u7684\u6a21\u5757\u3002</li> </ul>"},{"location":"lessons/4-ComputerVision/11-ObjectDetection/lab/README_chs/#_4","title":"\u6536\u83b7","text":"<p>\u5bf9\u8c61\u68c0\u6d4b\u662f\u5de5\u4e1a\u4e2d\u9891\u7e41\u9700\u8981\u7684\u4efb\u52a1\u3002\u867d\u7136\u6709\u4e9b\u670d\u52a1\u53ef\u4ee5\u7528\u4e8e\u6267\u884c\u5bf9\u8c61\u68c0\u6d4b\uff08\u4f8b\u5982Azure Custom Vision\uff09\uff0c\u4e86\u89e3\u5bf9\u8c61\u68c0\u6d4b\u7684\u5de5\u4f5c\u539f\u7406\u5e76\u80fd\u591f\u8bad\u7ec3\u81ea\u5df1\u7684\u6a21\u578b\u662f\u5f88\u91cd\u8981\u7684\u3002</p>"},{"location":"lessons/4-ComputerVision/12-Segmentation/","title":"Segmentation","text":"<p>We have previously learned about Object Detection, which allows us to locate objects in the image by predicting their bounding boxes. However, for some tasks we do not only need bounding boxes, but also more precise object localization. This task is called  segmentation.</p>"},{"location":"lessons/4-ComputerVision/12-Segmentation/#pre-lecture-quiz","title":"Pre-lecture quiz","text":"<p>Segmentation can be viewed as pixel classification, whereas for each pixel of image we must predict its class (background being one of the classes). There are two main segmentation algorithms:</p> <ul> <li>Semantic segmentation only tells the pixel class, and does not make a distinction between different objects of the same class</li> <li>Instance segmentation divides classes into different instances.</li> </ul> <p>For instance segmentation, these sheep are different objects, but for semantic segmentation all sheep are represented by one class.</p> <p></p> <p>Image from this blog post</p> <p>There are different neural architectures for segmentation, but they all have the same structure. In a way, it is similar to the autoencoder you learned about previously, but instead of deconstructing the original image, our goal is to deconstruct a mask. Thus, a segmentation network has the following parts:</p> <ul> <li>Encoder extracts features from input image</li> <li>Decoder transforms those features into the mask image, with the same size and number of channels corresponding to the number of classes.</li> </ul> <p></p> <p>Image from this publication</p> <p>We should especially mention the loss function that is used for segmentation. When using classical autoencoders, we need to measure the similarity between two images, and we can use mean square error (MSE) to do that. In segmentation, each pixel in the target mask image represents the class number (one-hot-encoded along the third dimension), so we need to use loss functions specific for classification - cross-entropy loss, averaged over all pixels. If the mask is binary - binary cross-entropy loss (BCE) is used.</p> <p>\u2705 One-hot encoding is a way to encode a class label into a vector of length equal to the number of classes. Take a look at this article on this technique.</p>"},{"location":"lessons/4-ComputerVision/12-Segmentation/#segmentation-for-medical-imaging","title":"Segmentation for Medical Imaging","text":"<p>In this lesson, we will see the segmentation in action by training the network to recognize human nevi (also known as moles) on medical images. We will be using PH<sup>2</sup> Database of dermoscopy images as the image source. This dataset contains 200 images of three classes: typical nevus, atypical nevus, and melanoma. All images also contain a corresponding mask that outlines the nevus.</p> <p>\u2705 This technique is particularly appropriate for this type of medical imaging, but what other real-world applications could you envision?</p> <p></p> <p>Image from the PH<sup>2</sup> Database</p> <p>We will train a model to segment any nevus from its background.</p>"},{"location":"lessons/4-ComputerVision/12-Segmentation/#exercises-semantic-segmentation","title":"\u270d\ufe0f Exercises: Semantic Segmentation","text":"<p>Open the notebooks below to learn more about different semantic segmentation architectures, practice working with them, and see them in action.</p> <ul> <li>Semantic Segmentation Pytorch</li> <li>Semantic Segmentation TensorFlow</li> </ul>"},{"location":"lessons/4-ComputerVision/12-Segmentation/#post-lecture-quiz","title":"Post-lecture quiz","text":""},{"location":"lessons/4-ComputerVision/12-Segmentation/#conclusion","title":"Conclusion","text":"<p>Segmentation is a very powerful technique for image classification, moving beyond bounding boxes to pixel-level classification. It is a technique used in medical imaging, among other applications.</p>"},{"location":"lessons/4-ComputerVision/12-Segmentation/#challenge","title":"\ud83d\ude80 Challenge","text":"<p>Body segmentation is just one of the common tasks that we can do with images of people. Another important tasks include skeleton detection and pose detection. Try out OpenPose library to see how pose detection can be used.</p>"},{"location":"lessons/4-ComputerVision/12-Segmentation/#review-self-study","title":"Review &amp; Self Study","text":"<p>This wikipedia article offers a good overview of the various applications of this technique. Learn more on your own about the subdomains of Instance segmentation and Panoptic segmentation in this field of inquiry.</p>"},{"location":"lessons/4-ComputerVision/12-Segmentation/#assignment","title":"Assignment","text":"<p>In this lab, try human body segmentation using Segmentation Full Body MADS Dataset from Kaggle.</p>"},{"location":"lessons/4-ComputerVision/12-Segmentation/README_chs/","title":"\u5206\u5272","text":"<p>\u6211\u4eec\u4e4b\u524d\u5b66\u4e60\u4e86\u7269\u4f53\u68c0\u6d4b\uff0c\u5b83\u5141\u8bb8\u6211\u4eec\u901a\u8fc7\u9884\u6d4b\u5176\u8fb9\u754c\u6846\u6765\u5b9a\u4f4d\u56fe\u50cf\u4e2d\u7684\u7269\u4f53\u3002\u7136\u800c\uff0c\u5bf9\u4e8e\u67d0\u4e9b\u4efb\u52a1\uff0c\u6211\u4eec\u4e0d\u4ec5\u9700\u8981\u8fb9\u754c\u6846\uff0c\u8fd8\u9700\u8981\u66f4\u7cbe\u786e\u7684\u7269\u4f53\u5b9a\u4f4d\u3002\u8fd9\u9879\u4efb\u52a1\u88ab\u79f0\u4e3a\u5206\u5272\u3002</p>"},{"location":"lessons/4-ComputerVision/12-Segmentation/README_chs/#_2","title":"\u8bb2\u524d\u6d4b\u9a8c","text":"<p>\u5206\u5272\u53ef\u4ee5\u770b\u4f5c\u662f\u50cf\u7d20\u5206\u7c7b\uff0c\u5373\u5bf9\u4e8e\u56fe\u50cf\u7684\u6bcf\u4e2a\u50cf\u7d20\uff0c\u6211\u4eec\u5fc5\u987b\u9884\u6d4b\u5176\u7c7b\u522b\uff08\u80cc\u666f\u662f\u5176\u4e2d\u4e00\u4e2a\u7c7b\u522b\uff09\u3002\u4e3b\u8981\u6709\u4e24\u79cd\u5206\u5272\u7b97\u6cd5\uff1a</p> <ul> <li>\u8bed\u4e49\u5206\u5272 \u53ea\u544a\u8bc9\u50cf\u7d20\u7684\u7c7b\u522b\uff0c\u4e0d\u80fd\u533a\u5206\u540c\u4e00\u7c7b\u522b\u7684\u4e0d\u540c\u7269\u4f53</li> <li>\u5b9e\u4f8b\u5206\u5272 \u5c06\u7c7b\u522b\u5206\u6210\u4e0d\u540c\u7684\u5b9e\u4f8b\u3002</li> </ul> <p>\u5bf9\u4e8e\u5b9e\u4f8b\u5206\u5272\uff0c\u8fd9\u4e9b\u7ef5\u7f8a\u662f\u4e0d\u540c\u7684\u7269\u4f53\uff0c\u4f46\u5bf9\u4e8e\u8bed\u4e49\u5206\u5272\uff0c\u6240\u6709\u7ef5\u7f8a\u90fd\u4ee3\u8868\u4e00\u4e2a\u7c7b\u522b\u3002</p> <p></p> <p>\u56fe\u7247\u6765\u81ea\u8fd9\u7bc7\u535a\u5ba2</p> <p>\u6709\u591a\u79cd\u795e\u7ecf\u7ed3\u6784\u7528\u4e8e\u5206\u5272\uff0c\u4f46\u5b83\u4eec\u90fd\u5177\u6709\u76f8\u540c\u7684\u7ed3\u6784\u3002\u5728\u67d0\u79cd\u7a0b\u5ea6\u4e0a\uff0c\u5b83\u7c7b\u4f3c\u4e8e\u4f60\u4e4b\u524d\u5b66\u4e60\u8fc7\u7684\u81ea\u52a8\u7f16\u7801\u5668\uff0c\u4f46\u6211\u4eec\u7684\u76ee\u6807\u4e0d\u662f\u89e3\u6784\u539f\u59cb\u56fe\u50cf\uff0c\u800c\u662f\u89e3\u6784\u63a9\u7801\u3002\u56e0\u6b64\uff0c\u5206\u5272\u7f51\u7edc\u5177\u6709\u4ee5\u4e0b\u90e8\u5206\uff1a</p> <ul> <li>\u7f16\u7801\u5668 \u4ece\u8f93\u5165\u56fe\u50cf\u4e2d\u63d0\u53d6\u7279\u5f81</li> <li>\u89e3\u7801\u5668 \u5c06\u8fd9\u4e9b\u7279\u5f81\u8f6c\u6362\u4e3a\u5177\u6709\u76f8\u540c\u5927\u5c0f\u548c\u76f8\u5e94\u7c7b\u522b\u6570\u91cf\u7684\u63a9\u7801\u56fe\u50cf\u3002</li> </ul> <p></p> <p>\u56fe\u7247\u6765\u81ea\u8fd9\u7bc7\u51fa\u7248\u7269</p> <p>\u6211\u4eec\u5c24\u5176\u8981\u63d0\u5230\u7528\u4e8e\u5206\u5272\u7684\u635f\u5931\u51fd\u6570\u3002\u5728\u4f7f\u7528\u7ecf\u5178\u81ea\u52a8\u7f16\u7801\u5668\u65f6\uff0c\u6211\u4eec\u9700\u8981\u6d4b\u91cf\u4e24\u5e45\u56fe\u50cf\u4e4b\u95f4\u7684\u76f8\u4f3c\u6027\uff0c\u5e76\u53ef\u4ee5\u4f7f\u7528\u5747\u65b9\u8bef\u5dee(MSE)\u6765\u505a\u5230\u8fd9\u4e00\u70b9\u3002\u5728\u5206\u5272\u4e2d\uff0c\u76ee\u6807\u63a9\u7801\u56fe\u50cf\u4e2d\u7684\u6bcf\u4e2a\u50cf\u7d20\u8868\u793a\u7c7b\u53f7\uff08\u6cbf\u7b2c\u4e09\u7ef4\u5ea6\u5355\u70ed\u7f16\u7801\uff09\uff0c\u56e0\u6b64\u6211\u4eec\u9700\u8981\u4f7f\u7528\u7279\u5b9a\u4e8e\u5206\u7c7b\u7684\u635f\u5931\u51fd\u6570 - \u5e73\u5747\u4e8e\u6240\u6709\u50cf\u7d20\u7684\u4ea4\u53c9\u71b5\u635f\u5931\u3002\u5982\u679c\u63a9\u7801\u662f\u4e8c\u8fdb\u5236\u7684\uff0c\u5219\u4f7f\u7528 \u4e8c\u5143\u4ea4\u53c9\u71b5\u635f\u5931\uff08BCE\uff09\u3002</p> <p>\u2705 \u5355\u70ed\u7f16\u7801\u662f\u4e00\u79cd\u5c06\u7c7b\u522b\u6807\u7b7e\u7f16\u7801\u6210\u957f\u5ea6\u7b49\u4e8e\u7c7b\u522b\u6570\u7684\u5411\u91cf\u7684\u65b9\u6cd5\u3002\u53c2\u89c1\u672c\u6587\u4e86\u89e3\u8fd9\u79cd\u6280\u672f\u3002</p>"},{"location":"lessons/4-ComputerVision/12-Segmentation/README_chs/#_3","title":"\u533b\u5b66\u56fe\u50cf\u5206\u5272","text":"<p>\u5728\u8fd9\u8282\u8bfe\u4e2d\uff0c\u6211\u4eec\u5c06\u901a\u8fc7\u8bad\u7ec3\u7f51\u7edc\u8bc6\u522b\u533b\u5b66\u56fe\u50cf\u4e2d\u7684\u4eba\u7c7b\u75e3\uff08\u4e5f\u79f0\u4e3a\u75e3\uff09\u6765\u770b\u5230\u5206\u5272\u7684\u5b9e\u9645\u5e94\u7528\u3002\u6211\u4eec\u5c06\u4f7f\u7528\u6765\u81eaPH<sup>2</sup>\u6570\u636e\u5e93\u7684\u76ae\u80a4\u955c\u56fe\u50cf\u4f5c\u4e3a\u56fe\u50cf\u6765\u6e90\u3002\u8be5\u6570\u636e\u96c6\u5305\u542b\u5178\u578b\u75e3\u3001\u4e0d\u5178\u578b\u75e3\u548c\u9ed1\u8272\u7d20\u7624\u7684200\u5f20\u56fe\u50cf\u3002\u6240\u6709\u56fe\u50cf\u8fd8\u5305\u542b\u4e00\u4e2a\u5bf9\u5e94\u7684\u63a9\u7801\uff0c outlining \u75e3\u3002</p> <p>\u2705 \u8fd9\u79cd\u6280\u672f\u7279\u522b\u9002\u5408\u8fd9\u79cd\u7c7b\u578b\u7684\u533b\u5b66\u6210\u50cf\uff0c\u4f46\u4f60\u8fd8\u53ef\u4ee5\u60f3\u8c61\u5b83\u6709\u54ea\u4e9b\u5176\u4ed6\u7684\u5b9e\u9645\u5e94\u7528\uff1f</p> <p></p> <p>\u56fe\u7247\u6765\u81ea PH<sup>2</sup> \u6570\u636e\u5e93</p> <p>\u6211\u4eec\u5c06\u8bad\u7ec3\u4e00\u4e2a\u6a21\u578b\u6765\u5c06\u75e3\u4ece\u5176\u80cc\u666f\u4e2d\u5206\u5272\u51fa\u6765\u3002</p>"},{"location":"lessons/4-ComputerVision/12-Segmentation/README_chs/#_4","title":"\u270d\ufe0f \u7ec3\u4e60\uff1a\u8bed\u4e49\u5206\u5272","text":"<p>\u6253\u5f00\u4e0b\u9762\u7684\u7b14\u8bb0\u672c\uff0c\u4ee5\u4e86\u89e3\u66f4\u591a\u5173\u4e8e\u4e0d\u540c\u7684\u8bed\u4e49\u5206\u5272\u67b6\u6784\uff0c\u7ec3\u4e60\u4f7f\u7528\u5b83\u4eec\uff0c\u5e76\u89c2\u770b\u5b83\u4eec\u7684\u5b9e\u9645\u6548\u679c\u3002</p> <ul> <li>Semantic Segmentation Pytorch</li> <li>Semantic Segmentation TensorFlow</li> </ul>"},{"location":"lessons/4-ComputerVision/12-Segmentation/README_chs/#_5","title":"\u8bfe\u540e\u6d4b\u9a8c","text":""},{"location":"lessons/4-ComputerVision/12-Segmentation/README_chs/#_6","title":"\u7ed3\u8bba","text":"<p>\u5206\u5272\u662f\u4e00\u79cd\u975e\u5e38\u5f3a\u5927\u7684\u56fe\u50cf\u5206\u7c7b\u6280\u672f\uff0c\u8d85\u8d8a\u4e86\u8fb9\u754c\u6846\uff0c\u5b9e\u73b0\u5230\u50cf\u7d20\u7ea7\u522b\u7684\u5206\u7c7b\u3002\u5b83\u5728\u533b\u5b66\u6210\u50cf\u7b49\u5e94\u7528\u4e2d\u7684\u5e94\u7528\u975e\u5e38\u5e7f\u6cdb\u3002</p>"},{"location":"lessons/4-ComputerVision/12-Segmentation/README_chs/#_7","title":"\ud83d\ude80 \u6311\u6218","text":"<p>\u4eba\u4f53\u5206\u5272\u53ea\u662f\u6211\u4eec\u53ef\u4ee5\u4f7f\u7528\u4eba\u7269\u56fe\u50cf\u8fdb\u884c\u7684\u5e38\u89c1\u4efb\u52a1\u4e4b\u4e00\u3002\u53e6\u4e00\u4e2a\u91cd\u8981\u7684\u4efb\u52a1\u5305\u62ec\u9aa8\u67b6\u68c0\u6d4b\u548c\u59ff\u6001\u68c0\u6d4b\u3002\u8bd5\u8bd5OpenPose\u5e93\uff0c\u770b\u770b\u59ff\u6001\u68c0\u6d4b\u5982\u4f55\u4f7f\u7528\u3002</p>"},{"location":"lessons/4-ComputerVision/12-Segmentation/README_chs/#_8","title":"\u590d\u4e60\u4e0e\u81ea\u5b66","text":"<p>\u8fd9\u7bc7\u7ef4\u57fa\u767e\u79d1\u6587\u7ae0\u5bf9\u8fd9\u79cd\u6280\u672f\u7684\u5404\u79cd\u5e94\u7528\u63d0\u4f9b\u4e86\u5f88\u597d\u7684\u6982\u8ff0\u3002\u81ea\u5df1\u66f4\u591a\u5730\u4e86\u89e3\u4e00\u4e0b\u5b9e\u4f8b\u5206\u5272\u548c\u5168\u666f\u5206\u5272\u7684\u7ec6\u5206\u9886\u57df\u3002</p>"},{"location":"lessons/4-ComputerVision/12-Segmentation/README_chs/#_9","title":"\u4f5c\u4e1a","text":"<p>\u5728\u8fd9\u4e2a\u5b9e\u9a8c\u4e2d\uff0c\u5c1d\u8bd5\u4f7f\u7528 Kaggle \u4e0a\u7684Segmentation Full Body MADS \u6570\u636e\u96c6\u8fdb\u884c\u4eba\u4f53\u5206\u5272\u3002</p>"},{"location":"lessons/4-ComputerVision/12-Segmentation/lab/","title":"Human Body Segmentation","text":"<p>Lab Assignment from AI for Beginners Curriculum.</p>"},{"location":"lessons/4-ComputerVision/12-Segmentation/lab/#task","title":"Task","text":"<p>In video production, for example, in weather forecasts, we often need to cut out a human image from camera and place it on top of some other footage. This is typically done using chroma key techniques, when a human is filmed in front of a uniform color background, which is then removed. In this lab, we will train a neural network model to cut out the human silhouette.</p>"},{"location":"lessons/4-ComputerVision/12-Segmentation/lab/#the-dataset","title":"The Dataset","text":"<p>We will be using Segmentation Full Body MADS Dataset from Kaggle. Download the dataset manually from Kaggle.</p>"},{"location":"lessons/4-ComputerVision/12-Segmentation/lab/#stating-notebook","title":"Stating Notebook","text":"<p>Start the lab by opening BodySegmentation.ipynb</p>"},{"location":"lessons/4-ComputerVision/12-Segmentation/lab/#takeaway","title":"Takeaway","text":"<p>Body segmentation is just one of the common tasks that we can do with images of people. Another important tasks include skeleton detection and pose detection. Look into OpenPose library to see how those tasks can be implemented.</p>"},{"location":"lessons/4-ComputerVision/12-Segmentation/lab/README_chs/","title":"\u4eba\u4f53\u5206\u5272","text":"<p>\u6765\u81ea AI for Beginners Curriculum \u7684\u5b9e\u9a8c\u4f5c\u4e1a\u3002</p>"},{"location":"lessons/4-ComputerVision/12-Segmentation/lab/README_chs/#_2","title":"\u4efb\u52a1","text":"<p>\u5728\u89c6\u9891\u5236\u4f5c\u4e2d\uff0c\u4f8b\u5982\u5728\u5929\u6c14\u9884\u62a5\u4e2d\uff0c\u6211\u4eec\u7ecf\u5e38\u9700\u8981\u5c06\u76f8\u673a\u4e2d\u7684\u4eba\u4f53\u56fe\u50cf\u526a\u5207\u51fa\u6765\u5e76\u5c06\u5176\u653e\u7f6e\u5728\u5176\u4ed6\u955c\u5934\u4e4b\u4e0a\u3002\u8fd9\u901a\u5e38\u901a\u8fc7 \u8272\u5ea6\u952e \u6280\u672f\u5b8c\u6210\uff0c\u5f53\u4eba\u7c7b\u5728\u4e00\u4e2a\u5747\u5300\u7684\u989c\u8272\u80cc\u666f\u524d\u62cd\u6444\u65f6\uff0c\u8be5\u80cc\u666f\u968f\u540e\u88ab\u53bb\u9664\u3002\u5728\u672c\u5b9e\u9a8c\u4e2d\uff0c\u6211\u4eec\u5c06\u8bad\u7ec3\u4e00\u4e2a\u795e\u7ecf\u7f51\u7edc\u6a21\u578b\u6765\u526a\u5207\u4eba\u4f53\u8f6e\u5ed3\u3002</p>"},{"location":"lessons/4-ComputerVision/12-Segmentation/lab/README_chs/#_3","title":"\u6570\u636e\u96c6","text":"<p>\u6211\u4eec\u5c06\u4f7f\u7528\u6765\u81eaKaggle\u7684 Segmentation Full Body MADS Dataset\u3002\u8bf7\u4eceKaggle\u624b\u52a8\u4e0b\u8f7d\u8be5\u6570\u636e\u96c6\u3002</p>"},{"location":"lessons/4-ComputerVision/12-Segmentation/lab/README_chs/#notebook","title":"\u58f0\u660eNotebook","text":"<p>\u901a\u8fc7\u6253\u5f00 BodySegmentation.ipynb \u5f00\u59cb\u5b9e\u9a8c\u3002</p>"},{"location":"lessons/4-ComputerVision/12-Segmentation/lab/README_chs/#_4","title":"\u6536\u83b7","text":"<p>\u4eba\u4f53\u5206\u5272\u53ea\u662f\u6211\u4eec\u53ef\u4ee5\u4f7f\u7528\u4eba\u7269\u56fe\u50cf\u8fdb\u884c\u7684\u5e38\u89c1\u4efb\u52a1\u4e4b\u4e00\u3002\u5176\u4ed6\u91cd\u8981\u4efb\u52a1\u8fd8\u5305\u62ec \u9aa8\u67b6\u68c0\u6d4b \u548c \u59ff\u6001\u68c0\u6d4b\u3002\u67e5\u770b OpenPose \u5e93\uff0c\u4e86\u89e3\u8fd9\u4e9b\u4efb\u52a1\u5982\u4f55\u5b9e\u73b0\u3002</p>"},{"location":"lessons/5-NLP/","title":"Natural Language Processing","text":"<p>In this section, we will focus on using Neural Networks to handle tasks related to Natural Language Processing (NLP). There are many NLP problems that we want computers to be able to solve:</p> <ul> <li>Text classification is a typical classification problem pertaining to text sequences. Examples include classifying e-mail messages as spam vs. no-spam, or categorizing articles as sport, business, politics, etc. Also, when developing chat bots, we often need to understand what a user wanted to say -- in this case we are dealing with intent classification. Often, in intent classification we need to deal with many categories.</li> <li>Sentiment analysis is a typical regression problem, where we need to attribute a number (a sentiment) corresponding to how positive/negative the meaning of a sentence is. A more advanced version of sentiment analysis is aspect-based sentiment analysis (ABSA), where we attribute sentiment not to the whole sentence, but to different parts of it (aspects), eg. In this restaurant, I liked the cuisine, but the atmosphere was awful.</li> <li>Named Entity Recognition (NER) refers to the problem of extracting certain entities from text. For example, we might need to understand that in the phrase I need to fly to Paris tomorrow the word tomorrow refers to DATE, and Paris is a LOCATION.  </li> <li>Keyword extraction is similar to NER, but we need to extract words important to the meaning of the sentence automatically, without pre-training for specific entity types.</li> <li>Text clustering can be useful when we want to group together similar sentences, for example, similar requests in technical support conversations.</li> <li>Question answering refers to the ability of a model to answer a specific question. The model receives a text passage and a question as inputs, and it needs to provide a place in the text where the answer to the question is contained (or, sometimes, to generate the answer text).</li> <li>Text Generation is the ability of a model to generate new text. It can be considered as classification task that predicts next letter/word based on some text prompt. Advanced text generation models, such as GPT-3, are able to solve other NLP tasks such as classification using a technique called prompt programming or prompt engineering</li> <li>Text summarization is a technique when we want a computer to \"read\" long text and summarize it in a few sentences.</li> <li>Machine translation can be viewed as a combination of text understanding in one language, and text generation in another one.</li> </ul> <p>Initially, most of NLP tasks were solved using traditional methods such as grammars. For example, in machine translation parsers were used to transform initial sentence into a syntax tree, then higher level semantic structures were extracted to represent the meaning of the sentence, and based on this meaning and grammar of the target language the result was generated. Nowadays, many NLP tasks are more effectively solved using neural networks.</p> <p>Many classical NLP methods are implemented in Natural Language Processing Toolkit (NLTK) Python library. There is a great NLTK Book available online that covers how different NLP tasks can be solved using NLTK.</p> <p>In our course, we will mostly focus on using Neural Networks for NLP, and we will use NLTK where needed.</p> <p>We have already learned about using neural networks for dealing with tabular data and with images. The main difference between those types of data and text is that text is a sequence of variable length, while the input size in case of images is known in advance. While convolutional networks can extract patterns from input data, patterns in text are more complex. Eg., we can have negation being separated from the subject be arbitrary for many words (eg. I do not like oranges, vs. I do not like those big colorful tasty oranges), and that should still be interpreted as one pattern. Thus, to handle language we need to introduce new neural network types, such as recurrent networks and transformers.</p>"},{"location":"lessons/5-NLP/#install-libraries","title":"Install Libraries","text":"<p>If you are using local Python installation to run this course, you may need to install all required libraries for NLP using the following commands:</p> <p>For PyTorch</p> <pre><code>pip install -r requirements-torch.txt\n</code></pre> <p>For TensorFlow</p> <pre><code>pip install -r requirements-tf.txt\n</code></pre> <p>You can try NLP with TensorFlow on Microsoft Learn</p>"},{"location":"lessons/5-NLP/#gpu-warning","title":"GPU Warning","text":"<p>In this section, in some of the examples we will be training quite large models. * Use a GPU-Enabled Computer: It's advisable to run your notebooks on a GPU-enabled computer to reduce waiting times when working with large models. * GPU Memory Constraints: Running on a GPU may lead to situations where you run out of GPU memory, especially when training large models. * GPU Memory Consumption: The amount of GPU memory consumed during training depends on various factors, including the minibatch size. * Minimize Minibatch Size: If you encounter GPU memory issues, consider reducing the minibatch size in your code as a potential solution. * TensorFlow GPU Memory Release: Older versions of TensorFlow may not release GPU memory correctly when training multiple models within one Python kernel. To manage GPU memory usage effectively, you can configure TensorFlow to allocate GPU memory only as needed. * Code Inclusion: To set TensorFlow to grow GPU memory allocation only when required, include the following code in your notebooks:</p> <pre><code>physical_devices = tf.config.list_physical_devices('GPU') \nif len(physical_devices)&gt;0:\n    tf.config.experimental.set_memory_growth(physical_devices[0], True) \n</code></pre> <p>If you're interested in learning about NLP from a classic ML perspective, visit this suite of lessons</p>"},{"location":"lessons/5-NLP/#in-this-section","title":"In this Section","text":"<p>In this section we will learn about:</p> <ul> <li>Representing text as tensors</li> <li>Word Embeddings</li> <li>Language Modeling</li> <li>Recurrent Neural Networks</li> <li>Generative Networks</li> <li>Transformers</li> </ul>"},{"location":"lessons/5-NLP/README_chs/","title":"\u81ea\u7136\u8bed\u8a00\u5904\u7406","text":"<p>\u5728\u672c\u8282\u4e2d\uff0c\u6211\u4eec\u5c06\u91cd\u70b9\u4f7f\u7528\u795e\u7ecf\u7f51\u7edc\u5904\u7406\u4e0e\u81ea\u7136\u8bed\u8a00\u5904\u7406 (NLP) \u76f8\u5173\u7684\u4efb\u52a1\u3002\u6211\u4eec\u5e0c\u671b\u8ba1\u7b97\u673a\u80fd\u591f\u89e3\u51b3\u8bb8\u591aNLP\u95ee\u9898\uff1a</p> <ul> <li>\u6587\u672c\u5206\u7c7b \u662f\u5173\u4e8e\u6587\u672c\u5e8f\u5217\u7684\u5178\u578b\u5206\u7c7b\u95ee\u9898\u3002\u4f8b\u5982\uff0c\u5c06\u7535\u5b50\u90ae\u4ef6\u6d88\u606f\u5206\u7c7b\u4e3a\u5783\u573e\u90ae\u4ef6\u6216\u975e\u5783\u573e\u90ae\u4ef6\uff0c\u6216\u5c06\u6587\u7ae0\u5206\u7c7b\u4e3a\u4f53\u80b2\u3001\u5546\u4e1a\u3001\u653f\u6cbb\u7b49\u3002\u6b64\u5916\uff0c\u5728\u5f00\u53d1\u804a\u5929\u673a\u5668\u4eba\u65f6\uff0c\u6211\u4eec\u901a\u5e38\u9700\u8981\u7406\u89e3\u7528\u6237\u60f3\u8981\u8868\u8fbe\u7684\u610f\u601d\u2014\u2014\u8fd9\u79cd\u60c5\u51b5\u4e0b\u6211\u4eec\u5904\u7406\u7684\u662f\u610f\u56fe\u5206\u7c7b\u3002\u5728\u610f\u56fe\u5206\u7c7b\u4e2d\uff0c\u6211\u4eec\u901a\u5e38\u9700\u8981\u5904\u7406\u8bb8\u591a\u7c7b\u522b\u3002</li> <li>\u60c5\u611f\u5206\u6790 \u662f\u4e00\u79cd\u5178\u578b\u7684\u56de\u5f52\u95ee\u9898\uff0c\u6211\u4eec\u9700\u8981\u7ed9\u8bed\u53e5\u7684\u6b63\u9762/\u8d1f\u9762\u610f\u4e49\u8d4b\u4e88\u4e00\u4e2a\u6570\u5b57\uff08\u60c5\u611f\uff09\u3002\u60c5\u611f\u5206\u6790\u7684\u4e00\u4e2a\u66f4\u9ad8\u7ea7\u7248\u672c\u662f\u57fa\u4e8e\u65b9\u9762\u7684\u60c5\u611f\u5206\u6790\uff08ABSA\uff09\uff0c\u5176\u4e2d\u6211\u4eec\u5c06\u60c5\u611f\u5f52\u56e0\u4e8e\u8bed\u53e5\u7684\u4e0d\u540c\u90e8\u5206\uff08\u65b9\u9762\uff09\uff0c\u4f8b\u5982\u5728\u8fd9\u5bb6\u9910\u5385\uff0c\u6211\u559c\u6b22\u70f9\u996a\uff0c\u4f46\u6c1b\u56f4\u7cdf\u900f\u4e86\u3002</li> <li>\u547d\u540d\u5b9e\u4f53\u8bc6\u522b (NER) \u662f\u6307\u4ece\u6587\u672c\u4e2d\u63d0\u53d6\u7279\u5b9a\u5b9e\u4f53\u7684\u95ee\u9898\u3002\u4f8b\u5982\uff0c\u6211\u4eec\u53ef\u80fd\u9700\u8981\u7406\u89e3\u5728\u77ed\u8bed\u6211\u9700\u8981\u660e\u5929\u98de\u5f80\u5df4\u9ece\u4e2d\uff0c\u5355\u8bcd\u660e\u5929\u6307\u7684\u662f\u65e5\u671f\uff0c\u5df4\u9ece\u662f\u4e00\u4e2a\u5730\u70b9\u3002</li> <li>\u5173\u952e\u8bcd\u63d0\u53d6 \u7c7b\u4f3c\u4e8eNER\uff0c\u4f46\u6211\u4eec\u9700\u8981\u81ea\u52a8\u63d0\u53d6\u5bf9\u53e5\u5b50\u610f\u4e49\u91cd\u8981\u7684\u8bcd\uff0c\u65e0\u9700\u9488\u5bf9\u7279\u5b9a\u5b9e\u4f53\u7c7b\u578b\u8fdb\u884c\u9884\u8bad\u7ec3\u3002</li> <li>\u6587\u672c\u805a\u7c7b \u5728\u6211\u4eec\u5e0c\u671b\u5c06\u7c7b\u4f3c\u7684\u53e5\u5b50\u7ec4\u5408\u5728\u4e00\u8d77\u65f6\u975e\u5e38\u6709\u7528\uff0c\u4f8b\u5982\uff0c\u5728\u6280\u672f\u652f\u6301\u5bf9\u8bdd\u4e2d\u7ec4\u5408\u7c7b\u4f3c\u7684\u8bf7\u6c42\u3002</li> <li>\u95ee\u9898\u56de\u7b54 \u662f\u6307\u6a21\u578b\u56de\u7b54\u7279\u5b9a\u95ee\u9898\u7684\u80fd\u529b\u3002\u6a21\u578b\u63a5\u6536\u4e00\u4e2a\u6587\u672c\u6bb5\u843d\u548c\u4e00\u4e2a\u95ee\u9898\u4f5c\u4e3a\u8f93\u5165\uff0c\u9700\u8981\u63d0\u4f9b\u95ee\u9898\u7b54\u6848\u6240\u5728\u7684\u6587\u672c\u4f4d\u7f6e\uff08\u6709\u65f6\u9700\u8981\u751f\u6210\u7b54\u6848\u6587\u672c\uff09\u3002</li> <li>\u6587\u672c\u751f\u6210 \u662f\u6307\u6a21\u578b\u751f\u6210\u65b0\u6587\u672c\u7684\u80fd\u529b\u3002\u8fd9\u53ef\u4ee5\u88ab\u89c6\u4e3a\u57fa\u4e8e\u67d0\u4e9b\u6587\u672c\u63d0\u793a\u9884\u6d4b\u4e0b\u4e00\u4e2a\u5b57\u6bcd/\u5355\u8bcd\u7684\u5206\u7c7b\u4efb\u52a1\u3002\u5148\u8fdb\u7684\u6587\u672c\u751f\u6210\u6a21\u578b\uff0c\u5982GPT-3\uff0c\u80fd\u591f\u901a\u8fc7\u4e00\u79cd\u79f0\u4e3a\u63d0\u793a\u7f16\u7a0b\u6216\u63d0\u793a\u5de5\u7a0b\u7684\u6280\u672f\u89e3\u51b3\u5176\u4ed6NLP\u4efb\u52a1\uff0c\u5982\u5206\u7c7b\u3002</li> <li>\u6587\u672c\u6458\u8981 \u662f\u6307\u6211\u4eec\u5e0c\u671b\u8ba1\u7b97\u673a\u201c\u9605\u8bfb\u201d\u957f\u6587\u672c\u5e76\u5c06\u5176\u6458\u8981\u4e3a\u51e0\u53e5\u8bdd\u7684\u6280\u672f\u3002</li> <li>\u673a\u5668\u7ffb\u8bd1 \u53ef\u4ee5\u88ab\u89c6\u4e3a\u4e00\u79cd\u5c06\u4e00\u79cd\u8bed\u8a00\u4e2d\u7684\u6587\u672c\u7406\u89e3\u548c\u751f\u6210\u53e6\u4e00\u79cd\u8bed\u8a00\u6587\u672c\u7684\u7ed3\u5408\u3002</li> </ul> <p>\u6700\u521d\uff0c\u5927\u591a\u6570NLP\u4efb\u52a1\u662f\u4f7f\u7528\u4f20\u7edf\u65b9\u6cd5\uff08\u5982\u8bed\u6cd5\uff09\u89e3\u51b3\u7684\u3002\u4f8b\u5982\u5728\u673a\u5668\u7ffb\u8bd1\u4e2d\uff0c\u89e3\u6790\u5668\u7528\u4e8e\u5c06\u521d\u59cb\u53e5\u5b50\u8f6c\u6362\u4e3a\u8bed\u6cd5\u6811\uff0c\u7136\u540e\u63d0\u53d6\u66f4\u9ad8\u7ea7\u522b\u7684\u8bed\u4e49\u7ed3\u6784\u6765\u8868\u793a\u53e5\u5b50\u7684\u610f\u4e49\uff0c\u5e76\u57fa\u4e8e\u8fd9\u79cd\u610f\u4e49\u548c\u76ee\u6807\u8bed\u8a00\u7684\u8bed\u6cd5\u751f\u6210\u7ed3\u679c\u3002\u5982\u4eca\uff0c\u8bb8\u591aNLP\u4efb\u52a1\u66f4\u6709\u6548\u5730\u4f7f\u7528\u795e\u7ecf\u7f51\u7edc\u89e3\u51b3\u3002</p> <p>\u8bb8\u591a\u7ecf\u5178\u7684NLP\u65b9\u6cd5\u5728\u81ea\u7136\u8bed\u8a00\u5904\u7406\u5de5\u5177\u5305 (NLTK) Python\u5e93\u4e2d\u6709\u5b9e\u73b0\u3002\u7f51\u4e0a\u6709\u4e00\u672c\u5f88\u68d2\u7684NLTK\u4e66\uff0c\u6db5\u76d6\u4e86\u5982\u4f55\u4f7f\u7528NLTK\u89e3\u51b3\u4e0d\u540c\u7684NLP\u4efb\u52a1\u3002</p> <p>\u5728\u6211\u4eec\u7684\u8bfe\u7a0b\u4e2d\uff0c\u6211\u4eec\u5c06\u4e3b\u8981\u5173\u6ce8\u4f7f\u7528\u795e\u7ecf\u7f51\u7edc\u8fdb\u884cNLP\uff0c\u5e76\u5728\u9700\u8981\u65f6\u4f7f\u7528NLTK\u3002</p> <p>\u6211\u4eec\u5df2\u7ecf\u5b66\u4e60\u4e86\u4f7f\u7528\u795e\u7ecf\u7f51\u7edc\u5904\u7406\u8868\u683c\u6570\u636e\u548c\u56fe\u50cf\u3002\u4e0e\u8fd9\u4e9b\u7c7b\u578b\u7684\u6570\u636e\u4e0d\u540c\uff0c\u6587\u672c\u662f\u4e00\u4e2a\u957f\u5ea6\u53ef\u53d8\u7684\u5e8f\u5217\uff0c\u800c\u56fe\u50cf\u7684\u8f93\u5165\u5927\u5c0f\u662f\u63d0\u524d\u77e5\u9053\u7684\u3002\u867d\u7136\u5377\u79ef\u7f51\u7edc\u53ef\u4ee5\u4ece\u8f93\u5165\u6570\u636e\u4e2d\u63d0\u53d6\u6a21\u5f0f\uff0c\u4f46\u6587\u672c\u4e2d\u7684\u6a21\u5f0f\u66f4\u52a0\u590d\u6742\u3002\u4f8b\u5982\uff0c\u5426\u5b9a\u8bcd\u53ef\u80fd\u88ab\u8bb8\u591a\u5355\u8bcd\u4efb\u610f\u5206\u9694\uff08\u4f8b\u5982\u6211\u4e0d\u559c\u6b22\u6a59\u5b50 vs. \u6211\u4e0d\u559c\u6b22\u90a3\u4e9b\u5927\u800c\u8272\u5f69\u9c9c\u8273\u7684\u7f8e\u5473\u6a59\u5b50\uff09\uff0c\u8fd9\u4ecd\u5e94\u88ab\u89e3\u91ca\u4e3a\u4e00\u4e2a\u6a21\u5f0f\u3002\u56e0\u6b64\uff0c\u4e3a\u4e86\u5904\u7406\u8bed\u8a00\uff0c\u6211\u4eec\u9700\u8981\u5f15\u5165\u65b0\u7684\u795e\u7ecf\u7f51\u7edc\u7c7b\u578b\uff0c\u5982\u5faa\u73af\u7f51\u7edc\u548ctransformer\u3002</p>"},{"location":"lessons/5-NLP/README_chs/#_2","title":"\u5b89\u88c5\u5e93","text":"<p>\u5982\u679c\u60a8\u4f7f\u7528\u672c\u5730Python\u5b89\u88c5\u7a0b\u5e8f\u6765\u8fd0\u884c\u672c\u8bfe\u7a0b\uff0c\u60a8\u53ef\u80fd\u9700\u8981\u4f7f\u7528\u4ee5\u4e0b\u547d\u4ee4\u5b89\u88c5\u6240\u6709\u7528\u4e8eNLP\u7684\u5fc5\u9700\u5e93\uff1a</p> <p>\u5bf9\u4e8ePyTorch</p> <pre><code>pip install -r requirements-torch.txt\n</code></pre> <p>\u5bf9\u4e8eTensorFlow</p> <pre><code>pip install -r requirements-tf.txt\n</code></pre> <p>\u60a8\u53ef\u4ee5\u5728Microsoft Learn\u4e0a\u5c1d\u8bd5\u4f7f\u7528TensorFlow\u8fdb\u884cNLP\u3002</p>"},{"location":"lessons/5-NLP/README_chs/#gpu","title":"GPU\u8b66\u544a","text":"<p>\u5728\u672c\u8282\u4e2d\uff0c\u5728\u67d0\u4e9b\u793a\u4f8b\u4e2d\uff0c\u6211\u4eec\u5c06\u8bad\u7ec3\u76f8\u5f53\u5927\u7684\u6a21\u578b\u3002 * \u4f7f\u7528\u542f\u7528\u4e86GPU\u7684\u8ba1\u7b97\u673a\uff1a\u5efa\u8bae\u5728\u542f\u7528\u4e86GPU\u7684\u8ba1\u7b97\u673a\u4e0a\u8fd0\u884c\u7b14\u8bb0\u672c\uff0c\u4ee5\u5728\u5904\u7406\u5927\u578b\u6a21\u578b\u65f6\u51cf\u5c11\u7b49\u5f85\u65f6\u95f4\u3002 * GPU\u5185\u5b58\u9650\u5236\uff1a\u5728GPU\u4e0a\u8fd0\u884c\u53ef\u80fd\u4f1a\u5bfc\u81f4GPU\u5185\u5b58\u4e0d\u8db3\u7684\u60c5\u51b5\uff0c\u5c24\u5176\u662f\u5728\u8bad\u7ec3\u5927\u578b\u6a21\u578b\u65f6\u3002 * GPU\u5185\u5b58\u6d88\u8017\uff1a\u8bad\u7ec3\u671f\u95f4\u6d88\u8017\u7684GPU\u5185\u5b58\u91cf\u53d6\u51b3\u4e8e\u5404\u79cd\u56e0\u7d20\uff0c\u5305\u62ec\u5c0f\u6279\u91cf\u5927\u5c0f\u3002 * \u6700\u5c0f\u5316\u5c0f\u6279\u91cf\u5927\u5c0f\uff1a\u5982\u679c\u9047\u5230GPU\u5185\u5b58\u95ee\u9898\uff0c\u8bf7\u8003\u8651\u51cf\u5c11\u4ee3\u7801\u4e2d\u7684\u5c0f\u6279\u91cf\u5927\u5c0f\u4f5c\u4e3a\u6f5c\u5728\u89e3\u51b3\u65b9\u6848\u3002 * TensorFlow GPU\u5185\u5b58\u91ca\u653e\uff1a\u65e7\u7248\u672c\u7684TensorFlow\u5728\u4e00\u4e2aPython\u5185\u6838\u4e2d\u8bad\u7ec3\u591a\u4e2a\u6a21\u578b\u65f6\u53ef\u80fd\u4e0d\u4f1a\u6b63\u786e\u91ca\u653eGPU\u5185\u5b58\u3002\u4e3a\u4e86\u6709\u6548\u7ba1\u7406GPU\u5185\u5b58\u4f7f\u7528\uff0c\u60a8\u53ef\u4ee5\u914d\u7f6eTensorFlow\u4ec5\u5728\u9700\u8981\u65f6\u5206\u914dGPU\u5185\u5b58\u3002 * \u4ee3\u7801\u5305\u542b\uff1a\u8981\u8bbe\u7f6eTensorFlow\u4ec5\u5728\u9700\u8981\u65f6\u5206\u914dGPU\u5185\u5b58\uff0c\u8bf7\u5728\u7b14\u8bb0\u672c\u4e2d\u5305\u542b\u4ee5\u4e0b\u4ee3\u7801\uff1a</p> <pre><code>physical_devices = tf.config.list_physical_devices('GPU') \nif len(physical_devices)&gt;0:\n    tf.config.experimental.set_memory_growth(physical_devices[0], True) \n</code></pre> <p>\u5982\u679c\u60a8\u6709\u5174\u8da3\u4ece\u7ecf\u5178\u7684ML\u89d2\u5ea6\u5b66\u4e60NLP\uff0c\u8bf7\u8bbf\u95ee\u8fd9\u5957\u8bfe\u7a0b</p>"},{"location":"lessons/5-NLP/README_chs/#_3","title":"\u672c\u8282\u5185\u5bb9","text":"<p>\u5728\u672c\u8282\u4e2d\uff0c\u6211\u4eec\u5c06\u5b66\u4e60\uff1a</p> <ul> <li>\u5c06\u6587\u672c\u8868\u793a\u4e3a\u5f20\u91cf</li> <li>\u8bcd\u5d4c\u5165</li> <li>\u8bed\u8a00\u5efa\u6a21</li> <li>\u5faa\u73af\u795e\u7ecf\u7f51\u7edc</li> <li>\u751f\u6210\u7f51\u7edc</li> <li>transformer</li> </ul>"},{"location":"lessons/5-NLP/13-TextRep/","title":"Representing Text as Tensors","text":""},{"location":"lessons/5-NLP/13-TextRep/#pre-lecture-quiz","title":"Pre-lecture quiz","text":""},{"location":"lessons/5-NLP/13-TextRep/#text-classification","title":"Text Classification","text":"<p>Throughout the first part of this section, we will focus on text classification task. We will use the AG News Dataset, which contains news articles like the following:</p> <ul> <li>Category: Sci/Tech</li> <li>Title: Ky. Company Wins Grant to Study Peptides (AP)</li> <li>Body: AP - A company founded by a chemistry researcher at the University of Louisville won a grant to develop...</li> </ul> <p>Our goal will be to classify the news item into one of the categories based on text.</p>"},{"location":"lessons/5-NLP/13-TextRep/#representing-text","title":"Representing text","text":"<p>If we want to solve Natural Language Processing (NLP) tasks with neural networks, we need some way to represent text as tensors. Computers already represent textual characters as numbers that map to fonts on your screen using encodings such as ASCII or UTF-8.</p> <p></p> <p>Image source</p> <p>As humans, we understand what each letter represents, and how all characters come together to form the words of a sentence. However, computers by themselves do not have such an understanding, and neural network has to learn the meaning during training.</p> <p>Therefore, we can use different approaches when representing text:</p> <ul> <li>Character-level representation, when we represent text by treating each character as a number. Given that we have C different characters in our text corpus, the word Hello would be represented by 5xC tensor. Each letter would correspond to a tensor column in one-hot encoding.</li> <li>Word-level representation, in which we create a vocabulary of all words in our text, and then represent words using one-hot encoding. This approach is somehow better, because each letter by itself does not have much meaning, and thus by using higher-level semantic concepts - words - we simplify the task for the neural network. However, given the large dictionary size, we need to deal with high-dimensional sparse tensors.</li> </ul> <p>Regardless of the representation, we first need to convert the text into a sequence of tokens, one token being either a character, a word, or sometimes even part of a word. Then, we convert the token into a number, typically using vocabulary, and this number can be fed into a neural network using one-hot encoding.</p>"},{"location":"lessons/5-NLP/13-TextRep/#n-grams","title":"N-Grams","text":"<p>In natural language, precise meaning of words can only be determined in context. For example, meanings of neural network and fishing network are completely different. One of the ways to take this into account is to build our model on pairs of words, and considering word pairs as separate vocabulary tokens. In this way, the sentence I like to go fishing will be represented by the following sequence of tokens: I like, like to, to go, go fishing. The problem with this approach is that the dictionary size grows significantly, and combinations like go fishing and go shopping are presented by different tokens, which do not share any semantic similarity despite the same verb.  </p> <p>In some cases, we may consider using tri-grams -- combinations of three words -- as well. Thus the approach is such is often called n-grams. Also, it makes sense to use n-grams with character-level representation, in which case n-grams will roughly correspond to different syllabi.</p>"},{"location":"lessons/5-NLP/13-TextRep/#bag-of-words-and-tfidf","title":"Bag-of-Words and TF/IDF","text":"<p>When solving tasks like text classification, we need to be able to represent text by one fixed-size vector, which we will use as an input to final dense classifier. One of the simplest ways to do that is to combine all individual word representations, eg. by adding them. If we add one-hot encodings of each word, we will end up with a vector of frequencies, showing how many times each word appears inside the text. Such representation of text is called bag of words (BoW).</p> <p></p> <p>Image by the author</p> <p>A BoW essentially represents which words appear in text and in which quantities, which can indeed be a good indication of what the text is about. For example, news article on politics is likely to contains words such as president and country, while scientific publication would have something like collider, discovered, etc. Thus, word frequencies can in many cases be a good indicator of text content.</p> <p>The problem with BoW is that certain common words, such as and, is, etc. appear in most of the texts, and they have highest frequencies, masking out the words that are really important. We may lower the importance of those words by taking into account the frequency at which words occur in the whole document collection. This is the main idea behind TF/IDF approach, which is covered in more detail in the notebooks attached to this lesson.</p> <p>However, none of those approaches can fully take into account the semantics of text. We need more powerful neural networks models to do this, which we will discuss later in this section.</p>"},{"location":"lessons/5-NLP/13-TextRep/#exercises-text-representation","title":"\u270d\ufe0f Exercises: Text Representation","text":"<p>Continue your learning in the following notebooks:</p> <ul> <li>Text Representation with PyTorch</li> <li>Text Representation with TensorFlow</li> </ul>"},{"location":"lessons/5-NLP/13-TextRep/#conclusion","title":"Conclusion","text":"<p>So far, we have studied techniques that can add frequency weight to different words. They are, however, unable to represent meaning or order. As the famous linguist J. R. Firth said in 1935, \"The complete meaning of a word is always contextual, and no study of meaning apart from context can be taken seriously.\" We will learn later in the course how to capture contextual information from text using language modeling.</p>"},{"location":"lessons/5-NLP/13-TextRep/#challenge","title":"\ud83d\ude80 Challenge","text":"<p>Try some other exercises using bag-of-words and different data models. You might be inspired by this competition on Kaggle</p>"},{"location":"lessons/5-NLP/13-TextRep/#post-lecture-quiz","title":"Post-lecture quiz","text":""},{"location":"lessons/5-NLP/13-TextRep/#review-self-study","title":"Review &amp; Self Study","text":"<p>Practice your skills with text embeddings and bag-of-words techniques on Microsoft Learn</p>"},{"location":"lessons/5-NLP/13-TextRep/#assignment-notebooks","title":"Assignment: Notebooks","text":""},{"location":"lessons/5-NLP/13-TextRep/README_chs/","title":"\u5c06\u6587\u672c\u8868\u793a\u4e3a\u5f20\u91cf","text":""},{"location":"lessons/5-NLP/13-TextRep/README_chs/#_2","title":"\u8bfe\u524d\u6d4b\u9a8c","text":""},{"location":"lessons/5-NLP/13-TextRep/README_chs/#_3","title":"\u6587\u672c\u5206\u7c7b","text":"<p>\u5728\u672c\u8282\u7684\u7b2c\u4e00\u90e8\u5206\u4e2d\uff0c\u6211\u4eec\u5c06\u91cd\u70b9\u5173\u6ce8\u6587\u672c\u5206\u7c7b\u4efb\u52a1\u3002\u6211\u4eec\u5c06\u4f7f\u7528AG News\u6570\u636e\u96c6\uff0c\u8be5\u6570\u636e\u96c6\u5305\u542b\u5982\u4e0b\u7684\u65b0\u95fb\u6587\u7ae0\uff1a</p> <ul> <li>\u7c7b\u522b\uff1a\u79d1\u6280</li> <li>\u6807\u9898\uff1aKy. \u516c\u53f8\u8d62\u5f97\u7814\u7a76\u80bd\u7684\u8d44\u52a9\uff08AP\uff09</li> <li>\u6b63\u6587\uff1aAP - \u4e00\u5bb6\u7531\u8def\u6613\u65af\u7ef4\u5c14\u5927\u5b66\u7684\u5316\u5b66\u7814\u7a76\u5458\u521b\u7acb\u7684\u516c\u53f8\u8d62\u5f97\u4e86\u4e00\u9879\u5f00\u53d1\u8d44\u91d1...</li> </ul> <p>\u6211\u4eec\u7684\u76ee\u6807\u662f\u6839\u636e\u6587\u672c\u5c06\u65b0\u95fb\u6761\u76ee\u5206\u7c7b\u5230\u67d0\u4e00\u4e2a\u7c7b\u522b\u4e2d\u3002</p>"},{"location":"lessons/5-NLP/13-TextRep/README_chs/#_4","title":"\u8868\u793a\u6587\u672c","text":"<p>\u5982\u679c\u6211\u4eec\u60f3\u7528\u795e\u7ecf\u7f51\u7edc\u89e3\u51b3\u81ea\u7136\u8bed\u8a00\u5904\u7406\uff08NLP\uff09\u4efb\u52a1\uff0c\u6211\u4eec\u9700\u8981\u67d0\u79cd\u65b9\u6cd5\u5c06\u6587\u672c\u8868\u793a\u4e3a\u5f20\u91cf\u3002\u8ba1\u7b97\u673a\u5df2\u7ecf\u4f7f\u7528\u8bf8\u5982ASCII\u6216UTF-8\u4e4b\u7c7b\u7684\u7f16\u7801\uff0c\u5c06\u6587\u672c\u5b57\u7b26\u8868\u793a\u4e3a\u6620\u5c04\u5230\u5c4f\u5e55\u5b57\u4f53\u7684\u6570\u5b57\u3002</p> <p></p> <p>\u56fe\u7247\u6765\u6e90</p> <p>\u4f5c\u4e3a\u4eba\u7c7b\uff0c\u6211\u4eec\u7406\u89e3\u6bcf\u4e2a\u5b57\u6bcd\u4ee3\u8868\u7684\u610f\u601d\uff0c\u4ee5\u53ca\u6240\u6709\u5b57\u7b26\u5982\u4f55\u7ec4\u5408\u6210\u4e00\u4e2a\u53e5\u5b50\u7684\u5355\u8bcd\u3002\u7136\u800c\uff0c\u8ba1\u7b97\u673a\u672c\u8eab\u5e76\u6ca1\u6709\u8fd9\u79cd\u7406\u89e3\uff0c\u5e76\u4e14\u795e\u7ecf\u7f51\u7edc\u5fc5\u987b\u5728\u8bad\u7ec3\u671f\u95f4\u5b66\u4e60\u542b\u4e49\u3002</p> <p>\u56e0\u6b64\uff0c\u6211\u4eec\u5728\u8868\u793a\u6587\u672c\u65f6\u53ef\u4ee5\u4f7f\u7528\u4e0d\u540c\u7684\u65b9\u6cd5\uff1a</p> <ul> <li>\u5b57\u7b26\u7ea7\u8868\u793a\uff0c\u6211\u4eec\u5c06\u6587\u672c\u8868\u793a\u4e3a\u6bcf\u4e2a\u5b57\u7b26\u4f5c\u4e3a\u4e00\u4e2a\u6570\u5b57\u3002\u5047\u8bbe\u6211\u4eec\u7684\u6587\u672c\u8bed\u6599\u5e93\u4e2d\u6709C\u4e2a\u4e0d\u540c\u7684\u5b57\u7b26\uff0c\u90a3\u4e48\u5355\u8bcdHello\u5c06\u8868\u793a\u4e3a5xC\u7684\u5f20\u91cf\u3002\u6bcf\u4e2a\u5b57\u6bcd\u5bf9\u5e94\u4e00\u4e2aone-hot\u7f16\u7801\u7684\u5f20\u91cf\u5217\u3002</li> <li>\u8bcd\u6c47\u7ea7\u8868\u793a\uff0c\u6211\u4eec\u5728\u5176\u4e2d\u521b\u5efa\u6587\u672c\u4e2d\u7684\u6240\u6709\u5355\u8bcd\u7684\u8bcd\u6c47\u8868\uff0c\u7136\u540e\u4f7f\u7528one-hot\u7f16\u7801\u8868\u793a\u5355\u8bcd\u3002\u8fd9\u79cd\u65b9\u6cd5\u5728\u67d0\u79cd\u7a0b\u5ea6\u4e0a\u66f4\u597d\uff0c\u56e0\u4e3a\u5355\u4e2a\u5b57\u6bcd\u672c\u8eab\u6ca1\u6709\u592a\u591a\u610f\u4e49\uff0c\u56e0\u6b64\u901a\u8fc7\u4f7f\u7528\u66f4\u9ad8\u5c42\u6b21\u7684\u8bed\u4e49\u6982\u5ff5\u2014\u2014\u5355\u8bcd\u2014\u2014\u6211\u4eec\u7b80\u5316\u4e86\u795e\u7ecf\u7f51\u7edc\u7684\u4efb\u52a1\u3002\u7136\u800c\uff0c\u9274\u4e8e\u8bcd\u5178\u7684\u5927\u5c0f\u5f88\u5927\uff0c\u6211\u4eec\u9700\u8981\u5904\u7406\u9ad8\u7ef4\u7a00\u758f\u5f20\u91cf\u3002</li> </ul> <p>\u65e0\u8bba\u91c7\u7528\u54ea\u79cd\u8868\u793a\u65b9\u5f0f\uff0c\u6211\u4eec\u9996\u5148\u9700\u8981\u5c06\u6587\u672c\u8f6c\u6362\u4e3a\u6807\u8bb0\u5e8f\u5217\uff0c\u4e00\u4e2a\u6807\u8bb0\u53ef\u4ee5\u662f\u4e00\u4e2a\u5b57\u7b26\u3001\u4e00\u4e2a\u5355\u8bcd\uff0c\u6709\u65f6\u751a\u81f3\u662f\u4e00\u4e2a\u90e8\u5206\u5355\u8bcd\u3002\u7136\u540e\uff0c\u6211\u4eec\u4f7f\u7528\u8bcd\u6c47\u8868\u5c06\u6807\u8bb0\u8f6c\u6362\u4e3a\u6570\u5b57\uff0c\u901a\u5e38\u4f7f\u7528one-hot\u7f16\u7801\uff0c\u8fd9\u4e2a\u6570\u5b57\u53ef\u4ee5\u8f93\u5165\u795e\u7ecf\u7f51\u7edc\u3002</p>"},{"location":"lessons/5-NLP/13-TextRep/README_chs/#n","title":"N\u5143\u8bed\u6cd5","text":"<p>\u5728\u81ea\u7136\u8bed\u8a00\u4e2d\uff0c\u5355\u8bcd\u7684\u7cbe\u786e\u542b\u4e49\u53ea\u80fd\u5728\u4e0a\u4e0b\u6587\u4e2d\u786e\u5b9a\u3002\u4f8b\u5982\uff0c\u795e\u7ecf\u7f51\u7edc\u548c\u6355\u9c7c\u7f51\u7684\u542b\u4e49\u5b8c\u5168\u4e0d\u540c\u3002\u8003\u8651\u8fd9\u4e00\u70b9\u7684\u4e00\u79cd\u65b9\u6cd5\u662f\u6784\u5efa\u57fa\u4e8e\u5355\u8bcd\u5bf9\u7684\u6a21\u578b\uff0c\u5e76\u5c06\u5355\u8bcd\u5bf9\u89c6\u4e3a\u72ec\u7acb\u7684\u8bcd\u6c47\u6807\u8bb0\u3002\u8fd9\u6837\uff0c\u53e5\u5b50I like to go fishing\u5c06\u8868\u793a\u4e3a\u4ee5\u4e0b\u6807\u8bb0\u5e8f\u5217\uff1aI like\uff0clike to\uff0cto go\uff0cgo fishing\u3002\u8fd9\u79cd\u65b9\u6cd5\u7684\u95ee\u9898\u662f\u8bcd\u5178\u5927\u5c0f\u663e\u8457\u589e\u957f\uff0c\u5e76\u4e14\u50cfgo fishing\u548cgo shopping\u8fd9\u6837\u7684\u7ec4\u5408\u7531\u4e0d\u540c\u7684\u6807\u8bb0\u8868\u793a\uff0c\u5c3d\u7ba1\u5b83\u4eec\u5177\u6709\u76f8\u540c\u7684\u52a8\u8bcd\uff0c\u4f46\u6ca1\u6709\u4efb\u4f55\u8bed\u4e49\u76f8\u4f3c\u6027\u3002</p> <p>\u5728\u67d0\u4e9b\u60c5\u51b5\u4e0b\uff0c\u6211\u4eec\u8fd8\u53ef\u4ee5\u8003\u8651\u4f7f\u7528\u4e09\u5143\u8bed\u6cd5\u2014\u2014\u4e09\u4e2a\u5355\u8bcd\u7684\u7ec4\u5408\u3002\u56e0\u6b64\uff0c\u8fd9\u79cd\u65b9\u6cd5\u901a\u5e38\u88ab\u79f0\u4e3an\u5143\u8bed\u6cd5\u3002\u6b64\u5916\uff0c\u5728\u5b57\u7b26\u7ea7\u8868\u793a\u4e2d\u4f7f\u7528n\u5143\u8bed\u6cd5\u4e5f\u662f\u6709\u610f\u4e49\u7684\uff0c\u5728\u8fd9\u79cd\u60c5\u51b5\u4e0b\uff0cn\u5143\u8bed\u6cd5\u5927\u81f4\u5bf9\u5e94\u4e8e\u4e0d\u540c\u7684\u97f3\u8282\u3002</p>"},{"location":"lessons/5-NLP/13-TextRep/README_chs/#tfidf","title":"\u8bcd\u888b\u548cTF/IDF","text":"<p>\u5728\u89e3\u51b3\u8bf8\u5982\u6587\u672c\u5206\u7c7b\u4e4b\u7c7b\u7684\u4efb\u52a1\u65f6\uff0c\u6211\u4eec\u9700\u8981\u80fd\u591f\u4f7f\u7528\u4e00\u4e2a\u56fa\u5b9a\u5927\u5c0f\u7684\u5411\u91cf\u8868\u793a\u6587\u672c\uff0c\u6211\u4eec\u5c06\u4f7f\u7528\u8be5\u5411\u91cf\u4f5c\u4e3a\u6700\u7ec8\u5bc6\u96c6\u5206\u7c7b\u5668\u7684\u8f93\u5165\u3002\u6700\u7b80\u5355\u7684\u65b9\u6cd5\u4e4b\u4e00\u662f\u7ed3\u5408\u6240\u6709\u5355\u8bcd\u7684\u8868\u793a\uff0c\u4f8b\u5982\u901a\u8fc7\u5c06\u5b83\u4eec\u76f8\u52a0\u3002\u5982\u679c\u6211\u4eec\u5bf9\u6bcf\u4e2a\u5355\u8bcd\u7684one-hot\u7f16\u7801\u6c42\u548c\uff0c\u6211\u4eec\u5c06\u5f97\u5230\u4e00\u4e2a\u9891\u7387\u5411\u91cf\uff0c\u663e\u793a\u6bcf\u4e2a\u5355\u8bcd\u5728\u6587\u672c\u4e2d\u51fa\u73b0\u7684\u6b21\u6570\u3002\u8fd9\u79cd\u6587\u672c\u8868\u793a\u79f0\u4e3a\u8bcd\u888b\uff08BoW\uff09\u3002</p> <p></p> <p>\u56fe\u7247\u4f5c\u8005\u81ea\u5236</p> <p>BoW\u672c\u8d28\u4e0a\u8868\u793a\u5728\u6587\u672c\u4e2d\u51fa\u73b0\u7684\u5355\u8bcd\u53ca\u5176\u6570\u91cf\uff0c\u8fd9\u786e\u5b9e\u53ef\u4ee5\u5f88\u597d\u5730\u63d0\u793a\u6587\u672c\u7684\u5185\u5bb9\u3002\u4f8b\u5982\uff0c\u5173\u4e8e\u653f\u6cbb\u7684\u65b0\u95fb\u6587\u7ae0\u53ef\u80fd\u5305\u542b\u5355\u8bcdpresident\u548ccountry\uff0c\u800c\u79d1\u5b66\u51fa\u7248\u7269\u53ef\u80fd\u5305\u542bcollider\uff0cdiscovered\u7b49\u3002\u56e0\u6b64\uff0c\u5355\u8bcd\u9891\u7387\u5728\u8bb8\u591a\u60c5\u51b5\u4e0b\u53ef\u4ee5\u5f88\u597d\u5730\u6307\u793a\u6587\u672c\u5185\u5bb9\u3002</p> <p>BoW\u7684\u95ee\u9898\u5728\u4e8e\u67d0\u4e9b\u5e38\u89c1\u5355\u8bcd\uff0c\u5982and\u548cis\uff0c\u51fa\u73b0\u5728\u5927\u591a\u6570\u6587\u672c\u4e2d\uff0c\u5b83\u4eec\u7684\u9891\u7387\u6700\u9ad8\uff0c\u63a9\u76d6\u4e86\u771f\u6b63\u91cd\u8981\u7684\u5355\u8bcd\u3002\u6211\u4eec\u53ef\u4ee5\u901a\u8fc7\u8003\u8651\u5355\u8bcd\u5728\u6574\u4e2a\u6587\u6863\u96c6\u5408\u4e2d\u51fa\u73b0\u7684\u9891\u7387\u6765\u964d\u4f4e\u8fd9\u4e9b\u5355\u8bcd\u7684\u91cd\u8981\u6027\u3002\u8fd9\u5c31\u662fTF/IDF\u65b9\u6cd5\u7684\u4e3b\u8981\u601d\u60f3\uff0c\u66f4\u8be6\u7ec6\u5185\u5bb9\u5728\u672c\u8bfe\u9644\u5e26\u7684\u7b14\u8bb0\u4e2d\u4ecb\u7ecd\u3002</p> <p>\u4e0d\u8fc7\uff0c\u8fd9\u4e9b\u65b9\u6cd5\u90fd\u65e0\u6cd5\u5b8c\u5168\u8003\u8651\u6587\u672c\u7684\u8bed\u4e49\u3002\u6211\u4eec\u9700\u8981\u66f4\u5f3a\u5927\u7684\u795e\u7ecf\u7f51\u7edc\u6a21\u578b\u6765\u5b8c\u6210\u8fd9\u9879\u5de5\u4f5c\uff0c\u6211\u4eec\u5c06\u5728\u672c\u8282\u540e\u9762\u8ba8\u8bba\u3002</p>"},{"location":"lessons/5-NLP/13-TextRep/README_chs/#_5","title":"\u270d\ufe0f \u7ec3\u4e60\uff1a\u6587\u672c\u8868\u793a","text":"<p>\u5728\u4ee5\u4e0b\u7b14\u8bb0\u672c\u4e2d\u7ee7\u7eed\u5b66\u4e60\uff1a</p> <ul> <li>\u4f7f\u7528PyTorch\u8fdb\u884c\u6587\u672c\u8868\u793a</li> <li>\u4f7f\u7528TensorFlow\u8fdb\u884c\u6587\u672c\u8868\u793a</li> </ul>"},{"location":"lessons/5-NLP/13-TextRep/README_chs/#_6","title":"\u7ed3\u8bba","text":"<p>\u5230\u76ee\u524d\u4e3a\u6b62\uff0c\u6211\u4eec\u7814\u7a76\u4e86\u53ef\u4ee5\u4e3a\u4e0d\u540c\u5355\u8bcd\u6dfb\u52a0\u9891\u7387\u6743\u91cd\u7684\u6280\u672f\u3002\u7136\u800c\uff0c\u5b83\u4eec\u65e0\u6cd5\u8868\u793a\u610f\u4e49\u6216\u987a\u5e8f\u3002\u6b63\u5982\u8457\u540d\u8bed\u8a00\u5b66\u5bb6J. R. Firth\u57281935\u5e74\u6240\u8bf4\uff0c\u201c\u4e00\u4e2a\u5355\u8bcd\u7684\u5b8c\u6574\u610f\u4e49\u603b\u662f\u4e0a\u4e0b\u6587\u7684\uff0c\u4efb\u4f55\u8131\u79bb\u4e0a\u4e0b\u6587\u7684\u610f\u4e49\u7814\u7a76\u90fd\u4e0d\u80fd\u88ab\u8ba4\u771f\u5bf9\u5f85\u3002\u201d\u6211\u4eec\u5c06\u5728\u8bfe\u7a0b\u7684\u540e\u7eed\u90e8\u5206\u5b66\u4e60\u5982\u4f55\u4f7f\u7528\u8bed\u8a00\u5efa\u6a21\u4ece\u6587\u672c\u4e2d\u6355\u83b7\u4e0a\u4e0b\u6587\u4fe1\u606f\u3002</p>"},{"location":"lessons/5-NLP/13-TextRep/README_chs/#_7","title":"\ud83d\ude80 \u6311\u6218","text":"<p>\u5c1d\u8bd5\u4f7f\u7528\u8bcd\u888b\u548c\u4e0d\u540c\u7684\u6570\u636e\u6a21\u578b\u8fdb\u884c\u5176\u4ed6\u7ec3\u4e60\u3002\u4f60\u53ef\u4ee5\u4ece\u8fd9\u4e2a\u5728Kaggle\u4e0a\u7684\u7ade\u8d5b\u4e2d\u83b7\u5f97\u7075\u611f</p>"},{"location":"lessons/5-NLP/13-TextRep/README_chs/#_8","title":"\u8bfe\u540e\u6d4b\u9a8c","text":""},{"location":"lessons/5-NLP/13-TextRep/README_chs/#_9","title":"\u590d\u4e60\u4e0e\u81ea\u5b66","text":"<p>\u5728Microsoft Learn\u4e0a\u7ec3\u4e60\u4f60\u7684\u6587\u672c\u5d4c\u5165\u548c\u8bcd\u888b\u6280\u672f\u6280\u80fd</p>"},{"location":"lessons/5-NLP/13-TextRep/README_chs/#_10","title":"\u4f5c\u4e1a\uff1a\u7b14\u8bb0\u672c","text":""},{"location":"lessons/5-NLP/13-TextRep/assignment/","title":"Assignment: Notebooks","text":"<p>Using the notebooks associated to this lesson (either the PyTorch or the TensorFlow version), rerun them using your own dataset, perhaps one from Kaggle, used with attribution. Rewrite the notebook to underline your own findings. Try some innovative datasets that might prove surprising, such as this one about UFO sightings from NUFORC.</p>"},{"location":"lessons/5-NLP/13-TextRep/assignment_chs/","title":"\u4efb\u52a1\uff1a\u7b14\u8bb0\u672c","text":"<p>\u4f7f\u7528\u4e0e\u672c\u8bfe\u76f8\u5173\u7684\u7b14\u8bb0\u672c\uff08\u65e0\u8bba\u662f PyTorch \u8fd8\u662f TensorFlow \u7248\u672c\uff09\uff0c\u4f7f\u7528\u4f60\u81ea\u5df1\u7684\u6570\u636e\u96c6\u91cd\u65b0\u8fd0\u884c\u5b83\u4eec\uff0c\u6216\u8bb8\u53ef\u4ee5\u4f7f\u7528\u6765\u81ea Kaggle \u7684\uff0c\u5e76\u8fdb\u884c\u5f52\u56e0\u3002\u91cd\u5199\u7b14\u8bb0\u672c\u4ee5\u5f3a\u8c03\u4f60\u81ea\u5df1\u7684\u53d1\u73b0\u3002\u5c1d\u8bd5\u4e00\u4e9b\u53ef\u80fd\u4f1a\u6709\u60ca\u559c\u7684\u521b\u65b0\u6570\u636e\u96c6\uff0c\u4f8b\u5982\u6765\u81ea NUFORC \u7684\u8fd9\u4e2a\u5173\u4e8e UFO \u76ee\u51fb\u4e8b\u4ef6\u7684\u6570\u636e\u96c6\u3002</p>"},{"location":"lessons/5-NLP/14-Embeddings/","title":"Embeddings","text":""},{"location":"lessons/5-NLP/14-Embeddings/#pre-lecture-quiz","title":"Pre-lecture quiz","text":"<p>When training classifiers based on BoW or TF/IDF, we operated on high-dimensional bag-of-words vectors with length <code>vocab_size</code>, and we were explicitly converting from low-dimensional positional representation vectors into sparse one-hot representation. This one-hot representation, however, is not memory-efficient. In addition, each word is treated independently from each other, i.e. one-hot encoded vectors do not express any semantic similarity between words.</p> <p>The idea of embedding is to represent words by lower-dimensional dense vectors, which somehow reflect the semantic meaning of a word. We will later discuss how to build meaningful word embeddings, but for now let's just think of embeddings as a way to lower dimensionality of a word vector.</p> <p>So, the embedding layer would take a word as an input, and produce an output vector of specified <code>embedding_size</code>. In a sense, it is very similar to a <code>Linear</code> layer, but instead of taking a one-hot encoded vector, it will be able to take a word number as an input, allowing us to avoid creating large one-hot-encoded vectors.</p> <p>By using an embedding layer as a first layer in our classifier network, we can switch from a bag-of-words to embedding bag model, where we first convert each word in our text into corresponding embedding, and then compute some aggregate function over all those embeddings, such as <code>sum</code>, <code>average</code> or <code>max</code>.  </p> <p></p> <p>Image by the author</p>"},{"location":"lessons/5-NLP/14-Embeddings/#exercises-embeddings","title":"\u270d\ufe0f Exercises: Embeddings","text":"<p>Continue your learning in the following notebooks: * Embeddings with PyTorch * Embeddings TensorFlow</p>"},{"location":"lessons/5-NLP/14-Embeddings/#semantic-embeddings-word2vec","title":"Semantic Embeddings: Word2Vec","text":"<p>While the embedding layer learned to map words to vector representation, however, this representation did not necessarily have much semantical meaning. It would be nice to learn a vector representation such that similar words or synonyms correspond to vectors that are close to each other in terms of some vector distance (eg. Euclidean distance).</p> <p>To do that, we need to pre-train our embedding model on a large collection of text in a specific way. One way to train semantic embeddings is called Word2Vec. It is based on two main architectures that are used to produce a distributed representation of words:</p> <ul> <li>Continuous bag-of-words (CBoW) \u2014 in this architecture, we train the model to predict a word from surrounding context. Given the ngram $(W_{-2},W_{-1},W_0,W_1,W_2)$, the goal of the model is to predict $W_0$ from $(W_{-2},W_{-1},W_1,W_2)$.</li> <li>Continuous skip-gram is opposite to CBoW. The model uses surrounding window of context words to predict the current word.</li> </ul> <p>CBoW is faster, while skip-gram is slower, but does a better job of representing infrequent words.</p> <p></p> <p>Image from this paper</p> <p>Word2Vec pre-trained embeddings (as well as other similar models, such as GloVe) can also be used in place of embedding layer in neural networks. However, we need to deal with vocabularies, because the vocabulary used to pre-train Word2Vec/GloVe is likely to differ from the vocabulary in our text corpus. Have a look into the above Notebooks to see how this problem can be resolved.</p>"},{"location":"lessons/5-NLP/14-Embeddings/#contextual-embeddings","title":"Contextual Embeddings","text":"<p>One key limitation of traditional pretrained embedding representations such as Word2Vec is the problem of word sense disambiguation. While pretrained embeddings can capture some of the meaning of words in context, every possible meaning of a word is encoded into the same embedding. This can cause problems in downstream models, since many words such as the word 'play' have different meanings depending on the context they are used in.</p> <p>For example word 'play' in those two different sentences have quite different meaning:</p> <ul> <li>I went to a play at the theatre.</li> <li>John wants to play with his friends.</li> </ul> <p>The pretrained embeddings above represent both of these meanings of the word 'play' in the same embedding. To overcome this limitation, we need to build embeddings based on the language model, which is trained on a large corpus of text, and knows how words can be put together in different contexts. Discussing contextual embeddings is out of scope for this tutorial, but we will come back to them when talking about language models later in the course.</p>"},{"location":"lessons/5-NLP/14-Embeddings/#conclusion","title":"Conclusion","text":"<p>In this lesson, you discovered how to build and use embedding layers in TensorFlow and Pytorch to better reflect the semantic meanings of words.</p>"},{"location":"lessons/5-NLP/14-Embeddings/#challenge","title":"\ud83d\ude80 Challenge","text":"<p>Word2Vec has been used for some interesting applications, including generating song lyrics and poetry. Take a look at this article which walks through how the author used Word2Vec to generate poetry. Watch this video by Dan Shiffmann as well to discover a different explanation of this technique. Then try to apply these techniques to your own text corpus, perhaps sourced from Kaggle.</p>"},{"location":"lessons/5-NLP/14-Embeddings/#post-lecture-quiz","title":"Post-lecture quiz","text":""},{"location":"lessons/5-NLP/14-Embeddings/#review-self-study","title":"Review &amp; Self Study","text":"<p>Read through this paper on Word2Vec: Efficient Estimation of Word Representations in Vector Space</p>"},{"location":"lessons/5-NLP/14-Embeddings/#assignment-notebooks","title":"Assignment: Notebooks","text":""},{"location":"lessons/5-NLP/14-Embeddings/README_chs/","title":"\u5d4c\u5165","text":""},{"location":"lessons/5-NLP/14-Embeddings/README_chs/#_2","title":"\u8bfe\u524d\u6d4b\u9a8c","text":"<p>\u5728\u57fa\u4e8eBoW\u6216TF/IDF\u8bad\u7ec3\u5206\u7c7b\u5668\u65f6\uff0c\u6211\u4eec\u5904\u7406\u7684\u662f\u957f\u5ea6\u4e3a<code>vocab_size</code>\u7684\u9ad8\u7ef4\u8bcd\u888b\u5411\u91cf\uff0c\u5e76\u4e14\u6211\u4eec\u660e\u786e\u5730\u4ece\u4f4e\u7ef4\u4f4d\u7f6e\u8868\u793a\u5411\u91cf\u8f6c\u6362\u4e3a\u7a00\u758f\u7684\u72ec\u70ed\u8868\u793a\u3002\u7136\u800c\uff0c\u8fd9\u79cd\u72ec\u70ed\u8868\u793a\u5e76\u4e0d\u9ad8\u6548\u3002\u6b64\u5916\uff0c\u6bcf\u4e2a\u8bcd\u4e4b\u95f4\u90fd\u662f\u72ec\u7acb\u5904\u7406\u7684\uff0c\u5373\u72ec\u70ed\u7f16\u7801\u5411\u91cf\u4e0d\u4f53\u73b0\u4efb\u4f55\u8bcd\u8bed\u4e4b\u95f4\u7684\u8bed\u4e49\u76f8\u4f3c\u6027\u3002</p> <p>\u5d4c\u5165\u7684\u60f3\u6cd5\u662f\u901a\u8fc7\u4f4e\u7ef4\u7a20\u5bc6\u5411\u91cf\u6765\u8868\u793a\u8bcd\u8bed\uff0c\u4ece\u67d0\u79cd\u7a0b\u5ea6\u4e0a\u53cd\u6620\u8bcd\u8bed\u7684\u8bed\u4e49\u542b\u4e49\u3002\u7a0d\u540e\u6211\u4eec\u5c06\u8ba8\u8bba\u5982\u4f55\u6784\u5efa\u6709\u610f\u4e49\u7684\u8bcd\u5d4c\u5165\uff0c\u4f46\u73b0\u5728\u6211\u4eec\u5c06\u5d4c\u5165\u89c6\u4e3a\u964d\u4f4e\u8bcd\u5411\u91cf\u7ef4\u5ea6\u7684\u4e00\u79cd\u65b9\u6cd5\u3002</p> <p>\u56e0\u6b64\uff0c\u5d4c\u5165\u5c42\u4f1a\u63a5\u53d7\u4e00\u4e2a\u8bcd\u4f5c\u4e3a\u8f93\u5165\uff0c\u5e76\u751f\u6210\u4e00\u4e2a\u6307\u5b9a<code>embedding_size</code>\u7684\u8f93\u51fa\u5411\u91cf\u3002\u5728\u67d0\u79cd\u610f\u4e49\u4e0a\uff0c\u5b83\u4e0e<code>Linear</code>\u5c42\u975e\u5e38\u76f8\u4f3c\uff0c\u4f46\u5b83\u4e0d\u662f\u63a5\u53d7\u72ec\u70ed\u7f16\u7801\u5411\u91cf\uff0c\u800c\u662f\u53ef\u4ee5\u63a5\u53d7\u8bcd\u8bed\u7f16\u53f7\u4f5c\u4e3a\u8f93\u5165\uff0c\u4ece\u800c\u907f\u514d\u521b\u5efa\u5e9e\u5927\u7684\u72ec\u70ed\u7f16\u7801\u5411\u91cf\u3002</p> <p>\u901a\u8fc7\u5c06\u5d4c\u5165\u5c42\u4f5c\u4e3a\u5206\u7c7b\u5668\u7f51\u7edc\u7684\u7b2c\u4e00\u5c42\uff0c\u6211\u4eec\u53ef\u4ee5\u4ece\u8bcd\u888b\u6a21\u578b\u5207\u6362\u5230\u5d4c\u5165\u888b\u6a21\u578b\uff0c\u5728\u5176\u4e2d\u6211\u4eec\u9996\u5148\u5c06\u6587\u672c\u4e2d\u7684\u6bcf\u4e2a\u8bcd\u8f6c\u6362\u4e3a\u76f8\u5e94\u7684\u5d4c\u5165\uff0c\u7136\u540e\u5bf9\u6240\u6709\u8fd9\u4e9b\u5d4c\u5165\u8ba1\u7b97\u4e00\u4e9b\u805a\u5408\u51fd\u6570\uff0c\u4f8b\u5982<code>sum</code>\u3001<code>average</code>\u6216<code>max</code>\u3002</p> <p></p> <p>\u56fe\u7247\u4f5c\u8005</p>"},{"location":"lessons/5-NLP/14-Embeddings/README_chs/#_3","title":"\u270d\ufe0f \u7ec3\u4e60\uff1a\u5d4c\u5165","text":"<p>\u5728\u4ee5\u4e0b\u7b14\u8bb0\u672c\u4e2d\u7ee7\u7eed\u5b66\u4e60\uff1a * \u4f7f\u7528PyTorch\u5d4c\u5165 * \u4f7f\u7528TensorFlow\u5d4c\u5165</p>"},{"location":"lessons/5-NLP/14-Embeddings/README_chs/#word2vec","title":"\u8bed\u4e49\u5d4c\u5165\uff1aWord2Vec","text":"<p>\u867d\u7136\u5d4c\u5165\u5c42\u5b66\u4e60\u5c06\u8bcd\u8bed\u6620\u5c04\u5230\u5411\u91cf\u8868\u793a\uff0c\u4f46\u8fd9\u79cd\u8868\u793a\u4e0d\u4e00\u5b9a\u5177\u6709\u5f88\u5f3a\u7684\u8bed\u4e49\u610f\u4e49\u3002\u5b66\u4e60\u4e00\u4e2a\u5411\u91cf\u8868\u793a\uff0c\u4f7f\u5f97\u76f8\u4f3c\u8bcd\u6216\u540c\u4e49\u8bcd\u5bf9\u5e94\u4e8e\u5728\u67d0\u79cd\u5411\u91cf\u8ddd\u79bb\uff08\u5982\u6b27\u51e0\u91cc\u5f97\u8ddd\u79bb\uff09\u4e0a\u5f7c\u6b64\u63a5\u8fd1\u7684\u5411\u91cf\u662f\u6709\u76ca\u7684\u3002</p> <p>\u4e3a\u6b64\uff0c\u6211\u4eec\u9700\u8981\u4ee5\u7279\u5b9a\u65b9\u5f0f\u5728\u5927\u89c4\u6a21\u6587\u672c\u96c6\u5408\u4e0a\u9884\u8bad\u7ec3\u5d4c\u5165\u6a21\u578b\u3002\u8fd9\u79cd\u8fdb\u884c\u8bed\u4e49\u5d4c\u5165\u8bad\u7ec3\u7684\u65b9\u6cd5\u4e4b\u4e00\u79f0\u4e3aWord2Vec\u3002\u5b83\u57fa\u4e8e\u4e24\u79cd\u4e3b\u8981\u67b6\u6784\u6765\u751f\u6210\u8bcd\u8bed\u7684\u5206\u5e03\u5f0f\u8868\u793a\uff1a</p> <ul> <li>\u8fde\u7eed\u8bcd\u888b\uff08CBoW\uff09\u2014\u2014\u5728\u8fd9\u79cd\u67b6\u6784\u4e2d\uff0c\u6211\u4eec\u8bad\u7ec3\u6a21\u578b\u4ece\u5468\u56f4\u7684\u4e0a\u4e0b\u6587\u4e2d\u9884\u6d4b\u4e00\u4e2a\u8bcd\u3002\u7ed9\u5b9angram $(W_{-2},W_{-1},W_0,W_1,W_2)$\uff0c\u6a21\u578b\u7684\u76ee\u6807\u662f\u4ece$(W_{-2},W_{-1},W_1,W_2)$\u9884\u6d4b$W_0$\u3002</li> <li>\u8fde\u7eed\u8df3\u5b57\u6a21\u578b\u4e0eCBoW\u76f8\u53cd\uff0c\u6a21\u578b\u4f7f\u7528\u4e0a\u4e0b\u6587\u8bcd\u7684\u7a97\u53e3\u6765\u9884\u6d4b\u5f53\u524d\u8bcd\u3002</li> </ul> <p>CBoW\u66f4\u5feb\uff0c\u800c\u8df3\u5b57\u6a21\u578b\u8f83\u6162\uff0c\u4f46\u5728\u8868\u793a\u4e0d\u5e38\u89c1\u8bcd\u8bed\u65f6\u6548\u679c\u66f4\u597d\u3002</p> <p></p> <p>\u56fe\u7247\u6765\u6e90\u4e8e\u8fd9\u7bc7\u8bba\u6587</p> <p>\u9884\u8bad\u7ec3\u7684Word2Vec\u5d4c\u5165\uff08\u4ee5\u53ca\u5176\u4ed6\u7c7b\u4f3c\u6a21\u578b\uff0c\u5982GloVe\uff09\u4e5f\u53ef\u4ee5\u5728\u795e\u7ecf\u7f51\u7edc\u4e2d\u66ff\u4ee3\u5d4c\u5165\u5c42\u4f7f\u7528\u3002\u7136\u800c\uff0c\u6211\u4eec\u9700\u8981\u5904\u7406\u8bcd\u6c47\u8868\u95ee\u9898\uff0c\u56e0\u4e3a\u7528\u4e8e\u9884\u8bad\u7ec3Word2Vec/GloVe\u7684\u8bcd\u6c47\u8868\u53ef\u80fd\u4e0e\u6211\u4eec\u7684\u6587\u672c\u8bed\u6599\u5e93\u4e2d\u7684\u8bcd\u6c47\u8868\u4e0d\u540c\u3002\u8bf7\u67e5\u770b\u4e0a\u8ff0\u7b14\u8bb0\u672c\u4e86\u89e3\u5982\u4f55\u89e3\u51b3\u6b64\u95ee\u9898\u3002</p>"},{"location":"lessons/5-NLP/14-Embeddings/README_chs/#_4","title":"\u4e0a\u4e0b\u6587\u5d4c\u5165","text":"<p>\u4f20\u7edf\u7684\u9884\u8bad\u7ec3\u5d4c\u5165\u8868\u793a\uff08\u5982Word2Vec\uff09\u7684\u4e00\u4e2a\u5173\u952e\u9650\u5236\u662f\u8bcd\u4e49\u6d88\u6b67\u95ee\u9898\u3002\u867d\u7136\u9884\u8bad\u7ec3\u7684\u5d4c\u5165\u53ef\u4ee5\u5728\u67d0\u79cd\u7a0b\u5ea6\u4e0a\u6355\u6349\u8bcd\u8bed\u5728\u4e0a\u4e0b\u6587\u4e2d\u7684\u610f\u4e49\uff0c\u4f46\u8bcd\u8bed\u7684\u6bcf\u79cd\u53ef\u80fd\u610f\u4e49\u90fd\u88ab\u7f16\u7801\u5728\u540c\u4e00\u4e2a\u5d4c\u5165\u4e2d\u3002\u8fd9\u53ef\u80fd\u4f1a\u5728\u4e0b\u6e38\u6a21\u578b\u4e2d\u5f15\u8d77\u95ee\u9898\uff0c\u56e0\u4e3a\u8bb8\u591a\u8bcd\u8bed\uff08\u5982\u5355\u8bcd\u201cplay\u201d\uff09\u6839\u636e\u4f7f\u7528\u7684\u4e0a\u4e0b\u6587\u5177\u6709\u4e0d\u540c\u7684\u610f\u4e49\u3002</p> <p>\u4f8b\u5982\uff0c\u8bcd\u201cplay\u201d\u5728\u8fd9\u4e24\u4e2a\u4e0d\u540c\u53e5\u5b50\u4e2d\u7684\u610f\u4e49\u622a\u7136\u4e0d\u540c\uff1a</p> <ul> <li>\u6211\u53bb\u5267\u9662\u770b\u4e86\u4e00\u573a\u620f\u5267\u3002</li> <li>\u7ea6\u7ff0\u60f3\u548c\u670b\u53cb\u4eec\u73a9\u800d\u3002</li> </ul> <p>\u4e0a\u8ff0\u9884\u8bad\u7ec3\u5d4c\u5165\u5c06\u8bcd\u201cplay\u201d\u7684\u8fd9\u4e24\u79cd\u610f\u4e49\u8868\u793a\u4e3a\u76f8\u540c\u7684\u5d4c\u5165\u3002\u4e3a\u4e86\u514b\u670d\u8fd9\u4e00\u9650\u5236\uff0c\u6211\u4eec\u9700\u8981\u57fa\u4e8e\u8bed\u8a00\u6a21\u578b\u6784\u5efa\u5d4c\u5165\uff0c\u8be5\u6a21\u578b\u5728\u5927\u89c4\u6a21\u6587\u672c\u8bed\u6599\u5e93\u4e0a\u8fdb\u884c\u8bad\u7ec3\uff0c\u5e76\u4e14\u77e5\u9053\u5982\u4f55\u5728\u4e0d\u540c\u4e0a\u4e0b\u6587\u4e2d\u7ec4\u5408\u8bcd\u8bed\u3002\u672c\u6559\u7a0b\u4e0d\u8ba8\u8bba\u4e0a\u4e0b\u6587\u5d4c\u5165\uff0c\u4f46\u6211\u4eec\u4f1a\u5728\u8bfe\u7a0b\u540e\u7eed\u8ba8\u8bba\u8bed\u8a00\u6a21\u578b\u65f6\u91cd\u6e29\u8fd9\u4e00\u4e3b\u9898\u3002</p>"},{"location":"lessons/5-NLP/14-Embeddings/README_chs/#_5","title":"\u603b\u7ed3","text":"<p>\u5728\u672c\u8bfe\u4e2d\uff0c\u4f60\u4e86\u89e3\u4e86\u5982\u4f55\u5728TensorFlow\u548cPytorch\u4e2d\u6784\u5efa\u548c\u4f7f\u7528\u5d4c\u5165\u5c42\u4ee5\u66f4\u597d\u5730\u53cd\u6620\u8bcd\u8bed\u7684\u8bed\u4e49\u610f\u4e49\u3002</p>"},{"location":"lessons/5-NLP/14-Embeddings/README_chs/#_6","title":"\ud83d\ude80 \u6311\u6218","text":"<p>Word2Vec\u5df2\u88ab\u7528\u4e8e\u4e00\u4e9b\u6709\u8da3\u7684\u5e94\u7528\uff0c\u5305\u62ec\u751f\u6210\u6b4c\u8bcd\u548c\u8bd7\u6b4c\u3002\u8bf7\u67e5\u9605\u8fd9\u7bc7\u6587\u7ae0\uff0c\u4e86\u89e3\u4f5c\u8005\u5982\u4f55\u4f7f\u7528Word2Vec\u751f\u6210\u8bd7\u6b4c\u3002\u8fd8\u53ef\u4ee5\u89c2\u770bDan Shiffmann\u7684\u89c6\u9891\uff0c\u4e86\u89e3\u8fd9\u79cd\u6280\u672f\u7684\u4e0d\u540c\u89e3\u91ca\u3002\u7136\u540e\u5c1d\u8bd5\u5c06\u8fd9\u4e9b\u6280\u672f\u5e94\u7528\u5230\u4f60\u81ea\u5df1\u7684\u6587\u672c\u8bed\u6599\u5e93\u4e2d\uff0c\u53ef\u80fd\u6765\u81eaKaggle\u3002</p>"},{"location":"lessons/5-NLP/14-Embeddings/README_chs/#_7","title":"\u8bfe\u540e\u6d4b\u9a8c","text":""},{"location":"lessons/5-NLP/14-Embeddings/README_chs/#_8","title":"\u590d\u4e60\u4e0e\u81ea\u5b66","text":"<p>\u9605\u8bfb\u8fd9\u7bc7\u5173\u4e8eWord2Vec\u7684\u8bba\u6587\uff1a\u5728\u5411\u91cf\u7a7a\u95f4\u4e2d\u9ad8\u6548\u4f30\u8ba1\u8bcd\u8bed\u8868\u793a</p>"},{"location":"lessons/5-NLP/14-Embeddings/README_chs/#_9","title":"\u4f5c\u4e1a\uff1a\u7b14\u8bb0\u672c","text":""},{"location":"lessons/5-NLP/14-Embeddings/assignment/","title":"Assignment: Notebooks","text":"<p>Using the notebooks associated to this lesson (either the PyTorch or the TensorFlow version), rerun them using your own dataset, perhaps one from Kaggle, used with attribution. Rewrite the notebook to underline your own findings. Try a different kind of dataset and document your findings, using text such as these Beatles lyrics.</p>"},{"location":"lessons/5-NLP/14-Embeddings/assignment_chs/","title":"\u4f5c\u4e1a: \u7b14\u8bb0\u672c","text":"<p>\u4f7f\u7528\u4e0e\u672c\u8bfe\u76f8\u5173\u7684\u7b14\u8bb0\u672c\uff08\u65e0\u8bba\u662fPyTorch\u7248\u672c\u8fd8\u662fTensorFlow\u7248\u672c\uff09\uff0c\u4f7f\u7528\u60a8\u81ea\u5df1\u7684\u6570\u636e\u96c6\u91cd\u65b0\u8fd0\u884c\u5b83\u4eec\uff0c\u53ef\u80fd\u662f\u4f7f\u7528Kaggle\u7684\u6570\u636e\u96c6\uff0c\u5e76\u6ce8\u660e\u51fa\u5904\u3002\u91cd\u5199\u7b14\u8bb0\u672c\u4ee5\u5f3a\u8c03\u60a8\u81ea\u5df1\u7684\u53d1\u73b0\u3002\u5c1d\u8bd5\u4e0d\u540c\u7c7b\u578b\u7684\u6570\u636e\u96c6\u5e76\u8bb0\u5f55\u60a8\u7684\u53d1\u73b0\uff0c\u4f7f\u7528\u8bf8\u5982\u8fd9\u4e9b\u62ab\u5934\u58eb\u6b4c\u8bcd\u4e4b\u7c7b\u7684\u6587\u672c\u3002</p>"},{"location":"lessons/5-NLP/15-LanguageModeling/","title":"Language Modeling","text":"<p>Semantic embeddings, such as Word2Vec and GloVe, are in fact a first step towards language modeling - creating models that somehow understand (or represent) the nature of the language.</p>"},{"location":"lessons/5-NLP/15-LanguageModeling/#pre-lecture-quiz","title":"Pre-lecture quiz","text":"<p>The main idea behind language modeling is training them on unlabeled datasets in an unsupervised manner. This is important because we have huge amounts of unlabeled text available, while the amount of labeled text would always be limited by the amount of effort we can spend on labeling. Most often, we can build language models that can predict missing words in the text, because it is easy to mask out a random word in text and use it as a training sample.</p>"},{"location":"lessons/5-NLP/15-LanguageModeling/#training-embeddings","title":"Training Embeddings","text":"<p>In our previous examples, we used pre-trained semantic embeddings, but it is interesting to see how those embeddings can be trained. There are several possible ideas the can be used:</p> <ul> <li>N-Gram language modeling, when we predict a token by looking at N previous tokens (N-gram)</li> <li>Continuous Bag-of-Words (CBoW), when we predict the middle token $W_0$ in a token sequence $W_{-N}$, ..., $W_N$.</li> <li>Skip-gram, where we predict a set of neighboring tokens {$W_{-N},\\dots, W_{-1}, W_1,\\dots, W_N$} from the middle token $W_0$.</li> </ul> <p></p> <p>Image from this paper</p>"},{"location":"lessons/5-NLP/15-LanguageModeling/#example-notebooks-training-cbow-model","title":"\u270d\ufe0f Example Notebooks: Training CBoW model","text":"<p>Continue your learning in the following notebooks:</p> <ul> <li>Training CBoW Word2Vec with TensorFlow</li> <li>Training CBoW Word2Vec with PyTorch</li> </ul>"},{"location":"lessons/5-NLP/15-LanguageModeling/#conclusion","title":"Conclusion","text":"<p>In the previous lesson we have seen that words embeddings work like magic! Now we know that training word embeddings is not a very complex task, and we should be able to train our own word embeddings for domain specific text if needed. </p>"},{"location":"lessons/5-NLP/15-LanguageModeling/#post-lecture-quiz","title":"Post-lecture quiz","text":""},{"location":"lessons/5-NLP/15-LanguageModeling/#review-self-study","title":"Review &amp; Self Study","text":"<ul> <li>Official PyTorch tutorial on Language Modeling.</li> <li>Official TensorFlow tutorial on training Word2Vec model.</li> <li>Using the gensim framework to train most commonly used embeddings in a few lines of code is described in this documentation.</li> </ul>"},{"location":"lessons/5-NLP/15-LanguageModeling/#assignment-train-skip-gram-model","title":"\ud83d\ude80 Assignment: Train Skip-Gram Model","text":"<p>In the lab, we challenge you to modify the code from this lesson to train skip-gram model instead of CBoW. Read the details</p>"},{"location":"lessons/5-NLP/15-LanguageModeling/README_chs/","title":"\u8bed\u8a00\u5efa\u6a21","text":"<p>\u8bed\u4e49\u5d4c\u5165\uff0c\u4f8b\u5982Word2Vec\u548cGloVe\uff0c\u5b9e\u9645\u4e0a\u662f\u8bed\u8a00\u5efa\u6a21\u7684\u7b2c\u4e00\u6b65\u2014\u2014\u521b\u5efa\u4e00\u79cd\u80fd\u591f\u7406\u89e3\uff08\u6216\u8868\u793a\uff09\u8bed\u8a00\u672c\u8d28\u7684\u6a21\u578b\u3002</p>"},{"location":"lessons/5-NLP/15-LanguageModeling/README_chs/#_2","title":"\u8bfe\u524d\u6d4b\u9a8c","text":"<p>\u8bed\u8a00\u5efa\u6a21\u80cc\u540e\u7684\u4e3b\u8981\u601d\u60f3\u662f\u4ee5\u65e0\u76d1\u7763\u65b9\u5f0f\u5728\u672a\u6807\u8bb0\u7684\u6570\u636e\u96c6\u4e0a\u8fdb\u884c\u8bad\u7ec3\u3002\u8fd9\u5f88\u91cd\u8981\uff0c\u56e0\u4e3a\u6211\u4eec\u6709\u5927\u91cf\u7684\u672a\u6807\u8bb0\u6587\u672c\u53ef\u7528\uff0c\u800c\u6807\u8bb0\u6587\u672c\u7684\u6570\u91cf\u603b\u662f\u53d7\u5230\u6211\u4eec\u53ef\u4ee5\u82b1\u8d39\u5728\u6807\u8bb0\u4e0a\u7684\u52aa\u529b\u7684\u9650\u5236\u3002\u901a\u5e38\uff0c\u6211\u4eec\u53ef\u4ee5\u6784\u5efa\u8bed\u8a00\u6a21\u578b\u6765\u9884\u6d4b\u6587\u672c\u4e2d\u7f3a\u5931\u7684\u5355\u8bcd\uff0c\u56e0\u4e3a\u5728\u6587\u672c\u4e2d\u968f\u673a\u5c4f\u853d\u4e00\u4e2a\u5355\u8bcd\u5e76\u7528\u5b83\u4f5c\u4e3a\u8bad\u7ec3\u6837\u672c\u662f\u5f88\u5bb9\u6613\u7684\u3002</p>"},{"location":"lessons/5-NLP/15-LanguageModeling/README_chs/#_3","title":"\u8bad\u7ec3\u5d4c\u5165","text":"<p>\u5728\u4e4b\u524d\u7684\u4f8b\u5b50\u4e2d\uff0c\u6211\u4eec\u4f7f\u7528\u4e86\u9884\u8bad\u7ec3\u7684\u8bed\u4e49\u5d4c\u5165\uff0c\u4f46\u770b\u770b\u8fd9\u4e9b\u5d4c\u5165\u662f\u5982\u4f55\u8bad\u7ec3\u7684\u4e5f\u662f\u5f88\u6709\u8da3\u7684\u3002\u6709\u51e0\u79cd\u53ef\u80fd\u7684\u60f3\u6cd5\u53ef\u4ee5\u4f7f\u7528\uff1a</p> <ul> <li>N-Gram\u8bed\u8a00\u5efa\u6a21\uff0c\u6211\u4eec\u901a\u8fc7\u67e5\u770b\u524dN\u4e2a\u6807\u8bb0\uff08N-gram\uff09\u6765\u9884\u6d4b\u4e00\u4e2a\u6807\u8bb0</li> <li>\u8fde\u7eed\u8bcd\u888b\u6a21\u578b\uff08CBoW\uff09\uff0c\u6211\u4eec\u5728\u4e00\u4e2a\u6807\u8bb0\u5e8f\u5217$W_{-N}$, ..., $W_N$\u4e2d\u9884\u6d4b\u4e2d\u95f4\u6807\u8bb0$W_0$</li> <li>\u8df3\u8bcd\u6a21\u578b\uff08Skip-gram\uff09\uff0c\u6211\u4eec\u4ece\u4e2d\u95f4\u6807\u8bb0$W_0$\u9884\u6d4b\u4e00\u7ec4\u76f8\u90bb\u6807\u8bb0{$W_{-N},\\dots, W_{-1}, W_1,\\dots, W_N$}</li> </ul> <p></p> <p>\u56fe\u7247\u6765\u81ea\u8fd9\u7bc7\u8bba\u6587</p>"},{"location":"lessons/5-NLP/15-LanguageModeling/README_chs/#cbow","title":"\u270d\ufe0f \u793a\u4f8b\u7b14\u8bb0\u672c\uff1a\u8bad\u7ec3CBoW\u6a21\u578b","text":"<p>\u5728\u4ee5\u4e0b\u7b14\u8bb0\u672c\u4e2d\u7ee7\u7eed\u5b66\u4e60\uff1a</p> <ul> <li>\u4f7f\u7528TensorFlow\u8bad\u7ec3CBoW Word2Vec</li> <li>\u4f7f\u7528PyTorch\u8bad\u7ec3CBoW Word2Vec</li> </ul>"},{"location":"lessons/5-NLP/15-LanguageModeling/README_chs/#_4","title":"\u7ed3\u8bba","text":"<p>\u5728\u4e0a\u4e00\u8bfe\u4e2d\uff0c\u6211\u4eec\u770b\u5230\u4e86\u5355\u8bcd\u5d4c\u5165\u7684\u795e\u5947\u4e4b\u5904\uff01\u73b0\u5728\u6211\u4eec\u77e5\u9053\u8bad\u7ec3\u5355\u8bcd\u5d4c\u5165\u5e76\u4e0d\u662f\u4e00\u9879\u975e\u5e38\u590d\u6742\u7684\u4efb\u52a1\uff0c\u5982\u679c\u9700\u8981\u7684\u8bdd\uff0c\u6211\u4eec\u5e94\u8be5\u80fd\u591f\u8bad\u7ec3\u6211\u4eec\u81ea\u5df1\u7684\u9886\u57df\u7279\u5b9a\u6587\u672c\u7684\u5355\u8bcd\u5d4c\u5165\u3002</p>"},{"location":"lessons/5-NLP/15-LanguageModeling/README_chs/#_5","title":"\u8bfe\u540e\u6d4b\u9a8c","text":""},{"location":"lessons/5-NLP/15-LanguageModeling/README_chs/#_6","title":"\u590d\u4e60\u4e0e\u81ea\u5b66","text":"<ul> <li>\u5b98\u65b9PyTorch\u8bed\u8a00\u5efa\u6a21\u6559\u7a0b</li> <li>\u5b98\u65b9TensorFlow\u8bad\u7ec3Word2Vec\u6a21\u578b\u6559\u7a0b</li> <li>\u5728gensim\u6846\u67b6\u4e2d\u4f7f\u7528\u51e0\u884c\u4ee3\u7801\u8bad\u7ec3\u6700\u5e38\u7528\u7684\u5d4c\u5165\u7684\u63cf\u8ff0\u5728\u6b64\u6587\u6863</li> </ul>"},{"location":"lessons/5-NLP/15-LanguageModeling/README_chs/#skip-gram","title":"\ud83d\ude80 \u4efb\u52a1\uff1a\u8bad\u7ec3Skip-Gram\u6a21\u578b","text":"<p>\u5728\u5b9e\u9a8c\u4e2d\uff0c\u6211\u4eec\u6311\u6218\u4f60\u4fee\u6539\u672c\u8bfe\u7684\u4ee3\u7801\u6765\u8bad\u7ec3\u8df3\u8bcd\uff08Skip-gram\uff09\u6a21\u578b\u800c\u4e0d\u662fCBoW\u3002\u9605\u8bfb\u8be6\u60c5</p>"},{"location":"lessons/5-NLP/15-LanguageModeling/lab/","title":"Training Skip-Gram Model","text":"<p>Lab Assignment from AI for Beginners Curriculum.</p>"},{"location":"lessons/5-NLP/15-LanguageModeling/lab/#task","title":"Task","text":"<p>In this lab, you we challenge you to train Word2Vec model using Skip-Gram technique. Train a network with embedding to predict neighboring words in $N$-tokens-wide Skip-Gram window. You can use the code from this lesson, and slightly modify it.</p>"},{"location":"lessons/5-NLP/15-LanguageModeling/lab/#the-dataset","title":"The Dataset","text":"<p>You are welcome to use any book. You can find a lot of free texts at Project Gutenberg, for example, here is a direct link to Alice's Adventures in Wonderland) by Lewis Carroll. Or, you can use Shakespeare's plays, which you can get using the following code:</p> <pre><code>path_to_file = tf.keras.utils.get_file(\n   'shakespeare.txt', \n   'https://storage.googleapis.com/download.tensorflow.org/data/shakespeare.txt')\ntext = open(path_to_file, 'rb').read().decode(encoding='utf-8')\n</code></pre>"},{"location":"lessons/5-NLP/15-LanguageModeling/lab/#explore","title":"Explore!","text":"<p>If you have time and want to get deeper into the subject, try to explore several things:</p> <ul> <li>How does embedding size affects the results?</li> <li>How does different text styles affect the result?</li> <li>Take several very different types of words and their synonyms, obtain their vector representations, apply PCA to reduce dimensions to 2, and plot them in 2D space. Do you see any patterns?</li> </ul>"},{"location":"lessons/5-NLP/15-LanguageModeling/lab/README_chs/","title":"\u8bad\u7ec3 Skip-Gram \u6a21\u578b","text":"<p>\u6765\u81ea AI for Beginners \u8bfe\u7a0b \u7684\u5b9e\u9a8c\u4efb\u52a1\u3002</p>"},{"location":"lessons/5-NLP/15-LanguageModeling/lab/README_chs/#_1","title":"\u4efb\u52a1","text":"<p>\u5728\u672c\u5b9e\u9a8c\u4e2d\uff0c\u6211\u4eec\u6311\u6218\u4f60\u4f7f\u7528 Skip-Gram \u6280\u672f\u8bad\u7ec3 Word2Vec \u6a21\u578b\u3002\u8bad\u7ec3\u4e00\u4e2a\u5e26\u6709\u5d4c\u5165\u7684\u7f51\u7edc\u6765\u9884\u6d4b $N$ \u4e2a\u8bcd\u4ee4\u5bbd Skip-Gram \u7a97\u53e3\u4e2d\u7684\u76f8\u90bb\u8bcd\u3002\u4f60\u53ef\u4ee5\u4f7f\u7528\u672c\u8bfe\u7684\u4ee3\u7801\uff0c\u5e76\u7a0d\u5fae\u4fee\u6539\u5b83\u3002</p>"},{"location":"lessons/5-NLP/15-LanguageModeling/lab/README_chs/#_2","title":"\u6570\u636e\u96c6","text":"<p>\u4f60\u53ef\u4ee5\u4f7f\u7528\u4efb\u4f55\u4e66\u7c4d\u3002\u5728 Project Gutenberg \u53ef\u4ee5\u627e\u5230\u8bb8\u591a\u514d\u8d39\u6587\u672c\uff0c\u4f8b\u5982\uff0c\u8fd9\u91cc\u662f\u5218\u6613\u65af\u00b7\u5361\u7f57\u5c14\u7684\u7231\u4e3d\u4e1d\u68a6\u6e38\u4ed9\u5883\u7684\u76f4\u63a5\u94fe\u63a5\u3002\u6216\u8005\uff0c\u4f60\u53ef\u4ee5\u4f7f\u7528\u838e\u58eb\u6bd4\u4e9a\u7684\u5267\u4f5c\uff0c\u53ef\u4ee5\u4f7f\u7528\u4ee5\u4e0b\u4ee3\u7801\u83b7\u53d6\uff1a</p> <pre><code>path_to_file = tf.keras.utils.get_file(\n   'shakespeare.txt', \n   'https://storage.googleapis.com/download.tensorflow.org/data/shakespeare.txt')\ntext = open(path_to_file, 'rb').read().decode(encoding='utf-8')\n</code></pre>"},{"location":"lessons/5-NLP/15-LanguageModeling/lab/README_chs/#_3","title":"\u63a2\u7d22\uff01","text":"<p>\u5982\u679c\u4f60\u6709\u65f6\u95f4\u5e76\u4e14\u60f3\u6df1\u5165\u7814\u7a76\u8fd9\u4e2a\u4e3b\u9898\uff0c\u5c1d\u8bd5\u63a2\u7d22\u51e0\u4ef6\u4e8b\uff1a</p> <ul> <li>\u5d4c\u5165\u7ef4\u5ea6\u5bf9\u7ed3\u679c\u6709\u4f55\u5f71\u54cd\uff1f</li> <li>\u4e0d\u540c\u7684\u6587\u672c\u98ce\u683c\u5bf9\u7ed3\u679c\u6709\u4f55\u5f71\u54cd\uff1f</li> <li>\u9009\u62e9\u51e0\u79cd\u975e\u5e38\u4e0d\u540c\u7c7b\u578b\u7684\u8bcd\u53ca\u5176\u540c\u4e49\u8bcd\uff0c\u83b7\u53d6\u5b83\u4eec\u7684\u5411\u91cf\u8868\u793a\uff0c\u5e94\u7528 PCA \u5c06\u7ef4\u5ea6\u51cf\u5c11\u5230 2\uff0c\u5e76\u5c06\u5b83\u4eec\u7ed8\u5236\u5728\u4e8c\u7ef4\u7a7a\u95f4\u4e2d\u3002\u4f60\u80fd\u770b\u5230\u4efb\u4f55\u6a21\u5f0f\u5417\uff1f</li> </ul>"},{"location":"lessons/5-NLP/16-RNN/","title":"Recurrent Neural Networks","text":""},{"location":"lessons/5-NLP/16-RNN/#pre-lecture-quiz","title":"Pre-lecture quiz","text":"<p>In previous sections, we have been using rich semantic representations of text and a simple linear classifier on top of the embeddings. What this architecture does is to capture the aggregated meaning of words in a sentence, but it does not take into account the order of words, because the aggregation operation on top of embeddings removed this information from the original text. Because these models are unable to model word ordering, they cannot solve more complex or ambiguous tasks such as text generation or question answering.</p> <p>To capture the meaning of text sequence, we need to use another neural network architecture, which is called a recurrent neural network, or RNN. In RNN, we pass our sentence through the network one symbol at a time, and the network produces some state, which we then pass to the network again with the next symbol.</p> <p></p> <p>Image by the author</p> <p>Given the input sequence of tokens X<sub>0</sub>,...,X<sub>n</sub>, RNN creates a sequence of neural network blocks, and trains this sequence end-to-end using backpropagation. Each network block takes a pair (X<sub>i</sub>,S<sub>i</sub>) as an input, and produces S<sub>i+1</sub> as a result. The final state S<sub>n</sub> or (output Y<sub>n</sub>) goes into a linear classifier to produce the result. All the network blocks share the same weights, and are trained end-to-end using one backpropagation pass.</p> <p>Because state vectors S<sub>0</sub>,...,S<sub>n</sub> are passed through the network, it is able to learn the sequential dependencies between words. For example, when the word not appears somewhere in the sequence, it can learn to negate certain elements within the state vector, resulting in negation.</p> <p>\u2705 Since the weights of all RNN blocks on the picture above are shared, the same picture can be represented as one block (on the right) with a recurrent feedback loop, which passes the output state of the network back to the input.</p>"},{"location":"lessons/5-NLP/16-RNN/#anatomy-of-an-rnn-cell","title":"Anatomy of an RNN Cell","text":"<p>Let's see how a simple RNN cell is organized. It accepts the previous state S<sub>i-1</sub> and current symbol X<sub>i</sub> as inputs, and has to produce the output state S<sub>i</sub> (and, sometimes, we are also interested in some other output Y<sub>i</sub>, as in the case with generative networks).</p> <p>A simple RNN cell has two weight matrices inside: one transforms an input symbol (let's call it W), and another one transforms an input state (H). In this case the output of the network is calculated as \u03c3(W\u00d7X<sub>i</sub>+H\u00d7S<sub>i-1</sub>+b), where \u03c3 is the activation function and b is additional bias.</p> <p></p> <p>Image by the author</p> <p>In many cases, input tokens are passed through the embedding layer before entering the RNN to lower the dimensionality. In this case, if the dimension of the input vectors is emb_size, and state vector is hid_size - the size of W is emb_size\u00d7hid_size, and the size of H is hid_size\u00d7hid_size.</p>"},{"location":"lessons/5-NLP/16-RNN/#long-short-term-memory-lstm","title":"Long Short Term Memory (LSTM)","text":"<p>One of the main problems of classical RNNs is the so-called vanishing gradients problem. Because RNNs are trained end-to-end in one backpropagation pass, it has difficulty propagating error to the first layers of the network, and thus the network cannot learn relationships between distant tokens. One of the ways to avoid this problem is to introduce explicit state management by using so called gates. There are two well-known architectures of this kind: Long Short Term Memory (LSTM) and Gated Relay Unit (GRU).</p> <p></p> <p>Image source TBD</p> <p>The LSTM Network is organized in a manner similar to RNN, but there are two states that are being passed from layer to layer: the actual state C, and the hidden vector H. At each unit, the hidden vector H<sub>i</sub> is concatenated with input X<sub>i</sub>, and they control what happens to the state C via gates. Each gate is a neural network with sigmoid activation (output in the range [0,1]), which can be thought of as a bitwise mask when multiplied by the state vector. There are the following gates (from left to right on the picture above):</p> <ul> <li>The forget gate takes a hidden vector and determines which components of the vector C we need to forget, and which to pass through.</li> <li>The input gate takes some information from the input and hidden vectors and inserts it into state.</li> <li>The output gate transforms state via a linear layer with tanh activation, then selects some of its components using a hidden vector H<sub>i</sub> to produce a new state C<sub>i+1</sub>.</li> </ul> <p>Components of the state C can be thought of as some flags that can be switched on and off. For example, when we encounter a name Alice in the sequence, we may want to assume that it refers to a female character, and raise the flag in the state that we have a female noun in the sentence. When we further encounter phrases and Tom, we will raise the flag that we have a plural noun. Thus by manipulating state we can supposedly keep track of the grammatical properties of sentence parts.</p> <p>\u2705 An excellent resource for understanding the internals of LSTM is this great article Understanding LSTM Networks by Christopher Olah.</p>"},{"location":"lessons/5-NLP/16-RNN/#bidirectional-and-multilayer-rnns","title":"Bidirectional and Multilayer RNNs","text":"<p>We have discussed recurrent networks that operate in one direction, from beginning of a sequence to the end. It looks natural, because it resembles the way we read and listen to speech. However, since in many practical cases we have random access to the input sequence, it might make sense to run recurrent computation in both directions. Such networks are call bidirectional RNNs. When dealing with bidirectional network, we would need two hidden state vectors, one for each direction.</p> <p>A Recurrent network, either one-directional or bidirectional, captures certain patterns within a sequence, and can store them into a state vector or pass into output. As with convolutional networks, we can build another recurrent layer on top of the first one to capture higher level patterns and build from low-level patterns extracted by the first layer. This leads us to the notion of a multi-layer RNN which consists of two or more recurrent networks, where the output of the previous layer is passed to the next layer as input.</p> <p></p> <p>Picture from this wonderful post by Fernando L\u00f3pez</p>"},{"location":"lessons/5-NLP/16-RNN/#exercises-embeddings","title":"\u270d\ufe0f Exercises: Embeddings","text":"<p>Continue your learning in the following notebooks:</p> <ul> <li>RNNs with PyTorch</li> <li>RNNs with TensorFlow</li> </ul>"},{"location":"lessons/5-NLP/16-RNN/#conclusion","title":"Conclusion","text":"<p>In this unit, we have seen that RNNs can be used for sequence classification, but in fact, they can handle many more tasks, such as text generation, machine translation, and more. We will consider those tasks in the next unit.</p>"},{"location":"lessons/5-NLP/16-RNN/#challenge","title":"\ud83d\ude80 Challenge","text":"<p>Read through some literature about LSTMs and consider their applications:</p> <ul> <li>Grid Long Short-Term Memory</li> <li>Show, Attend and Tell: Neural Image Caption Generation with Visual Attention</li> </ul>"},{"location":"lessons/5-NLP/16-RNN/#post-lecture-quiz","title":"Post-lecture quiz","text":""},{"location":"lessons/5-NLP/16-RNN/#review-self-study","title":"Review &amp; Self Study","text":"<ul> <li>Understanding LSTM Networks by Christopher Olah.</li> </ul>"},{"location":"lessons/5-NLP/16-RNN/#assignment-notebooks","title":"Assignment: Notebooks","text":""},{"location":"lessons/5-NLP/16-RNN/README_chs/","title":"\u5faa\u73af\u795e\u7ecf\u7f51\u7edc","text":""},{"location":"lessons/5-NLP/16-RNN/README_chs/#_2","title":"\u8bfe\u524d\u6d4b\u9a8c","text":"<p>\u5728\u4e4b\u524d\u7684\u7ae0\u8282\u4e2d\uff0c\u6211\u4eec\u4f7f\u7528\u4e86\u4e30\u5bcc\u7684\u6587\u672c\u8bed\u4e49\u8868\u793a\uff0c\u5e76\u5728\u5d4c\u5165\u4e4b\u4e0a\u4f7f\u7528\u4e86\u4e00\u4e2a\u7b80\u5355\u7684\u7ebf\u6027\u5206\u7c7b\u5668\u3002\u8fd9\u79cd\u67b6\u6784\u7684\u4f5c\u7528\u662f\u6355\u6349\u53e5\u5b50\u4e2d\u5355\u8bcd\u7684\u805a\u5408\u610f\u4e49\uff0c\u4f46\u5b83\u6ca1\u6709\u8003\u8651\u5230\u5355\u8bcd\u7684\u987a\u5e8f\uff0c\u56e0\u4e3a\u5d4c\u5165\u4e4b\u4e0a\u7684\u805a\u5408\u64cd\u4f5c\u79fb\u9664\u4e86\u539f\u59cb\u6587\u672c\u4e2d\u7684\u8fd9\u90e8\u5206\u4fe1\u606f\u3002\u7531\u4e8e\u8fd9\u4e9b\u6a21\u578b\u65e0\u6cd5\u5bf9\u5355\u8bcd\u987a\u5e8f\u8fdb\u884c\u5efa\u6a21\uff0c\u65e0\u6cd5\u89e3\u51b3\u66f4\u590d\u6742\u6216\u542b\u7cca\u7684\u4efb\u52a1\uff0c\u5982\u6587\u672c\u751f\u6210\u6216\u95ee\u9898\u89e3\u7b54\u3002</p> <p>\u4e3a\u4e86\u6355\u6349\u6587\u672c\u5e8f\u5217\u7684\u610f\u4e49\uff0c\u6211\u4eec\u9700\u8981\u4f7f\u7528\u53e6\u4e00\u79cd\u795e\u7ecf\u7f51\u7edc\u67b6\u6784\uff0c\u79f0\u4e3a\u5faa\u73af\u795e\u7ecf\u7f51\u7edc\uff0c\u7b80\u79f0RNN\u3002\u5728RNN\u4e2d\uff0c\u6211\u4eec\u5c06\u53e5\u5b50\u4e00\u4e2a\u7b26\u53f7\u63a5\u4e00\u4e2a\u7b26\u53f7\u5730\u901a\u8fc7\u7f51\u7edc\uff0c\u7f51\u7edc\u4f1a\u4ea7\u751f\u67d0\u79cd\u72b6\u6001\uff0c\u7136\u540e\u6211\u4eec\u5c06\u8be5\u72b6\u6001\u4e0e\u4e0b\u4e00\u4e2a\u7b26\u53f7\u4e00\u8d77\u518d\u6b21\u4f20\u9012\u7ed9\u7f51\u7edc\u3002</p> <p></p> <p>\u56fe\u7247\u4f5c\u8005\u6240\u6709</p> <p>\u7ed9\u5b9a\u8f93\u5165\u5e8f\u5217\u7684\u4ee4\u724cX<sub>0</sub>,...,X<sub>n</sub>\uff0cRNN\u521b\u5efa\u4e00\u4e2a\u795e\u7ecf\u7f51\u7edc\u5757\u7684\u5e8f\u5217\uff0c\u5e76\u4f7f\u7528\u53cd\u5411\u4f20\u64ad\u7aef\u5230\u7aef\u5730\u8bad\u7ec3\u8fd9\u4e2a\u5e8f\u5217\u3002\u6bcf\u4e2a\u7f51\u7edc\u5757\u5c06\u4e00\u5bf9(X<sub>i</sub>,S<sub>i</sub>)\u4f5c\u4e3a\u8f93\u5165\uff0c\u751f\u6210S<sub>i+1</sub>\u4f5c\u4e3a\u7ed3\u679c\u3002\u6700\u7ec8\u72b6\u6001S<sub>n</sub>\u6216(\u8f93\u51faY<sub>n</sub>)\u8fdb\u5165\u4e00\u4e2a\u7ebf\u6027\u5206\u7c7b\u5668\u4ee5\u751f\u6210\u7ed3\u679c\u3002\u6240\u6709\u7684\u7f51\u7edc\u5757\u5171\u4eab\u76f8\u540c\u7684\u6743\u91cd\uff0c\u5e76\u901a\u8fc7\u4e00\u6b21\u53cd\u5411\u4f20\u64ad\u901a\u8fc7\u7aef\u5230\u7aef\u5730\u8bad\u7ec3\u3002</p> <p>\u7531\u4e8e\u72b6\u6001\u5411\u91cfS<sub>0</sub>,...,S<sub>n</sub>\u901a\u8fc7\u7f51\u7edc\u4f20\u9012\uff0c\u5b83\u80fd\u591f\u5b66\u4e60\u5355\u8bcd\u4e4b\u95f4\u7684\u987a\u5e8f\u4f9d\u8d56\u5173\u7cfb\u3002\u4f8b\u5982\uff0c\u5f53\u67d0\u4e2a\u5355\u8bcdnot\u51fa\u73b0\u5728\u5e8f\u5217\u4e2d\u7684\u67d0\u5904\u65f6\uff0c\u5b83\u53ef\u4ee5\u5b66\u4e60\u5728\u72b6\u6001\u5411\u91cf\u4e2d\u7684\u67d0\u4e9b\u5143\u7d20\u4e0a\u6267\u884c\u5426\u5b9a\uff0c\u4ece\u800c\u5b9e\u73b0\u5426\u5b9a\u3002</p> <p>\u2705 \u7531\u4e8e\u4e0a\u56fe\u4e2d\u7684\u6240\u6709RNN\u5757\u7684\u6743\u91cd\u662f\u5171\u4eab\u7684\uff0c\u53f3\u4fa7\u7684\u76f8\u540c\u56fe\u7247\u53ef\u4ee5\u8868\u793a\u4e3a\u4e00\u4e2a\u5e26\u6709\u5faa\u73af\u53cd\u9988\u73af\u7684\u5757\uff0c\u5b83\u5c06\u7f51\u7edc\u7684\u8f93\u51fa\u72b6\u6001\u8fd4\u56de\u5230\u8f93\u5165\u3002</p>"},{"location":"lessons/5-NLP/16-RNN/README_chs/#rnn","title":"RNN\u5355\u5143\u7684\u5256\u6790","text":"<p>\u8ba9\u6211\u4eec\u770b\u770b\u4e00\u4e2a\u7b80\u5355\u7684RNN\u5355\u5143\u662f\u5982\u4f55\u7ec4\u7ec7\u7684\u3002\u5b83\u63a5\u6536\u524d\u4e00\u4e2a\u72b6\u6001S<sub>i-1</sub>\u548c\u5f53\u524d\u7b26\u53f7X<sub>i</sub>\u4f5c\u4e3a\u8f93\u5165\uff0c\u5e76\u9700\u8981\u751f\u6210\u8f93\u51fa\u72b6\u6001S<sub>i</sub>\uff08\u6709\u65f6\uff0c\u6211\u4eec\u4e5f\u5bf9\u67d0\u4e9b\u5176\u4ed6\u8f93\u51faY<sub>i</sub>\u611f\u5174\u8da3\uff0c\u5c31\u50cf\u5728\u751f\u6210\u7f51\u7edc\u7684\u60c5\u51b5\u4e0b\uff09\u3002</p> <p>\u4e00\u4e2a\u7b80\u5355\u7684RNN\u5355\u5143\u91cc\u9762\u6709\u4e24\u4e2a\u6743\u91cd\u77e9\u9635\uff1a\u4e00\u4e2a\u7528\u4e8e\u8f6c\u6362\u8f93\u5165\u7b26\u53f7\uff08\u79f0\u4e3aW\uff09\uff0c\u53e6\u4e00\u4e2a\u7528\u4e8e\u8f6c\u6362\u8f93\u5165\u72b6\u6001\uff08\u79f0\u4e3aH\uff09\u3002\u5728\u8fd9\u79cd\u60c5\u51b5\u4e0b\uff0c\u7f51\u7edc\u7684\u8f93\u51fa\u8ba1\u7b97\u4e3a\u03c3(W\u00d7X<sub>i</sub>+H\u00d7S<sub>i-1</sub>+b)\uff0c\u5176\u4e2d\u03c3\u662f\u6fc0\u6d3b\u51fd\u6570\uff0cb\u662f\u9644\u52a0\u7684\u504f\u7f6e\u3002</p> <p></p> <p>\u56fe\u7247\u4f5c\u8005\u6240\u6709</p> <p>\u5728\u5f88\u591a\u60c5\u51b5\u4e0b\uff0c\u8f93\u5165\u4ee4\u724c\u5728\u8fdb\u5165RNN\u4e4b\u524d\u4f1a\u7ecf\u8fc7\u5d4c\u5165\u5c42\u4ee5\u964d\u4f4e\u7ef4\u5ea6\u3002\u5728\u8fd9\u79cd\u60c5\u51b5\u4e0b\uff0c\u5982\u679c\u8f93\u5165\u5411\u91cf\u7684\u7ef4\u5ea6\u662femb_size\uff0c\u72b6\u6001\u5411\u91cf\u662fhid_size - \u4e8e\u662fW\u7684\u5927\u5c0f\u662femb_size\u00d7hid_size\uff0c\u800cH\u7684\u5927\u5c0f\u662fhid_size\u00d7hid_size\u3002</p>"},{"location":"lessons/5-NLP/16-RNN/README_chs/#lstm","title":"\u957f\u77ed\u671f\u8bb0\u5fc6\u7f51\u7edc\uff08LSTM\uff09","text":"<p>\u7ecf\u5178RNN\u7684\u4e3b\u8981\u95ee\u9898\u4e4b\u4e00\u662f\u6240\u8c13\u7684\u68af\u5ea6\u6d88\u5931\u95ee\u9898\u3002\u7531\u4e8eRNN\u5728\u4e00\u6b21\u53cd\u5411\u4f20\u64ad\u4e2d\u7684\u7aef\u5230\u7aef\u8bad\u7ec3\uff0c\u5b83\u5f88\u96be\u5c06\u8bef\u5dee\u4f20\u64ad\u5230\u7f51\u7edc\u7684\u7b2c\u4e00\u5c42\uff0c\u56e0\u6b64\u7f51\u7edc\u65e0\u6cd5\u5b66\u4e60\u8fdc\u8ddd\u79bb\u4ee4\u724c\u4e4b\u95f4\u7684\u5173\u7cfb\u3002\u89e3\u51b3\u8fd9\u4e2a\u95ee\u9898\u7684\u65b9\u6cd5\u4e4b\u4e00\u662f\u901a\u8fc7\u4f7f\u7528\u6240\u8c13\u7684\u95e8\u63a7\u5f15\u5165\u663e\u5f0f\u72b6\u6001\u7ba1\u7406\u3002\u8fd9\u79cd\u67b6\u6784\u6709\u4e24\u79cd\u8f83\u4e3a\u77e5\u540d\u7684\u7c7b\u578b\uff1a\u957f\u77ed\u671f\u8bb0\u5fc6\uff08LSTM\uff09\u548c\u95e8\u63a7\u5faa\u73af\u5355\u5143\uff08GRU\uff09\u3002</p> <p></p> <p>\u56fe\u7247\u6765\u6e90\u5f85\u5b9a</p> <p>LSTM\u7f51\u7edc\u7684\u7ec4\u7ec7\u65b9\u5f0f\u7c7b\u4f3c\u4e8eRNN\uff0c\u4f46\u6709\u4e24\u4e2a\u72b6\u6001\u5728\u5c42\u4e0e\u5c42\u4e4b\u95f4\u4f20\u9012\uff1a\u5b9e\u9645\u72b6\u6001C\u548c\u9690\u85cf\u5411\u91cfH\u3002\u5728\u6bcf\u4e2a\u5355\u5143\u4e2d\uff0c\u9690\u85cf\u5411\u91cfH<sub>i</sub>\u4e0e\u8f93\u5165X<sub>i</sub>\u62fc\u63a5\u5728\u4e00\u8d77\uff0c\u5b83\u4eec\u901a\u8fc7\u95e8\u63a7\u6765\u63a7\u5236\u72b6\u6001C\u7684\u53d8\u5316\u3002\u6bcf\u4e2a\u95e8\u63a7\u90fd\u662f\u5177\u6709sigmoid\u6fc0\u6d3b\u51fd\u6570\uff08\u8f93\u51fa\u5728[0,1]\u8303\u56f4\u5185\uff09\u7684\u795e\u7ecf\u7f51\u7edc\uff0c\u4e58\u4ee5\u72b6\u6001\u5411\u91cf\u65f6\uff0c\u53ef\u4ee5\u89c6\u4e3a\u9010\u4f4d\u63a9\u7801\u3002\u4ee5\u4e0b\u662f\u5404\u4e2a\u95e8\u63a7\uff08\u4ece\u5de6\u5230\u53f3\u5982\u4e0a\u56fe\u6240\u793a\uff09\uff1a</p> <ul> <li>\u9057\u5fd8\u95e8\u63a7\u63a5\u6536\u9690\u85cf\u5411\u91cf\u5e76\u786e\u5b9a\u6211\u4eec\u9700\u8981\u5fd8\u8bb0\u72b6\u6001\u5411\u91cfC\u7684\u54ea\u4e9b\u90e8\u5206\uff0c\u4ee5\u53ca\u54ea\u4e9b\u90e8\u5206\u9700\u8981\u4fdd\u7559\u3002</li> <li>\u8f93\u5165\u95e8\u63a7\u4ece\u8f93\u5165\u548c\u9690\u85cf\u5411\u91cf\u4e2d\u63d0\u53d6\u4fe1\u606f\u5e76\u63d2\u5165\u72b6\u6001\u3002</li> <li>\u8f93\u51fa\u95e8\u63a7\u901a\u8fc7\u5e26\u6709tanh\u6fc0\u6d3b\u51fd\u6570\u7684\u7ebf\u6027\u5c42\u53d8\u6362\u72b6\u6001\uff0c\u7136\u540e\u4f7f\u7528\u9690\u85cf\u5411\u91cfH<sub>i</sub>\u9009\u62e9\u5176\u90e8\u5206\u7ec4\u6210\uff0c\u4ee5\u751f\u6210\u65b0\u72b6\u6001C<sub>i+1</sub>\u3002</li> </ul> <p>\u72b6\u6001C\u7684\u5143\u7d20\u53ef\u4ee5\u89c6\u4e3a\u67d0\u4e9b\u53ef\u4ee5\u5f00\u5173\u7684\u6807\u5fd7\u3002\u4f8b\u5982\uff0c\u5f53\u6211\u4eec\u5728\u5e8f\u5217\u4e2d\u9047\u5230\u4e00\u4e2a\u540d\u5b57Alice\u65f6\uff0c\u6211\u4eec\u53ef\u80fd\u5047\u5b9a\u5b83\u6307\u7684\u662f\u4e00\u4e2a\u5973\u6027\u89d2\u8272\uff0c\u5e76\u5728\u72b6\u6001\u4e2d\u6fc0\u6d3b\u4e00\u4e2a\u6807\u793a\u6211\u4eec\u5df2\u77e5\u53e5\u5b50\u4e2d\u6709\u5973\u6027\u540d\u8bcd\u3002\u5f53\u6211\u4eec\u8fdb\u4e00\u6b65\u9047\u5230and Tom\u65f6\uff0c\u4f1a\u6fc0\u6d3b\u8868\u793a\u6211\u4eec\u6709\u4e00\u4e2a\u590d\u6570\u540d\u8bcd\u7684\u6807\u5fd7\u3002\u56e0\u6b64\uff0c\u901a\u8fc7\u64cd\u4f5c\u72b6\u6001\uff0c\u6211\u4eec\u53ef\u4ee5\u8ddf\u8e2a\u53e5\u5b50\u90e8\u5206\u7684\u8bed\u6cd5\u5c5e\u6027\u3002</p> <p>\u2705 \u4e00\u7bc7\u7406\u89e3LSTM\u5185\u90e8\u7ed3\u6784\u7684\u7edd\u4f73\u8d44\u6e90\u662fChristopher Olah\u64b0\u5199\u7684\u7406\u89e3LSTM\u7f51\u7edc\u8fd9\u7bc7\u6587\u7ae0\u3002</p>"},{"location":"lessons/5-NLP/16-RNN/README_chs/#rnn_1","title":"\u53cc\u5411\u548c\u591a\u5c42RNN","text":"<p>\u6211\u4eec\u5df2\u7ecf\u8ba8\u8bba\u4e86\u4ece\u5e8f\u5217\u5f00\u59cb\u5230\u7ed3\u675f\u5355\u5411\u64cd\u4f5c\u7684\u5faa\u73af\u7f51\u7edc\u3002\u8fd9\u770b\u8d77\u6765\u5f88\u81ea\u7136\uff0c\u56e0\u4e3a\u5b83\u7c7b\u4f3c\u4e8e\u6211\u4eec\u9605\u8bfb\u548c\u8046\u542c\u6f14\u8bb2\u7684\u65b9\u5f0f\u3002\u7136\u800c\uff0c\u7531\u4e8e\u5728\u8bb8\u591a\u5b9e\u9645\u60c5\u51b5\u4e0b\uff0c\u6211\u4eec\u53ef\u4ee5\u968f\u673a\u8bbf\u95ee\u8f93\u5165\u5e8f\u5217\uff0c\u6240\u4ee5\u8fd0\u884c\u53cc\u5411\u7684\u5faa\u73af\u8fd0\u7b97\u4e5f\u6709\u610f\u4e49\u3002\u8fd9\u7c7b\u7f51\u7edc\u79f0\u4e3a\u53cc\u5411RNN\u3002\u5728\u5904\u7406\u53cc\u5411\u7f51\u7edc\u65f6\uff0c\u6211\u4eec\u9700\u8981\u4e24\u4e2a\u9690\u85cf\u72b6\u6001\u5411\u91cf\uff0c\u4e00\u4e2a\u7528\u4e8e\u6bcf\u4e2a\u65b9\u5411\u3002</p> <p>\u4e00\u4e2a\u5faa\u73af\u7f51\u7edc\uff0c\u65e0\u8bba\u662f\u5355\u5411\u7684\u8fd8\u662f\u53cc\u5411\u7684\uff0c\u90fd\u4f1a\u6355\u6349\u5e8f\u5217\u4e2d\u7684\u67d0\u4e9b\u6a21\u5f0f\uff0c\u5e76\u5c06\u5b83\u4eec\u5b58\u50a8\u5728\u72b6\u6001\u5411\u91cf\u4e2d\u6216\u4f20\u9012\u5230\u8f93\u51fa\u4e2d\u3002\u5c31\u50cf\u5377\u79ef\u7f51\u7edc\u4e00\u6837\uff0c\u6211\u4eec\u53ef\u4ee5\u5728\u7b2c\u4e00\u5c42\u4e4b\u4e0a\u6784\u5efa\u53e6\u4e00\u4e2a\u5faa\u73af\u5c42\uff0c\u4ee5\u6355\u6349\u66f4\u9ad8\u5c42\u6b21\u7684\u6a21\u5f0f\uff0c\u4ece\u7b2c\u4e00\u5c42\u63d0\u53d6\u7684\u4f4e\u7ea7\u6a21\u5f0f\u6784\u5efa\u9ad8\u5c42\u6a21\u5f0f\u3002\u8fd9\u5f15\u5bfc\u6211\u4eec\u5230\u591a\u5c42RNN\u7684\u6982\u5ff5\uff0c\u5b83\u7531\u4e24\u4e2a\u6216\u66f4\u591a\u7684\u5faa\u73af\u7f51\u7edc\u6784\u6210\uff0c\u5176\u4e2d\u524d\u4e00\u5c42\u7684\u8f93\u51fa\u4f5c\u4e3a\u8f93\u5165\u4f20\u9012\u5230\u4e0b\u4e00\u5c42\u3002</p> <p></p> <p>\u56fe\u7247\u6e90\u81eaFernando L\u00f3pez \u8fd9\u7bc7\u7cbe\u5f69\u7684\u6587\u7ae0</p>"},{"location":"lessons/5-NLP/16-RNN/README_chs/#_3","title":"\u270d\ufe0f \u7ec3\u4e60\uff1a\u5d4c\u5165","text":"<p>\u5728\u4ee5\u4e0b\u7b14\u8bb0\u672c\u4e2d\u7ee7\u7eed\u5b66\u4e60\uff1a</p> <ul> <li>\u4f7f\u7528PyTorch\u7684RNN</li> <li>\u4f7f\u7528TensorFlow\u7684RNN</li> </ul>"},{"location":"lessons/5-NLP/16-RNN/README_chs/#_4","title":"\u7ed3\u8bba","text":"<p>\u5728\u672c\u5355\u5143\u4e2d\uff0c\u6211\u4eec\u770b\u5230\u4e86RNN\u53ef\u7528\u4e8e\u5e8f\u5217\u5206\u7c7b\uff0c\u4f46\u5b9e\u9645\u4e0a\uff0c\u5b83\u4eec\u8fd8\u53ef\u4ee5\u5904\u7406\u8bb8\u591a\u5176\u4ed6\u4efb\u52a1\uff0c\u5982\u6587\u672c\u751f\u6210\u3001\u673a\u5668\u7ffb\u8bd1\u7b49\u3002\u5728\u4e0b\u4e00\u4e2a\u5355\u5143\u4e2d\uff0c\u6211\u4eec\u5c06\u8003\u8651\u8fd9\u4e9b\u4efb\u52a1\u3002</p>"},{"location":"lessons/5-NLP/16-RNN/README_chs/#_5","title":"\ud83d\ude80 \u6311\u6218","text":"<p>\u9605\u8bfb\u4e00\u4e9b\u5173\u4e8eLSTM\u7684\u6587\u732e\u5e76\u8003\u8651\u5176\u5e94\u7528\uff1a</p> <ul> <li>\u7f51\u683c\u957f\u77ed\u671f\u8bb0\u5fc6</li> <li>\u5c55\u793a\u3001\u5173\u6ce8\u4e0e\u8bb2\u8ff0\uff1a\u5e26\u89c6\u89c9\u6ce8\u610f\u529b\u7684\u795e\u7ecf\u56fe\u50cf\u5b57\u5e55\u751f\u6210</li> </ul>"},{"location":"lessons/5-NLP/16-RNN/README_chs/#_6","title":"\u8bfe\u540e\u6d4b\u9a8c","text":""},{"location":"lessons/5-NLP/16-RNN/README_chs/#_7","title":"\u590d\u4e60\u4e0e\u81ea\u5b66","text":"<ul> <li>\u7406\u89e3LSTM\u7f51\u7edc by Christopher Olah.</li> </ul>"},{"location":"lessons/5-NLP/16-RNN/README_chs/#_8","title":"\u4f5c\u4e1a\uff1a\u7b14\u8bb0\u672c","text":""},{"location":"lessons/5-NLP/16-RNN/assignment/","title":"Assignment: Notebooks","text":"<p>Using the notebooks associated to this lesson (either the PyTorch or the TensorFlow version), rerun them using your own dataset, perhaps one from Kaggle, used with attribution. Rewrite the notebook to underline your own findings. Try a different kind of dataset and document your findings, using text such as this Kaggle competition dataset about weather tweets.</p>"},{"location":"lessons/5-NLP/16-RNN/assignment_chs/","title":"\u4f5c\u4e1a\uff1a\u7b14\u8bb0\u672c","text":"<p>\u4f7f\u7528\u4e0e\u672c\u8bfe\u7a0b\u76f8\u5173\u7684\u7b14\u8bb0\u672c\uff08PyTorch\u6216TensorFlow\u7248\u672c\uff09\uff0c\u4f7f\u7528\u4f60\u81ea\u5df1\u7684\u6570\u636e\u96c6\u91cd\u65b0\u8fd0\u884c\u5b83\u4eec\uff0c\u6216\u8bb8\u662f\u6765\u81eaKaggle\u7684\u6570\u636e\u96c6\uff0c\u9700\u6ce8\u660e\u51fa\u5904\u3002\u91cd\u5199\u7b14\u8bb0\u672c\u4ee5\u5f3a\u8c03\u4f60\u81ea\u5df1\u7684\u53d1\u73b0\u3002\u5c1d\u8bd5\u4f7f\u7528\u4e0d\u540c\u79cd\u7c7b\u7684\u6570\u636e\u96c6\u5e76\u8bb0\u5f55\u4f60\u7684\u53d1\u73b0\uff0c\u4f7f\u7528\u7c7b\u4f3c\u5982\u4e0b\u6587\u672c\uff1a\u8fd9\u4e2a\u5173\u4e8e\u5929\u6c14\u63a8\u6587\u7684Kaggle\u7ade\u8d5b\u6570\u636e\u96c6\u3002</p>"},{"location":"lessons/5-NLP/17-GenerativeNetworks/","title":"Generative networks","text":""},{"location":"lessons/5-NLP/17-GenerativeNetworks/#pre-lecture-quiz","title":"Pre-lecture quiz","text":"<p>Recurrent Neural Networks (RNNs) and their gated cell variants such as Long Short Term Memory Cells (LSTMs) and Gated Recurrent Units (GRUs) provided a mechanism for language modeling in that they can learn word ordering and provide predictions for the next word in a sequence. This allows us to use RNNs for generative tasks, such as ordinary text generation, machine translation, and even image captioning.</p> <p>\u2705 Think about all the times you've benefited from generative tasks such as text completion as you type. Do some research into your favorite applications to see if they leveraged RNNs.</p> <p>In RNN architecture we discussed in the previous unit, each RNN unit produced the next hidden state as an output. However, we can also add another output to each recurrent unit, which would allow us to output a sequence (which is equal in length to the original sequence). Moreover, we can use RNN units that do not accept an input at each step, and just take some initial state vector, and then produce a sequence of outputs.</p> <p>This allows for different neural architectures that are shown in the picture below:</p> <p></p> <p>Image from blog post Unreasonable Effectiveness of Recurrent Neural Networks by Andrej Karpaty</p> <ul> <li>One-to-one is a traditional neural network with one input and one output</li> <li>One-to-many is a generative architecture that accepts one input value, and generates a sequence of output values. For example, if we want to train an image captioning network that would produce a textual description of a picture, we can a picture as input, pass it through a CNN to obtain its hidden state, and then have a recurrent chain generate caption word-by-word</li> <li>Many-to-one corresponds to the RNN architectures we described in the previous unit, such as text classification</li> <li>Many-to-many, or sequence-to-sequence corresponds to tasks such as machine translation, where we have first RNN collect all information from the input sequence into the hidden state, and another RNN chain unrolls this state into the output sequence.</li> </ul> <p>In this unit, we will focus on simple generative models that help us generate text. For simplicity, we will use character-level tokenization.</p> <p>We will train this RNN to generate text step by step. On each step, we will take a sequence of characters of length <code>nchars</code>, and ask the network to generate the next output character for each input character:</p> <p></p> <p>When generating text (during inference), we start with some prompt, which is passed through RNN cells to generate its intermediate state, and then from this state the generation starts. We generate one character at a time, and pass the state and the generated character to another RNN cell to generate the next one, until we generate enough characters.</p> <p></p> <p>Image by the author</p>"},{"location":"lessons/5-NLP/17-GenerativeNetworks/#exercises-generative-networks","title":"\u270d\ufe0f Exercises: Generative Networks","text":"<p>Continue your learning in the following notebooks:</p> <ul> <li>Generative Networks with PyTorch</li> <li>Generative Networks with TensorFlow</li> </ul>"},{"location":"lessons/5-NLP/17-GenerativeNetworks/#soft-text-generation-and-temperature","title":"Soft text generation and temperature","text":"<p>The output of each RNN cell is a probability distribution of characters. If we always take the character with the highest probability as the next character in generated text, the text often can become \"cycled\" between the same character sequences again and again, like in this example:</p> <pre><code>today of the second the company and a second the company ...\n</code></pre> <p>However, if we look at the probability distribution for the next character, it could be that the difference between a few highest probabilities is not huge, e.g. one character can have probability 0.2, another - 0.19, etc. For example, when looking for the next character in the sequence 'play', next character can equally well be either space, or e (as in the word player).</p> <p>This leads us to the conclusion that it is not always \"fair\" to select the character with a higher probability, because choosing the second highest might still lead us to meaningful text. It is more wise to sample characters from the probability distribution given by the network output. We can also use a parameter, temperature, that will flatten out the probability distribution, in case we want to add more randomness, or make it more steep, if we want to stick more to the highest-probability characters.</p> <p>Explore how this soft text generation is implemented in the notebooks linked above.</p>"},{"location":"lessons/5-NLP/17-GenerativeNetworks/#conclusion","title":"Conclusion","text":"<p>While text generation may be useful in its own right, the major benefits come from the ability to generate text using RNNs from some initial feature vector. For example, text generation is used as part of machine translation (sequence-to-sequence, in this case state vector from encoder is used to generate or decode translated message), or generating textual description of an image (in which case the feature vector would come from CNN extractor).</p>"},{"location":"lessons/5-NLP/17-GenerativeNetworks/#challenge","title":"\ud83d\ude80 Challenge","text":"<p>Take some lessons on Microsoft Learn on this topic</p> <ul> <li>Text Generation with PyTorch/TensorFlow</li> </ul>"},{"location":"lessons/5-NLP/17-GenerativeNetworks/#post-lecture-quiz","title":"Post-lecture quiz","text":""},{"location":"lessons/5-NLP/17-GenerativeNetworks/#review-self-study","title":"Review &amp; Self Study","text":"<p>Here are some articles to expand your knowledge</p> <ul> <li>Different approaches to text generation with Markov Chain, LSTM and GPT-2: blog post</li> <li>Text generation sample in Keras documentation</li> </ul>"},{"location":"lessons/5-NLP/17-GenerativeNetworks/#assignment","title":"Assignment","text":"<p>We have seen how to generate text character-by-character. In the lab, you will explore word-level text generation.</p>"},{"location":"lessons/5-NLP/17-GenerativeNetworks/README_chs/","title":"\u751f\u6210\u7f51\u7edc","text":""},{"location":"lessons/5-NLP/17-GenerativeNetworks/README_chs/#_2","title":"\u8bfe\u524d\u6d4b\u9a8c","text":"<p>\u5faa\u73af\u795e\u7ecf\u7f51\u7edc\uff08RNNs\uff09\u53ca\u5176\u95e8\u63a7\u5355\u5143\u53d8\u4f53\uff0c\u4f8b\u5982\u957f\u77ed\u671f\u8bb0\u5fc6\u5355\u5143\uff08LSTMs\uff09\u548c\u95e8\u63a7\u5faa\u73af\u5355\u5143\uff08GRUs\uff09\uff0c\u63d0\u4f9b\u4e86\u4e00\u79cd\u8bed\u8a00\u5efa\u6a21\u673a\u5236\uff0c\u56e0\u4e3a\u5b83\u4eec\u53ef\u4ee5\u5b66\u4e60\u5355\u8bcd\u6392\u5e8f\u5e76\u4e3a\u5e8f\u5217\u4e2d\u7684\u4e0b\u4e00\u4e2a\u5355\u8bcd\u63d0\u4f9b\u9884\u6d4b\u3002\u8fd9\u4f7f\u6211\u4eec\u80fd\u591f\u4f7f\u7528RNN\u8fdb\u884c\u751f\u6210\u4efb\u52a1\uff0c\u4f8b\u5982\u666e\u901a\u6587\u672c\u751f\u6210\u3001\u673a\u5668\u7ffb\u8bd1\uff0c\u751a\u81f3\u56fe\u7247\u63cf\u8ff0\u3002</p> <p>\u2705 \u60f3\u60f3\u5728\u4f60\u6253\u5b57\u65f6\u4ece\u751f\u6210\u4efb\u52a1\uff08\u5982\u6587\u672c\u5b8c\u6210\uff09\u4e2d\u53d7\u76ca\u7684\u6240\u6709\u60c5\u5f62\u3002\u7814\u7a76\u4e00\u4e0b\u4f60\u559c\u6b22\u7684\u5e94\u7528\u7a0b\u5e8f\uff0c\u770b\u770b\u5b83\u4eec\u662f\u5426\u5229\u7528\u4e86RNN\u3002</p> <p>\u5728\u6211\u4eec\u5728\u524d\u4e00\u5355\u5143\u4e2d\u8ba8\u8bba\u7684RNN\u67b6\u6784\u4e2d\uff0c\u6bcf\u4e2aRNN\u5355\u5143\u90fd\u751f\u6210\u4e0b\u4e00\u4e2a\u9690\u85cf\u72b6\u6001\u4f5c\u4e3a\u8f93\u51fa\u3002\u7136\u800c\uff0c\u6211\u4eec\u4e5f\u53ef\u4ee5\u4e3a\u6bcf\u4e2a\u5faa\u73af\u5355\u5143\u6dfb\u52a0\u53e6\u4e00\u4e2a\u8f93\u51fa\uff0c\u8fd9\u5c06\u5141\u8bb8\u6211\u4eec\u8f93\u51fa\u4e00\u4e2a\u5e8f\u5217\uff08\u8be5\u5e8f\u5217\u957f\u5ea6\u7b49\u4e8e\u539f\u59cb\u5e8f\u5217\uff09\u3002\u6b64\u5916\uff0c\u6211\u4eec\u53ef\u4ee5\u4f7f\u7528\u4e0d\u5728\u6bcf\u4e00\u6b65\u63a5\u53d7\u8f93\u5165\u7684RNN\u5355\u5143\uff0c\u53ea\u9700\u63a5\u53d7\u4e00\u4e9b\u521d\u59cb\u72b6\u6001\u5411\u91cf\uff0c\u7136\u540e\u751f\u6210\u4e00\u7cfb\u5217\u8f93\u51fa\u3002</p> <p>\u8fd9\u5141\u8bb8\u4e0d\u540c\u7684\u795e\u7ecf\u67b6\u6784\uff0c\u5982\u4e0b\u56fe\u6240\u793a\uff1a</p> <p></p> <p>\u56fe\u7247\u6765\u81ea\u535a\u6587 \u5faa\u73af\u795e\u7ecf\u7f51\u7edc\u7684\u65e0\u9650\u6709\u6548\u6027 \u4f5c\u8005 Andrej Karpaty</p> <ul> <li>\u4e00\u5bf9\u4e00\u662f\u4e00\u4e2a\u4f20\u7edf\u7684\u795e\u7ecf\u7f51\u7edc\uff0c\u5177\u6709\u4e00\u4e2a\u8f93\u5165\u548c\u4e00\u4e2a\u8f93\u51fa</li> <li>\u4e00\u5bf9\u591a\u662f\u4e00\u79cd\u751f\u6210\u67b6\u6784\uff0c\u63a5\u53d7\u4e00\u4e2a\u8f93\u5165\u503c\uff0c\u5e76\u751f\u6210\u4e00\u7cfb\u5217\u8f93\u51fa\u503c\u3002\u4f8b\u5982\uff0c\u5982\u679c\u6211\u4eec\u60f3\u8bad\u7ec3\u4e00\u4e2a\u56fe\u50cf\u63cf\u8ff0\u7f51\u7edc\uff0c\u5b83\u5c06\u751f\u6210\u56fe\u7247\u7684\u6587\u672c\u63cf\u8ff0\uff0c\u6211\u4eec\u53ef\u4ee5\u5c06\u56fe\u7247\u4f5c\u4e3a\u8f93\u5165\uff0c\u901a\u8fc7CNN\u83b7\u5f97\u5176\u9690\u85cf\u72b6\u6001\uff0c\u7136\u540e\u8ba9\u4e00\u4e2a\u5faa\u73af\u94fe\u9010\u5b57\u751f\u6210\u63cf\u8ff0</li> <li>\u591a\u5bf9\u4e00\u5bf9\u5e94\u4e8e\u6211\u4eec\u5728\u524d\u4e00\u5355\u5143\u4e2d\u63cf\u8ff0\u7684RNN\u67b6\u6784\uff0c\u5982\u6587\u672c\u5206\u7c7b</li> <li>\u591a\u5bf9\u591a\u6216\u5e8f\u5217\u5bf9\u5e8f\u5217\u5bf9\u5e94\u4e8e\u4efb\u52a1\u5982\u673a\u5668\u7ffb\u8bd1\uff0c\u5176\u4e2d\u6211\u4eec\u5148\u6709RNN\u5c06\u8f93\u5165\u5e8f\u5217\u7684\u6240\u6709\u4fe1\u606f\u6536\u96c6\u5230\u9690\u85cf\u72b6\u6001\u4e2d\uff0c\u7136\u540e\u53e6\u4e00\u4e2aRNN\u94fe\u5c06\u8be5\u72b6\u6001\u5c55\u5f00\u4e3a\u8f93\u51fa\u5e8f\u5217\u3002</li> </ul> <p>\u5728\u672c\u5355\u5143\u4e2d\uff0c\u6211\u4eec\u5c06\u4e13\u6ce8\u4e8e\u5e2e\u52a9\u6211\u4eec\u751f\u6210\u6587\u672c\u7684\u7b80\u5355\u751f\u6210\u6a21\u578b\u3002\u4e3a\u4e86\u7b80\u5316\uff0c\u6211\u4eec\u5c06\u4f7f\u7528\u5b57\u7b26\u7ea7\u522b\u7684\u6807\u8bb0\u5316\u3002</p> <p>\u6211\u4eec\u5c06\u8bad\u7ec3\u8fd9\u4e2aRNN\u4e00\u6b65\u6b65\u751f\u6210\u6587\u672c\u3002\u5728\u6bcf\u4e00\u6b65\uff0c\u6211\u4eec\u5c06\u83b7\u53d6\u957f\u5ea6\u4e3a<code>nchars</code>\u7684\u5b57\u7b26\u5e8f\u5217\uff0c\u5e76\u8981\u6c42\u7f51\u7edc\u4e3a\u6bcf\u4e2a\u8f93\u5165\u5b57\u7b26\u751f\u6210\u4e0b\u4e00\u4e2a\u8f93\u51fa\u5b57\u7b26\uff1a</p> <p></p> <p>\u5728\u751f\u6210\u6587\u672c\uff08\u63a8\u7406\u8fc7\u7a0b\u4e2d\uff09\uff0c\u6211\u4eec\u4ece\u4e00\u4e9b\u63d0\u793a\u5f00\u59cb\uff0c\u5c06\u5176\u4f20\u9012\u901a\u8fc7RNN\u5355\u5143\u4ee5\u751f\u6210\u5176\u4e2d\u95f4\u72b6\u6001\uff0c\u7136\u540e\u4ece\u8be5\u72b6\u6001\u5f00\u59cb\u751f\u6210\u3002\u6211\u4eec\u4e00\u6b21\u751f\u6210\u4e00\u4e2a\u5b57\u7b26\uff0c\u5e76\u5c06\u72b6\u6001\u548c\u751f\u6210\u7684\u5b57\u7b26\u4f20\u9012\u7ed9\u53e6\u4e00\u4e2aRNN\u5355\u5143\u4ee5\u751f\u6210\u4e0b\u4e00\u4e2a\u5b57\u7b26\uff0c\u76f4\u5230\u751f\u6210\u8db3\u591f\u7684\u5b57\u7b26\u3002</p> <p></p> <p>\u4f5c\u8005\u63d0\u4f9b\u7684\u56fe\u7247</p>"},{"location":"lessons/5-NLP/17-GenerativeNetworks/README_chs/#_3","title":"\u270d\ufe0f \u7ec3\u4e60\uff1a\u751f\u6210\u7f51\u7edc","text":"<p>\u5728\u4ee5\u4e0b\u7b14\u8bb0\u672c\u4e2d\u7ee7\u7eed\u5b66\u4e60\uff1a</p> <ul> <li>\u4f7f\u7528PyTorch\u7684\u751f\u6210\u7f51\u7edc</li> <li>\u4f7f\u7528TensorFlow\u7684\u751f\u6210\u7f51\u7edc</li> </ul>"},{"location":"lessons/5-NLP/17-GenerativeNetworks/README_chs/#_4","title":"\u8f6f\u6587\u672c\u751f\u6210\u548c\u6e29\u5ea6","text":"<p>\u6bcf\u4e2aRNN\u5355\u5143\u7684\u8f93\u51fa\u662f\u5b57\u7b26\u7684\u6982\u7387\u5206\u5e03\u3002\u5982\u679c\u6211\u4eec\u59cb\u7ec8\u9009\u62e9\u6982\u7387\u6700\u9ad8\u7684\u5b57\u7b26\u4f5c\u4e3a\u751f\u6210\u6587\u672c\u7684\u4e0b\u4e00\u4e2a\u5b57\u7b26\uff0c\u6587\u672c\u901a\u5e38\u53ef\u80fd\u4f1a\u5728\u76f8\u540c\u7684\u5b57\u7b26\u5e8f\u5217\u4e4b\u95f4\u201c\u5faa\u73af\u201d\u53cd\u590d\uff0c\u5982\u4e0b\u4f8b\u6240\u793a\uff1a</p> <pre><code>today of the second the company and a second the company ...\n</code></pre> <p>\u7136\u800c\uff0c\u5982\u679c\u6211\u4eec\u67e5\u770b\u4e0b\u4e00\u4e2a\u5b57\u7b26\u7684\u6982\u7387\u5206\u5e03\uff0c\u53ef\u80fd\u51e0\u4e2a\u6700\u9ad8\u6982\u7387\u4e4b\u95f4\u7684\u5dee\u5f02\u5e76\u4e0d\u5927\uff0c\u4f8b\u5982\u4e00\u4e2a\u5b57\u7b26\u7684\u6982\u7387\u53ef\u4ee5\u662f0.2\uff0c\u53e6\u4e00\u4e2a\u662f0.19\uff0c\u7b49\u7b49\u3002\u4f8b\u5982\uff0c\u5f53\u5bfb\u627e\u5e8f\u5217'play'\u7684\u4e0b\u4e00\u4e2a\u5b57\u7b26\u65f6\uff0c\u4e0b\u4e00\u4e2a\u5b57\u7b26\u53ef\u4ee5\u540c\u6837\u53ef\u80fd\u662f\u7a7a\u683c\u6216e\uff08\u5982\u5355\u8bcdplayer\uff09\u3002</p> <p>\u8fd9\u4f7f\u6211\u4eec\u5f97\u51fa\u7ed3\u8bba\uff1a\u9009\u62e9\u6982\u7387\u8f83\u9ad8\u7684\u5b57\u7b26\u5e76\u4e0d\u603b\u662f\u201c\u516c\u5e73\u7684\u201d\uff0c\u56e0\u4e3a\u9009\u62e9\u6982\u7387\u7b2c\u4e8c\u9ad8\u7684\u5b57\u7b26\u4ecd\u7136\u53ef\u80fd\u4f1a\u5bfc\u81f4\u6709\u610f\u4e49\u7684\u6587\u672c\u3002\u66f4\u660e\u667a\u7684\u65b9\u6cd5\u662f\u4ece\u7f51\u7edc\u8f93\u51fa\u7ed9\u51fa\u7684\u6982\u7387\u5206\u5e03\u4e2d\u62bd\u6837\u5b57\u7b26\u3002\u6211\u4eec\u8fd8\u53ef\u4ee5\u4f7f\u7528\u4e00\u4e2a\u53c2\u6570\uff0c\u6e29\u5ea6\uff0c\u6765\u5e73\u6ed1\u6982\u7387\u5206\u5e03\uff0c\u4ee5\u4fbf\u5728\u6211\u4eec\u5e0c\u671b\u589e\u52a0\u66f4\u591a\u968f\u673a\u6027\u6216\u5e0c\u671b\u66f4\u591a\u5730\u575a\u6301\u6700\u9ad8\u6982\u7387\u5b57\u7b26\u65f6\u52a0\u4ee5\u8c03\u6574\u3002</p> <p>\u63a2\u7d22\u4e0a\u8ff0\u7b14\u8bb0\u672c\u4e2d\u5982\u4f55\u5b9e\u73b0\u8fd9\u79cd\u8f6f\u6587\u672c\u751f\u6210\u3002</p>"},{"location":"lessons/5-NLP/17-GenerativeNetworks/README_chs/#_5","title":"\u7ed3\u8bba","text":"<p>\u5c3d\u7ba1\u6587\u672c\u751f\u6210\u672c\u8eab\u53ef\u80fd\u6709\u7528\uff0c\u4f46\u4e3b\u8981\u7684\u597d\u5904\u6765\u81ea\u4e8e\u80fd\u591f\u4f7f\u7528RNN\u6839\u636e\u4e00\u4e9b\u521d\u59cb\u7279\u5f81\u5411\u91cf\u751f\u6210\u6587\u672c\u3002\u4f8b\u5982\uff0c\u6587\u672c\u751f\u6210\u7528\u4f5c\u673a\u5668\u7ffb\u8bd1\u7684\u4e00\u90e8\u5206\uff08\u5e8f\u5217\u5230\u5e8f\u5217\uff0c\u5728\u8fd9\u79cd\u60c5\u51b5\u4e0b\u72b6\u6001\u5411\u91cf\u6765\u81ea\u7f16\u7801\u5668\uff0c\u7528\u4e8e\u751f\u6210\u6216\u89e3\u7801\u539f\u6587\uff09\uff0c\u6216\u751f\u6210\u56fe\u50cf\u7684\u6587\u672c\u63cf\u8ff0\uff08\u5728\u8fd9\u79cd\u60c5\u51b5\u4e0b\u7279\u5f81\u5411\u91cf\u6765\u81eaCNN\u63d0\u53d6\u5668\uff09\u3002</p>"},{"location":"lessons/5-NLP/17-GenerativeNetworks/README_chs/#_6","title":"\ud83d\ude80 \u6311\u6218","text":"<p>\u5728Microsoft Learn\u4e0a\u4e0a\u8fd9\u65b9\u9762\u7684\u8bfe\u7a0b</p> <ul> <li>\u4f7f\u7528PyTorch/TensorFlow\u8fdb\u884c\u6587\u672c\u751f\u6210</li> </ul>"},{"location":"lessons/5-NLP/17-GenerativeNetworks/README_chs/#_7","title":"\u8bfe\u540e\u6d4b\u9a8c","text":""},{"location":"lessons/5-NLP/17-GenerativeNetworks/README_chs/#_8","title":"\u590d\u4e60\u4e0e\u81ea\u5b66","text":"<p>\u8fd9\u91cc\u6709\u4e00\u4e9b\u6587\u7ae0\u53ef\u4ee5\u6269\u5c55\u4f60\u7684\u77e5\u8bc6</p> <ul> <li>\u4e0d\u540c\u65b9\u6cd5\u751f\u6210\u6587\u672c\uff1a\u9a6c\u5c14\u53ef\u592b\u94fe\u3001LSTM\u548cGPT-2: \u535a\u6587</li> <li>Keras\u6587\u6863\u4e2d\u7684\u6587\u672c\u751f\u6210\u793a\u4f8b</li> </ul>"},{"location":"lessons/5-NLP/17-GenerativeNetworks/README_chs/#_9","title":"\u4f5c\u4e1a","text":"<p>\u6211\u4eec\u5df2\u7ecf\u770b\u5230\u4e86\u5982\u4f55\u9010\u5b57\u751f\u6210\u6587\u672c\u3002\u5728\u5b9e\u9a8c\u4e2d\uff0c\u4f60\u5c06\u63a2\u7d22\u8bcd\u7ea7\u522b\u7684\u6587\u672c\u751f\u6210\u3002</p>"},{"location":"lessons/5-NLP/17-GenerativeNetworks/lab/","title":"Word-level Text Generation using RNNs","text":"<p>Lab Assignment from AI for Beginners Curriculum.</p>"},{"location":"lessons/5-NLP/17-GenerativeNetworks/lab/#task","title":"Task","text":"<p>In this lab, you need to take any book, and use it as a dataset to train word-level text generator.</p>"},{"location":"lessons/5-NLP/17-GenerativeNetworks/lab/#the-dataset","title":"The Dataset","text":"<p>You are welcome to use any book. You can find a lot of free texts at Project Gutenberg, for example, here is a direct link to Alice's Adventures in Wonderland) by Lewis Carroll.</p>"},{"location":"lessons/5-NLP/17-GenerativeNetworks/lab/README_chs/","title":"\u57fa\u4e8eRNN\u7684\u8bcd\u7ea7\u6587\u672c\u751f\u6210","text":"<p>AI for Beginners\u8bfe\u7a0b\u7684\u5b9e\u9a8c\u4f5c\u4e1a\u3002</p>"},{"location":"lessons/5-NLP/17-GenerativeNetworks/lab/README_chs/#_1","title":"\u4efb\u52a1","text":"<p>\u5728\u8fd9\u4e2a\u5b9e\u9a8c\u4e2d\uff0c\u4f60\u9700\u8981\u9009\u62e9\u4efb\u610f\u4e00\u672c\u4e66\uff0c\u5e76\u5c06\u5176\u7528\u4f5c\u6570\u636e\u96c6\u6765\u8bad\u7ec3\u4e00\u4e2a\u8bcd\u7ea7\u6587\u672c\u751f\u6210\u5668\u3002</p>"},{"location":"lessons/5-NLP/17-GenerativeNetworks/lab/README_chs/#_2","title":"\u6570\u636e\u96c6","text":"<p>\u4f60\u53ef\u4ee5\u4f7f\u7528\u4efb\u4f55\u4e00\u672c\u4e66\u3002\u4f60\u53ef\u4ee5\u5728\u53e4\u767b\u5821\u8ba1\u5212\u627e\u5230\u8bb8\u591a\u514d\u8d39\u6587\u672c\uff0c\u4f8b\u5982\uff0c\u8fd9\u91cc\u662fLewis Carroll\u7684\u300a\u7231\u4e3d\u4e1d\u68a6\u6e38\u4ed9\u5883\u300b\u7684\u76f4\u63a5\u94fe\u63a5\u3002</p>"},{"location":"lessons/5-NLP/18-Transformers/READMEtransformers/","title":"Attention Mechanisms and Transformers","text":""},{"location":"lessons/5-NLP/18-Transformers/READMEtransformers/#pre-lecture-quiz","title":"Pre-lecture quiz","text":"<p>One of the most important problems in the NLP domain is machine translation, an essential task that underlies tools such as Google Translate. In this section, we will focus on machine translation, or, more generally, on any sequence-to-sequence task (which is also called sentence transduction).</p> <p>With RNNs, sequence-to-sequence is implemented by two recurrent networks, where one network, the encoder, collapses an input sequence into a hidden state, while another network, the decoder, unrolls this hidden state into a translated result. There are a couple of problems with this approach:</p> <ul> <li>The final state of the encoder network has a hard time remembering the beginning of a sentence, thus causing poor quality of the model for long sentences</li> <li>All words in a sequence have the same impact on the result. In reality, however, specific words in the input sequence often have more impact on sequential outputs than others.</li> </ul> <p>Attention Mechanisms provide a means of weighting the contextual impact of each input vector on each output prediction of the RNN. The way it is implemented is by creating shortcuts between intermediate states of the input RNN and the output RNN. In this manner, when generating output symbol y<sub>t</sub>, we will take into account all input hidden states h<sub>i</sub>, with different weight coefficients \u03b1<sub>t,i</sub>.</p> <p></p> <p>The encoder-decoder model with additive attention mechanism in Bahdanau et al., 2015, cited from this blog post</p> <p>The attention matrix {\u03b1<sub>i,j</sub>} would represent the degree that certain input words play in the generation of a given word in the output sequence. Below is an example of such a matrix:</p> <p></p> <p>Figure from Bahdanau et al., 2015 (Fig.3)</p> <p>Attention mechanisms are responsible for much of the current or near current state of the art in NLP. Adding attention however greatly increases the number of model parameters which led to scaling issues with RNNs. A key constraint of scaling RNNs is that the recurrent nature of the models makes it challenging to batch and parallelize training. In an RNN each element of a sequence needs to be processed in sequential order which means it cannot be easily parallelized.</p> <p></p> <p>Figure from Google's Blog</p> <p>The adoption of attention mechanisms combined with this constraint led to the creation of the now State of the Art Transformer Models that we know and use today such as BERT to Open-GPT3.</p>"},{"location":"lessons/5-NLP/18-Transformers/READMEtransformers/#transformer-models","title":"Transformer models","text":"<p>One of the main ideas behind transformers is to avoid sequential nature of RNNs and to create a model that is parallelizable during training. This is achieved by implementing two ideas:</p> <ul> <li>positional encoding</li> <li>using self-attention mechanism to capture patterns instead of RNNs (or CNNs) (that is why the paper that introduces transformers is called Attention is all you need</li> </ul>"},{"location":"lessons/5-NLP/18-Transformers/READMEtransformers/#positional-encodingembedding","title":"Positional Encoding/Embedding","text":"<p>The idea of positional encoding is the following.  1. When using RNNs, the relative position of the tokens is represented by the number of steps, and thus does not need to be explicitly represented.  2. However, once we switch to attention, we need to know the relative positions of tokens within a sequence.  3. To get positional encoding, we augment our sequence of tokens with a sequence of token positions in the sequence (i.e., a sequence of numbers 0,1, ...). 4. We then mix the token position with a token embedding vector. To transform the position (integer) into a vector, we can use different approaches:</p> <ul> <li>Trainable embedding, similar to token embedding. This is the approach we consider here. We apply embedding layers on top of both tokens and their positions, resulting in embedding vectors of the same dimensions, which we then add together.</li> <li>Fixed position encoding function, as proposed in the original paper.</li> </ul> <p></p> <p>Image by the author</p> <p>The result that we get with positional embedding embeds both the original token and its position within a sequence.</p>"},{"location":"lessons/5-NLP/18-Transformers/READMEtransformers/#multi-head-self-attention","title":"Multi-Head Self-Attention","text":"<p>Next, we need to capture some patterns within our sequence. To do this, transformers use a self-attention mechanism, which is essentially attention applied to the same sequence as the input and output. Applying self-attention allows us to take into account context within the sentence, and see which words are inter-related. For example, it allows us to see which words are referred to by coreferences, such as it, and also take the context into account:</p> <p></p> <p>Image from the Google Blog</p> <p>In transformers, we use Multi-Head Attention in order to give the network the power to capture several different types of dependencies, eg. long-term vs. short-term word relations, co-reference vs. something else, etc.</p> <p>TensorFlow Notebook contains more detains on the implementation of transformer layers.</p>"},{"location":"lessons/5-NLP/18-Transformers/READMEtransformers/#encoder-decoder-attention","title":"Encoder-Decoder Attention","text":"<p>In transformers, attention is used in two places:</p> <ul> <li>To capture patterns within the input text using self-attention</li> <li>To perform sequence translation - it is the attention layer between encoder and decoder.</li> </ul> <p>Encoder-decoder attention is very similar to the attention mechanism used in RNNs, as described in the beginning of this section. This animated diagram explains the role of encoder-decoder attention.</p> <p></p> <p>Since each input position is mapped independently to each output position, transformers can parallelize better than RNNs, which enables much larger and more expressive language models. Each attention head can be used to learn different relationships between words that improves downstream Natural Language Processing tasks.</p>"},{"location":"lessons/5-NLP/18-Transformers/READMEtransformers/#bert","title":"BERT","text":"<p>BERT (Bidirectional Encoder Representations from Transformers) is a very large multi layer transformer network with 12 layers for BERT-base, and 24 for BERT-large. The model is first pre-trained on a large corpus of text data (WikiPedia + books) using unsupervised training (predicting masked words in a sentence). During pre-training the model absorbs significant levels of language understanding which can then be leveraged with other datasets using fine tuning. This process is called transfer learning.</p> <p></p> <p>Image source</p>"},{"location":"lessons/5-NLP/18-Transformers/READMEtransformers/#exercises-transformers","title":"\u270d\ufe0f Exercises: Transformers","text":"<p>Continue your learning in the following notebooks:</p> <ul> <li>Transformers in PyTorch</li> <li>Transformers in TensorFlow</li> </ul>"},{"location":"lessons/5-NLP/18-Transformers/READMEtransformers/#conclusion","title":"Conclusion","text":"<p>In this lesson you learned about Transformers and Attention Mechanisms, all essential tools in the NLP toolbox. There are many variations of Transformer architectures including BERT, DistilBERT. BigBird, OpenGPT3 and more that can be fine tuned. The HuggingFace package provides repository for training many of these architectures with both PyTorch and TensorFlow.</p>"},{"location":"lessons/5-NLP/18-Transformers/READMEtransformers/#challenge","title":"\ud83d\ude80 Challenge","text":""},{"location":"lessons/5-NLP/18-Transformers/READMEtransformers/#post-lecture-quiz","title":"Post-lecture quiz","text":""},{"location":"lessons/5-NLP/18-Transformers/READMEtransformers/#review-self-study","title":"Review &amp; Self Study","text":"<ul> <li>Blog post, explaining the classical Attention is all you need paper on transformers.</li> <li>A series of blog posts on transformers, explaining the architecture in detail.</li> </ul>"},{"location":"lessons/5-NLP/18-Transformers/READMEtransformers/#assignment","title":"Assignment","text":""},{"location":"lessons/5-NLP/18-Transformers/READMEtransformers_chs/","title":"\u6ce8\u610f\u673a\u5236\u548cTransformer","text":""},{"location":"lessons/5-NLP/18-Transformers/READMEtransformers_chs/#_1","title":"\u8bb2\u5ea7\u524d\u6d4b\u9a8c","text":"<p>\u81ea\u7136\u8bed\u8a00\u5904\u7406\u9886\u57df\u4e2d\u6700\u91cd\u8981\u7684\u95ee\u9898\u4e4b\u4e00\u662f\u673a\u5668\u7ffb\u8bd1\uff0c\u8fd9\u4e00\u4efb\u52a1\u662f\u8bf8\u5982\u8c37\u6b4c\u7ffb\u8bd1\u7b49\u5de5\u5177\u7684\u57fa\u7840\u3002\u5728\u672c\u8282\u4e2d\uff0c\u6211\u4eec\u5c06\u91cd\u70b9\u5173\u6ce8\u673a\u5668\u7ffb\u8bd1\uff0c\u6216\u66f4\u5e7f\u6cdb\u5730\u8bf4\uff0c\u4efb\u4f55\u5e8f\u5217\u5230\u5e8f\u5217\u4efb\u52a1\uff08\u4e5f\u79f0\u4e3a\u53e5\u5b50\u8f6c\u6362\uff09\u3002</p> <p>\u5728RNN\u4e2d\uff0c\u5e8f\u5217\u5230\u5e8f\u5217\u662f\u7531\u4e24\u4e2a\u9012\u5f52\u7f51\u7edc\u5b9e\u73b0\u7684\uff0c\u5176\u4e2d\u4e00\u4e2a\u7f51\u7edc\uff0c\u5373\u7f16\u7801\u5668\uff0c\u5c06\u8f93\u5165\u5e8f\u5217\u538b\u7f29\u6210\u4e00\u4e2a\u9690\u85cf\u72b6\u6001\uff0c\u800c\u53e6\u4e00\u4e2a\u7f51\u7edc\uff0c\u5373\u89e3\u7801\u5668\uff0c\u5c06\u8fd9\u4e2a\u9690\u85cf\u72b6\u6001\u5c55\u5f00\u6210\u4e00\u4e2a\u7ffb\u8bd1\u7ed3\u679c\u3002\u8fd9\u79cd\u65b9\u6cd5\u6709\u51e0\u4e2a\u95ee\u9898\uff1a</p> <ul> <li>\u7f16\u7801\u5668\u7f51\u7edc\u7684\u6700\u7ec8\u72b6\u6001\u96be\u4ee5\u8bb0\u4f4f\u53e5\u5b50\u7684\u5f00\u5934\uff0c\u4ece\u800c\u5bfc\u81f4\u957f\u53e5\u5b50\u7684\u6a21\u578b\u8d28\u91cf\u8f83\u5dee</li> <li>\u5e8f\u5217\u4e2d\u7684\u6240\u6709\u5355\u8bcd\u5bf9\u7ed3\u679c\u7684\u5f71\u54cd\u76f8\u540c\u3002\u7136\u800c\uff0c\u5b9e\u9645\u4e0a\uff0c\u8f93\u5165\u5e8f\u5217\u4e2d\u7684\u7279\u5b9a\u5355\u8bcd\u5bf9\u987a\u5e8f\u8f93\u51fa\u7684\u5f71\u54cd\u5f80\u5f80\u6bd4\u5176\u4ed6\u5355\u8bcd\u5927\u3002</li> </ul> <p>\u6ce8\u610f\u673a\u5236\u63d0\u4f9b\u4e86\u4e00\u79cd\u7ed9\u6bcf\u4e2a\u8f93\u5165\u5411\u91cf\u5bf9RNN\u6bcf\u4e2a\u8f93\u51fa\u9884\u6d4b\u7684\u4e0a\u4e0b\u6587\u5f71\u54cd\u8fdb\u884c\u52a0\u6743\u7684\u65b9\u6cd5\u3002\u5176\u5b9e\u73b0\u65b9\u5f0f\u662f\u901a\u8fc7\u5728\u8f93\u5165RNN\u548c\u8f93\u51faRNN\u7684\u4e2d\u95f4\u72b6\u6001\u4e4b\u95f4\u521b\u5efa\u6377\u5f84\u3002\u8fd9\u6837\uff0c\u5728\u751f\u6210\u8f93\u51fa\u7b26\u53f7y<sub>t</sub>\u65f6\uff0c\u6211\u4eec\u5c06\u8003\u8651\u6240\u6709\u8f93\u5165\u7684\u9690\u85cf\u72b6\u6001h<sub>i</sub>\uff0c\u4f46\u6709\u4e0d\u540c\u7684\u6743\u91cd\u7cfb\u6570\u03b1<sub>t,i</sub>\u3002</p> <p></p> <p>Bahdanau et al., 2015 \u4e2d\u7684\u52a0\u6027\u6ce8\u610f\u673a\u5236\u7f16\u7801\u5668-\u89e3\u7801\u5668\u6a21\u578b\uff0c\u6b64\u56fe\u6765\u81ea\u8fd9\u7bc7\u535a\u5ba2\u6587\u7ae0</p> <p>\u6ce8\u610f\u77e9\u9635{\u03b1<sub>i,j</sub>}\u8868\u793a\u67d0\u4e9b\u8f93\u5165\u8bcd\u5728\u751f\u6210\u8f93\u51fa\u5e8f\u5217\u4e2d\u7279\u5b9a\u8bcd\u65f6\u7684\u4f5c\u7528\u5927\u5c0f\u3002\u4e0b\u9762\u662f\u4e00\u4e2a\u8fd9\u6837\u7684\u77e9\u9635\u793a\u4f8b\uff1a</p> <p></p> <p>\u56fe\u6765\u81eaBahdanau et al., 2015 (\u56fe3)</p> <p>\u6ce8\u610f\u673a\u5236\u5728\u5f53\u524d\u6216\u6700\u8fd1\u7684\u81ea\u7136\u8bed\u8a00\u5904\u7406\u6280\u672f\u4e2d\u8d77\u5230\u4e86\u81f3\u5173\u91cd\u8981\u7684\u4f5c\u7528\u3002\u4f46\u662f\uff0c\u6dfb\u52a0\u6ce8\u610f\u673a\u5236\u5927\u5927\u589e\u52a0\u4e86\u6a21\u578b\u53c2\u6570\u7684\u6570\u91cf\uff0c\u8fd9\u5bfc\u81f4\u4e86RNN\u7684\u6269\u5c55\u95ee\u9898\u3002\u6269\u5c55RNN\u7684\u4e00\u4e2a\u5173\u952e\u7ea6\u675f\u662f\u6a21\u578b\u7684\u9012\u5f52\u6027\u8d28\u4f7f\u5f97\u6279\u5904\u7406\u548c\u5e76\u884c\u8bad\u7ec3\u53d8\u5f97\u5177\u6709\u6311\u6218\u6027\u3002\u5728RNN\u4e2d\uff0c\u6bcf\u4e2a\u5e8f\u5217\u5143\u7d20\u9700\u8981\u6309\u987a\u5e8f\u5904\u7406\uff0c\u8fd9\u610f\u5473\u7740\u5b83\u4e0d\u80fd\u8f7b\u6613\u5e76\u884c\u5316\u3002</p> <p></p> <p>\u8c37\u6b4c\u535a\u5ba2\u4e2d\u7684\u56fe</p> <p>\u7ed3\u5408\u8fd9\u79cd\u9650\u5236\uff0c\u6ce8\u610f\u673a\u5236\u7684\u91c7\u7528\u5bfc\u81f4\u4e86\u6211\u4eec\u4eca\u5929\u6240\u77e5\u5e76\u4f7f\u7528\u7684\u6700\u5148\u8fdb\u7684Transformer\u6a21\u578b\u7684\u521b\u5efa\uff0c\u5305\u62ecBERT\u548cOpen-GPT3\u7b49\u3002</p>"},{"location":"lessons/5-NLP/18-Transformers/READMEtransformers_chs/#transformer_1","title":"Transformer\u6a21\u578b","text":"<p>Transformer\u80cc\u540e\u7684\u4e3b\u8981\u60f3\u6cd5\u4e4b\u4e00\u662f\u907f\u514dRNN\u7684\u987a\u5e8f\u6027\u8d28\uff0c\u5e76\u521b\u5efa\u4e00\u4e2a\u5728\u8bad\u7ec3\u671f\u95f4\u53ef\u5e76\u884c\u5316\u7684\u6a21\u578b\u3002\u8fd9\u662f\u901a\u8fc7\u5b9e\u73b0\u4e24\u4e2a\u60f3\u6cd5\u6765\u5b9e\u73b0\u7684\uff1a</p> <ul> <li>\u4f4d\u7f6e\u7f16\u7801</li> <li>\u4f7f\u7528\u81ea\u6ce8\u610f\u673a\u5236\u6765\u6355\u6349\u6a21\u5f0f\uff0c\u800c\u4e0d\u662fRNN\uff08\u6216CNN\uff09\uff08\u8fd9\u5c31\u662f\u4ecb\u7ecdTransformer\u7684\u8bba\u6587\u88ab\u79f0\u4e3aAttention is all you need\u7684\u539f\u56e0\uff09</li> </ul>"},{"location":"lessons/5-NLP/18-Transformers/READMEtransformers_chs/#_2","title":"\u4f4d\u7f6e\u7f16\u7801/\u5d4c\u5165","text":"<p>\u4f4d\u7f6e\u7f16\u7801\u7684\u60f3\u6cd5\u5982\u4e0b\u3002 1. \u4f7f\u7528RNN\u65f6\uff0c\u6807\u8bb0\u7684\u76f8\u5bf9\u4f4d\u7f6e\u7531\u6b65\u6570\u8868\u793a\uff0c\u56e0\u6b64\u4e0d\u9700\u8981\u663e\u5f0f\u8868\u793a\u3002 2. \u4f46\u662f\uff0c\u4e00\u65e6\u6211\u4eec\u5207\u6362\u5230\u6ce8\u610f\u673a\u5236\uff0c\u6211\u4eec\u9700\u8981\u77e5\u9053\u6807\u8bb0\u5728\u5e8f\u5217\u4e2d\u7684\u76f8\u5bf9\u4f4d\u7f6e\u3002 3. \u4e3a\u4e86\u83b7\u5f97\u4f4d\u7f6e\u7f16\u7801\uff0c\u6211\u4eec\u5c06\u6807\u8bb0\u5e8f\u5217\u4e0e\u6807\u8bb0\u5728\u5e8f\u5217\u4e2d\u7684\u4f4d\u7f6e\u5e8f\u5217\uff08\u5373\u4e00\u7cfb\u5217\u6570\u5b570,1, ...\uff09\u8fdb\u884c\u6269\u5c55\u3002 4. \u7136\u540e\u6211\u4eec\u5c06\u6807\u8bb0\u4f4d\u7f6e\u4e0e\u6807\u8bb0\u5d4c\u5165\u5411\u91cf\u6df7\u5408\u3002\u4e3a\u4e86\u5c06\u4f4d\u7f6e\uff08\u6574\u6570\uff09\u8f6c\u6362\u4e3a\u5411\u91cf\uff0c\u6211\u4eec\u53ef\u4ee5\u4f7f\u7528\u4e0d\u540c\u7684\u65b9\u6cd5\uff1a</p> <ul> <li>\u53ef\u8bad\u7ec3\u5d4c\u5165\uff0c\u7c7b\u4f3c\u4e8e\u6807\u8bb0\u5d4c\u5165\u3002\u8fd9\u662f\u6211\u4eec\u8003\u8651\u7684\u65b9\u6cd5\u3002\u6211\u4eec\u5728\u6807\u8bb0\u548c\u5b83\u4eec\u7684\u4f4d\u7f6e\u4e0a\u5e94\u7528\u5d4c\u5165\u5c42\uff0c\u5f97\u5230\u76f8\u540c\u7ef4\u5ea6\u7684\u5d4c\u5165\u5411\u91cf\uff0c\u7136\u540e\u5c06\u5b83\u4eec\u52a0\u5728\u4e00\u8d77\u3002</li> <li>\u56fa\u5b9a\u4f4d\u7f6e\u7f16\u7801\u51fd\u6570\uff0c\u5982\u539f\u59cb\u8bba\u6587\u6240\u63d0\u8bae\u7684\u3002</li> </ul> <p></p> <p>\u4f5c\u8005\u63d0\u4f9b\u7684\u56fe\u7247</p> <p>\u901a\u8fc7\u4f4d\u7f6e\u5d4c\u5165\uff0c\u6211\u4eec\u5f97\u5230\u7684\u7ed3\u679c\u65e2\u5d4c\u5165\u4e86\u539f\u59cb\u6807\u8bb0\uff0c\u4e5f\u5d4c\u5165\u4e86\u5176\u5728\u5e8f\u5217\u4e2d\u7684\u4f4d\u7f6e\u3002</p>"},{"location":"lessons/5-NLP/18-Transformers/READMEtransformers_chs/#_3","title":"\u591a\u5934\u81ea\u6ce8\u610f","text":"<p>\u63a5\u4e0b\u6765\uff0c\u6211\u4eec\u9700\u8981\u6355\u6349\u5e8f\u5217\u4e2d\u7684\u4e00\u4e9b\u6a21\u5f0f\u3002\u4e3a\u4e86\u505a\u5230\u8fd9\u4e00\u70b9\uff0cTransformer\u4f7f\u7528\u4e86\u81ea\u6ce8\u610f\u673a\u5236\uff0c\u8fd9\u672c\u8d28\u4e0a\u662f\u5c06\u6ce8\u610f\u673a\u5236\u5e94\u7528\u4e8e\u76f8\u540c\u7684\u8f93\u5165\u548c\u8f93\u51fa\u5e8f\u5217\u3002\u5e94\u7528\u81ea\u6ce8\u610f\u673a\u5236\u4f7f\u6211\u4eec\u80fd\u591f\u8003\u8651\u53e5\u5b50\u4e2d\u7684\u4e0a\u4e0b\u6587\uff0c\u5e76\u67e5\u770b\u54ea\u4e9b\u8bcd\u662f\u76f8\u4e92\u5173\u8054\u7684\u3002\u4f8b\u5982\uff0c\u5b83\u5141\u8bb8\u6211\u4eec\u67e5\u770b\u54ea\u4e9b\u8bcd\u662f\u4ee3\u8bcd\uff08\u5982\u5b83\uff09\u6240\u6307\u7684\uff0c\u5e76\u4e14\u4e5f\u8003\u8651\u4e0a\u4e0b\u6587\uff1a</p> <p></p> <p>\u56fe\u7247\u6765\u81ea\u8c37\u6b4c\u535a\u5ba2</p> <p>\u5728Transformer\u4e2d\uff0c\u6211\u4eec\u4f7f\u7528\u591a\u5934\u6ce8\u610f\uff0c\u4ee5\u4f7f\u7f51\u7edc\u80fd\u591f\u6355\u6349\u51e0\u79cd\u4e0d\u540c\u7c7b\u578b\u7684\u4f9d\u8d56\u5173\u7cfb\uff0c\u4f8b\u5982\u957f\u65f6\u4e0e\u77ed\u65f6\u8bcd\u5173\u7cfb\uff0c\u5171\u6307\u5173\u7cfb\u4e0e\u5176\u4ed6\u7b49\u7b49\u3002</p> <p>TensorFlow\u7b14\u8bb0\u672c\u5305\u542b\u5173\u4e8eTransformer\u5c42\u5b9e\u73b0\u7684\u66f4\u591a\u8be6\u7ec6\u4fe1\u606f\u3002</p>"},{"location":"lessons/5-NLP/18-Transformers/READMEtransformers_chs/#-","title":"\u7f16\u7801\u5668-\u89e3\u7801\u5668\u6ce8\u610f","text":"<p>\u5728Transformer\u4e2d\uff0c\u6ce8\u610f\u673a\u5236\u5728\u4e24\u4e2a\u5730\u65b9\u4f7f\u7528\uff1a</p> <ul> <li>\u4f7f\u7528\u81ea\u6ce8\u610f\u673a\u5236\u6355\u6349\u8f93\u5165\u6587\u672c\u4e2d\u7684\u6a21\u5f0f</li> <li>\u6267\u884c\u5e8f\u5217\u7ffb\u8bd1\u2014\u2014\u8fd9\u662f\u7f16\u7801\u5668\u548c\u89e3\u7801\u5668\u4e4b\u95f4\u7684\u6ce8\u610f\u5c42\u3002</li> </ul> <p>\u7f16\u7801\u5668-\u89e3\u7801\u5668\u6ce8\u610f\u975e\u5e38\u7c7b\u4f3c\u4e8e\u5728\u672c\u8282\u5f00\u5934\u63cf\u8ff0\u7684RNN\u4e2d\u4f7f\u7528\u7684\u6ce8\u610f\u673a\u5236\u3002\u6b64\u52a8\u753b\u56fe\u89e3\u91ca\u4e86\u7f16\u7801\u5668-\u89e3\u7801\u5668\u6ce8\u610f\u7684\u4f5c\u7528\u3002</p> <p></p> <p>\u7531\u4e8e\u6bcf\u4e2a\u8f93\u5165\u4f4d\u7f6e\u72ec\u7acb\u5730\u6620\u5c04\u5230\u6bcf\u4e2a\u8f93\u51fa\u4f4d\u7f6e\uff0cTransformer\u6bd4RNN\u66f4\u80fd\u5e76\u884c\u5316\uff0c\u8fd9\u4f7f\u5f97\u66f4\u5927\u4e14\u66f4\u5177\u8868\u73b0\u529b\u7684\u8bed\u8a00\u6a21\u578b\u6210\u4e3a\u53ef\u80fd\u3002\u6bcf\u4e2a\u6ce8\u610f\u5934\u53ef\u4ee5\u7528\u6765\u5b66\u4e60\u4e0d\u540c\u7684\u5355\u8bcd\u5173\u7cfb\uff0c\u4ece\u800c\u63d0\u9ad8\u81ea\u7136\u8bed\u8a00\u5904\u7406\u4efb\u52a1\u7684\u6548\u679c\u3002</p>"},{"location":"lessons/5-NLP/18-Transformers/READMEtransformers_chs/#bert","title":"BERT","text":"<p>BERT\uff08\u53cc\u5411\u7f16\u7801\u5668\u8868\u793a\u7684Transformer\uff09\u662f\u4e00\u4e2a\u975e\u5e38\u5927\u7684\u591a\u5c42Transformer\u7f51\u7edc\uff0cBERT-base\u670912\u5c42\uff0cBERT-large\u670924\u5c42\u3002\u8be5\u6a21\u578b\u9996\u5148\u5728\u5927\u89c4\u6a21\u6587\u672c\u6570\u636e\u96c6\uff08\u7ef4\u57fa\u767e\u79d1+\u4e66\u7c4d\uff09\u4e0a\u8fdb\u884c\u65e0\u76d1\u7763\u8bad\u7ec3\uff08\u9884\u6d4b\u53e5\u5b50\u4e2d\u7684\u906e\u853d\u8bcd\uff09\u3002\u5728\u9884\u8bad\u7ec3\u671f\u95f4\uff0c\u6a21\u578b\u5438\u6536\u4e86\u5927\u91cf\u7684\u8bed\u8a00\u7406\u89e3\uff0c\u8fd9\u53ef\u4ee5\u5728\u5176\u4ed6\u6570\u636e\u96c6\u4e0a\u901a\u8fc7\u5fae\u8c03\u8fdb\u884c\u5145\u5206\u5229\u7528\u3002\u8fd9\u4e2a\u8fc7\u7a0b\u88ab\u79f0\u4e3a\u8fc1\u79fb\u5b66\u4e60\u3002</p> <p></p> <p>\u56fe\u7247\u6765\u6e90</p>"},{"location":"lessons/5-NLP/18-Transformers/READMEtransformers_chs/#transformer_2","title":"\u270d\ufe0f \u7ec3\u4e60\uff1aTransformer","text":"<p>\u5728\u4ee5\u4e0b\u7b14\u8bb0\u672c\u4e2d\u7ee7\u7eed\u5b66\u4e60\uff1a</p> <ul> <li>PyTorch\u4e2d\u7684Transformer</li> <li>TensorFlow\u4e2d\u7684Transformer</li> </ul>"},{"location":"lessons/5-NLP/18-Transformers/READMEtransformers_chs/#_4","title":"\u7ed3\u8bba","text":"<p>\u5728\u672c\u8bfe\u4e2d\uff0c\u4f60\u4e86\u89e3\u4e86Transformer\u548c\u6ce8\u610f\u673a\u5236\uff0c\u8fd9\u4e9b\u90fd\u662fNLP\u5de5\u5177\u7bb1\u4e2d\u7684\u57fa\u672c\u5de5\u5177\u3002Transformer\u67b6\u6784\u6709\u5f88\u591a\u53d8\u4f53\uff0c\u5305\u62ecBERT\u3001DistilBERT\u3001BigBird\u3001OpenGPT3\u7b49\uff0c\u53ef\u4ee5\u8fdb\u884c\u5fae\u8c03\u3002HuggingFace\u5305\u63d0\u4f9b\u4e86\u4f7f\u7528PyTorch\u548cTensorFlow\u8bad\u7ec3\u8fd9\u4e9b\u67b6\u6784\u7684\u8d44\u6e90\u5e93\u3002</p>"},{"location":"lessons/5-NLP/18-Transformers/READMEtransformers_chs/#_5","title":"\ud83d\ude80 \u6311\u6218","text":""},{"location":"lessons/5-NLP/18-Transformers/READMEtransformers_chs/#_6","title":"\u8bfe\u540e\u6d4b\u9a8c","text":""},{"location":"lessons/5-NLP/18-Transformers/READMEtransformers_chs/#_7","title":"\u590d\u4e60\u548c\u81ea\u5b66","text":"<ul> <li>\u535a\u5ba2\u6587\u7ae0\uff0c\u89e3\u91ca\u7ecf\u5178\u7684Attention is all you need\u8bba\u6587\uff0c\u5173\u4e8eTransformer\u3002</li> <li>\u4e00\u7cfb\u5217\u535a\u5ba2\u6587\u7ae0\uff0c\u8be6\u7ec6\u89e3\u91caTransformer\u7684\u67b6\u6784\u3002</li> </ul>"},{"location":"lessons/5-NLP/18-Transformers/READMEtransformers_chs/#_8","title":"\u4f5c\u4e1a","text":""},{"location":"lessons/5-NLP/18-Transformers/assignment/","title":"Assignment: Transformers","text":"<p>Experiment with Transformers on HuggingFace! Try some of the scripts they provide to work with the various models available on their site: https://huggingface.co/docs/transformers/run_scripts. Try one of their datasets, then import one of your own from this curriculum or from Kaggle and see if you can generate interesting texts. Produce a notebook with your findings.</p>"},{"location":"lessons/5-NLP/18-Transformers/assignment_chs/","title":"\u4f5c\u4e1a: Transformers","text":"<p>\u5728 HuggingFace \u4e0a\u5c1d\u8bd5 Transformers\uff01\u5c1d\u8bd5\u4f7f\u7528\u4ed6\u4eec\u63d0\u4f9b\u7684\u4e00\u4e9b\u811a\u672c\u6765\u5904\u7406\u4ed6\u4eec\u7f51\u7ad9\u4e0a\u63d0\u4f9b\u7684\u5404\u79cd\u6a21\u578b\uff1ahttps://huggingface.co/docs/transformers/run_scripts\u3002\u8bd5\u7740\u4f7f\u7528\u4ed6\u4eec\u7684\u4e00\u4e2a\u6570\u636e\u96c6\uff0c\u7136\u540e\u4ece\u672c\u8bfe\u7a0b\u6216\u4ece Kaggle \u5bfc\u5165\u60a8\u81ea\u5df1\u7684\u6570\u636e\u96c6\uff0c\u770b\u770b\u662f\u5426\u80fd\u751f\u6210\u6709\u8da3\u7684\u6587\u672c\u3002\u5236\u4f5c\u4e00\u4efd\u5305\u542b\u60a8\u53d1\u73b0\u5185\u5bb9\u7684\u7b14\u8bb0\u672c\u3002</p>"},{"location":"lessons/5-NLP/19-NER/","title":"Named Entity Recognition","text":"<p>Up to now, we have mostly been concentrating on one NLP task - classification. However, there are also other NLP tasks that can be accomplished with neural networks. One of those tasks is Named Entity Recognition (NER), which deals with recognizing specific entities within text, such as places, person names, date-time intervals, chemical formulae and so on.</p>"},{"location":"lessons/5-NLP/19-NER/#pre-lecture-quiz","title":"Pre-lecture quiz","text":""},{"location":"lessons/5-NLP/19-NER/#example-of-using-ner","title":"Example of Using NER","text":"<p>Suppose you want to develop a natural language chat bot, similar to Amazon Alexa or Google Assistant. The way intelligent chat bots work is to understand what the user wants by doing text classification on the input sentence. The result of this classification is so-called intent, which determines what a chat bot should do.</p> <p></p> <p>Image by the author</p> <p>However, a user may provide some parameters as part of the phrase. For example, when asking for the weather, she may specify a location or date. A bot should be able to understand those entities, and fill in the parameter slots accordingly before performing the action. This is exactly where NER comes in.</p> <p>\u2705 Another example would be analyzing scientific medical papers. One of the main things we need to look for are specific medical terms, such as diseases and medical substances. While a small number of diseases can probably be extracted using substring search, more complex entities, such as chemical compounds and medication names, need a more complex approach.</p>"},{"location":"lessons/5-NLP/19-NER/#ner-as-token-classification","title":"NER as Token Classification","text":"<p>NER models are essentially token classification models, because for each of the input tokens we need to decide whether it belongs to an entity or not, and if it does - to which entity class.</p> <p>Consider the following paper title:</p> <p>Tricuspid valve regurgitation and lithium carbonate toxicity in a newborn infant.</p> <p>Entities here are:</p> <ul> <li>Tricuspid valve regurgitation is a disease (<code>DIS</code>)</li> <li>Lithium carbonate is a chemical substance (<code>CHEM</code>)</li> <li>Toxicity is also a disease (<code>DIS</code>)</li> </ul> <p>Notice that one entity can span several tokens. And, as in this case, we need to distinguish between two consecutive entities. Thus, it is common to use two classes for each entity - one specifying the first token of the entity (often the <code>B-</code> prefix is used, for beginning), and another - the continuation of an entity (<code>I-</code>, for inner token). We also use <code>O</code> as a class to represent all other tokens. Such token tagging is called BIO tagging (or IOB). When tagged, our title will look like this:</p> Token Tag Tricuspid B-DIS valve I-DIS regurgitation I-DIS and O lithium B-CHEM carbonate I-CHEM toxicity B-DIS in O a O newborn O infant O . O <p>Since we need to build a one-to-one correspondence between tokens and classes, we can train a rightmost many-to-many neural network model from this picture:</p> <p></p> <p>Image from this blog post by Andrej Karpathy. NER token classification models correspond to the right-most network architecture on this picture.</p>"},{"location":"lessons/5-NLP/19-NER/#training-ner-models","title":"Training NER models","text":"<p>Since a NER model is essentially a token classification model, we can use RNNs that we are already familiar with for this task. In this case, each block of recurrent network will return the token ID. The following example notebook shows how to train LSTM for token classification.</p>"},{"location":"lessons/5-NLP/19-NER/#example-notebooks-ner","title":"\u270d\ufe0f Example Notebooks: NER","text":"<p>Continue your learning in the following notebook:</p> <ul> <li>NER with TensorFlow</li> </ul>"},{"location":"lessons/5-NLP/19-NER/#conclusion","title":"Conclusion","text":"<p>A NER model is a token classification model, which means that it can be used to perform token classification. This is a very common task in NLP, helping to recognize specific entities within text including places, names, dates, and more.</p>"},{"location":"lessons/5-NLP/19-NER/#challenge","title":"\ud83d\ude80 Challenge","text":"<p>Complete the assignment linked below to train a named entity recognition model for medical terms, then try it on a different dataset.</p>"},{"location":"lessons/5-NLP/19-NER/#post-lecture-quiz","title":"Post-lecture quiz","text":""},{"location":"lessons/5-NLP/19-NER/#review-self-study","title":"Review &amp; Self Study","text":"<p>Read through the blog The Unreasonable Effectiveness of Recurrent Neural Networks and follow along with the Further Reading section in that article to deepen your knowledge.</p>"},{"location":"lessons/5-NLP/19-NER/#assignment","title":"Assignment","text":"<p>In the assignment for this lesson, you will have to train a medical entity recognition model. You can start with training an LSTM model as described in this lesson, and proceed with using the BERT transformer model. Read the instructions to get all the details.</p>"},{"location":"lessons/5-NLP/19-NER/README_chs/","title":"\u547d\u540d\u5b9e\u4f53\u8bc6\u522b","text":"<p>\u5230\u76ee\u524d\u4e3a\u6b62\uff0c\u6211\u4eec\u4e3b\u8981\u96c6\u4e2d\u5728\u4e00\u4e2a\u81ea\u7136\u8bed\u8a00\u5904\u7406\u4efb\u52a1 - \u5206\u7c7b\u3002\u7136\u800c\uff0c\u8fd8\u6709\u5176\u4ed6\u53ef\u4ee5\u901a\u8fc7\u795e\u7ecf\u7f51\u7edc\u5b8c\u6210\u7684\u81ea\u7136\u8bed\u8a00\u5904\u7406\u4efb\u52a1\u3002\u5176\u4e2d\u4e00\u4e2a\u4efb\u52a1\u662f\u547d\u540d\u5b9e\u4f53\u8bc6\u522b (NER)\uff0c\u5b83\u5904\u7406\u8bc6\u522b\u6587\u672c\u4e2d\u7684\u7279\u5b9a\u5b9e\u4f53\uff0c\u5982\u5730\u70b9\u3001\u4eba\u7269\u59d3\u540d\u3001\u65e5\u671f\u65f6\u95f4\u95f4\u9694\u3001\u5316\u5b66\u516c\u5f0f\u7b49\u3002</p>"},{"location":"lessons/5-NLP/19-NER/README_chs/#_2","title":"\u8bfe\u524d\u6d4b\u9a8c","text":""},{"location":"lessons/5-NLP/19-NER/README_chs/#ner","title":"\u4f7f\u7528NER\u7684\u793a\u4f8b","text":"<p>\u5047\u8bbe\u4f60\u60f3\u5f00\u53d1\u4e00\u4e2a\u7c7b\u4f3c\u4e8eAmazon Alexa\u6216Google Assistant\u7684\u81ea\u7136\u8bed\u8a00\u804a\u5929\u673a\u5668\u4eba\u3002\u667a\u80fd\u804a\u5929\u673a\u5668\u4eba\u7684\u5de5\u4f5c\u65b9\u5f0f\u662f\u901a\u8fc7\u5bf9\u8f93\u5165\u53e5\u5b50\u8fdb\u884c\u6587\u672c\u5206\u7c7b\u6765\u7406\u89e3\u7528\u6237\u7684\u9700\u6c42\u3002\u8fd9\u4e2a\u5206\u7c7b\u7684\u7ed3\u679c\u88ab\u79f0\u4e3a\u610f\u56fe\uff0c\u5b83\u51b3\u5b9a\u4e86\u804a\u5929\u673a\u5668\u4eba\u5e94\u8be5\u505a\u4ec0\u4e48\u3002</p> <p></p> <p>\u56fe\u7247\u7531\u4f5c\u8005\u63d0\u4f9b</p> <p>\u7136\u800c\uff0c\u7528\u6237\u53ef\u80fd\u4f1a\u5728\u77ed\u8bed\u4e2d\u63d0\u4f9b\u4e00\u4e9b\u53c2\u6570\u3002\u4f8b\u5982\uff0c\u5f53\u95ee\u5929\u6c14\u65f6\uff0c\u5979\u53ef\u80fd\u4f1a\u6307\u5b9a\u4f4d\u7f6e\u6216\u65e5\u671f\u3002\u673a\u5668\u4eba\u5e94\u8be5\u80fd\u591f\u7406\u89e3\u8fd9\u4e9b\u5b9e\u4f53\uff0c\u5e76\u5728\u6267\u884c\u64cd\u4f5c\u4e4b\u524d\u76f8\u5e94\u5730\u586b\u5199\u53c2\u6570\u69fd\u3002\u8fd9\u6b63\u662fNER\u7684\u7528\u9014\u6240\u5728\u3002</p> <p>\u2705 \u53e6\u4e00\u4e2a\u4f8b\u5b50\u662f\u5206\u6790\u79d1\u5b66\u533b\u5b66\u8bba\u6587\u3002\u6211\u4eec\u9700\u8981\u67e5\u627e\u7684\u4e3b\u8981\u662f\u7279\u5b9a\u7684\u533b\u5b66\u672f\u8bed\uff0c\u5982\u75be\u75c5\u548c\u836f\u54c1\u540d\u79f0\u3002\u867d\u7136\u5c11\u91cf\u75be\u75c5\u53ef\u80fd\u53ef\u4ee5\u4f7f\u7528\u5b50\u5b57\u7b26\u4e32\u641c\u7d22\u63d0\u53d6\uff0c\u590d\u6742\u7684\u5b9e\u4f53\u5982\u5316\u5b66\u5316\u5408\u7269\u548c\u836f\u54c1\u540d\u79f0\u5219\u9700\u8981\u66f4\u590d\u6742\u7684\u65b9\u6cd5\u3002</p>"},{"location":"lessons/5-NLP/19-NER/README_chs/#nertoken","title":"NER\u4f5c\u4e3aToken\u5206\u7c7b","text":"<p>NER\u6a21\u578b\u672c\u8d28\u4e0a\u662ftoken\u5206\u7c7b\u6a21\u578b\uff0c\u56e0\u4e3a\u5bf9\u4e8e\u6bcf\u4e2a\u8f93\u5165\u7684token\uff0c\u6211\u4eec\u9700\u8981\u51b3\u5b9a\u5b83\u662f\u5426\u5c5e\u4e8e\u67d0\u4e2a\u5b9e\u4f53\uff0c\u5982\u679c\u662f - \u5c5e\u4e8e\u54ea\u4e2a\u5b9e\u4f53\u7c7b\u522b\u3002</p> <p>\u8003\u8651\u4ee5\u4e0b\u8bba\u6587\u6807\u9898\uff1a</p> <p>\u4e09\u5c16\u74e3\u53cd\u6d41\u548c\u78b3\u9178\u9502\u4e2d\u6bd2\u5728\u65b0\u751f\u513f\u4e2d\u7684\u75c5\u60c5\u3002</p> <p>\u8fd9\u91cc\u7684\u5b9e\u4f53\u662f\uff1a</p> <ul> <li>\u4e09\u5c16\u74e3\u53cd\u6d41\u662f\u4e00\u79cd\u75be\u75c5 (<code>DIS</code>)</li> <li>\u78b3\u9178\u9502\u662f\u4e00\u79cd\u5316\u5b66\u7269\u8d28 (<code>CHEM</code>)</li> <li>\u4e2d\u6bd2\u4e5f\u662f\u4e00\u79cd\u75be\u75c5 (<code>DIS</code>)</li> </ul> <p>\u6ce8\u610f\u4e00\u4e2a\u5b9e\u4f53\u53ef\u80fd\u8de8\u8d8a\u591a\u4e2atoken\u3002\u800c\u4e14\uff0c\u5982\u5728\u8fd9\u79cd\u60c5\u51b5\u4e0b\uff0c\u6211\u4eec\u9700\u8981\u533a\u5206\u4e24\u4e2a\u8fde\u7eed\u7684\u5b9e\u4f53\u3002\u56e0\u6b64\uff0c\u901a\u5e38\u4f7f\u7528\u4e24\u4e2a\u7c7b\u6765\u8868\u793a\u6bcf\u4e2a\u5b9e\u4f53 - \u4e00\u4e2a\u6307\u5b9a\u5b9e\u4f53\u7684\u7b2c\u4e00\u4e2atoken\uff08\u901a\u5e38\u4f7f\u7528<code>B-</code>\u524d\u7f00\uff0c\u8868\u793a\u5f00\u59cb\uff09\uff0c\u53e6\u4e00\u4e2a\u8868\u793a\u5b9e\u4f53\u7684\u5ef6\u7eed\uff08<code>I-</code>\uff0c\u8868\u793a\u5185\u90e8token\uff09\u3002\u6211\u4eec\u8fd8\u4f7f\u7528<code>O</code>\u4f5c\u4e3a\u7c7b\u522b\u6765\u8868\u793a\u6240\u6709\u5176\u4ed6token\u3002\u8fd9\u6837\u7684token\u6807\u8bb0\u79f0\u4e3aBIO\u6807\u8bb0\uff08\u6216IOB\uff09\u3002\u6807\u8bb0\u540e\uff0c\u6211\u4eec\u7684\u6807\u9898\u770b\u8d77\u6765\u662f\u8fd9\u6837\u7684\uff1a</p> Token Tag \u4e09\u5c16\u74e3 B-DIS \u53cd\u6d41 I-DIS \u548c O \u78b3\u9178\u9502 B-CHEM \u4e2d\u6bd2 I-CHEM \u5728 O \u65b0\u751f\u513f O \u4e2d\u7684 O \u75c5\u60c5 O \u3002 O <p>\u7531\u4e8e\u6211\u4eec\u9700\u8981\u5728token\u548c\u7c7b\u4e4b\u95f4\u5efa\u7acb\u4e00\u5bf9\u4e00\u7684\u5bf9\u5e94\u5173\u7cfb\uff0c\u6211\u4eec\u53ef\u4ee5\u4ece\u8fd9\u4e2a\u56fe\u4e2d\u8bad\u7ec3\u4e00\u4e2a\u6700\u53f3\u4fa7\u7684\u591a\u5bf9\u591a\u795e\u7ecf\u7f51\u7edc\u6a21\u578b\uff1a</p> <p></p> <p>\u56fe\u7247\u6765\u81ea\u8fd9\u7bc7\u535a\u5ba2\u6587\u7ae0\u7531Andrej Karpathy\u64b0\u5199\u3002NER token\u5206\u7c7b\u6a21\u578b\u5bf9\u5e94\u4e8e\u56fe\u7247\u4e2d\u6700\u53f3\u8fb9\u7684\u7f51\u7edc\u67b6\u6784\u3002</p>"},{"location":"lessons/5-NLP/19-NER/README_chs/#ner_1","title":"\u8bad\u7ec3NER\u6a21\u578b","text":"<p>\u7531\u4e8eNER\u6a21\u578b\u672c\u8d28\u4e0a\u662f\u4e00\u4e2atoken\u5206\u7c7b\u6a21\u578b\uff0c\u6211\u4eec\u53ef\u4ee5\u5229\u7528\u6211\u4eec\u5df2\u7ecf\u719f\u6089\u7684RNN\u5b8c\u6210\u8fd9\u4e2a\u4efb\u52a1\u3002\u5728\u8fd9\u79cd\u60c5\u51b5\u4e0b\uff0c\u6bcf\u5757\u9012\u5f52\u7f51\u7edc\u5c06\u8fd4\u56detoken ID\u3002\u4ee5\u4e0b\u793a\u4f8b\u7b14\u8bb0\u672c\u5c55\u793a\u4e86\u5982\u4f55\u8bad\u7ec3\u7528\u4e8etoken\u5206\u7c7b\u7684LSTM\u3002</p>"},{"location":"lessons/5-NLP/19-NER/README_chs/#ner_2","title":"\u270d\ufe0f \u793a\u4f8b\u7b14\u8bb0\u672c: NER","text":"<p>\u5728\u4ee5\u4e0b\u7b14\u8bb0\u672c\u4e2d\u7ee7\u7eed\u5b66\u4e60\uff1a</p> <ul> <li>NER\u4e0eTensorFlow</li> </ul>"},{"location":"lessons/5-NLP/19-NER/README_chs/#_3","title":"\u7ed3\u8bba","text":"<p>\u4e00\u4e2aNER\u6a21\u578b\u662f\u4e00\u4e2atoken\u5206\u7c7b\u6a21\u578b\uff0c\u8fd9\u610f\u5473\u7740\u5b83\u53ef\u4ee5\u7528\u6765\u6267\u884ctoken\u5206\u7c7b\u3002\u8fd9\u662f\u5728NLP\u4e2d\u975e\u5e38\u5e38\u89c1\u7684\u4efb\u52a1\uff0c\u6709\u52a9\u4e8e\u8bc6\u522b\u6587\u672c\u4e2d\u7684\u7279\u5b9a\u5b9e\u4f53\uff0c\u5305\u62ec\u5730\u70b9\u3001\u540d\u5b57\u3001\u65e5\u671f\u7b49\u7b49\u3002</p>"},{"location":"lessons/5-NLP/19-NER/README_chs/#_4","title":"\ud83d\ude80 \u6311\u6218","text":"<p>\u5b8c\u6210\u4e0b\u9762\u94fe\u63a5\u7684\u4f5c\u4e1a\uff0c\u8bad\u7ec3\u4e00\u4e2a\u533b\u5b66\u672f\u8bed\u547d\u540d\u5b9e\u4f53\u8bc6\u522b\u6a21\u578b\uff0c\u7136\u540e\u5c1d\u8bd5\u5728\u4e0d\u540c\u7684\u6570\u636e\u96c6\u4e0a\u8fdb\u884c\u5b9e\u9a8c\u3002</p>"},{"location":"lessons/5-NLP/19-NER/README_chs/#_5","title":"\u8bfe\u540e\u6d4b\u9a8c","text":""},{"location":"lessons/5-NLP/19-NER/README_chs/#_6","title":"\u590d\u4e60\u548c\u81ea\u5b66","text":"<p>\u9605\u8bfb\u535a\u5ba2\u9012\u5f52\u795e\u7ecf\u7f51\u7edc\u7684\u975e\u51e1\u6709\u6548\u6027\u5e76\u6309\u7167\u6587\u7ae0\u4e2d\u7684\u6df1\u5165\u9605\u8bfb\u90e8\u5206\u8fdb\u884c\u5b66\u4e60\uff0c\u4ee5\u52a0\u6df1\u4f60\u7684\u77e5\u8bc6\u3002</p>"},{"location":"lessons/5-NLP/19-NER/README_chs/#_7","title":"\u4f5c\u4e1a","text":"<p>\u5728\u672c\u8bfe\u7684\u4f5c\u4e1a\u4e2d\uff0c\u4f60\u9700\u8981\u8bad\u7ec3\u4e00\u4e2a\u533b\u5b66\u5b9e\u4f53\u8bc6\u522b\u6a21\u578b\u3002\u4f60\u53ef\u4ee5\u4ece\u8bad\u7ec3LSTM\u6a21\u578b\u5f00\u59cb\uff0c\u6b63\u5982\u672c\u8bfe\u6240\u8ff0\uff0c\u7136\u540e\u4f7f\u7528BERT\u8f6c\u6362\u5668\u6a21\u578b\u3002\u9605\u8bfb\u6307\u793a\u4ee5\u83b7\u53d6\u6240\u6709\u8be6\u60c5\u3002</p>"},{"location":"lessons/5-NLP/19-NER/lab/","title":"NER","text":"<p>Lab Assignment from AI for Beginners Curriculum.</p>"},{"location":"lessons/5-NLP/19-NER/lab/#task","title":"Task","text":"<p>In this lab, you need to train named entity recognition model for medical terms.</p>"},{"location":"lessons/5-NLP/19-NER/lab/#the-dataset","title":"The Dataset","text":"<p>To train NER model, we need properly labeled dataset with medical entities. BC5CDR dataset contains labeled diseases and chemicals entities from more than 1500 papers. You may download the dataset after registering at their web site.</p> <p>BC5CDR Dataset looks like this:</p> <pre><code>6794356|t|Tricuspid valve regurgitation and lithium carbonate toxicity in a newborn infant.\n6794356|a|A newborn with massive tricuspid regurgitation, atrial flutter, congestive heart failure, and a high serum lithium level is described. This is the first patient to initially manifest tricuspid regurgitation and atrial flutter, and the 11th described patient with cardiac disease among infants exposed to lithium compounds in the first trimester of pregnancy. Sixty-three percent of these infants had tricuspid valve involvement. Lithium carbonate may be a factor in the increasing incidence of congenital heart disease when taken during early pregnancy. It also causes neurologic depression, cyanosis, and cardiac arrhythmia when consumed prior to delivery.\n6794356 0   29  Tricuspid valve regurgitation   Disease D014262\n6794356 34  51  lithium carbonate   Chemical    D016651\n6794356 52  60  toxicity    Disease D064420\n...\n</code></pre> <p>In this dataset, there are paper title and abstract in the first two lines, and then there are individual entities, with beginning and end positions within title+abstract block. In addition to entity type, you get the ontology ID of this entity within some medical ontology.</p> <p>You will need to write some Python code to convert this into BIO encoding.</p>"},{"location":"lessons/5-NLP/19-NER/lab/#the-network","title":"The Network","text":"<p>First attempt at NER can be done by using LSTM network, as in our example you have seen during the lesson. However, in NLP tasks, transformer architecture, and specifically BERT language models show much better results. Pre-trained BERT models understand the general structure of a language, and can be fine-tuned for specific tasks with relatively small datasets and computational costs.</p> <p>Since we are planning to apply NER to medical scenario, it makes sense to use BERT model trained on medical texts. Microsoft Research has released a pre-trained a model called [PubMedBERT][PubMedBERT] ([publication][PubMedBERT-Pub]), which was fine-tuned using texts from PubMed repository.</p> <p>The de facto standard for training transformer models is Hugging Face Transformers library. It also contains a repository of community-maintained pre-trained models, including PubMedBERT. To load and use this model, we just need a couple of lines of code:</p> <pre><code>model_name = \"microsoft/BiomedNLP-PubMedBERT-base-uncased-abstract\"\nclasses = ... # number of classes: 2*entities+1\ntokenizer = AutoTokenizer.from_pretrained(model_name)\nmodel = BertForTokenClassification.from_pretrained(model_name, classes)\n</code></pre> <p>This gives us the <code>model</code> itself, built for token classification task using <code>classes</code> number of classes, as well as <code>tokenizer</code> object that can split input text into tokens. You will need to convert the dataset into BIO format, taking PubMedBERT tokenization into account. You can use this bit of Python code as an inspiration.</p>"},{"location":"lessons/5-NLP/19-NER/lab/#takeaway","title":"Takeaway","text":"<p>This task is very close to the actual task you are likely go have if you want to gain more insights into large volumes on natural language texts. In our case, we can apply our trained model to the dataset of COVID-related papers and see which insights we will be able to get. This blog post and this paper describe the research the can be done on this corpus of papers using NER.</p>"},{"location":"lessons/5-NLP/19-NER/lab/README_chs/","title":"\u547d\u540d\u5b9e\u4f53\u8bc6\u522b\uff08NER\uff09","text":"<p>\u6765\u81ea AI for Beginners Curriculum \u7684\u5b9e\u9a8c\u4efb\u52a1\u3002</p>"},{"location":"lessons/5-NLP/19-NER/lab/README_chs/#_1","title":"\u4efb\u52a1","text":"<p>\u5728\u672c\u6b21\u5b9e\u9a8c\u4e2d\uff0c\u60a8\u9700\u8981\u8bad\u7ec3\u4e00\u4e2a\u7528\u4e8e\u533b\u5b66\u672f\u8bed\u7684\u547d\u540d\u5b9e\u4f53\u8bc6\u522b\u6a21\u578b\u3002</p>"},{"location":"lessons/5-NLP/19-NER/lab/README_chs/#_2","title":"\u6570\u636e\u96c6","text":"<p>\u8981\u8bad\u7ec3 NER \u6a21\u578b\uff0c\u6211\u4eec\u9700\u8981\u4e00\u4e2a\u9002\u5f53\u6807\u6ce8\u4e86\u533b\u5b66\u5b9e\u4f53\u7684\u6570\u636e\u96c6\u3002BC5CDR \u6570\u636e\u96c6 \u5305\u542b\u4e86\u4ece1500\u591a\u7bc7\u8bba\u6587\u4e2d\u6807\u6ce8\u7684\u75be\u75c5\u548c\u5316\u5b66\u5b9e\u4f53\u3002\u60a8\u53ef\u4ee5\u5728\u4ed6\u4eec\u7684\u7f51\u7ad9\u6ce8\u518c\u540e\u4e0b\u8f7d\u6570\u636e\u96c6\u3002</p> <p>BC5CDR \u6570\u636e\u96c6\u5982\u4e0b\u6240\u793a\uff1a</p> <pre><code>6794356|t|\u65b0\u751f\u513f\u4e09\u5c16\u74e3\u8fd4\u6d41\u548c\u78b3\u9178\u9502\u4e2d\u6bd2\u3002\n6794356|a|\u63cf\u8ff0\u4e86\u4e00\u540d\u6709\u5927\u91cf\u4e09\u5c16\u74e3\u8fd4\u6d41\u3001\u5fc3\u623f\u6251\u52a8\u3001\u5145\u8840\u6027\u5fc3\u529b\u8870\u7aed\u548c\u9ad8\u8840\u6e05\u9502\u6c34\u5e73\u7684\u65b0\u751f\u513f\u3002\u8fd9\u662f\u7b2c\u4e00\u4f8b\u6700\u521d\u8868\u73b0\u4e3a\u4e09\u5c16\u74e3\u8fd4\u6d41\u548c\u5fc3\u623f\u6251\u52a8\u7684\u60a3\u8005\uff0c\u4e5f\u662f\u7b2c11\u4f8b\u5728\u6000\u5b55\u65e9\u671f\u66b4\u9732\u4e8e\u9502\u5316\u5408\u7269\u7684\u5a74\u513f\u4e2d\u7684\u5177\u6709\u5fc3\u810f\u75c5\u7684\u60a3\u8005\u3002\u8fd9\u4e9b\u5a74\u513f\u4e2d63\uff05\u6709\u4e09\u5c16\u74e3\u53c2\u4e0e\u3002\u78b3\u9178\u9502\u53ef\u80fd\u662f\u6000\u5b55\u65e9\u671f\u670d\u7528\u65f6\u5148\u5929\u6027\u5fc3\u810f\u75c5\u53d1\u75c5\u7387\u589e\u52a0\u7684\u56e0\u7d20\u4e4b\u4e00\u3002\u5b83\u5728\u5206\u5a29\u524d\u98df\u7528\u65f6\u8fd8\u4f1a\u5bfc\u81f4\u795e\u7ecf\u6291\u5236\u3001\u9752\u7d2b\u75c7\u548c\u5fc3\u5f8b\u4e0d\u9f50\u3002\n6794356 0   29  \u4e09\u5c16\u74e3\u8fd4\u6d41   \u75be\u75c5  D014262\n6794356 34  51  \u78b3\u9178\u9502 \u5316\u5b66\u54c1 D016651\n6794356 52  60  \u6bd2\u6027  \u75be\u75c5  D064420\n...\n</code></pre> <p>\u5728\u8fd9\u4e2a\u6570\u636e\u96c6\u4e2d\uff0c\u7b2c\u4e00\u884c\u662f\u8bba\u6587\u7684\u6807\u9898\uff0c\u7b2c\u4e8c\u884c\u662f\u6458\u8981\uff0c\u63a5\u7740\u662f\u6bcf\u4e2a\u72ec\u7acb\u7684\u5b9e\u4f53\u53ca\u5176\u5728\u6807\u9898+\u6458\u8981\u5757\u4e2d\u7684\u8d77\u59cb\u548c\u7ed3\u675f\u4f4d\u7f6e\u3002\u9664\u4e86\u5b9e\u4f53\u7c7b\u578b\uff0c\u8fd8\u4f1a\u7ed9\u51fa\u8be5\u5b9e\u4f53\u5728\u67d0\u4e2a\u533b\u5b66\u672c\u4f53\u4e2d\u7684\u672c\u4f53ID\u3002</p> <p>\u60a8\u9700\u8981\u7f16\u5199\u4e00\u4e9bPython\u4ee3\u7801\u5c06\u5176\u8f6c\u6362\u4e3aBIO\u7f16\u7801\u683c\u5f0f\u3002</p>"},{"location":"lessons/5-NLP/19-NER/lab/README_chs/#_3","title":"\u7f51\u7edc","text":"<p>\u9996\u6b21\u5c1d\u8bd5NER\u53ef\u4ee5\u4f7f\u7528LSTM\u7f51\u7edc\uff0c\u5c31\u50cf\u60a8\u5728\u8bfe\u7a0b\u4e2d\u770b\u5230\u7684\u4f8b\u5b50\u4e00\u6837\u3002\u7136\u800c\uff0c\u5728NLP\u4efb\u52a1\u4e2d\uff0c\u8f6c\u6362\u5668\u67b6\u6784\uff0c\u5c24\u5176\u662fBERT\u8bed\u8a00\u6a21\u578b\uff0c\u663e\u793a\u51fa\u66f4\u597d\u7684\u7ed3\u679c\u3002\u9884\u8bad\u7ec3\u7684BERT\u6a21\u578b\u7406\u89e3\u8bed\u8a00\u7684\u603b\u4f53\u7ed3\u6784\uff0c\u5e76\u53ef\u4ee5\u7528\u76f8\u5bf9\u8f83\u5c0f\u7684\u6570\u636e\u96c6\u548c\u8ba1\u7b97\u6210\u672c\u8fdb\u884c\u9488\u5bf9\u5177\u4f53\u4efb\u52a1\u7684\u5fae\u8c03\u3002</p> <p>\u7531\u4e8e\u6211\u4eec\u8ba1\u5212\u5c06NER\u5e94\u7528\u4e8e\u533b\u7597\u573a\u666f\uff0c\u56e0\u6b64\u4f7f\u7528\u5728\u533b\u7597\u6587\u672c\u4e0a\u8bad\u7ec3\u7684BERT\u6a21\u578b\u662f\u6709\u610f\u4e49\u7684\u3002\u5fae\u8f6f\u7814\u7a76\u9662\u53d1\u5e03\u4e86\u4e00\u4e2a\u9884\u8bad\u7ec3\u6a21\u578b\uff0c\u79f0\u4e3a[PubMedBERT][PubMedBERT]\uff08[\u53d1\u8868\u6587\u7ae0][PubMedBERT-Pub]\uff09\uff0c\u8be5\u6a21\u578b\u4f7f\u7528PubMed\u5e93\u4e2d\u7684\u6587\u672c\u5fae\u8c03\u8fc7\u3002</p> <p>\u8bad\u7ec3\u8f6c\u6362\u5668\u6a21\u578b\u7684\u4e8b\u5b9e\u4e0a\u7684\u6807\u51c6\u662fHugging Face Transformers\u5e93\u3002\u5b83\u8fd8\u5305\u542b\u4e86\u4e00\u4e2a\u793e\u533a\u7ef4\u62a4\u7684\u9884\u8bad\u7ec3\u6a21\u578b\u5e93\uff0c\u5305\u62ecPubMedBERT\u3002\u8981\u52a0\u8f7d\u5e76\u4f7f\u7528\u6b64\u6a21\u578b\uff0c\u6211\u4eec\u53ea\u9700\u51e0\u884c\u4ee3\u7801\uff1a</p> <pre><code>model_name = \"microsoft/BiomedNLP-PubMedBERT-base-uncased-abstract\"\nclasses = ... # \u7c7b\u522b\u6570\u91cf\uff1a2*\u5b9e\u4f53+1\ntokenizer = AutoTokenizer.from_pretrained(model_name)\nmodel = BertForTokenClassification.from_pretrained(model_name, classes)\n</code></pre> <p>\u8fd9\u4e3a\u6211\u4eec\u63d0\u4f9b\u4e86\u4e00\u4e2a <code>model</code>\uff0c\u5b83\u9488\u5bf9\u6807\u8bb0\u5206\u7c7b\u4efb\u52a1\u6784\u5efa\uff0c\u4f7f\u7528 <code>classes</code> \u6570\u91cf\u7684\u7c7b\u522b\uff0c\u8fd8\u6709\u4e00\u4e2a <code>tokenizer</code> \u5bf9\u8c61\uff0c\u53ef\u4ee5\u5c06\u8f93\u5165\u6587\u672c\u62c6\u5206\u4e3a\u6807\u8bb0\u3002\u60a8\u9700\u8981\u5c06\u6570\u636e\u96c6\u8f6c\u6362\u4e3aBIO\u683c\u5f0f\uff0c\u5e76\u8003\u8651PubMedBERT\u7684\u5206\u8bcd\u3002\u60a8\u53ef\u4ee5\u4f7f\u7528\u8fd9\u6bb5Python\u4ee3\u7801\u4f5c\u4e3a\u7075\u611f\u3002</p>"},{"location":"lessons/5-NLP/19-NER/lab/README_chs/#_4","title":"\u6536\u83b7","text":"<p>\u8fd9\u4e2a\u4efb\u52a1\u975e\u5e38\u63a5\u8fd1\u5b9e\u9645\u4e2d\u7684\u4efb\u52a1\uff0c\u5982\u679c\u60a8\u60f3\u6df1\u5165\u5206\u6790\u5927\u91cf\u81ea\u7136\u8bed\u8a00\u6587\u672c\u3002\u5728\u6211\u4eec\u7684\u6848\u4f8b\u4e2d\uff0c\u6211\u4eec\u53ef\u4ee5\u5c06\u6211\u4eec\u8bad\u7ec3\u7684\u6a21\u578b\u5e94\u7528\u4e8e\u4e0eCOVID\u76f8\u5173\u7684\u8bba\u6587\u6570\u636e\u96c6\uff0c\u770b\u770b\u6211\u4eec\u80fd\u5f97\u5230\u54ea\u4e9b\u89c1\u89e3\u3002\u8fd9\u7bc7\u535a\u5ba2\u6587\u7ae0 \u548c \u8fd9\u7bc7\u8bba\u6587 \u63cf\u8ff0\u4e86\u4f7f\u7528NER\u5728\u8fd9\u6279\u6587\u732e\u8bed\u6599\u5e93\u4e0a\u53ef\u4ee5\u8fdb\u884c\u7684\u7814\u7a76\u3002</p>"},{"location":"lessons/5-NLP/20-LangModels/READMELargeLang/","title":"Pre-Trained Large Language Models","text":"<p>In all of our previous tasks, we were training a neural network to perform a certain task using labeled dataset. With large transformer models, such as BERT, we use language modelling in self-supervised fashion to build a language model, which is then specialized for specific downstream task with further domain-specific training. However, it has been demonstrated that large language models can also solve many tasks without ANY domain-specific training. A family of models capable of doing that is called GPT: Generative Pre-Trained Transformer.</p>"},{"location":"lessons/5-NLP/20-LangModels/READMELargeLang/#pre-lecture-quiz","title":"Pre-lecture quiz","text":""},{"location":"lessons/5-NLP/20-LangModels/READMELargeLang/#text-generation-and-perplexity","title":"Text Generation and Perplexity","text":"<p>The idea of a neural network being able to do general tasks without downstream training is presented in Language Models are Unsupervised Multitask Learners paper. The main idea is the many other tasks can be modeled using text generation, because understanding text essentially means being able to produce it. Because the model is trained on a huge amount of text that encompasses human knowledge, it also becomes knowledgeable about wide variety of subjects.</p> <p>Understanding and being able to produce text also entails knowing something about the world around us. People  also learn by reading to the large extent, and GPT network is similar in this respect.</p> <p>Text generation networks work by predicting probability of the next word $$P(w_N)$$ However, unconditional probability of the next word equals to the frequency of the this word in the text corpus. GPT is able to give us conditional probability of the next word, given the previous ones: $$P(w_N | w_{n-1}, ..., w_0)$$</p> <p>You can read more about probabilities in our Data Science for Beginers Curriculum</p> <p>Quality of language generating model can be defined using perplexity. It is intrinsic metric that allows us to measure the model quality without any task-specific dataset. It is based on the notion of probability of a sentence - the model assigns high probability to a sentence that is likely to be real (i.e. the model is not perplexed by it), and low probability to sentences that make less sense (eg. Can it does what?). When we give our model sentences from real text corpus, we would expect them to have high probability, and low perplexity. Mathematically, it is defined as normalized inverse probability of the test set: $$ \\mathrm{Perplexity}(W) = \\sqrt[N]{1\\over P(W_1,...,W_N)} $$ </p> <p>You can experiment with text generation using GPT-powered text editor from Hugging Face. In this editor, you start writing your text, and pressing [TAB] will offer you several completion options. If they are too short, or you are not satisfied with them - press [TAB] again, and you will have more options, including longer pieces of text.</p>"},{"location":"lessons/5-NLP/20-LangModels/READMELargeLang/#gpt-is-a-family","title":"GPT is a Family","text":"<p>GPT is not a single model, but rather a collection of models developed and trained by OpenAI. </p> <p>Under the GPT models, we have:</p> GPT-2 GPT 3 GPT-4 Language model with upto 1.5 billion parameters. Language model with up to 175 billion parameters 100T parameters and accepts both image and text inputs and outputs text. <p>The GPT-3 and GPT-4 models are available as a cognitive service from Microsoft Azure, and as OpenAI API.</p>"},{"location":"lessons/5-NLP/20-LangModels/READMELargeLang/#prompt-engineering","title":"Prompt Engineering","text":"<p>Because GPT has been trained on a vast volumes of data to understand language and code, they provide outputs in response to inputs (prompts). Prompts are GPT inputs or queries whereby one provides instructions to models on tasks they next completed. To elicit a desired outcome, you need the most effective prompt which involves selecting the right words, formats, phrases or even symbols. This approach is Prompt Engineering</p> <p>This documentation provides you with more information on prompt engineering.</p>"},{"location":"lessons/5-NLP/20-LangModels/READMELargeLang/#example-notebook-playing-with-openai-gpt","title":"\u270d\ufe0f Example Notebook: Playing with OpenAI-GPT","text":"<p>Continue your learning in the following notebooks:</p> <ul> <li>Generating text with OpenAI-GPT and Hugging Face Transformers</li> </ul>"},{"location":"lessons/5-NLP/20-LangModels/READMELargeLang/#conclusion","title":"Conclusion","text":"<p>New general pre-trained language models do not only model language structure, but also contain vast amount of natural language. Thus, they can be effectively used to solve some NLP tasks in zero-shop or few-shot settings.</p>"},{"location":"lessons/5-NLP/20-LangModels/READMELargeLang/#post-lecture-quiz","title":"Post-lecture quiz","text":""},{"location":"lessons/5-NLP/20-LangModels/READMELargeLang_chs/","title":"\u9884\u8bad\u7ec3\u5927\u8bed\u8a00\u6a21\u578b","text":"<p>\u5728\u6211\u4eec\u4e4b\u524d\u7684\u6240\u6709\u4efb\u52a1\u4e2d\uff0c\u6211\u4eec\u90fd\u662f\u4f7f\u7528\u6807\u6ce8\u6570\u636e\u96c6\u6765\u8bad\u7ec3\u795e\u7ecf\u7f51\u7edc\u4ee5\u6267\u884c\u67d0\u9879\u4efb\u52a1\u3002\u800c\u5bf9\u4e8e\u5927\u578btransformer\u6a21\u578b\u5982BERT\uff0c\u6211\u4eec\u4f7f\u7528\u81ea\u76d1\u7763\u65b9\u5f0f\u8fdb\u884c\u8bed\u8a00\u5efa\u6a21\uff0c\u6784\u5efa\u51fa\u4e00\u4e2a\u8bed\u8a00\u6a21\u578b\uff0c\u7136\u540e\u7ecf\u8fc7\u8fdb\u4e00\u6b65\u7684\u9886\u57df\u7279\u5b9a\u8bad\u7ec3\uff0c\u5c06\u5176\u4e13\u95e8\u5316\u7528\u4e8e\u5177\u4f53\u7684\u4e0b\u6e38\u4efb\u52a1\u3002\u7136\u800c\uff0c\u5df2\u7ecf\u8bc1\u660e\u4e86\u5927\u578b\u8bed\u8a00\u6a21\u578b\u4e5f\u53ef\u4ee5\u5728\u6ca1\u6709\u4efb\u4f55\u9886\u57df\u7279\u5b9a\u8bad\u7ec3\u7684\u60c5\u51b5\u4e0b\u89e3\u51b3\u8bb8\u591a\u4efb\u52a1\u3002\u8fd9\u79cd\u80fd\u591f\u505a\u5230\u8fd9\u4e00\u70b9\u7684\u4e00\u7c7b\u6a21\u578b\u88ab\u79f0\u4e3aGPT\uff1a\u751f\u6210\u9884\u8bad\u7ec3\u8f6c\u6362\u5668\u3002</p>"},{"location":"lessons/5-NLP/20-LangModels/READMELargeLang_chs/#_2","title":"\u8bfe\u524d\u6d4b\u9a8c","text":""},{"location":"lessons/5-NLP/20-LangModels/READMELargeLang_chs/#_3","title":"\u6587\u672c\u751f\u6210\u548c\u56f0\u60d1\u5ea6","text":"<p>\u5728\u300a\u8bed\u8a00\u6a21\u578b\u662f\u65e0\u76d1\u7763\u7684\u591a\u4efb\u52a1\u5b66\u4e60\u8005\u300b\u8bba\u6587\u4e2d\uff0c\u63d0\u51fa\u4e86\u795e\u7ecf\u7f51\u7edc\u80fd\u591f\u5728\u6ca1\u6709\u4e0b\u6e38\u8bad\u7ec3\u7684\u60c5\u51b5\u4e0b\u5b8c\u6210\u4e00\u822c\u4efb\u52a1\u7684\u60f3\u6cd5\u3002\u4e3b\u8981\u601d\u60f3\u662f\u5f88\u591a\u5176\u4ed6\u4efb\u52a1\u53ef\u4ee5\u901a\u8fc7\u6587\u672c\u751f\u6210\u6765\u5efa\u6a21\uff0c\u56e0\u4e3a\u7406\u89e3\u6587\u672c\u672c\u8d28\u4e0a\u610f\u5473\u7740\u80fd\u591f\u751f\u6210\u6587\u672c\u3002\u7531\u4e8e\u6a21\u578b\u8bad\u7ec3\u5728\u5305\u542b\u4eba\u7c7b\u77e5\u8bc6\u7684\u5927\u91cf\u6587\u672c\u6570\u636e\u4e0a\uff0c\u5b83\u56e0\u6b64\u4e5f\u4e86\u89e3\u5e7f\u6cdb\u7684\u4e3b\u9898\u3002</p> <p>\u7406\u89e3\u548c\u751f\u6210\u6587\u672c\u4e5f\u610f\u5473\u7740\u5bf9\u5468\u56f4\u4e16\u754c\u6709\u6240\u4e86\u89e3\u3002\u4eba\u7c7b\u4e5f\u5728\u5f88\u5927\u7a0b\u5ea6\u4e0a\u901a\u8fc7\u9605\u8bfb\u6765\u5b66\u4e60\uff0cGPT\u7f51\u7edc\u5728\u8fd9\u65b9\u9762\u7c7b\u4f3c\u3002</p> <p>\u6587\u672c\u751f\u6210\u7f51\u7edc\u901a\u8fc7\u9884\u6d4b\u4e0b\u4e00\u4e2a\u5355\u8bcd\u7684\u6982\u7387$$P(w_N)$$\u6765\u5de5\u4f5c\u3002\u7136\u800c\uff0c\u4e0b\u4e00\u4e2a\u5355\u8bcd\u7684\u65e0\u6761\u4ef6\u6982\u7387\u7b49\u4e8e\u8fd9\u4e2a\u5355\u8bcd\u5728\u6587\u672c\u4e2d\u7684\u9891\u7387\u3002GPT\u80fd\u591f\u7ed9\u51fa\u4e0b\u4e00\u4e2a\u5355\u8bcd\u7684\u6761\u4ef6\u6982\u7387\uff08\u7ed9\u5b9a\u524d\u9762\u7684\u5355\u8bcd\uff09\uff1a$$P(w_N | w_{n-1}, ..., w_0)$$</p> <p>\u60a8\u53ef\u4ee5\u5728\u6211\u4eec\u7684\u521d\u5b66\u8005\u6570\u636e\u79d1\u5b66\u8bfe\u7a0b\u4e2d\u9605\u8bfb\u66f4\u591a\u5173\u4e8e\u6982\u7387\u7684\u5185\u5bb9\u3002</p> <p>\u8bed\u8a00\u751f\u6210\u6a21\u578b\u7684\u8d28\u91cf\u53ef\u4ee5\u7528\u56f0\u60d1\u5ea6\u6765\u5b9a\u4e49\u3002\u8fd9\u662f\u4e00\u4e2a\u5185\u5728\u7684\u5ea6\u91cf\uff0c\u5141\u8bb8\u6211\u4eec\u5728\u6ca1\u6709\u4efb\u4f55\u4efb\u52a1\u7279\u5b9a\u6570\u636e\u96c6\u7684\u60c5\u51b5\u4e0b\u8861\u91cf\u6a21\u578b\u7684\u8d28\u91cf\u3002\u8fd9\u57fa\u4e8e\u53e5\u5b50\u7684\u6982\u7387\u7684\u6982\u5ff5\u2014\u2014\u6a21\u578b\u5bf9\u770b\u4f3c\u771f\u5b9e\u7684\u53e5\u5b50\u8d4b\u4e88\u9ad8\u6982\u7387\uff08\u5373\uff0c\u6a21\u578b\u5e76\u4e0d\u611f\u5230\u56f0\u60d1\uff09\uff0c\u800c\u5bf9\u4e0d\u5408\u7406\u7684\u53e5\u5b50\uff08\u4f8b\u5982\u5b83\u4f1a\u505a\u4ec0\u4e48\uff1f\uff09\u8d4b\u4e88\u4f4e\u6982\u7387\u3002\u5f53\u6211\u4eec\u63d0\u4f9b\u7ed9\u6a21\u578b\u6765\u81ea\u771f\u5b9e\u6587\u672c\u8bed\u6599\u5e93\u7684\u53e5\u5b50\u65f6\uff0c\u6211\u4eec\u5e0c\u671b\u5b83\u4eec\u5177\u6709\u9ad8\u6982\u7387\u548c\u4f4e\u56f0\u60d1\u5ea6\u3002\u6570\u5b66\u4e0a\uff0c\u5b83\u5b9a\u4e49\u4e3a\u6d4b\u8bd5\u96c6\u7684\u5f52\u4e00\u5316\u9006\u6982\u7387\uff1a $$ \\mathrm{Perplexity}(W) = \\sqrt[N]{1\\over P(W_1,...,W_N)} $$ </p> <p>\u60a8\u53ef\u4ee5\u4f7f\u7528\u6765\u81eaHugging Face\u7684GPT\u9a71\u52a8\u7684\u6587\u672c\u7f16\u8f91\u5668 \u5b9e\u9a8c\u6587\u672c\u751f\u6210\u3002\u5728\u8fd9\u4e2a\u7f16\u8f91\u5668\u4e2d\uff0c\u60a8\u5f00\u59cb\u7f16\u5199\u6587\u672c\uff0c\u6309[TAB]\u952e\u5c06\u4e3a\u60a8\u63d0\u4f9b\u591a\u4e2a\u5b8c\u6210\u9009\u9879\u3002\u5982\u679c\u5b83\u4eec\u592a\u77ed\u6216\u60a8\u4e0d\u6ee1\u610f\uff0c\u6309[TAB]\u952e\uff0c\u60a8\u5c06\u6709\u66f4\u591a\u9009\u9879\uff0c\u5305\u62ec\u66f4\u957f\u7684\u6587\u672c\u7247\u6bb5\u3002</p>"},{"location":"lessons/5-NLP/20-LangModels/READMELargeLang_chs/#gpt","title":"GPT\u662f\u4e00\u4e2a\u5bb6\u65cf","text":"<p>GPT\u4e0d\u662f\u5355\u4e00\u6a21\u578b\uff0c\u800c\u662f\u4e00\u7ec4\u7531OpenAI\u5f00\u53d1\u548c\u8bad\u7ec3\u7684\u6a21\u578b\u3002</p> <p>\u5728GPT\u6a21\u578b\u4e0b\uff0c\u6211\u4eec\u6709\uff1a</p> GPT-2 GPT 3 GPT-4 \u8bed\u8a00\u6a21\u578b\uff0c\u53c2\u6570\u591a\u8fbe15\u4ebf \u8bed\u8a00\u6a21\u578b\uff0c\u53c2\u6570\u591a\u8fbe1750\u4ebf 100\u4e07\u4ebf\u53c2\u6570\u5e76\u63a5\u53d7\u56fe\u50cf\u548c\u6587\u672c\u8f93\u5165\uff0c\u8f93\u51fa\u6587\u672c\u3002 <p>GPT-3\u548cGPT-4\u6a21\u578b\u53ef\u901a\u8fc7\u6765\u81eaMicrosoft Azure\u7684\u8ba4\u77e5\u670d\u52a1\u4ee5\u53caOpenAI API\u83b7\u53d6\u3002</p>"},{"location":"lessons/5-NLP/20-LangModels/READMELargeLang_chs/#_4","title":"\u63d0\u793a\u5de5\u7a0b","text":"<p>\u7531\u4e8eGPT\u7ecf\u8fc7\u5927\u91cf\u6570\u636e\u7684\u8bad\u7ec3\u4ee5\u7406\u89e3\u8bed\u8a00\u548c\u4ee3\u7801\uff0c\u5b83\u4eec\u5728\u54cd\u5e94\u8f93\u5165\uff08\u63d0\u793a\uff09\u65f6\u63d0\u4f9b\u8f93\u51fa\u3002\u63d0\u793a\u662fGPT\u7684\u8f93\u5165\u6216\u67e5\u8be2\uff0c\u901a\u8fc7\u8fd9\u4e9b\u8f93\u5165\uff0c\u7528\u6237\u4e3a\u6a21\u578b\u63d0\u4f9b\u4e0b\u4e00\u6b65\u5b8c\u6210\u4efb\u52a1\u7684\u8bf4\u660e\u3002\u4e3a\u4e86\u5f15\u51fa\u6240\u9700\u7684\u7ed3\u679c\uff0c\u60a8\u9700\u8981\u6700\u6709\u6548\u7684\u63d0\u793a\uff0c\u8fd9\u6d89\u53ca\u9009\u62e9\u6b63\u786e\u7684\u5355\u8bcd\u3001\u683c\u5f0f\u3001\u77ed\u8bed\u751a\u81f3\u7b26\u53f7\u3002\u8fd9\u79cd\u65b9\u6cd5\u79f0\u4e3a\u63d0\u793a\u5de5\u7a0b\u3002</p> <p>\u672c\u6587\u6863\u63d0\u4f9b\u4e86\u6709\u5173\u63d0\u793a\u5de5\u7a0b\u7684\u66f4\u591a\u4fe1\u606f\u3002</p>"},{"location":"lessons/5-NLP/20-LangModels/READMELargeLang_chs/#openai-gpt","title":"\u270d\ufe0f \u793a\u4f8b\u7b14\u8bb0\u672c: \u4f7f\u7528OpenAI-GPT\u8fdb\u884c\u5b9e\u9a8c","text":"<p>\u5728\u4ee5\u4e0b\u7b14\u8bb0\u672c\u4e2d\u7ee7\u7eed\u60a8\u7684\u5b66\u4e60\uff1a</p> <ul> <li>\u4f7f\u7528OpenAI-GPT\u548cHugging Face Transformers\u751f\u6210\u6587\u672c</li> </ul>"},{"location":"lessons/5-NLP/20-LangModels/READMELargeLang_chs/#_5","title":"\u7ed3\u8bba","text":"<p>\u65b0\u7684\u901a\u7528\u9884\u8bad\u7ec3\u8bed\u8a00\u6a21\u578b\u4e0d\u4ec5\u5efa\u6a21\u8bed\u8a00\u7ed3\u6784\uff0c\u8fd8\u5305\u542b\u5927\u91cf\u7684\u81ea\u7136\u8bed\u8a00\u3002\u56e0\u6b64\uff0c\u5b83\u4eec\u53ef\u4ee5\u5728\u96f6\u6837\u672c\u6216\u5c11\u91cf\u6837\u672c\u8bbe\u7f6e\u4e2d\u6709\u6548\u89e3\u51b3\u4e00\u4e9bNLP\u4efb\u52a1\u3002</p>"},{"location":"lessons/5-NLP/20-LangModels/READMELargeLang_chs/#_6","title":"\u8bfe\u540e\u6d4b\u9a8c","text":""},{"location":"lessons/6-Other/21-GeneticAlgorithms/","title":"Genetic Algorithms","text":""},{"location":"lessons/6-Other/21-GeneticAlgorithms/#pre-lecture-quiz","title":"Pre-lecture quiz","text":"<p>Genetic Algorithms (GA) are based on an evolutionary approach to AI, in which methods of the evolution of a population is used to obtain an optimal solution for a given problem. They were proposed in 1975 by John Henry Holland.</p> <p>Genetic Algorithms are based on the following ideas:</p> <ul> <li>Valid solutions to the problem can be represented as genes</li> <li>Crossover allows us to combine two solutions together to obtain a new valid solution</li> <li>Selection is used to select more optimal solutions using some fitness function</li> <li>Mutations are introduced to destabilize optimization and get us out of the local minimum</li> </ul> <p>If you want to implement a Genetic Algorithm, you need the following:</p> <ul> <li>To find a method of coding our problem solutions using genes g\u2208\u0393</li> <li>On the set of genes \u0393 we need to define fitness function fit: \u0393\u2192R. Smaller function values correspond to better solutions.</li> <li>To define crossover mechanism to combine two genes together to get a new valid solution crossover: \u0393<sup>2\u2192\u0393. <li>To define mutation mechanism mutate: \u0393\u2192\u0393.</li> <p>In many cases, crossover and mutation are quite simple algorithms to manipulate genes as numeric sequences or bit vectors.</p> <p>The specific implementation of a genetic algorithm can vary from case to case, but the overall structure is the following:</p> <ol> <li>Select an initial population G\u2282\u0393</li> <li>Randomly select one of the operations that will be performed at this step: crossover or mutation</li> <li>Crossover:</li> <li>Randomly select two genes g<sub>1</sub>, g<sub>2</sub> \u2208 G</li> <li>Compute crossover g=crossover(g<sub>1</sub>,g<sub>2</sub>)</li> <li>If fit(g)&lt;fit(g<sub>1</sub>) or fit(g)&lt;fit(g<sub>2</sub>) - replace corresponding gene in the population by g.</li> <li>Mutation - select random gene g\u2208G and replace it by mutate(g)</li> <li>Repeat from step 2, until we get a sufficiently small value of fit, or until the limit on the number of steps is reached.</li> </ol>"},{"location":"lessons/6-Other/21-GeneticAlgorithms/#typical-tasks","title":"Typical Tasks","text":"<p>Tasks typically solved by Genetic Algorithms include:</p> <ol> <li>Schedule optimization</li> <li>Optimal packing</li> <li>Optimal cutting</li> <li>Speeding up exhaustive search</li> </ol>"},{"location":"lessons/6-Other/21-GeneticAlgorithms/#exercises-genetic-algorithms","title":"\u270d\ufe0f Exercises: Genetic Algorithms","text":"<p>Continue your learning in the following notebooks:</p> <p>Go to this notebook to see two examples of using Genetic Algorithms:</p> <ol> <li>Fair division of treasure</li> <li>8 Queens Problem</li> </ol>"},{"location":"lessons/6-Other/21-GeneticAlgorithms/#conclusion","title":"Conclusion","text":"<p>Genetic Algorithms are used to solve many problems, including logistics and search problems. The field is Inspired by research that merged topics in Psychology and Computer Science. </p>"},{"location":"lessons/6-Other/21-GeneticAlgorithms/#challenge","title":"\ud83d\ude80 Challenge","text":"<p>\"Genetic algorithms are simple to implement, but their behavior is difficult to understand.\" source Do some research to find an implementation of a genetic algorithm such as solving a Sudoku puzzle, and explain how it works as a sketch or flowchart.</p>"},{"location":"lessons/6-Other/21-GeneticAlgorithms/#post-lecture-quiz","title":"Post-lecture quiz","text":""},{"location":"lessons/6-Other/21-GeneticAlgorithms/#review-self-study","title":"Review &amp; Self Study","text":"<p>Watch this great video talking about how computer can learn to play Super Mario using neural networks trained by genetic algorithms. We will learn more about computer learning to play games like that in the next section.</p>"},{"location":"lessons/6-Other/21-GeneticAlgorithms/#assignment-diophantine-equation","title":"Assignment: Diophantine Equation","text":"<p>Your goal is to solve so-called Diophantine equation - an equation with integer roots. For example, consider the equation a+2b+3c+4d=30. You need to find the integer roots that satisfy this equation.</p> <p>This assignment is inspired by this post.</p> <p>Hints:</p> <ol> <li>You can consider roots to be in the interval [0;30]</li> <li>As a gene, consider using the list of root values</li> </ol> <p>Use Diophantine.ipynb as a starting point.</p>"},{"location":"lessons/6-Other/21-GeneticAlgorithms/README_chs/","title":"\u9057\u4f20\u7b97\u6cd5","text":""},{"location":"lessons/6-Other/21-GeneticAlgorithms/README_chs/#_2","title":"\u8bfe\u524d\u5c0f\u6d4b\u9a8c","text":"<p>\u9057\u4f20\u7b97\u6cd5 (GA) \u57fa\u4e8e\u4e00\u79cd \u8fdb\u5316\u65b9\u6cd5 \u6765\u5b9e\u73b0\u4eba\u5de5\u667a\u80fd\uff0c\u901a\u8fc7\u4f7f\u7528\u79cd\u7fa4\u7684\u8fdb\u5316\u65b9\u6cd5\u6765\u83b7\u5f97\u7ed9\u5b9a\u95ee\u9898\u7684\u6700\u4f18\u89e3\u3002\u5b83\u4eec\u57281975\u5e74\u7531 John Henry Holland \u63d0\u51fa\u3002</p> <p>\u9057\u4f20\u7b97\u6cd5\u57fa\u4e8e\u4ee5\u4e0b\u601d\u60f3\uff1a</p> <ul> <li>\u95ee\u9898\u7684\u6709\u6548\u89e3\u53ef\u4ee5\u8868\u793a\u4e3a \u57fa\u56e0</li> <li>\u4ea4\u53c9 \u5141\u8bb8\u6211\u4eec\u5c06\u4e24\u4e2a\u89e3\u51b3\u65b9\u6848\u7ed3\u5408\u5728\u4e00\u8d77\uff0c\u4ee5\u83b7\u5f97\u4e00\u4e2a\u65b0\u7684\u6709\u6548\u89e3\u51b3\u65b9\u6848</li> <li>\u4f7f\u7528\u67d0\u4e9b \u9002\u5e94\u6027\u51fd\u6570 \u8fdb\u884c \u9009\u62e9 \u6765\u6311\u9009\u51fa\u66f4\u4f18\u7684\u89e3\u51b3\u65b9\u6848</li> <li>\u5f15\u5165 \u53d8\u5f02 \u4ee5\u6270\u4e71\u4f18\u5316\u8fc7\u7a0b\uff0c\u5e76\u4f7f\u6211\u4eec\u6446\u8131\u5c40\u90e8\u6781\u5c0f\u503c</li> </ul> <p>\u5982\u679c\u4f60\u60f3\u5b9e\u73b0\u4e00\u4e2a\u9057\u4f20\u7b97\u6cd5\uff0c\u4f60\u9700\u8981\u4ee5\u4e0b\u5185\u5bb9\uff1a</p> <ul> <li>\u627e\u5230\u4e00\u79cd\u4f7f\u7528 \u57fa\u56e0 g\u2208\u0393 \u5bf9\u95ee\u9898\u89e3\u51b3\u65b9\u6848\u8fdb\u884c\u7f16\u7801\u7684\u65b9\u6cd5</li> <li>\u5728\u57fa\u56e0\u96c6\u5408 \u0393 \u4e0a\u5b9a\u4e49 \u9002\u5e94\u6027\u51fd\u6570 fit: \u0393\u2192R\u3002\u51fd\u6570\u503c\u8d8a\u5c0f\u7684\u89e3\u8d8a\u597d\u3002</li> <li>\u5b9a\u4e49 \u4ea4\u53c9 \u673a\u5236\uff0c\u5c06\u4e24\u4e2a\u57fa\u56e0\u7ed3\u5408\u8d77\u6765\uff0c\u4ee5\u83b7\u5f97\u4e00\u4e2a\u65b0\u7684\u6709\u6548\u89e3\u51b3\u65b9\u6848 crossover: \u0393<sup>2\u2192\u0393\u3002 <li>\u5b9a\u4e49 \u53d8\u5f02 \u673a\u5236 mutate: \u0393\u2192\u0393\u3002</li> <p>\u5728\u8bb8\u591a\u60c5\u51b5\u4e0b\uff0c\u4ea4\u53c9\u548c\u53d8\u5f02\u662f\u5f88\u7b80\u5355\u7684\u7b97\u6cd5\uff0c\u901a\u8fc7\u64cd\u4f5c\u57fa\u56e0\u4f5c\u4e3a\u6570\u503c\u5e8f\u5217\u6216\u4f4d\u5411\u91cf\u6765\u5b9e\u73b0\u3002</p> <p>\u5177\u4f53\u7684\u9057\u4f20\u7b97\u6cd5\u5b9e\u73b0\u53ef\u80fd\u56e0\u60c5\u51b5\u800c\u5f02\uff0c\u4f46\u6574\u4f53\u7ed3\u6784\u5982\u4e0b\uff1a</p> <ol> <li>\u9009\u62e9\u521d\u59cb\u79cd\u7fa4 G\u2282\u0393</li> <li>\u968f\u673a\u9009\u62e9\u5c06\u5728\u6b64\u6b65\u9aa4\u4e2d\u6267\u884c\u7684\u64cd\u4f5c\uff1a\u4ea4\u53c9\u6216\u53d8\u5f02</li> <li>\u4ea4\u53c9\uff1a</li> <li>\u968f\u673a\u9009\u62e9\u4e24\u4e2a\u57fa\u56e0 g<sub>1</sub>, g<sub>2</sub> \u2208 G</li> <li>\u8ba1\u7b97\u4ea4\u53c9 g=crossover(g<sub>1</sub>,g<sub>2</sub>)</li> <li>\u5982\u679c fit(g)&lt;fit(g<sub>1</sub>) \u6216 fit(g)&lt;fit(g<sub>2</sub>) - \u7528 g \u66ff\u6362\u79cd\u7fa4\u4e2d\u7684\u76f8\u5e94\u57fa\u56e0\u3002</li> <li>\u53d8\u5f02 - \u968f\u673a\u9009\u62e9\u4e00\u4e2a\u57fa\u56e0 g\u2208G \u5e76\u7528 mutate(g) \u66ff\u6362\u5b83</li> <li>\u4ece\u6b65\u9aa4 2 \u5f00\u59cb\u91cd\u590d\uff0c\u76f4\u5230\u6211\u4eec\u5f97\u5230\u7b26\u5408\u8981\u6c42\u7684\u9002\u5e94\u6027\u503c\u6216\u8fbe\u5230\u6b65\u9aa4\u6570\u9650\u5236\u4e3a\u6b62\u3002</li> </ol>"},{"location":"lessons/6-Other/21-GeneticAlgorithms/README_chs/#_3","title":"\u5178\u578b\u4efb\u52a1","text":"<p>\u901a\u5e38\u7531\u9057\u4f20\u7b97\u6cd5\u89e3\u51b3\u7684\u4efb\u52a1\u5305\u62ec\uff1a</p> <ol> <li>\u8ba1\u5212\u4f18\u5316</li> <li>\u6700\u4f73\u6253\u5305</li> <li>\u6700\u4f18\u5207\u5272</li> <li>\u52a0\u901f\u7a77\u5c3d\u641c\u7d22</li> </ol>"},{"location":"lessons/6-Other/21-GeneticAlgorithms/README_chs/#_4","title":"\u270d\ufe0f \u7ec3\u4e60\uff1a\u9057\u4f20\u7b97\u6cd5","text":"<p>\u5728\u4ee5\u4e0b\u7b14\u8bb0\u672c\u4e2d\u7ee7\u7eed\u5b66\u4e60\uff1a</p> <p>\u53bb \u8fd9\u4e2a\u7b14\u8bb0\u672c \u67e5\u770b\u4f7f\u7528\u9057\u4f20\u7b97\u6cd5\u7684\u4e24\u4e2a\u4f8b\u5b50\uff1a</p> <ol> <li>\u516c\u5e73\u5206\u5272\u5b9d\u7269</li> <li>8\u7687\u540e\u95ee\u9898</li> </ol>"},{"location":"lessons/6-Other/21-GeneticAlgorithms/README_chs/#_5","title":"\u7ed3\u8bba","text":"<p>\u9057\u4f20\u7b97\u6cd5\u7528\u4e8e\u89e3\u51b3\u5305\u62ec\u7269\u6d41\u548c\u641c\u7d22\u5728\u5185\u7684\u8bb8\u591a\u95ee\u9898\u3002\u8be5\u9886\u57df\u7684\u7075\u611f\u6765\u6e90\u4e8e\u5c06\u5fc3\u7406\u5b66\u548c\u8ba1\u7b97\u673a\u79d1\u5b66\u4e3b\u9898\u878d\u5408\u7684\u7814\u7a76\u3002</p>"},{"location":"lessons/6-Other/21-GeneticAlgorithms/README_chs/#_6","title":"\ud83d\ude80 \u6311\u6218","text":"<p>\u201c\u9057\u4f20\u7b97\u6cd5\u5f88\u5bb9\u6613\u5b9e\u73b0\uff0c\u4f46\u5b83\u4eec\u7684\u884c\u4e3a\u5f88\u96be\u7406\u89e3\u3002\u201d \u6765\u6e90 \u505a\u4e00\u4e9b\u7814\u7a76\uff0c\u627e\u5230\u4e00\u4e2a\u9057\u4f20\u7b97\u6cd5\u7684\u5b9e\u73b0\uff0c\u4f8b\u5982\u89e3\u51b3\u6570\u72ec\u96be\u9898\uff0c\u5e76\u7528\u8349\u56fe\u6216\u6d41\u7a0b\u56fe\u89e3\u91ca\u5b83\u7684\u5de5\u4f5c\u539f\u7406\u3002</p>"},{"location":"lessons/6-Other/21-GeneticAlgorithms/README_chs/#_7","title":"\u8bfe\u540e\u5c0f\u6d4b\u9a8c","text":""},{"location":"lessons/6-Other/21-GeneticAlgorithms/README_chs/#_8","title":"\u590d\u4e60\u4e0e\u81ea\u5b66","text":"<p>\u89c2\u770b \u8fd9\u4e2a\u5f88\u68d2\u7684\u89c6\u9891 \u8ba8\u8bba\u8ba1\u7b97\u673a\u5982\u4f55\u4f7f\u7528\u9057\u4f20\u7b97\u6cd5\u8bad\u7ec3\u7684\u795e\u7ecf\u7f51\u7edc\u5b66\u4e60\u73a9\u8d85\u7ea7\u9a6c\u91cc\u5965\u3002\u6211\u4eec\u5c06\u5728\u4e0b\u4e00\u8282\u4e2d\u4e86\u89e3\u66f4\u591a\u5173\u4e8e\u8ba1\u7b97\u673a\u5b66\u4e60\u73a9\u8fd9\u6837\u7684\u6e38\u620f\u7684\u5185\u5bb9\u3002</p>"},{"location":"lessons/6-Other/21-GeneticAlgorithms/README_chs/#_9","title":"\u4f5c\u4e1a\uff1a\u4e22\u756a\u56fe\u65b9\u7a0b","text":"<p>\u4f60\u7684\u76ee\u6807\u662f\u89e3\u51b3\u6240\u8c13\u7684 \u4e22\u756a\u56fe\u65b9\u7a0b - \u4e00\u4e2a\u5177\u6709\u6574\u6570\u6839\u7684\u65b9\u7a0b\u3002\u4f8b\u5982\uff0c\u8003\u8651\u65b9\u7a0b a+2b+3c+4d=30\u3002\u4f60\u9700\u8981\u627e\u5230\u6ee1\u8db3\u6b64\u65b9\u7a0b\u7684\u6574\u6570\u6839\u3002</p> <p>\u6b64\u4f5c\u4e1a\u7684\u7075\u611f\u6765\u81ea \u8fd9\u7bc7\u6587\u7ae0\u3002</p> <p>\u63d0\u793a\uff1a</p> <ol> <li>\u4f60\u53ef\u4ee5\u8003\u8651\u6839\u5728 [0;30] \u533a\u95f4\u5185</li> <li>\u4f5c\u4e3a\u57fa\u56e0\uff0c\u8003\u8651\u4f7f\u7528\u6839\u503c\u5217\u8868</li> </ol> <p>\u4f7f\u7528 Diophantine.ipynb \u4f5c\u4e3a\u8d77\u70b9\u3002</p>"},{"location":"lessons/6-Other/22-DeepRL/","title":"Deep Reinforcement Learning","text":"<p>Reinforcement learning (RL) is seen as one of the basic machine learning paradigms, next to supervised learning and unsupervised learning. While in supervised learning we rely on the dataset with known outcomes, RL is based on learning by doing. For example, when we first see a computer game, we start playing, even without knowing the rules, and soon we are able to improve our skills just by the process of playing and adjusting our behavior.</p>"},{"location":"lessons/6-Other/22-DeepRL/#pre-lecture-quiz","title":"Pre-lecture quiz","text":"<p>To perform RL, we need:</p> <ul> <li>An environment or simulator that sets the rules of the game. We should be able to run the experiments in the simulator and observe the results.</li> <li>Some Reward function, which indicate how successful our experiment was. In case of learning to play a computer game, the reward would be our final score.</li> </ul> <p>Based on the reward function, we should be able to adjust our behavior and improve our skills, so that the next time we play better. The main difference between other types of machine learning and RL is that in RL we typically do not know whether we win or lose until we finish the game. Thus, we cannot say whether a certain move alone is good or not - we only receive a reward at the end of the game.</p> <p>During RL, we typically perform many experiments. During each experiment, we need to balance between following the optimal strategy that we have learned so far (exploitation) and exploring new possible states (exploration).</p>"},{"location":"lessons/6-Other/22-DeepRL/#openai-gym","title":"OpenAI Gym","text":"<p>A great tool for RL is the OpenAI Gym - a simulation environment, which can simulate many different environments starting from Atari games, to the physics behind pole balancing. It is one of the most popular simulation environments for training reinforcement learning algorithms, and is maintained by OpenAI.</p> <p>Note: You can see all the environments available from OpenAI Gym here.</p>"},{"location":"lessons/6-Other/22-DeepRL/#cartpole-balancing","title":"CartPole Balancing","text":"<p>You have probably all seen modern balancing devices such as the Segway or Gyroscooters. They are able to automatically balance by adjusting their wheels in response to a signal from an accelerometer or gyroscope. In this section, we will learn how to solve a similar problem - balancing a pole. It is similar to a situation when a circus performer needs to balance a pole on his hand - but this pole balancing only occurs in 1D.</p> <p>A simplified version of balancing is known as a CartPole problem. In the cartpole world, we have a horizontal slider that can move left or right, and the goal is to balance a vertical pole on top of the slider as it moves.</p> <p></p> <p>To create and use this environment, we need a couple of lines of Python code:</p> <pre><code>import gym\nenv = gym.make(\"CartPole-v1\")\n\nenv.reset()\ndone = False\ntotal_reward = 0\nwhile not done:\n   env.render()\n   action = env.action_space.sample()\n   observaton, reward, done, info = env.step(action)\n   total_reward += reward\n\nprint(f\"Total reward: {total_reward}\")\n</code></pre> <p>Each environment can be accessed exactly in the same way: * <code>env.reset</code> starts a new experiment * <code>env.step</code> performs a simulation step. It receives an action from the action space, and returns an observation (from the observation space), as well as a reward and a termination flag.</p> <p>In the example above we perform a random action at each step, which is why the experiment life is very short:</p> <p></p> <p>The goal of a RL algorithm is to train a model - the so called policy \u03c0 - which will return the action in response to a given state. We can also consider policy to be probabilistic, eg. for any state s and action a it will return the probability \u03c0(a|s) that we should take a in state s.</p>"},{"location":"lessons/6-Other/22-DeepRL/#policy-gradients-algorithm","title":"Policy Gradients Algorithm","text":"<p>The most obvious way to model a policy is by creating a neural network that will take states as input, and return corresponding actions (or rather the probabilities of all actions). In a sense, it would be similar to a normal classification task, with a major difference - we do not know in advance which actions should we take at each of the steps.</p> <p>The idea here is to estimate those probabilities. We build a vector of cumulative rewards which shows our total reward at each step of the experiment. We also apply reward discounting by multiplying earlier rewards by some coefficient \u03b3=0.99, in order to diminish the role of earlier rewards. Then, we reinforce those steps along the experiment path that yield larger rewards.</p> <p>Learn more about the Policy Gradient algorithm and see it in action in the example notebook.</p>"},{"location":"lessons/6-Other/22-DeepRL/#actor-critic-algorithm","title":"Actor-Critic Algorithm","text":"<p>An improved version of the Policy Gradients approach is called Actor-Critic. The main idea behind it is that the neural network would be trained to return two things:</p> <ul> <li>The policy, which determines which action to take. This part is called actor</li> <li>The estimation of the total reward we can expect to get at this state - this part is called critic.</li> </ul> <p>In a sense, this architecture resembles a GAN, where we have two networks that are trained against each other. In the actor-critic model, the actor proposes the action we need to take, and the critic tries to be critical and estimate the result. However, our goal is to train those networks in unison.</p> <p>Because we know both the real cumulative rewards and the results returned by the critic during the experiment, it is relatively easy to build a loss function that will minimize the difference between them. That would give us critic loss. We can compute actor loss by using the same approach as in the policy gradient algorithm.</p> <p>After running one of those algorithms, we can expect our CartPole to behave like this:</p> <p></p>"},{"location":"lessons/6-Other/22-DeepRL/#exercises-policy-gradients-and-actor-critic-rl","title":"\u270d\ufe0f Exercises: Policy Gradients and Actor-Critic RL","text":"<p>Continue your learning in the following notebooks:</p> <ul> <li>RL in TensorFlow</li> <li>RL in PyTorch</li> </ul>"},{"location":"lessons/6-Other/22-DeepRL/#other-rl-tasks","title":"Other RL Tasks","text":"<p>Reinforcement Learning nowadays is a fast growing field of research. Some of the interesting examples of reinforcement learning are:</p> <ul> <li>Teaching a computer to play Atari Games. The challenging part in this problem is that we do not have simple state represented as a vector, but rather a screenshot - and we need to use the CNN to convert this screen image to a feature vector, or to extract reward information. Atari games are available in the Gym.</li> <li>Teaching a computer to play board games, such as Chess and Go. Recently state-of-the-art programs like Alpha Zero were trained from scratch by two agents playing against each other, and improving at each step.</li> <li>In industry, RL is used to create control systems from simulation. A service called Bonsai is specifically designed for that.</li> </ul>"},{"location":"lessons/6-Other/22-DeepRL/#conclusion","title":"Conclusion","text":"<p>We have now learned how to train agents to achieve good results just by providing them a reward function that defines the desired state of the game, and by giving them an opportunity to intelligently explore the search space. We have successfully tried two algorithms, and achieved a good result in a relatively short period of time. However, this is just the beginning of your journey into RL, and you should definitely consider taking a separate course is you want to dig deeper.</p>"},{"location":"lessons/6-Other/22-DeepRL/#challenge","title":"\ud83d\ude80 Challenge","text":"<p>Explore the applications listed in the 'Other RL Tasks' section and try to implement one!</p>"},{"location":"lessons/6-Other/22-DeepRL/#post-lecture-quiz","title":"Post-lecture quiz","text":""},{"location":"lessons/6-Other/22-DeepRL/#review-self-study","title":"Review &amp; Self Study","text":"<p>Learn more about classical reinforcement learning in our Machine Learning for Beginners Curriculum.</p> <p>Watch this great video talking about how a computer can learn to play Super Mario.</p>"},{"location":"lessons/6-Other/22-DeepRL/#assignment-train-a-mountain-car","title":"Assignment: Train a Mountain Car","text":"<p>Your goal during this assignment would be to train a different Gym environment - Mountain Car.</p>"},{"location":"lessons/6-Other/22-DeepRL/README_chs/","title":"\u6df1\u5ea6\u5f3a\u5316\u5b66\u4e60","text":"<p>\u5f3a\u5316\u5b66\u4e60\uff08RL\uff09\u88ab\u8ba4\u4e3a\u662f\u4e0e\u76d1\u7763\u5b66\u4e60\u548c\u65e0\u76d1\u7763\u5b66\u4e60\u5e76\u5217\u7684\u57fa\u672c\u673a\u5668\u5b66\u4e60\u8303\u5f0f\u4e4b\u4e00\u3002\u5728\u76d1\u7763\u5b66\u4e60\u4e2d\uff0c\u6211\u4eec\u4f9d\u8d56\u4e8e\u5177\u6709\u5df2\u77e5\u7ed3\u679c\u7684\u6570\u636e\u96c6\uff0c\u800cRL\u5219\u57fa\u4e8e\u901a\u8fc7\u505a\u6765\u5b66\u4e60\u3002\u4f8b\u5982\uff0c\u5f53\u6211\u4eec\u7b2c\u4e00\u6b21\u770b\u5230\u8ba1\u7b97\u673a\u6e38\u620f\u65f6\uff0c\u5373\u4f7f\u4e0d\u77e5\u9053\u89c4\u5219\uff0c\u6211\u4eec\u4e5f\u4f1a\u5f00\u59cb\u73a9\uff0c\u5e76\u4e14\u5f88\u5feb\u5c31\u901a\u8fc7\u6e38\u620f\u8fc7\u7a0b\u548c\u8c03\u6574\u81ea\u5df1\u7684\u884c\u4e3a\u63d0\u5347\u6e38\u620f\u6280\u80fd\u3002</p>"},{"location":"lessons/6-Other/22-DeepRL/README_chs/#_2","title":"\u8bfe\u524d\u6d4b\u9a8c","text":"<p>\u8981\u6267\u884c\u5f3a\u5316\u5b66\u4e60\uff0c\u6211\u4eec\u9700\u8981\uff1a</p> <ul> <li>\u4e00\u4e2a\u73af\u5883\u6216\u6a21\u62df\u5668\uff0c\u5b83\u5236\u5b9a\u6e38\u620f\u7684\u89c4\u5219\u3002\u6211\u4eec\u5e94\u8be5\u80fd\u591f\u5728\u6a21\u62df\u5668\u4e2d\u8fd0\u884c\u5b9e\u9a8c\u5e76\u89c2\u5bdf\u7ed3\u679c\u3002</li> <li>\u67d0\u79cd\u5956\u52b1\u51fd\u6570\uff0c\u5b83\u6307\u51fa\u6211\u4eec\u7684\u5b9e\u9a8c\u6709\u591a\u6210\u529f\u3002\u5728\u5b66\u4e60\u73a9\u8ba1\u7b97\u673a\u6e38\u620f\u7684\u60c5\u51b5\u4e0b\uff0c\u5956\u52b1\u5c06\u662f\u6211\u4eec\u7684\u6700\u7ec8\u5f97\u5206\u3002</li> </ul> <p>\u57fa\u4e8e\u5956\u52b1\u51fd\u6570\uff0c\u6211\u4eec\u5e94\u8be5\u80fd\u591f\u8c03\u6574\u81ea\u5df1\u7684\u884c\u4e3a\u5e76\u63d0\u9ad8\u6280\u80fd\uff0c\u4ee5\u4fbf\u4e0b\u6b21\u73a9\u5f97\u66f4\u597d\u3002\u5176\u4ed6\u7c7b\u578b\u7684\u673a\u5668\u5b66\u4e60\u4e0eRL\u7684\u4e3b\u8981\u533a\u522b\u5728\u4e8e\uff0c\u5728RL\u4e2d\u6211\u4eec\u901a\u5e38\u4e0d\u77e5\u9053\u6211\u4eec\u662f\u5426\u8d62\u4e86\u76f4\u5230\u6e38\u620f\u7ed3\u675f\u3002\u56e0\u6b64\uff0c\u6211\u4eec\u65e0\u6cd5\u5224\u65ad\u5355\u72ec\u67d0\u4e00\u6b65\u662f\u5426\u662f\u597d\u7684\u4e00\u6b65\u2014\u2014\u6211\u4eec\u53ea\u80fd\u5728\u6e38\u620f\u7ed3\u675f\u540e\u83b7\u5f97\u5956\u52b1\u3002</p> <p>\u5728RL\u8fc7\u7a0b\u4e2d\uff0c\u6211\u4eec\u901a\u5e38\u4f1a\u8fdb\u884c\u8bb8\u591a\u5b9e\u9a8c\u3002\u5728\u6bcf\u6b21\u5b9e\u9a8c\u4e2d\uff0c\u6211\u4eec\u9700\u8981\u5728\u9075\u5faa\u6211\u4eec\u8fc4\u4eca\u4e3a\u6b62\u5b66\u5230\u7684\u6700\u4f73\u7b56\u7565\uff08\u5229\u7528\uff09\u548c\u63a2\u7d22\u65b0\u7684\u53ef\u80fd\u72b6\u6001\uff08\u63a2\u7d22\uff09\u4e4b\u95f4\u53d6\u5f97\u5e73\u8861\u3002</p>"},{"location":"lessons/6-Other/22-DeepRL/README_chs/#openai-gym","title":"OpenAI Gym","text":"<p>\u4e00\u4e2a\u5f88\u597d\u7684RL\u5de5\u5177\u662f OpenAI Gym \u2014\u2014\u4e00\u4e2a\u6a21\u62df\u73af\u5883\uff0c\u5b83\u53ef\u4ee5\u6a21\u62df\u4eceAtari\u6e38\u620f\u5230\u6760\u6746\u5e73\u8861\u80cc\u540e\u7684\u7269\u7406\u5728\u5185\u7684\u8bb8\u591a\u4e0d\u540c\u73af\u5883\u3002\u8fd9\u662f\u8bad\u7ec3\u5f3a\u5316\u5b66\u4e60\u7b97\u6cd5\u6700\u6d41\u884c\u7684\u6a21\u62df\u73af\u5883\u4e4b\u4e00\uff0c\u7531OpenAI\u7ef4\u62a4\u3002</p> <p>\u6ce8\u610f: \u4f60\u53ef\u4ee5\u5728\u8fd9\u91cc\u67e5\u770bOpenAI Gym\u63d0\u4f9b\u7684\u6240\u6709\u73af\u5883\u3002</p>"},{"location":"lessons/6-Other/22-DeepRL/README_chs/#_3","title":"\u5c0f\u8f66\u5012\u7acb\u6446\u5e73\u8861","text":"<p>\u4f60\u53ef\u80fd\u90fd\u89c1\u8fc7\u73b0\u4ee3\u5e73\u8861\u88c5\u7f6e\uff0c\u4f8b\u5982\u8d5b\u683c\u5a01\u6216\u9640\u87ba\u8f66\u3002\u5b83\u4eec\u901a\u8fc7\u6839\u636e\u52a0\u901f\u5ea6\u8ba1\u6216\u9640\u87ba\u4eea\u7684\u4fe1\u53f7\u8c03\u6574\u8f66\u8f6e\u81ea\u52a8\u5e73\u8861\u3002\u5728\u672c\u8282\u4e2d\uff0c\u6211\u4eec\u5c06\u5b66\u4e60\u5982\u4f55\u89e3\u51b3\u7c7b\u4f3c\u7684\u95ee\u9898\u2014\u2014\u5e73\u8861\u4e00\u4e2a\u6746\u3002\u8fd9\u7c7b\u4f3c\u4e8e\u6742\u6280\u6f14\u5458\u9700\u8981\u5728\u624b\u4e0a\u5e73\u8861\u4e00\u4e2a\u6746\u7684\u60c5\u51b5\u2014\u2014\u4f46\u8fd9\u79cd\u6746\u7684\u5e73\u8861\u4ec5\u57281D\u4e2d\u8fdb\u884c\u3002</p> <p>\u4e00\u79cd\u7b80\u5316\u7684\u5e73\u8861\u7248\u672c\u88ab\u79f0\u4e3a\u5c0f\u8f66\u5012\u7acb\u6446\u95ee\u9898\u3002\u5728\u5c0f\u8f66\u5012\u7acb\u6446\u4e16\u754c\u4e2d\uff0c\u6211\u4eec\u6709\u4e00\u4e2a\u53ef\u4ee5\u5de6\u53f3\u79fb\u52a8\u7684\u6c34\u5e73\u6ed1\u5757\uff0c\u76ee\u6807\u662f\u5728\u6ed1\u5757\u79fb\u52a8\u65f6\u5728\u5176\u9876\u90e8\u4fdd\u6301\u7ad6\u76f4\u6746\u7684\u5e73\u8861\u3002</p> <p></p> <p>\u521b\u5efa\u5e76\u4f7f\u7528\u8fd9\u4e2a\u73af\u5883\uff0c\u6211\u4eec\u9700\u8981\u51e0\u884cPython\u4ee3\u7801\uff1a</p> <pre><code>import gym\nenv = gym.make(\"CartPole-v1\")\n\nenv.reset()\ndone = False\ntotal_reward = 0\nwhile not done:\n   env.render()\n   action = env.action_space.sample()\n   observation, reward, done, info = env.step(action)\n   total_reward += reward\n\nprint(f\"Total reward: {total_reward}\")\n</code></pre> <p>\u6bcf\u4e2a\u73af\u5883\u53ef\u4ee5\u5b8c\u5168\u76f8\u540c\u5730\u8bbf\u95ee\uff1a * <code>env.reset</code> \u542f\u52a8\u4e00\u4e2a\u65b0\u5b9e\u9a8c * <code>env.step</code> \u6267\u884c\u4e00\u6b21\u6a21\u62df\u6b65\u9aa4\u3002\u5b83\u4ece\u52a8\u4f5c\u7a7a\u95f4\u63a5\u6536\u4e00\u4e2a\u52a8\u4f5c\uff0c\u5e76\u8fd4\u56de\u4e00\u4e2a\u89c2\u5bdf\u503c\uff08\u6765\u81ea\u89c2\u5bdf\u7a7a\u95f4\uff09\uff0c\u4ee5\u53ca\u4e00\u4e2a\u5956\u52b1\u548c\u7ec8\u6b62\u6807\u5fd7\u3002</p> <p>\u5728\u4e0a\u8ff0\u793a\u4f8b\u4e2d\uff0c\u6211\u4eec\u5728\u6bcf\u4e00\u6b65\u6267\u884c\u4e00\u4e2a\u968f\u673a\u52a8\u4f5c\uff0c\u8fd9\u5c31\u662f\u5b9e\u9a8c\u5bff\u547d\u975e\u5e38\u77ed\u7684\u539f\u56e0\uff1a</p> <p></p> <p>RL\u7b97\u6cd5\u7684\u76ee\u6807\u662f\u8bad\u7ec3\u4e00\u4e2a\u6a21\u578b\u2014\u2014\u6240\u8c13\u7684\u7b56\u7565 \u03c0\u2014\u2014\u5b83\u5c06\u5728\u7ed9\u5b9a\u72b6\u6001\u4e0b\u8fd4\u56de\u52a8\u4f5c\u3002\u6211\u4eec\u4e5f\u53ef\u4ee5\u8ba4\u4e3a\u7b56\u7565\u662f\u6982\u7387\u7684\uff0c\u4f8b\u5982\uff0c\u5bf9\u4e8e\u4efb\u4f55\u72b6\u6001 s \u548c\u52a8\u4f5c a\uff0c\u5b83\u5c06\u8fd4\u56de\u6211\u4eec\u5728\u72b6\u6001 s \u4e0b\u5e94\u91c7\u53d6 a \u7684\u6982\u7387 \u03c0(a|s)\u3002</p>"},{"location":"lessons/6-Other/22-DeepRL/README_chs/#_4","title":"\u7b56\u7565\u68af\u5ea6\u7b97\u6cd5","text":"<p>\u6700\u660e\u663e\u7684\u5efa\u6a21\u7b56\u7565\u65b9\u6cd5\u662f\u521b\u5efa\u4e00\u4e2a\u795e\u7ecf\u7f51\u7edc\uff0c\u5b83\u5c06\u72b6\u6001\u4f5c\u4e3a\u8f93\u5165\uff0c\u5e76\u8fd4\u56de\u76f8\u5e94\u7684\u52a8\u4f5c\uff08\u6216\u8005\u66f4\u786e\u5207\u5730\u8bf4\uff0c\u6240\u6709\u52a8\u4f5c\u7684\u6982\u7387\uff09\u3002\u5728\u67d0\u79cd\u610f\u4e49\u4e0a\uff0c\u5b83\u7c7b\u4f3c\u4e8e\u4e00\u4e2a\u666e\u901a\u7684\u5206\u7c7b\u4efb\u52a1\uff0c\u4e3b\u8981\u533a\u522b\u5728\u4e8e\u6211\u4eec\u4e0d\u77e5\u9053\u5728\u6bcf\u4e00\u6b65\u5e94\u8be5\u91c7\u53d6\u54ea\u4e9b\u52a8\u4f5c\u3002</p> <p>\u8fd9\u91cc\u7684\u60f3\u6cd5\u662f\u4f30\u8ba1\u8fd9\u4e9b\u6982\u7387\u3002\u6211\u4eec\u6784\u5efa\u4e00\u4e2a\u7d2f\u79ef\u5956\u52b1\u5411\u91cf\uff0c\u663e\u793a\u5b9e\u9a8c\u4e2d\u6bcf\u4e00\u6b65\u7684\u603b\u5956\u52b1\u3002\u6211\u4eec\u8fd8\u901a\u8fc7\u4e58\u4ee5\u67d0\u4e2a\u7cfb\u6570 \u03b3=0.99 \u6765\u5e94\u7528\u5956\u52b1\u6298\u73b0\uff0c\u4ee5\u51cf\u5c11\u65e9\u671f\u5956\u52b1\u7684\u4f5c\u7528\u3002\u7136\u540e\uff0c\u6211\u4eec\u52a0\u5f3a\u6cbf\u5b9e\u9a8c\u8def\u5f84\u4ea7\u751f\u8f83\u5927\u5956\u52b1\u7684\u6b65\u9aa4\u3002</p> <p>\u4e86\u89e3\u5173\u4e8e\u7b56\u7565\u68af\u5ea6\u7b97\u6cd5\u7684\u66f4\u591a\u4fe1\u606f\uff0c\u5e76\u5728\u793a\u4f8b\u7b14\u8bb0\u672c\u4e2d\u770b\u5230\u5b83\u7684\u5b9e\u9645\u5e94\u7528\u3002</p>"},{"location":"lessons/6-Other/22-DeepRL/README_chs/#actor-critic","title":"Actor-Critic\u7b97\u6cd5","text":"<p>\u7b56\u7565\u68af\u5ea6\u65b9\u6cd5\u7684\u6539\u8fdb\u7248\u672c\u79f0\u4e3aActor-Critic\u3002\u5176\u4e3b\u8981\u601d\u60f3\u662f\u795e\u7ecf\u7f51\u7edc\u5c06\u88ab\u8bad\u7ec3\u540c\u65f6\u8fd4\u56de\u4e24\u4ef6\u4e8b\uff1a</p> <ul> <li>\u7b56\u7565\uff0c\u51b3\u5b9a\u91c7\u53d6\u54ea\u4e2a\u52a8\u4f5c\u3002\u8fd9\u90e8\u5206\u79f0\u4e3aactor</li> <li>\u6211\u4eec\u53ef\u4ee5\u5728\u8be5\u72b6\u6001\u4e0b\u9884\u8ba1\u83b7\u5f97\u7684\u603b\u5956\u52b1\u4f30\u8ba1\u2014\u2014\u8fd9\u4e00\u90e8\u5206\u79f0\u4e3acritic\u3002</li> </ul> <p>\u5728\u67d0\u79cd\u610f\u4e49\u4e0a\uff0c\u8fd9\u79cd\u67b6\u6784\u7c7b\u4f3c\u4e8e\u751f\u6210\u5bf9\u6297\u7f51\u7edc\uff0c\u5176\u4e2d\u6709\u4e24\u4e2a\u76f8\u4e92\u5bf9\u6297\u8bad\u7ec3\u7684\u7f51\u7edc\u3002\u5728actor-critic\u6a21\u578b\u4e2d\uff0cactor\u63d0\u51fa\u6211\u4eec\u9700\u8981\u91c7\u53d6\u7684\u52a8\u4f5c\uff0ccritic\u5c1d\u8bd5\u6279\u8bc4\u5e76\u4f30\u8ba1\u7ed3\u679c\u3002\u7136\u800c\uff0c\u6211\u4eec\u7684\u76ee\u6807\u662f\u8054\u5408\u8bad\u7ec3\u8fd9\u4e9b\u7f51\u7edc\u3002</p> <p>\u56e0\u4e3a\u6211\u4eec\u5728\u5b9e\u9a8c\u4e2d\u77e5\u9053\u771f\u5b9e\u7684\u7d2f\u79ef\u5956\u52b1\u548ccritic\u8fd4\u56de\u7684\u7ed3\u679c\uff0c\u6784\u5efa\u4e00\u4e2a\u6700\u5c0f\u5316\u5b83\u4eec\u4e4b\u95f4\u5dee\u5f02\u7684\u635f\u5931\u51fd\u6570\u76f8\u5bf9\u5bb9\u6613\u3002\u8fd9\u5c06\u7ed9\u6211\u4eeccritic\u635f\u5931\u3002\u6211\u4eec\u53ef\u4ee5\u4f7f\u7528\u7b56\u7565\u68af\u5ea6\u7b97\u6cd5\u4e2d\u7684\u76f8\u540c\u65b9\u6cd5\u8ba1\u7b97actor\u635f\u5931\u3002</p> <p>\u8fd0\u884c\u8fd9\u4e9b\u7b97\u6cd5\u4e4b\u4e00\u540e\uff0c\u6211\u4eec\u53ef\u4ee5\u671f\u671b\u6211\u4eec\u7684\u5c0f\u8f66\u5012\u7acb\u6446\u8868\u73b0\u5982\u4e0b\uff1a</p> <p></p>"},{"location":"lessons/6-Other/22-DeepRL/README_chs/#actor-critic_1","title":"\u270d\ufe0f \u7ec3\u4e60\uff1a\u7b56\u7565\u68af\u5ea6\u548cActor-Critic\u5f3a\u5316\u5b66\u4e60","text":"<p>\u5728\u4ee5\u4e0b\u7b14\u8bb0\u672c\u4e2d\u7ee7\u7eed\u4f60\u7684\u5b66\u4e60\uff1a</p> <ul> <li>TensorFlow\u4e2d\u7684\u5f3a\u5316\u5b66\u4e60</li> <li>PyTorch\u4e2d\u7684\u5f3a\u5316\u5b66\u4e60</li> </ul>"},{"location":"lessons/6-Other/22-DeepRL/README_chs/#_5","title":"\u5176\u4ed6\u5f3a\u5316\u5b66\u4e60\u4efb\u52a1","text":"<p>\u5982\u4eca\uff0c\u5f3a\u5316\u5b66\u4e60\u662f\u4e00\u4e2a\u5feb\u901f\u53d1\u5c55\u7684\u7814\u7a76\u9886\u57df\u3002\u4e00\u4e9b\u6709\u8da3\u7684\u5f3a\u5316\u5b66\u4e60\u793a\u4f8b\u5305\u62ec\uff1a</p> <ul> <li>\u6559\u8ba1\u7b97\u673a\u73a9Atari\u6e38\u620f\u3002\u8fd9\u4e2a\u95ee\u9898\u7684\u6311\u6218\u5728\u4e8e\uff0c\u6211\u4eec\u6ca1\u6709\u7b80\u5355\u7684\u72b6\u6001\u8868\u793a\u4e3a\u5411\u91cf\uff0c\u800c\u662f\u4e00\u4e2a\u622a\u56fe\u2014\u2014\u6211\u4eec\u9700\u8981\u4f7f\u7528CNN\u5c06\u5c4f\u5e55\u56fe\u50cf\u8f6c\u5316\u4e3a\u7279\u5f81\u5411\u91cf\uff0c\u6216\u63d0\u53d6\u5956\u52b1\u4fe1\u606f\u3002Atari\u6e38\u620f\u5728Gym\u4e2d\u53ef\u7528\u3002</li> <li>\u6559\u8ba1\u7b97\u673a\u4e0b\u68cb\u6216\u56f4\u68cb\u7b49\u684c\u9762\u6e38\u620f\u3002\u6700\u8fd1\uff0c\u50cfAlpha Zero\u8fd9\u6837\u7684\u6700\u65b0\u7a0b\u5e8f\u662f\u901a\u8fc7\u4e24\u4e2a\u4ee3\u7406\u76f8\u4e92\u5bf9\u6218\u5e76\u5728\u6bcf\u4e00\u6b65\u63d0\u5347\u81ea\u5df1\u4ece\u96f6\u5f00\u59cb\u8bad\u7ec3\u7684\u3002</li> <li>\u5728\u5de5\u4e1a\u4e2d\uff0cRL\u7528\u4e8e\u4ece\u6a21\u62df\u4e2d\u521b\u5efa\u63a7\u5236\u7cfb\u7edf\u3002\u4e00\u4e2a\u540d\u4e3aBonsai\u7684\u670d\u52a1\u4e13\u95e8\u4e3a\u6b64\u8bbe\u8ba1\u3002</li> </ul>"},{"location":"lessons/6-Other/22-DeepRL/README_chs/#_6","title":"\u7ed3\u8bba","text":"<p>\u73b0\u5728\u6211\u4eec\u5df2\u5b66\u4e60\u5982\u4f55\u901a\u8fc7\u4e3a\u4ee3\u7406\u63d0\u4f9b\u5956\u52b1\u51fd\u6570\u5b9a\u4e49\u6e38\u620f\u6240\u9700\u72b6\u6001\uff0c\u5e76\u7ed9\u4ed6\u4eec\u667a\u80fd\u63a2\u7d22\u641c\u7d22\u7a7a\u95f4\u7684\u673a\u4f1a\u6765\u8bad\u7ec3\u4ee3\u7406\u4ee5\u83b7\u5f97\u826f\u597d\u7684\u7ed3\u679c\u3002\u6211\u4eec\u5df2\u7ecf\u6210\u529f\u5c1d\u8bd5\u4e86\u4e24\u79cd\u7b97\u6cd5\uff0c\u5e76\u5728\u76f8\u5bf9\u8f83\u77ed\u7684\u65f6\u95f4\u5185\u83b7\u5f97\u4e86\u4e0d\u9519\u7684\u7ed3\u679c\u3002\u7136\u800c\uff0c\u8fd9\u53ea\u662f\u4f60RL\u4e4b\u65c5\u7684\u5f00\u59cb\uff0c\u5982\u679c\u4f60\u60f3\u6df1\u5165\u7814\u7a76\uff0c\u7edd\u5bf9\u5e94\u8be5\u8003\u8651\u653b\u8bfb\u4e00\u4e2a\u5355\u72ec\u7684\u8bfe\u7a0b\u3002</p>"},{"location":"lessons/6-Other/22-DeepRL/README_chs/#_7","title":"\ud83d\ude80 \u6311\u6218","text":"<p>\u63a2\u7d22\u201c\u5176\u4ed6\u5f3a\u5316\u5b66\u4e60\u4efb\u52a1\u201d\u90e8\u5206\u5217\u51fa\u7684\u5e94\u7528\uff0c\u5e76\u5c1d\u8bd5\u5b9e\u73b0\u5176\u4e2d\u4e00\u4e2a\uff01</p>"},{"location":"lessons/6-Other/22-DeepRL/README_chs/#_8","title":"\u8bfe\u540e\u6d4b\u9a8c","text":""},{"location":"lessons/6-Other/22-DeepRL/README_chs/#_9","title":"\u56de\u987e\u4e0e\u81ea\u5b66","text":"<p>\u5728\u6211\u4eec\u7684\u521d\u5b66\u8005\u673a\u5668\u5b66\u4e60\u8bfe\u7a0b\u4e2d\u4e86\u89e3\u66f4\u591a\u5173\u4e8e\u7ecf\u5178\u5f3a\u5316\u5b66\u4e60\u7684\u5185\u5bb9\u3002</p> <p>\u89c2\u770b\u8fd9\u4e2a\u7cbe\u5f69\u7684\u89c6\u9891\uff0c\u4e86\u89e3\u4e00\u53f0\u8ba1\u7b97\u673a\u5982\u4f55\u5b66\u4e60\u73a9Super Mario\u3002</p>"},{"location":"lessons/6-Other/22-DeepRL/README_chs/#_10","title":"\u4f5c\u4e1a: \u8bad\u7ec3\u5c71\u5730\u8f66","text":"<p>\u5728\u8fd9\u4e2a\u4f5c\u4e1a\u4e2d\uff0c\u4f60\u7684\u76ee\u6807\u662f\u8bad\u7ec3\u4e00\u4e2a\u4e0d\u540c\u7684Gym\u73af\u5883\u2014\u2014Mountain Car\u3002</p>"},{"location":"lessons/6-Other/22-DeepRL/lab/","title":"Training Mountain Car to Escape","text":"<p>Lab Assignment from AI for Beginners Curriculum.</p>"},{"location":"lessons/6-Other/22-DeepRL/lab/#task","title":"Task","text":"<p>Your goal is to train the RL agent to control Mountain Car in OpenAI Environment.</p> <p></p>"},{"location":"lessons/6-Other/22-DeepRL/lab/#the-environment","title":"The Environment","text":"<p>Mountain Car environment consists of the car trapped inside a valley. Your goal is to jump out of the valley and reach the flag. The actions you can perform are to accelerate to the left, to the right, or do nothing. You can observe position of the car along x-axis, and velocity.</p>"},{"location":"lessons/6-Other/22-DeepRL/lab/#stating-notebook","title":"Stating Notebook","text":"<p>Start the lab by opening MountainCar.ipynb</p>"},{"location":"lessons/6-Other/22-DeepRL/lab/#takeaway","title":"Takeaway","text":"<p>You should learn throughout this lab that adopting RL algorithms to a new environment is often quite straightforward, because the OpenAI Gym has the same interface for all environments, and algorithms as such do not largely depend on the nature of the environment. You can even restructure the Python code in such a way as to pass any environment to RL algorithm as a parameter.</p>"},{"location":"lessons/6-Other/22-DeepRL/lab/README_chs/","title":"\u8bad\u7ec3\u5c71\u5730\u8f66\u9003\u8131","text":"<p>\u6765\u81ea AI for Beginners Curriculum \u7684\u5b9e\u9a8c\u4efb\u52a1\u3002</p>"},{"location":"lessons/6-Other/22-DeepRL/lab/README_chs/#_2","title":"\u4efb\u52a1","text":"<p>\u4f60\u7684\u76ee\u6807\u662f\u5728 OpenAI \u73af\u5883\u4e2d\u8bad\u7ec3 RL \u4ee3\u7406\u63a7\u5236 Mountain Car\u3002</p> <p></p>"},{"location":"lessons/6-Other/22-DeepRL/lab/README_chs/#_3","title":"\u73af\u5883","text":"<p>\u5c71\u5730\u8f66\u73af\u5883\u7531\u9677\u5728\u5c71\u8c37\u4e2d\u7684\u6c7d\u8f66\u7ec4\u6210\u3002\u4f60\u7684\u76ee\u6807\u662f\u8df3\u51fa\u5c71\u8c37\u5e76\u5230\u8fbe\u65d7\u5b50\u3002\u4f60\u53ef\u4ee5\u8fdb\u884c\u7684\u64cd\u4f5c\u662f\u5411\u5de6\u52a0\u901f\u3001\u5411\u53f3\u52a0\u901f\u6216\u4ec0\u4e48\u4e5f\u4e0d\u505a\u3002\u4f60\u53ef\u4ee5\u89c2\u5bdf\u6c7d\u8f66\u6cbf x \u8f74\u7684\u4f4d\u7f6e\u548c\u901f\u5ea6\u3002</p>"},{"location":"lessons/6-Other/22-DeepRL/lab/README_chs/#_4","title":"\u521d\u59cb\u7b14\u8bb0\u672c","text":"<p>\u901a\u8fc7\u6253\u5f00 MountainCar.ipynb \u5f00\u59cb\u5b9e\u9a8c\u3002</p>"},{"location":"lessons/6-Other/22-DeepRL/lab/README_chs/#_5","title":"\u6536\u83b7","text":"<p>\u4f60\u5e94\u8be5\u5728\u6574\u4e2a\u5b9e\u9a8c\u4e2d\u5b66\u4e60\u5230\uff0c\u5c06 RL \u7b97\u6cd5\u5e94\u7528\u4e8e\u65b0\u73af\u5883\u901a\u5e38\u662f\u76f8\u5f53\u76f4\u63a5\u7684\uff0c\u56e0\u4e3a OpenAI Gym \u5bf9\u6240\u6709\u73af\u5883\u90fd\u6709\u76f8\u540c\u7684\u63a5\u53e3\uff0c\u7b97\u6cd5\u672c\u8eab\u5728\u5f88\u5927\u7a0b\u5ea6\u4e0a\u4e0d\u4f9d\u8d56\u4e8e\u73af\u5883\u7684\u6027\u8d28\u3002\u4f60\u751a\u81f3\u53ef\u4ee5\u91cd\u65b0\u6784\u5efa Python \u4ee3\u7801\uff0c\u4ee5\u4fbf\u5c06\u4efb\u4f55\u73af\u5883\u4f5c\u4e3a\u53c2\u6570\u4f20\u9012\u7ed9 RL \u7b97\u6cd5\u3002</p>"},{"location":"lessons/6-Other/23-MultiagentSystems/","title":"Multi-Agent Systems","text":"<p>One of the possible ways of achieving intelligence is so-called emergent (or synergetic) approach, which is based on the fact that the combined behavior of many relatively simple agents can result in the overall more complex (or intelligent) behavior of the system as a whole. Theoretically, this is based on the principles of Collective Intelligence, Emergentism and Evolutionary Cybernetics, which state that higher-level systems gain some sort of added value when being properly combined from lower-level systems (so-called principle of metasystem transition).</p>"},{"location":"lessons/6-Other/23-MultiagentSystems/#pre-lecture-quiz","title":"Pre-lecture quiz","text":"<p>The direction of Multi-Agent Systems has emerged in AI in 1990s as a response to growth of the Internet and distributed systems. On of the classical AI textbooks, Artificial Intelligence: A Modern Approach, focuses on the view of classical AI from the point of view of Multi-agent systems.</p> <p>Central to Multi-agent approach is the notion of Agent - an entity that lives in some environment, which it can perceive, and act upon. This is a very broad definition, and there could be many different types and classifications of agents:</p> <ul> <li>By their ability to reason:</li> <li>Reactive agents usually have simple request-response type of behavior</li> <li>Deliberative agents employ some sort of logical reasoning and/or planning capabilities</li> <li>By the place where agent execute its code:</li> <li>Static agents work on a dedicated network node</li> <li>Mobile agents can move their code between network nodes</li> <li>By their behavior:</li> <li>Passive agents do not have specific goals. Such agents can react to external stimuli, but will not initiate any actions themselves. </li> <li>Active agents have some goals which they pursue</li> <li>Cognitive agents involve complex planning and reasoning</li> </ul> <p>Multi-agent systems are nowadays used in a number of applications:</p> <ul> <li>In games, many non-player characters employ some sort of AI, and can be considered to be intelligent agents</li> <li>In video production, rendering complex 3D scenes that involve crowds is typically done using multi-agent simulation</li> <li>In systems modeling, multi-agent approach is used to simulate the behavior of a complex model. For example, multi-agent approach has been successfully used to predict the spread of COVID-19 disease worldwide. Similar approach can be used to model traffic in the city, and see how it reacts to changes in traffic rules.</li> <li>In complex automation systems, each device can act as an independent agent, which makes the whole system less monolith and more robust.</li> </ul> <p>We will not spend a lot of time going deep into multi-agent systems, but consider one example of Multi-Agent Modeling.</p>"},{"location":"lessons/6-Other/23-MultiagentSystems/#netlogo","title":"NetLogo","text":"<p>NetLogo is a multi-agent modeling environment based on a modified version of the Logo programming language. This language was developed for teaching programming concepts to kids, and it allows you to control an agent called turtle, which can move, leaving a trace behind. This allows creating complex geometric figures, which is a very visual way to understand the behavior of an agent.</p> <p>In NetLogo, we can create many turtles by using the <code>create-turtles</code> command. We can then command all turtles to do some actions (in the example below - more 10 point forward):</p> <pre><code>create-turtles 10\nask turtles [\n  forward 10\n]\n</code></pre> <p>Of course, it is not interesting when all turtles do the same thing, so we can <code>ask</code> groups of turtles, eg. those who are in the vicinity of a certain point. We can also create turtles of different breeds using <code>breed [cats cat]</code> command. Here <code>cat</code> is the name of a breed, and we need to specify both singular and plural word, because different commands use different forms for clarity.</p> <p>\u2705 We will not go into learning the NetLogo language itself - you can visit the brilliant Beginner's Interactive NetLogo Dictionary resource if you are interested in learning more.</p> <p>You can download and install NetLogo to try it.</p>"},{"location":"lessons/6-Other/23-MultiagentSystems/#models-library","title":"Models Library","text":"<p>A great thing about NetLogo is that it contains a library of working models that you can try. Go to File \u2192 Models Library, and you have many categories of models to choose from.</p> <p></p> <p>A screenshot of the models library by Dmitry Soshnikov</p> <p>You can open one of the models, for example Biology \u2192 Flocking.</p>"},{"location":"lessons/6-Other/23-MultiagentSystems/#main-principles","title":"Main Principles","text":"<p>After opening the model, you are taken to the main NetLogo screen. Here is a sample model that describes the population of wolves and sheep, given finite resources (grass).</p> <p></p> <p>Screenshot by Dmitry Soshnikov</p> <p>On this screen, you can see:</p> <ul> <li>The Interface section which contains:</li> <li>The main field, where all agents live</li> <li>Different controls: buttons, sliders, etc.</li> <li>Graphs that you can use to display parameters of the simulation</li> <li>The Code tab which contains the editor, where you can type NetLogo program</li> </ul> <p>In most cases, the interface would have a Setup button, which initializes the simulation state, and a Go button that starts the execution. Those are handled by corresponding handlers in the code that look like this:</p> <pre><code>to go [\n...\n]\n</code></pre> <p>NetLogo's world consists of the following objects:</p> <ul> <li>Agents (turtles) that can move across the field and do something. You command agents by using <code>ask turtles [...]</code> syntax, and the code in brackets is executed by all agents in turtle mode.</li> <li>Patches are square areas of the field, on which agents live. You can refer to all agents on the same patch, or you can change patch colors and some other properties. You can also <code>ask patches</code> to do something.</li> <li>Observer is a unique agent that controls the world. All button handlers are executed in observer mode.</li> </ul> <p>\u2705 The beauty of a multi-agent environment is that the code that runs in turtle mode or in patch mode is executed at the same time by all agents in parallel. Thus, by writing a little code and programming the behavior of individual agent, you can create complex behavior of the simulation system as a whole.</p>"},{"location":"lessons/6-Other/23-MultiagentSystems/#flocking","title":"Flocking","text":"<p>As an example of multi-agent behavior, let's consider Flocking. Flocking is a complex pattern that is very similar to how flocks of birds fly. Watching them fly you can think that they follow some kind of collective algorithm, or that they possess some form of collective intelligence. However, this complex behavior arises when each individual agent (in this case, a bird) only observes some other agents in a short distance from it, and follows three simple rules:</p> <ul> <li>Alignment - it steers towards the average heading of neighboring agents</li> <li>Cohesion - it tries to steer towards the average position of neighbors (long range attraction)</li> <li>Separation - when getting too close to other birds, it tries to move away (short range repulsion)</li> </ul> <p>You can run the flocking example and observe the behavior. You can also adjust parameters, such as degree of separation, or the viewing range, which defines how far each bird can see. Note that if you decrease the viewing range to 0, all birds become blind, and flocking stops. If you decrease separation to 0, all birds gather into a straight line.</p> <p>\u2705 Switch to the Code tab and see where three rules of flocking (alignment, cohesion and separation) are implemented in code. Note how we refer only to those agents that are in sight.</p>"},{"location":"lessons/6-Other/23-MultiagentSystems/#other-models-to-see","title":"Other Models to see","text":"<p>There are a few more interesting models that you can experiment with:</p> <ul> <li>Art \u2192 Fireworks shows how a firework can be considered a collective behavior of individual fire streams</li> <li>Social Science \u2192 Traffic Basic and Social Science \u2192 Traffic Grid show the model of city traffic in 1D and 2D Grid with or without traffic lights. Each car in the simulation follows the following rules:</li> <li>If the space in front of it is empty - accelerate (up to a certain max speed)</li> <li>If it sees the obstacle in front - brake (and you can adjust how far a driver can see)</li> <li>Social Science \u2192 Party shows how people group together during a cocktail party. You can find the combination of parameters that lead to the fastest increase of happiness of the group.</li> </ul> <p>As you can see from these examples, multi-agent simulations can be quite a useful way to understand the behavior of a complex system consisting of individuals that follow the same or similar logic. It can also be used to control virtual agents, such as NPCs in computer games, or agents in 3D animated worlds.</p>"},{"location":"lessons/6-Other/23-MultiagentSystems/#deliberative-agents","title":"Deliberative Agents","text":"<p>The agents described above are very simple, reacting to changes in environment using some kind of algorithm. As such they are reactive agents. However, sometimes agents can reason and plan their action, in which case they are called deliberative.</p> <p>A typical example would be a personal agent that receives an instruction from a human to book a vacation tour. Suppose that there are many agents that live on the internet, who can help it. It should then contact other agents to see which flights are available, what are the hotel prices for different dates, and try to negotiate the best price. When the vacation plan is complete and confirmed by the owner, it can proceed with booking.</p> <p>In order to do that, agents need to communicate. For successful communication they need:</p> <ul> <li>Some standard languages to exchange knowledge, such as Knowledge Interchange Format (KIF) and Knowledge Query and Manipulation Language (KQML). Those languages are designed based on Speech Act theory.</li> <li>Those languages should also include some protocols for negotiations, based on different auction types.</li> <li>A common ontology to use, so that they refer to the same concepts knowing their semantics</li> <li>A way to discover what different agents can do, also based on some sort of ontology</li> </ul> <p>Deliberative agents are much more complex than reactive, because they do not only react to changes in environment, they should also be able to intiate actions. One of the proposed architectures for deliberative agents is the so-called Belief-Desire-Intention (BDI) agent:</p> <ul> <li>Beliefs form a set of knowledge about an agent's environment. It can be structured as a knowledge base or set of rules that an agent can apply to a specific situation in the environment.</li> <li>Desires define what an agent wants to do, i.e. its goals. For example, the goal of the personal assistant agent above is to book a tour, and the goal of a hotel agent is to maximize profit.</li> <li>Intentions are specific actions that an agent plans to achieve its goals. Actions typically change the environment and cause communication with other agents.</li> </ul> <p>There are some platforms available for building multi-agent systems, such as JADE. This paper contains a review of multi-agent platforms, together with a brief history of multi-agent systems and their different usage scenarios.</p>"},{"location":"lessons/6-Other/23-MultiagentSystems/#conclusion","title":"Conclusion","text":"<p>Multi-Agent systems can take very different forms and be used in many different applications.  They all tend to focus on the simpler behavior of an individual agent, and achieve more complex behavior of the overall system due to synergetic effect.</p>"},{"location":"lessons/6-Other/23-MultiagentSystems/#challenge","title":"\ud83d\ude80 Challenge","text":"<p>Take this lesson to the real world and try to conceptualize a multi-agent system that can solve a problem. What, for example, would a multi-agent system need to do to optimize a school bus route? How could it work in a bakery?</p>"},{"location":"lessons/6-Other/23-MultiagentSystems/#post-lecture-quiz","title":"Post-lecture quiz","text":""},{"location":"lessons/6-Other/23-MultiagentSystems/#review-self-study","title":"Review &amp; Self Study","text":"<p>Review the use of this type of system in industry. Pick a domain such as manufacturing or the video game industry and discover how multi-agent systems can be used to solve unique problems.</p>"},{"location":"lessons/6-Other/23-MultiagentSystems/#netlogo-assignment","title":"NetLogo Assignment","text":""},{"location":"lessons/6-Other/23-MultiagentSystems/README_chs/","title":"\u591a\u667a\u80fd\u4f53\u7cfb\u7edf","text":"<p>\u5b9e\u73b0\u667a\u80fd\u7684\u53ef\u80fd\u65b9\u5f0f\u4e4b\u4e00\u662f\u6240\u8c13\u7684\u6d8c\u73b0\uff08\u6216\u534f\u540c\uff09\u65b9\u6cd5\uff0c\u8be5\u65b9\u6cd5\u57fa\u4e8e\u8fd9\u6837\u4e00\u4e2a\u4e8b\u5b9e\uff1a\u8bb8\u591a\u76f8\u5bf9\u7b80\u5355\u7684\u667a\u80fd\u4f53\u7684\u7ec4\u5408\u884c\u4e3a\u53ef\u4ee5\u5bfc\u81f4\u6574\u4f53\u7cfb\u7edf\u66f4\u590d\u6742\uff08\u6216\u66f4\u667a\u80fd\uff09\u7684\u884c\u4e3a\u3002\u4ece\u7406\u8bba\u4e0a\u8bb2\uff0c\u8fd9\u57fa\u4e8e\u96c6\u4f53\u667a\u6167\u3001\u6d8c\u73b0\u4e3b\u4e49\u548c\u8fdb\u5316\u63a7\u5236\u8bba\u7684\u539f\u5219\uff0c\u8fd9\u4e9b\u539f\u5219\u8868\u660e\uff0c\u8f83\u9ad8\u5c42\u6b21\u7684\u7cfb\u7edf\u901a\u8fc7\u9002\u5f53\u5730\u7ed3\u5408\u8f83\u4f4e\u5c42\u6b21\u7684\u7cfb\u7edf\uff08\u6240\u8c13\u7684\u5143\u7cfb\u7edf\u8f6c\u6362\u539f\u5219\uff09\u53ef\u4ee5\u83b7\u5f97\u67d0\u79cd\u9644\u52a0\u503c\u3002</p>"},{"location":"lessons/6-Other/23-MultiagentSystems/README_chs/#_2","title":"\u8bfe\u524d\u6d4b\u9a8c","text":"<p>\u591a\u667a\u80fd\u4f53\u7cfb\u7edf\u7684\u65b9\u5411\u57281990\u5e74\u4ee3\u4f5c\u4e3a\u5bf9\u4e92\u8054\u7f51\u548c\u5206\u5e03\u5f0f\u7cfb\u7edf\u589e\u957f\u7684\u56de\u5e94\u5728AI\u4e2d\u51fa\u73b0\u3002\u4eba\u5de5\u667a\u80fd\uff1a\u73b0\u4ee3\u65b9\u6cd5\u662f\u7ecf\u5178\u7684AI\u6559\u6750\u4e4b\u4e00\uff0c\u5b83\u4ece\u591a\u667a\u80fd\u4f53\u7cfb\u7edf\u7684\u89d2\u5ea6\u805a\u7126\u7ecf\u5178AI\u3002</p> <p>\u591a\u667a\u80fd\u4f53\u65b9\u6cd5\u7684\u6838\u5fc3\u662f\u667a\u80fd\u4f53\u8fd9\u4e00\u6982\u5ff5 - \u4e00\u4e2a\u751f\u6d3b\u5728\u67d0\u79cd\u73af\u5883\u4e2d\u7684\u5b9e\u4f53\uff0c\u5b83\u53ef\u4ee5\u611f\u77e5\u73af\u5883\u5e76\u5bf9\u5176\u8fdb\u884c\u64cd\u4f5c\u3002\u8fd9\u662f\u4e00\u4e2a\u975e\u5e38\u5bbd\u6cdb\u7684\u5b9a\u4e49\uff0c\u53ef\u80fd\u6709\u5f88\u591a\u4e0d\u540c\u7c7b\u578b\u548c\u5206\u7c7b\u7684\u667a\u80fd\u4f53\uff1a</p> <ul> <li>\u6309\u5176\u63a8\u7406\u80fd\u529b\u5212\u5206\uff1a</li> <li>\u53cd\u5e94\u578b\u667a\u80fd\u4f53\u901a\u5e38\u5177\u6709\u7b80\u5355\u7684\u8bf7\u6c42-\u54cd\u5e94\u7c7b\u578b\u884c\u4e3a</li> <li>\u6df1\u601d\u578b\u667a\u80fd\u4f53\u91c7\u7528\u67d0\u79cd\u903b\u8f91\u63a8\u7406\u548c/\u6216\u8ba1\u5212\u80fd\u529b</li> <li>\u6309\u667a\u80fd\u4f53\u6267\u884c\u5176\u4ee3\u7801\u7684\u5730\u65b9\u5212\u5206\uff1a</li> <li>\u9759\u6001\u667a\u80fd\u4f53\u5728\u4e00\u4e2a\u4e13\u7528\u7684\u7f51\u7edc\u8282\u70b9\u4e0a\u5de5\u4f5c</li> <li>\u79fb\u52a8\u667a\u80fd\u4f53\u53ef\u4ee5\u5728\u7f51\u7edc\u8282\u70b9\u4e4b\u95f4\u79fb\u52a8\u5176\u4ee3\u7801</li> <li>\u6309\u5176\u884c\u4e3a\u5212\u5206\uff1a</li> <li>\u88ab\u52a8\u667a\u80fd\u4f53\u6ca1\u6709\u7279\u5b9a\u76ee\u6807\u3002\u8fd9\u4e9b\u667a\u80fd\u4f53\u53ef\u4ee5\u5bf9\u5916\u90e8\u523a\u6fc0\u4f5c\u51fa\u53cd\u5e94\uff0c\u4f46\u4e0d\u4f1a\u4e3b\u52a8\u91c7\u53d6\u884c\u52a8\u3002</li> <li>\u4e3b\u52a8\u667a\u80fd\u4f53\u6709\u4e00\u4e9b\u4ed6\u4eec\u8ffd\u6c42\u7684\u76ee\u6807</li> <li>\u8ba4\u77e5\u667a\u80fd\u4f53\u6d89\u53ca\u590d\u6742\u7684\u8ba1\u5212\u548c\u63a8\u7406</li> </ul> <p>\u591a\u667a\u80fd\u4f53\u7cfb\u7edf\u73b0\u5728\u7528\u4e8e\u8bb8\u591a\u5e94\u7528\u4e2d\uff1a</p> <ul> <li>\u5728\u6e38\u620f\u4e2d\uff0c\u8bb8\u591a\u975e\u73a9\u5bb6\u89d2\u8272\u91c7\u7528\u67d0\u79cd\u5f62\u5f0f\u7684AI\uff0c\u53ef\u4ee5\u88ab\u89c6\u4e3a\u667a\u80fd\u4f53</li> <li>\u5728\u89c6\u9891\u5236\u4f5c\u4e2d\uff0c\u6e32\u67d3\u6d89\u53ca\u4eba\u7fa4\u7684\u590d\u67423D\u573a\u666f\u901a\u5e38\u4f7f\u7528\u591a\u667a\u80fd\u4f53\u6a21\u62df\u5b8c\u6210</li> <li>\u5728\u7cfb\u7edf\u5efa\u6a21\u4e2d\uff0c\u591a\u667a\u80fd\u4f53\u65b9\u6cd5\u7528\u4e8e\u6a21\u62df\u590d\u6742\u6a21\u578b\u7684\u884c\u4e3a\u3002\u4f8b\u5982\uff0c\u591a\u667a\u80fd\u4f53\u65b9\u6cd5\u5df2\u6210\u529f\u7528\u4e8e\u9884\u6d4b\u5168\u7403COVID-19\u75be\u75c5\u7684\u4f20\u64ad\u3002\u7c7b\u4f3c\u7684\u65b9\u6cd5\u53ef\u4ee5\u7528\u4e8e\u6a21\u62df\u57ce\u5e02\u4ea4\u901a\uff0c\u5e76\u89c2\u5bdf\u5176\u5bf9\u4ea4\u901a\u89c4\u5219\u53d8\u5316\u7684\u53cd\u5e94\u3002</li> <li>\u5728\u590d\u6742\u7684\u81ea\u52a8\u5316\u7cfb\u7edf\u4e2d\uff0c\u6bcf\u4e2a\u8bbe\u5907\u53ef\u4ee5\u4f5c\u4e3a\u4e00\u4e2a\u72ec\u7acb\u7684\u667a\u80fd\u4f53\uff0c\u4f7f\u6574\u4e2a\u7cfb\u7edf\u4e0d\u90a3\u4e48\u5355\u4e00\uff0c\u5e76\u66f4\u52a0\u5065\u58ee\u3002</li> </ul> <p>\u6211\u4eec\u4e0d\u4f1a\u82b1\u5f88\u591a\u65f6\u95f4\u6df1\u5165\u7814\u7a76\u591a\u667a\u80fd\u4f53\u7cfb\u7edf\uff0c\u800c\u662f\u8003\u8651\u4e00\u4e2a\u591a\u667a\u80fd\u4f53\u5efa\u6a21\u7684\u793a\u4f8b\u3002</p>"},{"location":"lessons/6-Other/23-MultiagentSystems/README_chs/#netlogo","title":"NetLogo","text":"<p>NetLogo \u662f\u4e00\u4e2a\u57fa\u4e8e\u4fee\u6539\u7248Logo\u7f16\u7a0b\u8bed\u8a00\u7684\u591a\u667a\u80fd\u4f53\u5efa\u6a21\u73af\u5883\u3002\u8fd9\u79cd\u8bed\u8a00\u662f\u4e3a\u5411\u5b69\u5b50\u4eec\u6559\u6388\u7f16\u7a0b\u6982\u5ff5\u800c\u5f00\u53d1\u7684\uff0c\u5b83\u5141\u8bb8\u4f60\u63a7\u5236\u4e00\u4e2a\u79f0\u4e3a\u4e4c\u9f9f\u7684\u667a\u80fd\u4f53\uff0c\u5b83\u53ef\u4ee5\u79fb\u52a8\u5e76\u7559\u4e0b\u75d5\u8ff9\u3002\u8fd9\u4f7f\u5f97\u521b\u5efa\u590d\u6742\u7684\u51e0\u4f55\u56fe\u5f62\u6210\u4e3a\u53ef\u80fd\uff0c\u8fd9\u662f\u7406\u89e3\u667a\u80fd\u4f53\u884c\u4e3a\u7684\u4e00\u79cd\u975e\u5e38\u76f4\u89c2\u7684\u65b9\u5f0f\u3002</p> <p>\u5728NetLogo\u4e2d\uff0c\u6211\u4eec\u53ef\u4ee5\u4f7f\u7528 <code>create-turtles</code> \u547d\u4ee4\u521b\u5efa\u8bb8\u591a\u4e4c\u9f9f\u3002\u7136\u540e\u6211\u4eec\u53ef\u4ee5\u547d\u4ee4\u6240\u6709\u4e4c\u9f9f\u505a\u4e00\u4e9b\u52a8\u4f5c\uff08\u5728\u4e0b\u9762\u7684\u4f8b\u5b50\u4e2d - \u524d\u8fdb10\u70b9\uff09\uff1a</p> <pre><code>create-turtles 10\nask turtles [\n  forward 10\n]\n</code></pre> <p>\u5f53\u7136\uff0c\u5982\u679c\u6240\u6709\u4e4c\u9f9f\u90fd\u505a\u540c\u6837\u7684\u4e8b\u60c5\u5c31\u4e0d\u6709\u8da3\u4e86\uff0c\u6240\u4ee5\u6211\u4eec\u53ef\u4ee5 <code>ask</code> \u7279\u5b9a\u7ec4\u7684\u4e4c\u9f9f\uff0c\u6bd4\u5982\u90a3\u4e9b\u5728\u67d0\u4e00\u70b9\u9644\u8fd1\u7684\u4e4c\u9f9f\u3002\u6211\u4eec\u4e5f\u53ef\u4ee5\u4f7f\u7528 <code>breed [cats cat]</code> \u547d\u4ee4\u521b\u5efa\u4e0d\u540c\u79cd\u7c7b\u7684\u4e4c\u9f9f\u3002\u8fd9\u91cc <code>cat</code> \u662f\u79cd\u7c7b\u7684\u540d\u5b57\uff0c\u6211\u4eec\u9700\u8981\u6307\u5b9a\u5355\u6570\u548c\u590d\u6570\u7684\u8bcd\uff0c\u56e0\u4e3a\u4e0d\u540c\u7684\u547d\u4ee4\u4f7f\u7528\u4e0d\u540c\u7684\u5f62\u5f0f\u4ee5\u589e\u5f3a\u6e05\u6670\u5ea6\u3002</p> <p>\u2705 \u6211\u4eec\u4e0d\u4f1a\u5b66\u4e60NetLogo\u8bed\u8a00\u672c\u8eab - \u5982\u679c\u4f60\u6709\u5174\u8da3\u5b66\u4e60\u66f4\u591a\uff0c\u53ef\u4ee5\u8bbf\u95ee\u51fa\u8272\u7684\u521d\u5b66\u8005\u4e92\u52a8NetLogo\u8bcd\u5178\u8d44\u6e90\u3002</p> <p>\u4f60\u53ef\u4ee5\u4e0b\u8f7d\u5e76\u5b89\u88c5NetLogo\u8fdb\u884c\u5c1d\u8bd5\u3002</p>"},{"location":"lessons/6-Other/23-MultiagentSystems/README_chs/#_3","title":"\u6a21\u578b\u5e93","text":"<p>NetLogo\u7684\u4e00\u4e2a\u4f18\u70b9\u662f\u5b83\u5305\u542b\u4e00\u4e2a\u5de5\u4f5c\u6a21\u578b\u5e93\uff0c\u53ef\u4ee5\u5c1d\u8bd5\u3002\u8f6c\u5230 File \u2192 Models Library\uff0c\u4f60\u53ef\u4ee5\u9009\u62e9\u8bb8\u591a\u7c7b\u522b\u7684\u6a21\u578b\u3002</p> <p></p> <p>Dmitry Soshnikov\u5236\u4f5c\u7684\u6a21\u578b\u5e93\u622a\u56fe</p> <p>\u4f60\u53ef\u4ee5\u6253\u5f00\u5176\u4e2d\u4e00\u4e2a\u6a21\u578b\uff0c\u4f8b\u5982 Biology \u2192 Flocking\u3002</p>"},{"location":"lessons/6-Other/23-MultiagentSystems/README_chs/#_4","title":"\u57fa\u672c\u539f\u7406","text":"<p>\u6253\u5f00\u6a21\u578b\u540e\uff0c\u4f1a\u8fdb\u5165NetLogo\u7684\u4e3b\u5c4f\u5e55\u3002\u8fd9\u91cc\u662f\u63cf\u8ff0\u72fc\u548c\u7f8a\u7fa4\u4f53\u7ed9\u5b9a\u6709\u9650\u8d44\u6e90\uff08\u8349\u5730\uff09\u7684\u793a\u4f8b\u6a21\u578b\u3002</p> <p></p> <p>Dmitry Soshnikov\u5236\u4f5c\u7684\u622a\u56fe</p> <p>\u5728\u8fd9\u4e2a\u5c4f\u5e55\u4e0a\uff0c\u4f60\u53ef\u4ee5\u770b\u5230\uff1a</p> <ul> <li>\u754c\u9762\u90e8\u5206\u5305\u542b\uff1a</li> <li>\u5b58\u6d3b\u6240\u6709\u667a\u80fd\u4f53\u7684\u4e3b\u573a\u5730</li> <li>\u4e0d\u540c\u7684\u63a7\u4ef6\uff1a\u6309\u94ae\u3001\u6ed1\u5757\u7b49\u3002</li> <li>\u53ef\u7528\u4e8e\u663e\u793a\u6a21\u62df\u53c2\u6570\u7684\u56fe\u8868</li> <li>\u4ee3\u7801\u9009\u9879\u5361\u5305\u542b\u7f16\u8f91\u5668\uff0c\u53ef\u4ee5\u5728\u5176\u4e2d\u8f93\u5165NetLogo\u7a0b\u5e8f</li> </ul> <p>\u5728\u5927\u591a\u6570\u60c5\u51b5\u4e0b\uff0c\u754c\u9762\u4e0a\u4f1a\u6709\u4e00\u4e2a\u8bbe\u7f6e\u6309\u94ae\uff0c\u7528\u4e8e\u521d\u59cb\u5316\u6a21\u62df\u72b6\u6001\uff0c\u8fd8\u6709\u4e00\u4e2a\u542f\u52a8\u6309\u94ae\uff0c\u7528\u4e8e\u5f00\u59cb\u6267\u884c\u3002\u8fd9\u4e9b\u7531\u4ee3\u7801\u4e2d\u76f8\u5e94\u7684\u5904\u7406\u7a0b\u5e8f\u5904\u7406\uff0c\u901a\u5e38\u5982\u4e0b\u6240\u793a\uff1a</p> <pre><code>to go [\n...\n]\n</code></pre> <p>NetLogo\u7684\u4e16\u754c\u7531\u4ee5\u4e0b\u5bf9\u8c61\u7ec4\u6210\uff1a</p> <ul> <li>\u667a\u80fd\u4f53\uff08\u4e4c\u9f9f\uff09\u53ef\u4ee5\u5728\u573a\u5730\u4e0a\u79fb\u52a8\u5e76\u505a\u4e00\u4e9b\u4e8b\u60c5\u3002\u53ef\u4ee5\u4f7f\u7528 <code>ask turtles [...]</code> \u8bed\u6cd5\u547d\u4ee4\u667a\u80fd\u4f53\uff0c\u62ec\u53f7\u4e2d\u7684\u4ee3\u7801\u7531\u6240\u6709\u667a\u80fd\u4f53\u5728\u4e4c\u9f9f\u6a21\u5f0f\u4e0b\u6267\u884c\u3002</li> <li>\u8865\u4e01\uff08Patches\uff09\u662f\u667a\u80fd\u4f53\u751f\u6d3b\u7684\u573a\u5730\u4e0a\u7684\u65b9\u5f62\u533a\u57df\u3002\u53ef\u4ee5\u5f15\u7528\u540c\u4e00\u4e2a\u8865\u4e01\u4e0a\u7684\u6240\u6709\u667a\u80fd\u4f53\uff0c\u4e5f\u53ef\u4ee5\u66f4\u6539\u8865\u4e01\u989c\u8272\u548c\u5176\u4ed6\u4e00\u4e9b\u5c5e\u6027\u3002\u4f60\u4e5f\u53ef\u4ee5 <code>ask patches</code> \u6267\u884c\u67d0\u4e9b\u64cd\u4f5c\u3002</li> <li>\u89c2\u5bdf\u8005\u662f\u63a7\u5236\u4e16\u754c\u7684\u552f\u4e00\u667a\u80fd\u4f53\u3002\u6240\u6709\u6309\u94ae\u5904\u7406\u7a0b\u5e8f\u90fd\u5728\u89c2\u5bdf\u8005\u6a21\u5f0f\u4e0b\u6267\u884c\u3002</li> </ul> <p>\u2705 \u591a\u667a\u80fd\u4f53\u73af\u5883\u7684\u7f8e\u5999\u4e4b\u5904\u5728\u4e8e\uff0c\u8fd0\u884c\u5728\u4e4c\u9f9f\u6a21\u5f0f\u6216\u8865\u4e01\u6a21\u5f0f\u4e0b\u7684\u4ee3\u7801\u7531\u6240\u6709\u667a\u80fd\u4f53\u5e76\u884c\u6267\u884c\u3002\u56e0\u6b64\uff0c\u901a\u8fc7\u7f16\u5199\u5c11\u91cf\u4ee3\u7801\u5e76\u7f16\u7a0b\u5355\u4e2a\u667a\u80fd\u4f53\u7684\u884c\u4e3a\uff0c\u4f60\u53ef\u4ee5\u521b\u5efa\u6574\u4f53\u7cfb\u7edf\u7684\u590d\u6742\u884c\u4e3a\u3002</p>"},{"location":"lessons/6-Other/23-MultiagentSystems/README_chs/#_5","title":"\u7fa4\u4f53\u884c\u4e3a","text":"<p>\u4f5c\u4e3a\u591a\u667a\u80fd\u4f53\u884c\u4e3a\u7684\u4e00\u4f8b\uff0c\u8ba9\u6211\u4eec\u8003\u8651 \u7fa4\u4f53\u884c\u4e3a\u3002\u7fa4\u4f53\u884c\u4e3a\u662f\u4e00\u79cd\u590d\u6742\u7684\u6a21\u5f0f\uff0c\u975e\u5e38\u7c7b\u4f3c\u4e8e\u9e1f\u7fa4\u7684\u98de\u884c\u3002\u5f53\u4f60\u89c2\u5bdf\u5b83\u4eec\u98de\u884c\u65f6\uff0c\u53ef\u80fd\u4f1a\u8ba4\u4e3a\u5b83\u4eec\u9075\u5faa\u67d0\u79cd\u96c6\u4f53\u7b97\u6cd5\uff0c\u6216\u8005\u5b83\u4eec\u5177\u5907\u67d0\u79cd\u96c6\u4f53\u667a\u6167\u3002\u7136\u800c\uff0c\u8fd9\u79cd\u590d\u6742\u7684\u884c\u4e3a\u6e90\u4e8e\u6bcf\u4e2a\u5355\u72ec\u7684\u667a\u80fd\u4f53\uff08\u5728\u8fd9\u79cd\u60c5\u51b5\u4e0b\uff0c\u4e00\u4e2a\u9e1f\u7c7b\uff09\u53ea\u89c2\u5bdf\u5b83\u77ed\u8ddd\u79bb\u4e4b\u5916\u7684\u5176\u4ed6\u667a\u80fd\u4f53\uff0c\u5e76\u9075\u5faa\u4e09\u4e2a\u7b80\u5355\u89c4\u5219\uff1a</p> <ul> <li>\u5bf9\u9f50 - \u5b83\u671d\u5411\u90bb\u8fd1\u667a\u80fd\u4f53\u7684\u5e73\u5747\u65b9\u5411</li> <li>\u51dd\u805a - \u5b83\u8bd5\u56fe\u671d\u5411\u90bb\u8fd1\u667a\u80fd\u4f53\u7684\u5e73\u5747\u4f4d\u7f6e\uff08\u957f\u8303\u56f4\u5438\u5f15\u529b\uff09</li> <li>\u5206\u79bb - \u5f53\u9760\u8fd1\u5176\u4ed6\u9e1f\u7c7b\u65f6\uff0c\u5b83\u8bd5\u56fe\u8fdc\u79bb\uff08\u77ed\u8303\u56f4\u6392\u65a5\u529b\uff09</li> </ul> <p>\u4f60\u53ef\u4ee5\u8fd0\u884c\u7fa4\u4f53\u884c\u4e3a\u793a\u4f8b\u5e76\u89c2\u5bdf\u5176\u884c\u4e3a\u3002\u4f60\u8fd8\u53ef\u4ee5\u8c03\u6574\u53c2\u6570\uff0c\u4f8b\u5982\u5206\u79bb\u5ea6\u6216\u89c6\u91ce\u8303\u56f4\uff0c\u5373\u6bcf\u53ea\u9e1f\u80fd\u770b\u591a\u8fdc\u3002\u6ce8\u610f\uff0c\u5982\u679c\u4f60\u5c06\u89c6\u91ce\u8303\u56f4\u51cf\u5c11\u52300\uff0c\u6240\u6709\u9e1f\u7c7b\u90fd\u53d8\u5f97\u76f2\u76ee\uff0c\u7fa4\u4f53\u884c\u4e3a\u505c\u6b62\u3002\u5982\u679c\u4f60\u5c06\u5206\u79bb\u5ea6\u51cf\u5c11\u52300\uff0c\u6240\u6709\u9e1f\u7c7b\u805a\u96c6\u6210\u4e00\u6761\u76f4\u7ebf\u3002</p> <p>\u2705 \u5207\u6362\u5230\u4ee3\u7801\u9009\u9879\u5361\uff0c\u770b\u770b\u7fa4\u4f53\u884c\u4e3a\u7684\u4e09\u4e2a\u89c4\u5219\uff08\u5bf9\u9f50\u3001\u51dd\u805a\u548c\u5206\u79bb\uff09\u662f\u5982\u4f55\u5728\u4ee3\u7801\u4e2d\u5b9e\u73b0\u7684\u3002\u6ce8\u610f\u6211\u4eec\u5982\u4f55\u53ea\u5f15\u7528\u89c6\u8ddd\u5185\u7684\u667a\u80fd\u4f53\u3002</p>"},{"location":"lessons/6-Other/23-MultiagentSystems/README_chs/#_6","title":"\u5176\u4ed6\u53ef\u89c2\u770b\u7684\u6a21\u578b","text":"<p>\u8fd8\u6709\u4e00\u4e9b\u6709\u8da3\u7684\u6a21\u578b\u53ef\u4ee5\u8bd5\u9a8c\uff1a</p> <ul> <li>Art \u2192 Fireworks \u663e\u793a\u4e86\u5982\u4f55\u5c06\u70df\u82b1\u89c6\u4e3a\u4e2a\u522b\u706b\u6d41\u7684\u96c6\u4f53\u884c\u4e3a</li> <li>Social Science \u2192 Traffic Basic\u548cSocial Science \u2192 Traffic Grid \u663e\u793a\u4e861D\u548c2D\u7f51\u683c\u4e2d\u7684\u57ce\u5e02\u4ea4\u901a\u6a21\u578b\uff0c\u6709\u6216\u6ca1\u6709\u4ea4\u901a\u4fe1\u53f7\u706f\u3002\u6a21\u62df\u4e2d\u7684\u6bcf\u8f86\u8f66\u9075\u5faa\u4ee5\u4e0b\u89c4\u5219\uff1a</li> <li>\u5982\u679c\u524d\u9762\u7684\u7a7a\u95f4\u662f\u7a7a\u7684 - \u52a0\u901f\uff08\u5230\u67d0\u4e2a\u6700\u5927\u901f\u5ea6\uff09</li> <li>\u5982\u679c\u770b\u5230\u524d\u9762\u7684\u969c\u788d\u7269 - \u5239\u8f66\uff08\u53ef\u4ee5\u8c03\u6574\u53f8\u673a\u80fd\u770b\u5230\u7684\u8ddd\u79bb\uff09</li> <li>Social Science \u2192 Party \u663e\u793a\u4e86\u9e21\u5c3e\u9152\u4f1a\u4e0a\u4eba\u4eec\u805a\u5728\u4e00\u8d77\u7684\u5fc3\u7406\u548c\u793e\u4ea4\u884c\u4e3a\u3002\u4f60\u53ef\u4ee5\u627e\u5230\u5bfc\u81f4\u7fa4\u4f53\u5e78\u798f\u611f\u4e0a\u5347\u6700\u5feb\u7684\u53c2\u6570\u7ec4\u5408\u3002</li> </ul> <p>\u4ece\u8fd9\u4e9b\u793a\u4f8b\u4e2d\u53ef\u4ee5\u770b\u51fa\uff0c\u591a\u667a\u80fd\u4f53\u6a21\u62df\u53ef\u4ee5\u662f\u7406\u89e3\u7531\u9075\u5faa\u76f8\u540c\u6216\u76f8\u4f3c\u903b\u8f91\u7684\u4e2a\u4f53\u7ec4\u6210\u7684\u590d\u6742\u7cfb\u7edf\u884c\u4e3a\u7684\u4e00\u79cd\u65b9\u6cd5\u3002\u5b83\u8fd8\u53ef\u4ee5\u7528\u4e8e\u63a7\u5236\u865a\u62df\u667a\u80fd\u4f53\uff0c\u4f8b\u5982\u7535\u8111\u6e38\u620f\u4e2d\u7684NPC\uff0c\u6216\u80053D\u52a8\u753b\u4e16\u754c\u4e2d\u7684\u667a\u80fd\u4f53\u3002</p>"},{"location":"lessons/6-Other/23-MultiagentSystems/README_chs/#_7","title":"\u6df1\u601d\u578b\u667a\u80fd\u4f53","text":"<p>\u4e0a\u8ff0\u63cf\u8ff0\u7684\u667a\u80fd\u4f53\u975e\u5e38\u7b80\u5355\uff0c\u4f7f\u7528\u67d0\u79cd\u7b97\u6cd5\u5bf9\u73af\u5883\u53d8\u5316\u505a\u51fa\u53cd\u5e94\u3002\u56e0\u6b64\uff0c\u5b83\u4eec\u662f\u53cd\u5e94\u578b\u667a\u80fd\u4f53\u3002\u7136\u800c\uff0c\u6709\u65f6\u5019\u667a\u80fd\u4f53\u53ef\u4ee5\u63a8\u7406\u548c\u8ba1\u5212\u5176\u884c\u52a8\uff0c\u6b64\u65f6\u5b83\u4eec\u88ab\u79f0\u4e3a\u6df1\u601d\u578b\u667a\u80fd\u4f53\u3002</p> <p>\u4e00\u4e2a\u5178\u578b\u7684\u4f8b\u5b50\u662f\u4e2a\u4eba\u52a9\u624b\u667a\u80fd\u4f53\u63a5\u6536\u4eba\u7684\u6307\u4ee4\u9884\u5b9a\u4e00\u4e2a\u5ea6\u5047\u884c\u7a0b\u3002\u5047\u8bbe\u4e92\u8054\u7f51\u4e0a\u6709\u8bb8\u591a\u53ef\u4ee5\u5e2e\u52a9\u5b83\u7684\u667a\u80fd\u4f53\u3002\u7136\u540e\uff0c\u5b83\u5e94\u8be5\u8054\u7cfb\u5176\u4ed6\u667a\u80fd\u4f53\u67e5\u770b\u6709\u54ea\u4e9b\u822a\u73ed\u53ef\u7528\uff0c\u4e0d\u540c\u65e5\u671f\u7684\u9152\u5e97\u4ef7\u683c\uff0c\u5e76\u5c1d\u8bd5\u534f\u5546\u6700\u4f73\u4ef7\u683c\u3002\u5f53\u5ea6\u5047\u8ba1\u5212\u5b8c\u6210\u5e76\u7531\u4e3b\u4eba\u786e\u8ba4\u540e\uff0c\u5b83\u53ef\u4ee5\u7ee7\u7eed\u9884\u5b9a\u3002</p> <p>\u4e3a\u4e86\u505a\u5230\u8fd9\u4e00\u70b9\uff0c\u667a\u80fd\u4f53\u9700\u8981\u901a\u4fe1\u3002\u4e3a\u4e86\u6210\u529f\u901a\u4fe1\uff0c\u5b83\u4eec\u9700\u8981\uff1a</p> <ul> <li>\u4e00\u4e9b\u4ea4\u6362\u77e5\u8bc6\u7684\u6807\u51c6\u8bed\u8a00\uff0c\u4f8b\u5982\u77e5\u8bc6\u4ea4\u6362\u683c\u5f0f\uff08KIF\uff09\u548c\u77e5\u8bc6\u67e5\u8be2\u4e0e\u64cd\u4f5c\u8bed\u8a00\uff08KQML\uff09\u3002\u8fd9\u4e9b\u8bed\u8a00\u57fa\u4e8e\u8a00\u8bed\u884c\u4e3a\u7406\u8bba\u8bbe\u8ba1\u3002</li> <li>\u8fd9\u4e9b\u8bed\u8a00\u8fd8\u5e94\u5305\u542b\u4e00\u4e9b\u8c08\u5224\u534f\u8bae\uff0c\u57fa\u4e8e\u4e0d\u540c\u7684\u62cd\u5356\u7c7b\u578b\u3002</li> <li>\u4f7f\u7528\u7684\u5171\u6709\u672c\u4f53\uff0c\u4ee5\u4fbf\u5b83\u4eec\u5f15\u7528\u76f8\u540c\u7684\u6982\u5ff5\u5e76\u4e86\u89e3\u5176\u8bed\u4e49</li> <li>\u4e00\u79cd\u53d1\u73b0\u4e0d\u540c\u667a\u80fd\u4f53\u53ef\u4ee5\u505a\u4ec0\u4e48\u7684\u65b9\u6cd5\uff0c\u4e5f\u57fa\u4e8e\u67d0\u79cd\u5f62\u5f0f\u7684\u672c\u4f53</li> </ul> <p>\u6df1\u601d\u578b\u667a\u80fd\u4f53\u6bd4\u53cd\u5e94\u578b\u66f4\u590d\u6742\uff0c\u56e0\u4e3a\u5b83\u4eec\u4e0d\u4ec5\u5bf9\u73af\u5883\u53d8\u5316\u505a\u51fa\u53cd\u5e94\uff0c\u8fd8\u5e94\u8be5\u80fd\u591f\u53d1\u8d77\u884c\u52a8\u3002\u4e3a\u6df1\u601d\u578b\u667a\u80fd\u4f53\u63d0\u51fa\u7684\u67b6\u6784\u4e4b\u4e00\u662f\u6240\u8c13\u7684\u4fe1\u5ff5-\u6b32\u671b-\u610f\u56fe\uff08BDI\uff09\u667a\u80fd\u4f53\uff1a</p> <ul> <li>\u4fe1\u5ff5\u5f62\u6210\u4e86\u6709\u5173\u667a\u80fd\u4f53\u73af\u5883\u7684\u4e00\u7ec4\u77e5\u8bc6\u3002\u5b83\u53ef\u4ee5\u88ab\u6784\u5efa\u4e3a\u77e5\u8bc6\u5e93\u6216\u667a\u80fd\u4f53\u53ef\u4ee5\u5e94\u7528\u4e8e\u73af\u5883\u4e2d\u7279\u5b9a\u60c5\u51b5\u7684\u4e00\u7ec4\u89c4\u5219\u3002</li> <li>\u6b32\u671b\u5b9a\u4e49\u4e86\u667a\u80fd\u4f53\u60f3\u505a\u4ec0\u4e48\uff0c\u4e5f\u5c31\u662f\u5b83\u7684\u76ee\u6807\u3002\u4f8b\u5982\uff0c\u4e0a\u8ff0\u4e2a\u4eba\u52a9\u624b\u667a\u80fd\u4f53\u7684\u76ee\u6807\u662f\u9884\u5b9a\u4e00\u4e2a\u65c5\u884c\uff0c\u800c\u9152\u5e97\u667a\u80fd\u4f53\u7684\u76ee\u6807\u662f\u6700\u5927\u5316\u5229\u6da6\u3002</li> <li>\u610f\u56fe\u662f\u667a\u80fd\u4f53\u4e3a\u5b9e\u73b0\u5176\u76ee\u6807\u800c\u8ba1\u5212\u7684\u5177\u4f53\u884c\u52a8\u3002\u884c\u52a8\u901a\u5e38\u4f1a\u6539\u53d8\u73af\u5883\u5e76\u5f15\u8d77\u4e0e\u5176\u4ed6\u667a\u80fd\u4f53\u7684\u901a\u4fe1\u3002</li> </ul> <p>\u6709\u4e00\u4e9b\u53ef\u7528\u4e8e\u6784\u5efa\u591a\u667a\u80fd\u4f53\u7cfb\u7edf\u7684\u5e73\u53f0\uff0c\u4f8b\u5982JADE\u3002\u8fd9\u7bc7\u6587\u7ae0\u5305\u542b\u4e86\u591a\u667a\u80fd\u4f53\u5e73\u53f0\u7684\u7efc\u8ff0\uff0c\u4ee5\u53ca\u591a\u667a\u80fd\u4f53\u7cfb\u7edf\u7684\u7b80\u53f2\u53ca\u5176\u4e0d\u540c\u7684\u4f7f\u7528\u573a\u666f\u3002</p>"},{"location":"lessons/6-Other/23-MultiagentSystems/README_chs/#_8","title":"\u7ed3\u8bba","text":"<p>\u591a\u667a\u80fd\u4f53\u7cfb\u7edf\u53ef\u4ee5\u91c7\u53d6\u975e\u5e38\u4e0d\u540c\u7684\u5f62\u5f0f\uff0c\u5e76\u7528\u4e8e\u8bb8\u591a\u4e0d\u540c\u7684\u5e94\u7528\u4e2d\u3002 \u5b83\u4eec\u90fd\u503e\u5411\u4e8e\u4e13\u6ce8\u4e8e\u5355\u4e2a\u667a\u80fd\u4f53\u7684\u7b80\u5355\u884c\u4e3a\uff0c\u901a\u8fc7\u534f\u540c\u6548\u5e94\u5b9e\u73b0\u6574\u4f53\u7cfb\u7edf\u7684\u590d\u6742\u884c\u4e3a\u3002</p>"},{"location":"lessons/6-Other/23-MultiagentSystems/README_chs/#_9","title":"\ud83d\ude80 \u6311\u6218","text":"<p>\u5c06\u672c\u8bfe\u5185\u5bb9\u5e94\u7528\u4e8e\u73b0\u5b9e\u4e16\u754c\uff0c\u5c1d\u8bd5\u6982\u5ff5\u5316\u4e00\u4e2a\u53ef\u4ee5\u89e3\u51b3\u95ee\u9898\u7684\u591a\u667a\u80fd\u4f53\u7cfb\u7edf\u3002\u4f8b\u5982\uff0c\u591a\u667a\u80fd\u4f53\u7cfb\u7edf\u9700\u8981\u505a\u4e9b\u4ec0\u4e48\u6765\u4f18\u5316\u6821\u8f66\u8def\u7ebf\uff1f\u5b83\u5728\u9762\u5305\u5e97\u4e2d\u5982\u4f55\u5de5\u4f5c\uff1f</p>"},{"location":"lessons/6-Other/23-MultiagentSystems/README_chs/#_10","title":"\u8bfe\u540e\u6d4b\u9a8c","text":""},{"location":"lessons/6-Other/23-MultiagentSystems/README_chs/#_11","title":"\u590d\u4e60\u4e0e\u81ea\u5b66","text":"<p>\u590d\u4e60\u8fd9\u79cd\u7cfb\u7edf\u5728\u5de5\u4e1a\u4e2d\u7684\u4f7f\u7528\u3002\u5728\u5236\u9020\u4e1a\u6216\u89c6\u9891\u6e38\u620f\u4ea7\u4e1a\u7b49\u9886\u57df\u4e2d\uff0c\u4e86\u89e3\u591a\u667a\u80fd\u4f53\u7cfb\u7edf\u53ef\u4ee5\u5982\u4f55\u7528\u6765\u89e3\u51b3\u72ec\u7279\u95ee\u9898\u3002</p>"},{"location":"lessons/6-Other/23-MultiagentSystems/README_chs/#netlogo_1","title":"NetLogo\u4f5c\u4e1a","text":""},{"location":"lessons/6-Other/23-MultiagentSystems/assignment/","title":"NetLogo Assignment","text":"<p>Take one of the models in NetLogo's library and use it to simulate a real-life situation as closely as possible. A good example would be to tweak the Virus model in the Alternative Visualizations folder to show how it can be used to model the spread of COVID-19. Can you build a model that mimics a real life viral spread?</p> <p>Show your work by saving a copy and building a video demo explaining how the model is connected to a real-world situation.</p>"},{"location":"lessons/6-Other/23-MultiagentSystems/assignment_chs/","title":"NetLogo \u4f5c\u4e1a","text":"<p>\u9009\u62e9 NetLogo \u5e93\u4e2d\u7684\u4e00\u4e2a\u6a21\u578b\uff0c\u5e76\u4f7f\u7528\u5b83\u5c3d\u53ef\u80fd\u8d34\u8fd1\u5730\u6a21\u62df\u73b0\u5b9e\u751f\u6d3b\u4e2d\u7684\u60c5\u51b5\u3002\u4e00\u4e2a\u597d\u7684\u4f8b\u5b50\u662f\u8c03\u6574\u201cAlternative Visualizations\u201d\u6587\u4ef6\u5939\u4e2d\u7684\u75c5\u6bd2\u6a21\u578b\uff0c\u4ee5\u5c55\u793a\u5b83\u5982\u4f55\u7528\u4e8e\u6a21\u62df COVID-19 \u7684\u4f20\u64ad\u3002\u4f60\u80fd\u6784\u5efa\u4e00\u4e2a\u6a21\u4eff\u73b0\u5b9e\u751f\u6d3b\u4e2d\u75c5\u6bd2\u4f20\u64ad\u7684\u6a21\u578b\u5417\uff1f</p> <p>\u901a\u8fc7\u4fdd\u5b58\u4e00\u4e2a\u526f\u672c\u5e76\u5236\u4f5c\u4e00\u4e2a\u89c6\u9891\u6f14\u793a\u6765\u5c55\u793a\u4f60\u7684\u5de5\u4f5c\uff0c\u89e3\u91ca\u6a21\u578b\u5982\u4f55\u4e0e\u73b0\u5b9e\u4e16\u754c\u7684\u60c5\u51b5\u76f8\u5173\u8054\u3002</p>"},{"location":"lessons/7-Ethics/","title":"Ethical and Responsible AI","text":"<p>You have almost finished this course, and I hope that by now you clearly see that AI is based on a number of formal mathematical methods that allow us to find relationships in data and train models to replicate some aspects of human behavior. At this point in history, we consider AI to be a very powerful tool to extract patterns from data, and to apply those patterns to solve new problems.</p>"},{"location":"lessons/7-Ethics/#pre-lecture-quiz","title":"Pre-lecture quiz","text":"<p>However, in science fiction we often see stories where AI presents a danger to humankind. Usually those stories are centered around some sort of AI rebellion, when AI decides to confront human beings. This implies that AI has some sort of emotion or can take decisions unforeseen by its developers.</p> <p>The kind of AI that we have learned about in this course is nothing more than large matrix arithmetic. It is a very powerful tool to help us solve our problems, and as any other powerful tool - it can be used for good and for bad purposes. Importantly, it can be misused.</p>"},{"location":"lessons/7-Ethics/#principles-of-responsible-ai","title":"Principles of Responsible AI","text":"<p>To avoid this accidental or purposeful misuse of AI, Microsoft states the important Principles of Responsible AI. The following concepts underpin these principles:</p> <ul> <li>Fairness is related to the important problem of model biases, which can be caused by using biased data for training. For example, when we try to predict the probability of getting a software developer job for a person, the model is likely to give higher preference to males - just because the training dataset was likely biased towards a male audience. We need to carefully balance training data and investigate the model to avoid biases, and make sure that the model takes into account more relevant features.</li> <li>Reliability and Safety. By their nature, AI models can make mistakes. A neural network returns probabilities, and we need to take it into account when making decisions. Every model has some precision and recall, and we need to understand that to prevent harm that wrong advice can cause.</li> <li>Privacy and Security have some AI-specific implications. For example, when we use some data for training a model, this data becomes somehow \"integrated\" into the model. On one hand, that increases security and privacy, on the other - we need to remember which data the model was trained on.</li> <li>Inclusiveness means that we are not building AI to replace people, but rather to augment people and make our work more creative. It is also related to fairness, because when dealing with underrepresented communities, most of the datasets we collect are likely to be biased, and we need to make sure that those communities are included and correctly handled by AI.</li> <li>Transparency. This includes making sure that we are always clear about AI being used. Also, wherever possible, we want to use AI systems that are interpretable.</li> <li>Accountability. When AI models come up with some decisions, it is not always clear who is responsible for those decisions. We need to make sure that we understand where responsibility of AI decisions lies. In most cases we would want to include human beings into the loop of making important decisions, so that actual people are made accountable.</li> </ul>"},{"location":"lessons/7-Ethics/#tools-for-responsible-ai","title":"Tools for Responsible AI","text":"<p>Microsoft has developed the Responsible AI Toolbox which contains a set of tools:</p> <ul> <li>Interpretability Dashboard (InterpretML)</li> <li>Fairness Dashboard (FairLearn)</li> <li>Error Analysis Dashboard</li> <li> <p>Responsible AI Dashboard that includes</p> </li> <li> <p>EconML - tool for Causal Analysis, which focuses on what-if questions</p> </li> <li>DiCE - tool for Counterfactual Analysis allows you to see which features need to be changed to affect the decision of the model</li> </ul> <p>For more information about AI Ethics, please visit this lesson on the Machine Learning Curriculum which includes assignments.</p>"},{"location":"lessons/7-Ethics/#review-self-study","title":"Review &amp; Self Study","text":"<p>Take this Learn Path to learn more about responsible AI.</p>"},{"location":"lessons/7-Ethics/#post-lecture-quiz","title":"Post-lecture quiz","text":""},{"location":"lessons/7-Ethics/README_chs/","title":"\u9053\u5fb7\u4e0e\u8d1f\u8d23\u4efb\u7684\u4eba\u5de5\u667a\u80fd","text":"<p>\u4f60\u5373\u5c06\u5b8c\u6210\u672c\u8bfe\u7a0b\uff0c\u5e0c\u671b\u5230\u73b0\u5728\u4f60\u5df2\u7ecf\u6e05\u695a\u5730\u770b\u5230\uff0c\u4eba\u5de5\u667a\u80fd\u662f\u57fa\u4e8e\u4e00\u7cfb\u5217\u5f62\u5f0f\u5316\u7684\u6570\u5b66\u65b9\u6cd5\uff0c\u8fd9\u4e9b\u65b9\u6cd5\u5141\u8bb8\u6211\u4eec\u5728\u6570\u636e\u4e2d\u627e\u5230\u5173\u7cfb\u5e76\u8bad\u7ec3\u6a21\u578b\u6765\u590d\u5236\u4eba\u7c7b\u884c\u4e3a\u7684\u67d0\u4e9b\u65b9\u9762\u3002\u5728\u8fd9\u4e2a\u5386\u53f2\u65f6\u523b\uff0c\u6211\u4eec\u8ba4\u4e3a\u4eba\u5de5\u667a\u80fd\u662f\u4ece\u6570\u636e\u4e2d\u63d0\u53d6\u6a21\u5f0f\u5e76\u5c06\u8fd9\u4e9b\u6a21\u5f0f\u5e94\u7528\u4e8e\u89e3\u51b3\u65b0\u95ee\u9898\u7684\u975e\u5e38\u5f3a\u5927\u7684\u5de5\u5177\u3002</p>"},{"location":"lessons/7-Ethics/README_chs/#_2","title":"\u8bfe\u524d\u6d4b\u9a8c","text":"<p>\u7136\u800c\uff0c\u5728\u79d1\u5e7b\u5c0f\u8bf4\u4e2d\uff0c\u6211\u4eec\u7ecf\u5e38\u770b\u5230\u4eba\u5de5\u667a\u80fd\u5bf9\u4eba\u7c7b\u6784\u6210\u5a01\u80c1\u7684\u6545\u4e8b\u3002\u901a\u5e38\u8fd9\u4e9b\u6545\u4e8b\u56f4\u7ed5\u67d0\u79cd\u4eba\u5de5\u667a\u80fd\u7684\u53db\u4e71\u5c55\u5f00\uff0c\u5373\u4eba\u5de5\u667a\u80fd\u51b3\u5b9a\u4e0e\u4eba\u7c7b\u5bf9\u6297\u3002\u8fd9\u6697\u793a\u4eba\u5de5\u667a\u80fd\u6709\u67d0\u79cd\u60c5\u611f\u6216\u80fd\u591f\u505a\u51fa\u5f00\u53d1\u8005\u672a\u9884\u89c1\u7684\u51b3\u7b56\u3002</p> <p>\u5728\u672c\u8bfe\u7a0b\u4e2d\u6211\u4eec\u6240\u5b66\u7684\u4eba\u5de5\u667a\u80fd\u4e0d\u8fc7\u662f\u5927\u89c4\u6a21\u77e9\u9635\u8fd0\u7b97\u3002\u5b83\u662f\u5e2e\u52a9\u6211\u4eec\u89e3\u51b3\u95ee\u9898\u7684\u975e\u5e38\u5f3a\u5927\u7684\u5de5\u5177\uff0c\u6b63\u5982\u4efb\u4f55\u5176\u4ed6\u5f3a\u5927\u7684\u5de5\u5177\u4e00\u6837\u2014\u2014\u5b83\u65e2\u53ef\u4ee5\u7528\u4e8e\u597d\u7684\u76ee\u7684\uff0c\u4e5f\u53ef\u4ee5\u7528\u4e8e\u574f\u7684\u76ee\u7684\u3002\u91cd\u8981\u7684\u662f\uff0c\u5b83\u53ef\u80fd\u88ab\u8bef\u7528\u3002</p>"},{"location":"lessons/7-Ethics/README_chs/#_3","title":"\u8d1f\u8d23\u4efb\u7684\u4eba\u5de5\u667a\u80fd\u539f\u5219","text":"<p>\u4e3a\u4e86\u907f\u514d\u4eba\u5de5\u667a\u80fd\u7684\u610f\u5916\u6216\u6545\u610f\u8bef\u7528\uff0c\u5fae\u8f6f\u63d0\u51fa\u4e86\u91cd\u8981\u7684\u8d1f\u8d23\u4efb\u7684\u4eba\u5de5\u667a\u80fd\u539f\u5219\u3002\u4ee5\u4e0b\u6982\u5ff5\u662f\u8fd9\u4e9b\u539f\u5219\u7684\u57fa\u7840\uff1a</p> <ul> <li>\u516c\u5e73\u6027\u4e0e\u6a21\u578b\u504f\u89c1\u95ee\u9898\u5bc6\u5207\u76f8\u5173\uff0c\u6a21\u578b\u504f\u89c1\u53ef\u80fd\u662f\u7531\u4e8e\u4f7f\u7528\u4e86\u6709\u504f\u89c1\u7684\u8bad\u7ec3\u6570\u636e\u5f15\u8d77\u7684\u3002\u4f8b\u5982\uff0c\u5f53\u6211\u4eec\u8bd5\u56fe\u9884\u6d4b\u4e00\u4e2a\u4eba\u83b7\u5f97\u8f6f\u4ef6\u5f00\u53d1\u4eba\u5458\u5de5\u4f5c\u7684\u6982\u7387\u65f6\uff0c\u6a21\u578b\u53ef\u80fd\u66f4\u503e\u5411\u4e8e\u7537\u6027\u2014\u2014\u53ea\u662f\u56e0\u4e3a\u8bad\u7ec3\u6570\u636e\u96c6\u53ef\u80fd\u503e\u5411\u4e8e\u7537\u6027\u3002\u6211\u4eec\u9700\u8981\u614e\u91cd\u5e73\u8861\u8bad\u7ec3\u6570\u636e\u5e76\u8c03\u67e5\u6a21\u578b\u4ee5\u907f\u514d\u504f\u89c1\uff0c\u786e\u4fdd\u6a21\u578b\u8003\u8651\u5230\u66f4\u76f8\u5173\u7684\u7279\u5f81\u3002</li> <li>\u53ef\u9760\u6027\u548c\u5b89\u5168\u6027\u3002\u4eba\u5de5\u667a\u80fd\u6a21\u578b\u672c\u8d28\u4e0a\u53ef\u80fd\u4f1a\u72af\u9519\u8bef\u3002\u795e\u7ecf\u7f51\u7edc\u8fd4\u56de\u6982\u7387\uff0c\u6211\u4eec\u9700\u8981\u5728\u505a\u51b3\u7b56\u65f6\u5c06\u5176\u8003\u8651\u5728\u5185\u3002\u6bcf\u4e2a\u6a21\u578b\u90fd\u6709\u4e00\u5b9a\u7684\u7cbe\u5ea6\u548c\u53ec\u56de\u7387\uff0c\u6211\u4eec\u9700\u8981\u4e86\u89e3\u8fd9\u4e00\u70b9\u4ee5\u9632\u6b62\u9519\u8bef\u5efa\u8bae\u53ef\u80fd\u9020\u6210\u7684\u4f24\u5bb3\u3002</li> <li>\u9690\u79c1\u548c\u5b89\u5168\u6709\u4e00\u4e9b\u4e0e\u4eba\u5de5\u667a\u80fd\u76f8\u5173\u7684\u7279\u5b9a\u542b\u4e49\u3002\u4f8b\u5982\uff0c\u5f53\u6211\u4eec\u4f7f\u7528\u4e00\u4e9b\u6570\u636e\u6765\u8bad\u7ec3\u6a21\u578b\u65f6\uff0c\u8fd9\u4e9b\u6570\u636e\u4f1a\u67d0\u79cd\u7a0b\u5ea6\u4e0a\u201c\u96c6\u6210\u201d\u8fdb\u6a21\u578b\u4e2d\u3002\u4e00\u65b9\u9762\uff0c\u8fd9\u589e\u52a0\u4e86\u5b89\u5168\u6027\u548c\u9690\u79c1\u6027\uff0c\u53e6\u4e00\u65b9\u9762\u2014\u2014\u6211\u4eec\u9700\u8981\u8bb0\u4f4f\u6a21\u578b\u662f\u57fa\u4e8e\u54ea\u4e9b\u6570\u636e\u8fdb\u884c\u8bad\u7ec3\u7684\u3002</li> <li>\u5305\u5bb9\u6027\u610f\u5473\u7740\u6211\u4eec\u4e0d\u662f\u5728\u6784\u5efa\u4eba\u5de5\u667a\u80fd\u6765\u53d6\u4ee3\u4eba\u4eec\uff0c\u800c\u662f\u589e\u5f3a\u4eba\u4eec\uff0c\u4f7f\u6211\u4eec\u7684\u5de5\u4f5c\u66f4\u5177\u521b\u9020\u6027\u3002\u8fd9\u4e5f\u4e0e\u516c\u5e73\u6027\u6709\u5173\uff0c\u56e0\u4e3a\u5728\u5904\u7406\u4ee3\u8868\u6027\u4e0d\u8db3\u7684\u793e\u533a\u65f6\uff0c\u6211\u4eec\u6536\u96c6\u7684\u5927\u591a\u6570\u6570\u636e\u96c6\u53ef\u80fd\u4f1a\u6709\u504f\u89c1\uff0c\u6211\u4eec\u9700\u8981\u786e\u4fdd\u8fd9\u4e9b\u793e\u533a\u88ab\u5305\u62ec\u5728\u5185\u5e76\u5f97\u5230\u4eba\u5de5\u667a\u80fd\u7684\u6b63\u786e\u5904\u7406\u3002</li> <li>\u900f\u660e\u5ea6\u3002\u8fd9\u5305\u62ec\u786e\u4fdd\u6211\u4eec\u59cb\u7ec8\u660e\u786e\u5f3a\u8c03\u4eba\u5de5\u667a\u80fd\u7684\u4f7f\u7528\u3002\u6b64\u5916\uff0c\u5728\u53ef\u80fd\u7684\u60c5\u51b5\u4e0b\uff0c\u6211\u4eec\u5e0c\u671b\u4f7f\u7528\u53ef\u89e3\u91ca\u7684\u4eba\u5de5\u667a\u80fd\u7cfb\u7edf\u3002</li> <li>\u95ee\u8d23\u5236\u3002\u5f53\u4eba\u5de5\u667a\u80fd\u6a21\u578b\u505a\u51fa\u4e00\u4e9b\u51b3\u7b56\u65f6\uff0c\u5e76\u4e0d\u603b\u662f\u5f88\u6e05\u695a\u8c01\u5bf9\u8fd9\u4e9b\u51b3\u7b56\u8d1f\u8d23\u3002\u6211\u4eec\u9700\u8981\u786e\u4fdd\u6211\u4eec\u4e86\u89e3\u4eba\u5de5\u667a\u80fd\u51b3\u7b56\u7684\u8d23\u4efb\u6240\u5728\u3002\u5728\u5927\u591a\u6570\u60c5\u51b5\u4e0b\uff0c\u6211\u4eec\u5e0c\u671b\u5c06\u4eba\u7c7b\u7eb3\u5165\u505a\u51fa\u91cd\u8981\u51b3\u7b56\u7684\u73af\u8282\uff0c\u4ee5\u4fbf\u5b9e\u9645\u7684\u4eba\u5bf9\u8fd9\u4e9b\u51b3\u7b56\u8d1f\u8d23\u3002</li> </ul>"},{"location":"lessons/7-Ethics/README_chs/#_4","title":"\u8d1f\u8d23\u4efb\u7684\u4eba\u5de5\u667a\u80fd\u5de5\u5177","text":"<p>\u5fae\u8f6f\u5f00\u53d1\u4e86\u8d1f\u8d23\u4efb\u7684\u4eba\u5de5\u667a\u80fd\u5de5\u5177\u7bb1\uff0c\u5176\u4e2d\u5305\u542b\u4e00\u7ec4\u5de5\u5177\uff1a</p> <ul> <li>\u53ef\u89e3\u91ca\u6027\u4eea\u8868\u677f (InterpretML)</li> <li>\u516c\u5e73\u6027\u4eea\u8868\u677f (FairLearn)</li> <li>\u9519\u8bef\u5206\u6790\u4eea\u8868\u677f</li> <li> <p>\u8d1f\u8d23\u4efb\u7684\u4eba\u5de5\u667a\u80fd\u4eea\u8868\u677f\uff0c\u5305\u62ec</p> </li> <li> <p>EconML - \u56e0\u679c\u5206\u6790\u5de5\u5177\uff0c\u4fa7\u91cd\u4e8e\u5047\u8bbe\u6027\u95ee\u9898</p> </li> <li>DiCE - \u53cd\u4e8b\u5b9e\u5206\u6790\u5de5\u5177\uff0c\u5141\u8bb8\u4f60\u67e5\u770b\u9700\u8981\u66f4\u6539\u54ea\u4e9b\u7279\u5f81\u4ee5\u5f71\u54cd\u6a21\u578b\u7684\u51b3\u7b56</li> </ul> <p>\u5982\u9700\u4e86\u89e3\u66f4\u591a\u5173\u4e8e\u4eba\u5de5\u667a\u80fd\u4f26\u7406\u7684\u4fe1\u606f\uff0c\u8bf7\u8bbf\u95ee\u8fd9\u4e2a\u8bfe\u7a0b\u4e2d\u7684\u673a\u5668\u5b66\u4e60\u8bfe\u7a0b\uff0c\u5176\u4e2d\u5305\u62ec\u4f5c\u4e1a\u3002</p>"},{"location":"lessons/7-Ethics/README_chs/#_5","title":"\u590d\u4e60\u4e0e\u81ea\u5b66","text":"<p>\u8bf7\u5b66\u4e60\u6b64\u5b66\u4e60\u8def\u5f84\u4ee5\u4e86\u89e3\u66f4\u591a\u5173\u4e8e\u8d1f\u8d23\u4efb\u7684\u4eba\u5de5\u667a\u80fd\u7684\u4fe1\u606f\u3002</p>"},{"location":"lessons/7-Ethics/README_chs/#_6","title":"\u8bfe\u540e\u6d4b\u9a8c","text":""},{"location":"lessons/X-Extras/X1-MultiModal/","title":"Multi-Modal Networks","text":"<p>After the success of transformer models for solving NLP tasks, the same or similar architectures have been applied to computer vision tasks. There is a growing interest in building models that would combine vision and natural language capabilities. One of such attempts was done by OpenAI, and it is called CLIP and DALL.E.</p>"},{"location":"lessons/X-Extras/X1-MultiModal/#contrastive-image-pre-training-clip","title":"Contrastive Image Pre-Training (CLIP)","text":"<p>The main idea of CLIP is to be able to compare text prompts with an image and determine how well the image corresponds to the prompt.</p> <p></p> <p>Picture from this blog post</p> <p>The model is trained on images obtained from the Internet and their captions. For each batch, we take N pairs of (image, text), and convert them to some vector representations I<sub>1</sub>,..., I<sub>N</sub> / T<sub>1</sub>, ..., T<sub>N</sub>. Those representations are then matched together. The loss function is defined to maximize the cosine similarity between vectors corresponding to one pair (eg. I<sub>i</sub> and T<sub>i</sub>), and minimize cosine similarity between all other pairs. That is the reason this approach is called contrastive.</p> <p>CLIP model/library is available from OpenAI GitHub. The approach is described in this blog post, and in more detail in this paper.</p> <p>Once this model is pre-trained, we can give it a batch of images and a batch of text prompts, and it will return is the tensor with probabilities. CLIP can be used for several tasks:</p> <p>Image Classification</p> <p>Suppose we need to classify images between, say, cats, dogs and humans. In this case, we can give the model an image, and a series of text prompts: \"a picture of a cat\", \"a picture of a dog\", \"a picture of a human\". In the resulting vector of 3 probabilities we just need to select the index with a highest value.</p> <p></p> <p>Picture from this blog post</p> <p>Text-Based Image Search</p> <p>We can also do the opposite. If we have a collection of images, we can pass this collection to the model, and a text prompt - this will give us the image that is most similar to a given prompt.</p>"},{"location":"lessons/X-Extras/X1-MultiModal/#example-using-clip-for-image-classification-and-image-search","title":"\u270d\ufe0f Example: Using CLIP for Image Classification and Image Search","text":"<p>Open the Clip.ipynb notebook to see CLIP in action.</p>"},{"location":"lessons/X-Extras/X1-MultiModal/#image-generation-with-vqgan-clip","title":"Image Generation with VQGAN+ CLIP","text":"<p>CLIP can also be used for image generation from a text prompt. In order to do this, we need a generator model that will be able to generate images based on some vector input. One of such models is called VQGAN (Vector-Quantized GAN).</p> <p>The main ideas of VQGAN that differentiate it from ordinary GAN are the following: * Using autoregressive transformer architecture to generate a sequence of context-rich visual parts that compose the image. Those visual parts are in turn learned by CNN * Use sub-image discriminator that detects whether parts of the image are \"real\" of \"fake\" (unlike the \"all-or-nothing\" approach in traditional GAN).</p> <p>Learn more about VQGAN at the Taming Transformers web site.</p> <p>One of the important differences between VQGAN and traditional GAN is that the latter can produce a decent image from any input vector, while VQGAN is likely to produce an image that would not be coherent. Thus, we need to further guide the image creation process, and that can be done using CLIP. </p> <p></p> <p>To generate an image corresponding to a text prompt, we start with some random encoding vector that is passed through VQGAN to produce an image. Then CLIP is used to produce a loss function that shows how well the image corresponds to the text prompt. The goal then is to minimize this loss, using back propagation to adjust the input vector parameters.</p> <p>A great library that implements VQGAN+CLIP is Pixray</p> Picture generated from prompt a closeup watercolor portrait of young male teacher of literature with a book Picture generated from prompt a closeup oil portrait of young female teacher of computer science with a computer Picture generated from prompt a closeup oil portrait of old male teacher of mathematics in front of blackboard <p>Pictures from Artificial Teachers collection by Dmitry Soshnikov</p>"},{"location":"lessons/X-Extras/X1-MultiModal/#dall-e","title":"DALL-E","text":""},{"location":"lessons/X-Extras/X1-MultiModal/#dall-e-1","title":"DALL-E 1","text":"<p>DALL-E is a version of GPT-3 trained to generate images from prompts. It has been trained with 12-billion parameters.</p> <p>Unlike CLIP, DALL-E receives both text and image as a single stream of tokens for both images and text. Therefore, from multiple prompts, you can generate images based on the text.</p>"},{"location":"lessons/X-Extras/X1-MultiModal/#dall-e-2","title":"DALL-E 2","text":"<p>The main difference between DALL.E 1 and 2, is that it generates more realistic images and art. </p> <p>Examples of image genrations with DALL-E:  |   |  ----|----|---- Picture generated from prompt a closeup watercolor portrait of young male teacher of literature with a book | Picture generated from prompt a closeup oil portrait of young female teacher of computer science with a computer | Picture generated from prompt a closeup oil portrait of old male teacher of mathematics in front of blackboard</p>"},{"location":"lessons/X-Extras/X1-MultiModal/#references","title":"References","text":"<ul> <li>VQGAN Paper: Taming Transformers for High-Resolution Image Synthesis</li> <li>CLIP Paper: Learning Transferable Visual Models From Natural Language Supervision</li> </ul>"},{"location":"lessons/X-Extras/X1-MultiModal/README_chs/","title":"\u591a\u6a21\u6001\u7f51\u7edc","text":"<p>\u5728transformer\u6a21\u578b\u6210\u529f\u89e3\u51b3NLP\u4efb\u52a1\u4e4b\u540e\uff0c\u540c\u6837\u6216\u76f8\u4f3c\u7684\u67b6\u6784\u88ab\u5e94\u7528\u4e8e\u8ba1\u7b97\u673a\u89c6\u89c9\u4efb\u52a1\u3002\u73b0\u5728\u8d8a\u6765\u8d8a\u591a\u7684\u4eba\u5bf9\u6784\u5efa\u80fd\u591f\u7ed3\u5408\u89c6\u89c9\u548c\u81ea\u7136\u8bed\u8a00\u80fd\u529b\u7684\u6a21\u578b\u611f\u5174\u8da3\u3002OpenAI\u5bf9\u6b64\u505a\u4e86\u4e00\u4e9b\u5c1d\u8bd5\uff0c\u5176\u4e2d\u4e00\u4e2a\u88ab\u79f0\u4e3aCLIP\u548cDALL.E\u3002</p>"},{"location":"lessons/X-Extras/X1-MultiModal/README_chs/#clip","title":"\u5bf9\u6bd4\u56fe\u50cf\u9884\u8bad\u7ec3\uff08CLIP\uff09","text":"<p>CLIP\u7684\u4e3b\u8981\u601d\u60f3\u662f\u80fd\u591f\u6bd4\u8f83\u6587\u672c\u63d0\u793a\u548c\u56fe\u50cf\uff0c\u5e76\u786e\u5b9a\u56fe\u50cf\u4e0e\u63d0\u793a\u7684\u5bf9\u5e94\u7a0b\u5ea6\u3002</p> <p></p> <p>\u56fe\u7247\u6765\u81ea\u8fd9\u7bc7\u535a\u5ba2\u6587\u7ae0</p> <p>\u8be5\u6a21\u578b\u5728\u4ece\u4e92\u8054\u7f51\u4e0a\u83b7\u53d6\u7684\u56fe\u50cf\u53ca\u5176\u6807\u9898\u4e0a\u8fdb\u884c\u8bad\u7ec3\u3002\u5bf9\u4e8e\u6bcf\u4e2a\u6279\u6b21\uff0c\u6211\u4eec\u83b7\u53d6N\u5bf9\uff08\u56fe\u50cf\uff0c\u6587\u672c\uff09\uff0c\u5e76\u5c06\u5b83\u4eec\u8f6c\u6362\u4e3a\u4e00\u4e9b\u5411\u91cf\u8868\u793aI<sub>1</sub>,..., I<sub>N</sub> / T<sub>1</sub>, ..., T<sub>N</sub>\u3002\u7136\u540e\u5c06\u8fd9\u4e9b\u8868\u793a\u5339\u914d\u5728\u4e00\u8d77\u3002\u635f\u5931\u51fd\u6570\u88ab\u5b9a\u4e49\u4e3a\u6700\u5927\u5316\u5bf9\u5e94\u4e8e\u4e00\u5bf9\uff08\u4f8b\u5982I<sub>i</sub>\u548cT<sub>i</sub>\uff09\u7684\u5411\u91cf\u4e4b\u95f4\u7684\u4f59\u5f26\u76f8\u4f3c\u5ea6\uff0c\u5e76\u6700\u5c0f\u5316\u6240\u6709\u5176\u4ed6\u5bf9\u4e4b\u95f4\u7684\u4f59\u5f26\u76f8\u4f3c\u5ea6\u3002\u8fd9\u5c31\u662f\u8fd9\u79cd\u65b9\u6cd5\u88ab\u79f0\u4e3a\u5bf9\u6bd4\u7684\u539f\u56e0\u3002</p> <p>CLIP\u6a21\u578b/\u5e93\u53ef\u4ee5\u4eceOpenAI GitHub\u83b7\u53d6\u3002\u8be5\u65b9\u6cd5\u5728\u8fd9\u7bc7\u535a\u5ba2\u6587\u7ae0\u4e2d\u6709\u6240\u63cf\u8ff0\uff0c\u5e76\u5728\u8fd9\u7bc7\u8bba\u6587\u4e2d\u6709\u66f4\u8be6\u7ec6\u7684\u63cf\u8ff0\u3002</p> <p>\u4e00\u65e6\u8fd9\u4e2a\u6a21\u578b\u88ab\u9884\u8bad\u7ec3\u5b8c\u6210\uff0c\u6211\u4eec\u53ef\u4ee5\u7ed9\u5b83\u4e00\u4e2a\u56fe\u50cf\u6279\u6b21\u548c\u4e00\u4e2a\u6587\u672c\u63d0\u793a\u6279\u6b21\uff0c\u5b83\u5c06\u8fd4\u56de\u4e00\u4e2a\u5305\u542b\u6982\u7387\u7684\u5f20\u91cf\u3002CLIP\u53ef\u7528\u4e8e\u591a\u4e2a\u4efb\u52a1\uff1a</p> <p>\u56fe\u50cf\u5206\u7c7b</p> <p>\u5047\u8bbe\u6211\u4eec\u9700\u8981\u5728\u732b\u3001\u72d7\u548c\u4eba\u7c7b\u4e4b\u95f4\u5bf9\u56fe\u50cf\u8fdb\u884c\u5206\u7c7b\u3002\u5728\u8fd9\u79cd\u60c5\u51b5\u4e0b\uff0c\u6211\u4eec\u53ef\u4ee5\u7ed9\u6a21\u578b\u4e00\u4e2a\u56fe\u50cf\uff0c\u548c\u4e00\u7cfb\u5217\u7684\u6587\u672c\u63d0\u793a\uff1a\u201c\u4e00\u5f20\u732b\u7684\u7167\u7247\u201d\uff0c\u201c\u4e00\u5f20\u72d7\u7684\u7167\u7247\u201d\uff0c\u201c\u4e00\u5f20\u4eba\u7684\u7167\u7247\u201d\u3002\u5728\u7ed3\u679c\u76843\u4e2a\u6982\u7387\u5411\u91cf\u4e2d\uff0c\u6211\u4eec\u53ea\u9700\u9009\u62e9\u6570\u503c\u6700\u9ad8\u7684\u7d22\u5f15\u3002</p> <p></p> <p>\u56fe\u7247\u6765\u81ea\u8fd9\u7bc7\u535a\u5ba2\u6587\u7ae0</p> <p>\u57fa\u4e8e\u6587\u672c\u7684\u56fe\u50cf\u641c\u7d22</p> <p>\u6211\u4eec\u4e5f\u53ef\u4ee5\u505a\u76f8\u53cd\u7684\u64cd\u4f5c\u3002\u5982\u679c\u6211\u4eec\u6709\u4e00\u4e2a\u56fe\u50cf\u96c6\u5408\uff0c\u6211\u4eec\u53ef\u4ee5\u5c06\u8fd9\u4e2a\u96c6\u5408\u4f20\u9012\u7ed9\u6a21\u578b\uff0c\u518d\u52a0\u4e0a\u4e00\u4e2a\u6587\u672c\u63d0\u793a\u2014\u2014\u8fd9\u5c06\u7ed9\u6211\u4eec\u4e0e\u6240\u7ed9\u63d0\u793a\u6700\u76f8\u4f3c\u7684\u56fe\u50cf\u3002</p>"},{"location":"lessons/X-Extras/X1-MultiModal/README_chs/#clip_1","title":"\u270d\ufe0f \u793a\u4f8b\uff1a \u4f7f\u7528CLIP\u8fdb\u884c\u56fe\u50cf\u5206\u7c7b\u548c\u56fe\u50cf\u641c\u7d22","text":"<p>\u6253\u5f00Clip.ipynb\u7b14\u8bb0\u672c\uff0c\u770b\u770bCLIP\u7684\u5b9e\u9645\u5e94\u7528\u3002</p>"},{"location":"lessons/X-Extras/X1-MultiModal/README_chs/#vqgan-clip","title":"\u4f7f\u7528VQGAN + CLIP\u8fdb\u884c\u56fe\u50cf\u751f\u6210","text":"<p>CLIP\u8fd8\u53ef\u4ee5\u7528\u4e8e\u4ece\u6587\u672c\u63d0\u793a\u751f\u6210\u56fe\u50cf\u3002\u4e3a\u6b64\uff0c\u6211\u4eec\u9700\u8981\u4e00\u4e2a\u751f\u6210\u5668\u6a21\u578b\uff0c\u5b83\u80fd\u591f\u6839\u636e\u4e00\u4e9b\u5411\u91cf\u8f93\u5165\u751f\u6210\u56fe\u50cf\u3002\u8fd9\u6837\u7684\u6a21\u578b\u4e4b\u4e00\u79f0\u4e3aVQGAN\uff08\u77e2\u91cf\u91cf\u5316GAN\uff09\u3002</p> <p>VQGAN\u533a\u522b\u4e8e\u666e\u901aGAG\u7684\u4e3b\u8981\u601d\u60f3\u5982\u4e0b\uff1a * \u4f7f\u7528\u81ea\u56de\u5f52transformer\u67b6\u6784\u751f\u6210\u7ec4\u6210\u56fe\u50cf\u7684\u60c5\u5883\u4e30\u5bcc\u7684\u89c6\u89c9\u5e8f\u5217\u3002\u8fd9\u4e9b\u89c6\u89c9\u90e8\u5206\u7531CNN\u5b66\u4e60\u3002 * \u4f7f\u7528\u5b50\u56fe\u50cf\u5224\u522b\u5668\u68c0\u6d4b\u56fe\u50cf\u90e8\u5206\u662f\u201c\u771f\u5b9e\u201d\u8fd8\u662f\u201c\u4f2a\u9020\u201d\u7684\uff08\u4e0e\u4f20\u7edfGAN\u7684\u201c\u5168\u6216\u4e0d\u5168\u201d\u65b9\u6cd5\u4e0d\u540c\uff09\u3002</p> <p>\u901a\u8fc7\u8bbf\u95eeTaming Transformers\u7f51\u7ad9\u4e86\u89e3\u66f4\u591a\u5173\u4e8eVQGAN\u7684\u4fe1\u606f\u3002</p> <p>VQGAN\u4e0e\u4f20\u7edfGAN\u7684\u4e00\u4e2a\u91cd\u8981\u533a\u522b\u662f\uff0c\u540e\u8005\u53ef\u4ee5\u4ece\u4efb\u4f55\u8f93\u5165\u5411\u91cf\u751f\u6210\u4e00\u5f20\u4e0d\u9519\u7684\u56fe\u50cf\uff0c\u800cVQGAN\u5219\u53ef\u80fd\u751f\u6210\u4e0d\u8fde\u8d2f\u7684\u56fe\u50cf\u3002\u56e0\u6b64\uff0c\u6211\u4eec\u9700\u8981\u8fdb\u4e00\u6b65\u6307\u5bfc\u56fe\u50cf\u521b\u5efa\u8fc7\u7a0b\uff0c\u8fd9\u53ef\u4ee5\u901a\u8fc7CLIP\u6765\u5b8c\u6210\u3002</p> <p></p> <p>\u4e3a\u4e86\u751f\u6210\u4e0e\u6587\u672c\u63d0\u793a\u76f8\u5bf9\u5e94\u7684\u56fe\u50cf\uff0c\u6211\u4eec\u9996\u5148\u4ece\u4e00\u4e9b\u968f\u673a\u7f16\u7801\u5411\u91cf\u5f00\u59cb\uff0c\u7ecf\u8fc7VQGAN\u751f\u6210\u56fe\u50cf\u3002\u7136\u540e\u4f7f\u7528CLIP\u4ea7\u751f\u4e00\u4e2a\u635f\u5931\u51fd\u6570\uff0c\u663e\u793a\u56fe\u50cf\u4e0e\u6587\u672c\u63d0\u793a\u7684\u5bf9\u5e94\u7a0b\u5ea6\u3002\u7136\u540e\u7684\u76ee\u6807\u662f\u901a\u8fc7\u53cd\u5411\u4f20\u64ad\u8c03\u6574\u8f93\u5165\u5411\u91cf\u53c2\u6570\uff0c\u4ee5\u6700\u5c0f\u5316\u8be5\u635f\u5931\u3002</p> <p>\u4e00\u4e2a\u5b9e\u73b0VQGAN+CLIP\u7684\u6781\u4f73\u5e93\u662fPixray</p> \u6839\u636e\u63d0\u793a\u4e00\u5f20\u5e74\u8f7b\u7537\u8001\u5e08\u624b\u6301\u4e66\u672c\u7684\u8fd1\u8ddd\u79bb\u6c34\u5f69\u8096\u50cf\u751f\u6210\u7684\u56fe\u7247 \u6839\u636e\u63d0\u793a\u4e00\u5f20\u5e74\u8f7b\u5973\u8ba1\u7b97\u673a\u79d1\u5b66\u8001\u5e08\u624b\u65c1\u7535\u8111\u7684\u8fd1\u8ddd\u79bb\u6cb9\u753b\u8096\u50cf\u751f\u6210\u7684\u56fe\u7247 \u6839\u636e\u63d0\u793a\u4e00\u5f20\u8001\u5e74\u7537\u6570\u5b66\u8001\u5e08\u7ad9\u5728\u9ed1\u677f\u524d\u7684\u8fd1\u8ddd\u79bb\u6cb9\u753b\u8096\u50cf\u751f\u6210\u7684\u56fe\u7247 <p>\u56fe\u7247\u6765\u81eaDmitry Soshnikov\u7684\u4eba\u5de5\u6559\u5e08\u7cfb\u5217</p>"},{"location":"lessons/X-Extras/X1-MultiModal/README_chs/#dall-e","title":"DALL-E","text":""},{"location":"lessons/X-Extras/X1-MultiModal/README_chs/#dall-e-1","title":"DALL-E 1","text":"<p>DALL-E\u662f\u4e00\u4e2a\u7248\u672c\u7684GPT-3\uff0c\u7528\u4e8e\u4ece\u63d0\u793a\u4e2d\u751f\u6210\u56fe\u50cf\u3002\u5b83\u7ecf\u8fc7\u4e86\u5177\u6709120\u4ebf\u53c2\u6570\u7684\u8bad\u7ec3\u3002</p> <p>\u4e0d\u540c\u4e8eCLIP\uff0cDALL-E\u540c\u65f6\u63a5\u6536\u6587\u672c\u548c\u56fe\u50cf\u4f5c\u4e3a\u5355\u4e00\u7684\u4ee4\u724c\u6d41\u3002\u56e0\u6b64\uff0c\u5728\u591a\u4e2a\u63d0\u793a\u4e2d\uff0c\u4f60\u53ef\u4ee5\u6839\u636e\u6587\u672c\u751f\u6210\u56fe\u50cf\u3002</p>"},{"location":"lessons/X-Extras/X1-MultiModal/README_chs/#dall-e-2","title":"DALL-E 2","text":"<p>DALL.E 1\u548c2\u4e4b\u95f4\u7684\u4e3b\u8981\u533a\u522b\u662f\uff0cDALL-E 2\u751f\u6210\u7684\u56fe\u50cf\u548c\u827a\u672f\u4f5c\u54c1\u66f4\u52a0\u903c\u771f\u3002</p> <p>\u4f7f\u7528DALL-E\u751f\u6210\u7684\u56fe\u50cf\u793a\u4f8b\uff1a  |   |  ----|----|---- \u6839\u636e\u63d0\u793a\u4e00\u5f20\u5e74\u8f7b\u7537\u6587\u5b66\u8001\u5e08\u624b\u6301\u4e66\u672c\u7684\u8fd1\u8ddd\u79bb\u6c34\u5f69\u8096\u50cf\u751f\u6210\u7684\u56fe\u7247 | \u6839\u636e\u63d0\u793a\u4e00\u5f20\u5e74\u8f7b\u5973\u8ba1\u7b97\u673a\u79d1\u5b66\u8001\u5e08\u624b\u65c1\u7535\u8111\u7684\u8fd1\u8ddd\u79bb\u6cb9\u753b\u8096\u50cf\u751f\u6210\u7684\u56fe\u7247 | \u6839\u636e\u63d0\u793a\u4e00\u5f20\u8001\u5e74\u7537\u6570\u5b66\u8001\u5e08\u7ad9\u5728\u9ed1\u677f\u524d\u7684\u8fd1\u8ddd\u79bb\u6cb9\u753b\u8096\u50cf\u751f\u6210\u7684\u56fe\u7247</p>"},{"location":"lessons/X-Extras/X1-MultiModal/README_chs/#_2","title":"\u53c2\u8003\u6587\u732e","text":"<ul> <li>VQGAN\u8bba\u6587\uff1a\u7528\u4e8e\u9ad8\u5206\u8fa8\u7387\u56fe\u50cf\u5408\u6210\u7684\u9a6f\u5316transformer</li> <li>CLIP\u8bba\u6587\uff1a\u4ece\u81ea\u7136\u8bed\u8a00\u76d1\u7763\u4e2d\u5b66\u4e60\u53ef\u8f6c\u79fb\u7684\u89c6\u89c9\u6a21\u578b</li> </ul>"},{"location":"lessons/sketchnotes/","title":"Index","text":"<p>All the curriculum's sketchnotes can be downloaded here.</p> <p>\ud83c\udfa8 Created by: Tomomi Imura (Twitter: @girlie_mac, GitHub: girliemac)</p> <p></p>"},{"location":"lessons/sketchnotes/LICENSE/","title":"LICENSE","text":"<p>Attribution-ShareAlike 4.0 International</p> <p>=======================================================================</p> <p>Creative Commons Corporation (\"Creative Commons\") is not a law firm and does not provide legal services or legal advice. Distribution of Creative Commons public licenses does not create a lawyer-client or other relationship. Creative Commons makes its licenses and related information available on an \"as-is\" basis. Creative Commons gives no warranties regarding its licenses, any material licensed under their terms and conditions, or any related information. Creative Commons disclaims all liability for damages resulting from their use to the fullest extent possible.</p> <p>Using Creative Commons Public Licenses</p> <p>Creative Commons public licenses provide a standard set of terms and conditions that creators and other rights holders may use to share original works of authorship and other material subject to copyright and certain other rights specified in the public license below. The following considerations are for informational purposes only, are not exhaustive, and do not form part of our licenses.</p> <pre><code> Considerations for licensors: Our public licenses are\n intended for use by those authorized to give the public\n permission to use material in ways otherwise restricted by\n copyright and certain other rights. Our licenses are\n irrevocable. Licensors should read and understand the terms\n and conditions of the license they choose before applying it.\n Licensors should also secure all rights necessary before\n applying our licenses so that the public can reuse the\n material as expected. Licensors should clearly mark any\n material not subject to the license. This includes other CC-\n licensed material, or material used under an exception or\n limitation to copyright. More considerations for licensors:\nwiki.creativecommons.org/Considerations_for_licensors\n\n Considerations for the public: By using one of our public\n licenses, a licensor grants the public permission to use the\n licensed material under specified terms and conditions. If\n the licensor's permission is not necessary for any reason--for\n example, because of any applicable exception or limitation to\n copyright--then that use is not regulated by the license. Our\n licenses grant only permissions under copyright and certain\n other rights that a licensor has authority to grant. Use of\n the licensed material may still be restricted for other\n reasons, including because others have copyright or other\n rights in the material. A licensor may make special requests,\n such as asking that all changes be marked or described.\n Although not required by our licenses, you are encouraged to\n respect those requests where reasonable. More_considerations\n for the public:\nwiki.creativecommons.org/Considerations_for_licensees\n</code></pre> <p>=======================================================================</p> <p>Creative Commons Attribution-ShareAlike 4.0 International Public License</p> <p>By exercising the Licensed Rights (defined below), You accept and agree to be bound by the terms and conditions of this Creative Commons Attribution-ShareAlike 4.0 International Public License (\"Public License\"). To the extent this Public License may be interpreted as a contract, You are granted the Licensed Rights in consideration of Your acceptance of these terms and conditions, and the Licensor grants You such rights in consideration of benefits the Licensor receives from making the Licensed Material available under these terms and conditions.</p> <p>Section 1 -- Definitions.</p> <p>a. Adapted Material means material subject to Copyright and Similar      Rights that is derived from or based upon the Licensed Material      and in which the Licensed Material is translated, altered,      arranged, transformed, or otherwise modified in a manner requiring      permission under the Copyright and Similar Rights held by the      Licensor. For purposes of this Public License, where the Licensed      Material is a musical work, performance, or sound recording,      Adapted Material is always produced where the Licensed Material is      synched in timed relation with a moving image.</p> <p>b. Adapter's License means the license You apply to Your Copyright      and Similar Rights in Your contributions to Adapted Material in      accordance with the terms and conditions of this Public License.</p> <p>c. BY-SA Compatible License means a license listed at      creativecommons.org/compatiblelicenses, approved by Creative      Commons as essentially the equivalent of this Public License.</p> <p>d. Copyright and Similar Rights means copyright and/or similar rights      closely related to copyright including, without limitation,      performance, broadcast, sound recording, and Sui Generis Database      Rights, without regard to how the rights are labeled or      categorized. For purposes of this Public License, the rights      specified in Section 2(b)(1)-(2) are not Copyright and Similar      Rights.</p> <p>e. Effective Technological Measures means those measures that, in the      absence of proper authority, may not be circumvented under laws      fulfilling obligations under Article 11 of the WIPO Copyright      Treaty adopted on December 20, 1996, and/or similar international      agreements.</p> <p>f. Exceptions and Limitations means fair use, fair dealing, and/or      any other exception or limitation to Copyright and Similar Rights      that applies to Your use of the Licensed Material.</p> <p>g. License Elements means the license attributes listed in the name      of a Creative Commons Public License. The License Elements of this      Public License are Attribution and ShareAlike.</p> <p>h. Licensed Material means the artistic or literary work, database,      or other material to which the Licensor applied this Public      License.</p> <p>i. Licensed Rights means the rights granted to You subject to the      terms and conditions of this Public License, which are limited to      all Copyright and Similar Rights that apply to Your use of the      Licensed Material and that the Licensor has authority to license.</p> <p>j. Licensor means the individual(s) or entity(ies) granting rights      under this Public License.</p> <p>k. Share means to provide material to the public by any means or      process that requires permission under the Licensed Rights, such      as reproduction, public display, public performance, distribution,      dissemination, communication, or importation, and to make material      available to the public including in ways that members of the      public may access the material from a place and at a time      individually chosen by them.</p> <p>l. Sui Generis Database Rights means rights other than copyright      resulting from Directive 96/9/EC of the European Parliament and of      the Council of 11 March 1996 on the legal protection of databases,      as amended and/or succeeded, as well as other essentially      equivalent rights anywhere in the world.</p> <p>m. You means the individual or entity exercising the Licensed Rights      under this Public License. Your has a corresponding meaning.</p> <p>Section 2 -- Scope.</p> <p>a. License grant.</p> <pre><code>   1. Subject to the terms and conditions of this Public License,\n      the Licensor hereby grants You a worldwide, royalty-free,\n      non-sublicensable, non-exclusive, irrevocable license to\n      exercise the Licensed Rights in the Licensed Material to:\n\n        a. reproduce and Share the Licensed Material, in whole or\n           in part; and\n\n        b. produce, reproduce, and Share Adapted Material.\n\n   2. Exceptions and Limitations. For the avoidance of doubt, where\n      Exceptions and Limitations apply to Your use, this Public\n      License does not apply, and You do not need to comply with\n      its terms and conditions.\n\n   3. Term. The term of this Public License is specified in Section\n      6(a).\n\n   4. Media and formats; technical modifications allowed. The\n      Licensor authorizes You to exercise the Licensed Rights in\n      all media and formats whether now known or hereafter created,\n      and to make technical modifications necessary to do so. The\n      Licensor waives and/or agrees not to assert any right or\n      authority to forbid You from making technical modifications\n      necessary to exercise the Licensed Rights, including\n      technical modifications necessary to circumvent Effective\n      Technological Measures. For purposes of this Public License,\n      simply making modifications authorized by this Section 2(a)\n      (4) never produces Adapted Material.\n\n   5. Downstream recipients.\n\n        a. Offer from the Licensor -- Licensed Material. Every\n           recipient of the Licensed Material automatically\n           receives an offer from the Licensor to exercise the\n           Licensed Rights under the terms and conditions of this\n           Public License.\n\n        b. Additional offer from the Licensor -- Adapted Material.\n           Every recipient of Adapted Material from You\n           automatically receives an offer from the Licensor to\n           exercise the Licensed Rights in the Adapted Material\n           under the conditions of the Adapter's License You apply.\n\n        c. No downstream restrictions. You may not offer or impose\n           any additional or different terms or conditions on, or\n           apply any Effective Technological Measures to, the\n           Licensed Material if doing so restricts exercise of the\n           Licensed Rights by any recipient of the Licensed\n           Material.\n\n   6. No endorsement. Nothing in this Public License constitutes or\n      may be construed as permission to assert or imply that You\n      are, or that Your use of the Licensed Material is, connected\n      with, or sponsored, endorsed, or granted official status by,\n      the Licensor or others designated to receive attribution as\n      provided in Section 3(a)(1)(A)(i).\n</code></pre> <p>b. Other rights.</p> <pre><code>   1. Moral rights, such as the right of integrity, are not\n      licensed under this Public License, nor are publicity,\n      privacy, and/or other similar personality rights; however, to\n      the extent possible, the Licensor waives and/or agrees not to\n      assert any such rights held by the Licensor to the limited\n      extent necessary to allow You to exercise the Licensed\n      Rights, but not otherwise.\n\n   2. Patent and trademark rights are not licensed under this\n      Public License.\n\n   3. To the extent possible, the Licensor waives any right to\n      collect royalties from You for the exercise of the Licensed\n      Rights, whether directly or through a collecting society\n      under any voluntary or waivable statutory or compulsory\n      licensing scheme. In all other cases the Licensor expressly\n      reserves any right to collect such royalties.\n</code></pre> <p>Section 3 -- License Conditions.</p> <p>Your exercise of the Licensed Rights is expressly made subject to the following conditions.</p> <p>a. Attribution.</p> <pre><code>   1. If You Share the Licensed Material (including in modified\n      form), You must:\n\n        a. retain the following if it is supplied by the Licensor\n           with the Licensed Material:\n\n             i. identification of the creator(s) of the Licensed\n                Material and any others designated to receive\n                attribution, in any reasonable manner requested by\n                the Licensor (including by pseudonym if\n                designated);\n\n            ii. a copyright notice;\n\n           iii. a notice that refers to this Public License;\n\n            iv. a notice that refers to the disclaimer of\n                warranties;\n\n             v. a URI or hyperlink to the Licensed Material to the\n                extent reasonably practicable;\n\n        b. indicate if You modified the Licensed Material and\n           retain an indication of any previous modifications; and\n\n        c. indicate the Licensed Material is licensed under this\n           Public License, and include the text of, or the URI or\n           hyperlink to, this Public License.\n\n   2. You may satisfy the conditions in Section 3(a)(1) in any\n      reasonable manner based on the medium, means, and context in\n      which You Share the Licensed Material. For example, it may be\n      reasonable to satisfy the conditions by providing a URI or\n      hyperlink to a resource that includes the required\n      information.\n\n   3. If requested by the Licensor, You must remove any of the\n      information required by Section 3(a)(1)(A) to the extent\n      reasonably practicable.\n</code></pre> <p>b. ShareAlike.</p> <pre><code> In addition to the conditions in Section 3(a), if You Share\n Adapted Material You produce, the following conditions also apply.\n\n   1. The Adapter's License You apply must be a Creative Commons\n      license with the same License Elements, this version or\n      later, or a BY-SA Compatible License.\n\n   2. You must include the text of, or the URI or hyperlink to, the\n      Adapter's License You apply. You may satisfy this condition\n      in any reasonable manner based on the medium, means, and\n      context in which You Share Adapted Material.\n\n   3. You may not offer or impose any additional or different terms\n      or conditions on, or apply any Effective Technological\n      Measures to, Adapted Material that restrict exercise of the\n      rights granted under the Adapter's License You apply.\n</code></pre> <p>Section 4 -- Sui Generis Database Rights.</p> <p>Where the Licensed Rights include Sui Generis Database Rights that apply to Your use of the Licensed Material:</p> <p>a. for the avoidance of doubt, Section 2(a)(1) grants You the right      to extract, reuse, reproduce, and Share all or a substantial      portion of the contents of the database;</p> <p>b. if You include all or a substantial portion of the database      contents in a database in which You have Sui Generis Database      Rights, then the database in which You have Sui Generis Database      Rights (but not its individual contents) is Adapted Material,</p> <pre><code> including for purposes of Section 3(b); and\n</code></pre> <p>c. You must comply with the conditions in Section 3(a) if You Share      all or a substantial portion of the contents of the database.</p> <p>For the avoidance of doubt, this Section 4 supplements and does not replace Your obligations under this Public License where the Licensed Rights include other Copyright and Similar Rights.</p> <p>Section 5 -- Disclaimer of Warranties and Limitation of Liability.</p> <p>a. UNLESS OTHERWISE SEPARATELY UNDERTAKEN BY THE LICENSOR, TO THE      EXTENT POSSIBLE, THE LICENSOR OFFERS THE LICENSED MATERIAL AS-IS      AND AS-AVAILABLE, AND MAKES NO REPRESENTATIONS OR WARRANTIES OF      ANY KIND CONCERNING THE LICENSED MATERIAL, WHETHER EXPRESS,      IMPLIED, STATUTORY, OR OTHER. THIS INCLUDES, WITHOUT LIMITATION,      WARRANTIES OF TITLE, MERCHANTABILITY, FITNESS FOR A PARTICULAR      PURPOSE, NON-INFRINGEMENT, ABSENCE OF LATENT OR OTHER DEFECTS,      ACCURACY, OR THE PRESENCE OR ABSENCE OF ERRORS, WHETHER OR NOT      KNOWN OR DISCOVERABLE. WHERE DISCLAIMERS OF WARRANTIES ARE NOT      ALLOWED IN FULL OR IN PART, THIS DISCLAIMER MAY NOT APPLY TO YOU.</p> <p>b. TO THE EXTENT POSSIBLE, IN NO EVENT WILL THE LICENSOR BE LIABLE      TO YOU ON ANY LEGAL THEORY (INCLUDING, WITHOUT LIMITATION,      NEGLIGENCE) OR OTHERWISE FOR ANY DIRECT, SPECIAL, INDIRECT,      INCIDENTAL, CONSEQUENTIAL, PUNITIVE, EXEMPLARY, OR OTHER LOSSES,      COSTS, EXPENSES, OR DAMAGES ARISING OUT OF THIS PUBLIC LICENSE OR      USE OF THE LICENSED MATERIAL, EVEN IF THE LICENSOR HAS BEEN      ADVISED OF THE POSSIBILITY OF SUCH LOSSES, COSTS, EXPENSES, OR      DAMAGES. WHERE A LIMITATION OF LIABILITY IS NOT ALLOWED IN FULL OR      IN PART, THIS LIMITATION MAY NOT APPLY TO YOU.</p> <p>c. The disclaimer of warranties and limitation of liability provided      above shall be interpreted in a manner that, to the extent      possible, most closely approximates an absolute disclaimer and      waiver of all liability.</p> <p>Section 6 -- Term and Termination.</p> <p>a. This Public License applies for the term of the Copyright and      Similar Rights licensed here. However, if You fail to comply with      this Public License, then Your rights under this Public License      terminate automatically.</p> <p>b. Where Your right to use the Licensed Material has terminated under      Section 6(a), it reinstates:</p> <pre><code>   1. automatically as of the date the violation is cured, provided\n      it is cured within 30 days of Your discovery of the\n      violation; or\n\n   2. upon express reinstatement by the Licensor.\n\n For the avoidance of doubt, this Section 6(b) does not affect any\n right the Licensor may have to seek remedies for Your violations\n of this Public License.\n</code></pre> <p>c. For the avoidance of doubt, the Licensor may also offer the      Licensed Material under separate terms or conditions or stop      distributing the Licensed Material at any time; however, doing so      will not terminate this Public License.</p> <p>d. Sections 1, 5, 6, 7, and 8 survive termination of this Public      License.</p> <p>Section 7 -- Other Terms and Conditions.</p> <p>a. The Licensor shall not be bound by any additional or different      terms or conditions communicated by You unless expressly agreed.</p> <p>b. Any arrangements, understandings, or agreements regarding the      Licensed Material not stated herein are separate from and      independent of the terms and conditions of this Public License.</p> <p>Section 8 -- Interpretation.</p> <p>a. For the avoidance of doubt, this Public License does not, and      shall not be interpreted to, reduce, limit, restrict, or impose      conditions on any use of the Licensed Material that could lawfully      be made without permission under this Public License.</p> <p>b. To the extent possible, if any provision of this Public License is      deemed unenforceable, it shall be automatically reformed to the      minimum extent necessary to make it enforceable. If the provision      cannot be reformed, it shall be severed from this Public License      without affecting the enforceability of the remaining terms and      conditions.</p> <p>c. No term or condition of this Public License will be waived and no      failure to comply consented to unless expressly agreed to by the      Licensor.</p> <p>d. Nothing in this Public License constitutes or may be interpreted      as a limitation upon, or waiver of, any privileges and immunities      that apply to the Licensor or You, including from the legal      processes of any jurisdiction or authority.</p> <p>=======================================================================</p> <p>Creative Commons is not a party to its public licenses. Notwithstanding, Creative Commons may elect to apply one of its public licenses to material it publishes and in those instances will be considered the \u201cLicensor.\u201d The text of the Creative Commons public licenses is dedicated to the public domain under the CC0 Public Domain Dedication. Except for the limited purpose of indicating that material is shared under a Creative Commons public license or as otherwise permitted by the Creative Commons policies published at creativecommons.org/policies, Creative Commons does not authorize the use of the trademark \"Creative Commons\" or any other trademark or logo of Creative Commons without its prior written consent including, without limitation, in connection with any unauthorized modifications to any of its public licenses or any other arrangements, understandings, or agreements concerning use of licensed material. For the avoidance of doubt, this paragraph does not form part of the public licenses.</p> <p>Creative Commons may be contacted at creativecommons.org.</p>"},{"location":"lessons/sketchnotes/LICENSE_chs/","title":"LICENSE chs","text":"<p>Attribution-ShareAlike 4.0 International</p> <p>=======================================================================</p> <p>\u521b\u4f5c\u5171\u7528\u516c\u53f8 (\"Creative Commons\") \u4e0d\u662f\u5f8b\u5e08\u4e8b\u52a1\u6240\uff0c \u4e0d\u63d0\u4f9b\u6cd5\u5f8b\u670d\u52a1\u6216\u6cd5\u5f8b\u5efa\u8bae\u3002\u53d1\u884c\u521b\u4f5c\u5171\u7528\u516c\u5171\u8bb8\u53ef\u8bc1\u4e0d\u6784\u6210\u5f8b\u5e08\u5ba2\u6237\u6216\u5176\u4ed6\u5173\u7cfb\u3002\u521b\u4f5c\u5171\u7528\u4ee5\"\u6309\u539f\u6837\"\u7684\u57fa\u7840\u63d0\u4f9b\u5176\u8bb8\u53ef\u8bc1\u548c\u76f8\u5173\u4fe1\u606f\u3002\u521b\u4f5c\u5171\u7528\u4e0d\u5bf9\u5176\u8bb8\u53ef\u8bc1\uff0c\u4efb\u4f55\u4f9d\u636e\u5176\u6761\u6b3e\u548c\u6761\u4ef6\u8bb8\u53ef\u7684\u6750\u6599\u6216\u4efb\u4f55\u76f8\u5173\u4fe1\u606f\u4f5c\u51fa\u4fdd\u8bc1\u3002\u521b\u4f5c\u5171\u7528\u5bf9\u56e0\u5176\u4f7f\u7528\u800c\u5bfc\u81f4\u7684\u635f\u5bb3\u4e0d\u627f\u62c5\u4efb\u4f55\u8d23\u4efb\uff0c\u4e14\u5728\u6cd5\u5f8b\u5141\u8bb8\u7684\u8303\u56f4\u5185\uff0c\u5c3d\u6700\u5927\u53ef\u80fd\u514d\u9664\u8d23\u4efb\u3002</p> <p>\u4f7f\u7528\u521b\u4f5c\u5171\u7528\u516c\u5171\u8bb8\u53ef\u8bc1</p> <p>\u521b\u4f5c\u5171\u7528\u516c\u5171\u8bb8\u53ef\u8bc1\u63d0\u4f9b\u4e86\u4e00\u5957\u6807\u51c6\u6761\u6b3e\u548c\u6761\u4ef6\uff0c\u521b\u4f5c\u8005\u53ca\u5176\u4ed6\u6743\u5229\u4eba\u53ef\u4ee5\u7528\u6765\u5206\u4eab\u53d7\u7248\u6743\u53ca\u4ee5\u4e0b\u516c\u5171\u8bb8\u53ef\u8bc1\u4e2d\u89c4\u5b9a\u7684\u67d0\u4e9b\u5176\u4ed6\u6743\u5229\u7ea6\u675f\u7684\u539f\u521b\u4f5c\u54c1\u53ca\u5176\u4ed6\u6750\u6599\u3002\u4ee5\u4e0b\u5185\u5bb9\u4ec5\u4f9b\u4fe1\u606f\u53c2\u8003\uff0c\u4e0d\u662f\u8be6\u5c3d\u7684\uff0c\u4e5f\u4e0d\u6784\u6210\u6211\u4eec\u7684\u8bb8\u53ef\u8bc1\u7684\u4e00\u90e8\u5206\u3002</p> <pre><code> \u7ed9\u6388\u6743\u8005\u7684\u6ce8\u610f\u4e8b\u9879\uff1a\u6211\u4eec\u7684\u516c\u5171\u8bb8\u53ef\u8bc1\u65e8\u5728\u4f9b\u90a3\u4e9b\u6709\u6743\u5411\u516c\u4f17\u8bb8\u53ef\u5728\u7248\u6743\u53ca\u67d0\u4e9b\u5176\u4ed6\u6743\u5229\u9650\u5236\u4e0b\u4f7f\u7528\u6750\u6599\u7684\u4eba\u4f7f\u7528\u3002\u6211\u4eec\u7684\u8bb8\u53ef\u8bc1\u662f\u4e0d\u53ef\u64a4\u9500\u7684\u3002\u6388\u6743\u8005\u5728\u5e94\u7528\u8bb8\u53ef\u8bc1\u524d\u5e94\u9605\u8bfb\u5e76\u7406\u89e3\u4ed6\u4eec\u9009\u62e9\u7684\u8bb8\u53ef\u8bc1\u7684\u6761\u6b3e\u548c\u6761\u4ef6\u3002\u6388\u6743\u8005\u8fd8\u5e94\u8be5\u5728\u5e94\u7528\u6211\u4eec\u7684\u8bb8\u53ef\u8bc1\u4e4b\u524d\u786e\u4fdd\u62e5\u6709\u6240\u6709\u5fc5\u8981\u7684\u6743\u5229\uff0c\u4ee5\u4fbf\u516c\u4f17\u53ef\u4ee5\u5982\u9884\u671f\u5730\u91cd\u7528\u6750\u6599\u3002\u6388\u6743\u8005\u5e94\u6e05\u6670\u6807\u6ce8\u4efb\u4f55\u4e0d\u53d7\u8bb8\u53ef\u8bc1\u9650\u5236\u7684\u6750\u6599\u3002\u8fd9\u5305\u62ec\u5176\u4ed6CC\u8bb8\u53ef\u7684\u6750\u6599\uff0c\u6216\u5728\u7248\u6743\u4f8b\u5916\u6216\u9650\u5236\u4e0b\u4f7f\u7528\u7684\u6750\u6599\u3002\u66f4\u591a\u7684\u6388\u6743\u8005\u6ce8\u610f\u4e8b\u9879\uff1awiki.creativecommons.org/Considerations_for_licensors\n\n \u7ed9\u516c\u4f17\u7684\u6ce8\u610f\u4e8b\u9879\uff1a\u901a\u8fc7\u4f7f\u7528\u6211\u4eec\u7684\u516c\u5171\u8bb8\u53ef\u8bc1\uff0c\u8bb8\u53ef\u8005\u6388\u4e88\u516c\u4f17\u5728\u7279\u5b9a\u6761\u6b3e\u548c\u6761\u4ef6\u4e0b\u4f7f\u7528\u88ab\u8bb8\u53ef\u6750\u6599\u7684\u6743\u9650\u3002\u5982\u679c\u7531\u4e8e\u4efb\u4f55\u539f\u56e0\u4e0d\u9700\u8981\u8bb8\u53ef\u8005\u7684\u8bb8\u53ef\uff0c\u4f8b\u5982\u7531\u4e8e\u4efb\u4f55\u9002\u7528\u7684\u7248\u6743\u4f8b\u5916\u6216\u9650\u5236\uff0c\u90a3\u4e48\u8fd9\u79cd\u4f7f\u7528\u4e0d\u53d7\u8bb8\u53ef\u8bc1\u7684\u7ea6\u675f\u3002\u6211\u4eec\u7684\u8bb8\u53ef\u8bc1\u4ec5\u6388\u4e88\u7248\u6743\u548c\u8bb8\u53ef\u8005\u6709\u6743\u6388\u4e88\u7684\u67d0\u4e9b\u5176\u4ed6\u6743\u5229\u4e0b\u7684\u6743\u9650\u3002\u6750\u6599\u7684\u4f7f\u7528\u53ef\u80fd\u4ecd\u53d7\u5230\u5176\u4ed6\u539f\u56e0\u7684\u9650\u5236\uff0c\u5305\u62ec\u5176\u4ed6\u4eba\u5bf9\u6750\u6599\u6301\u6709\u7684\u7248\u6743\u6216\u5176\u4ed6\u6743\u5229\u3002\u8bb8\u53ef\u8005\u53ef\u80fd\u63d0\u51fa\u7279\u522b\u8981\u6c42\uff0c\u4f8b\u5982\u8981\u6c42\u6807\u660e\u6216\u63cf\u8ff0\u6240\u6709\u66f4\u6539\u3002\u867d\u7136\u6211\u4eec\u7684\u8bb8\u53ef\u8bc1\u4e0d\u8981\u6c42\u8fd9\u6837\u505a\uff0c\u4f46\u6211\u4eec\u9f13\u52b1\u5728\u5408\u7406\u8303\u56f4\u5185\u5c0a\u91cd\u8fd9\u4e9b\u8981\u6c42\u3002\u66f4\u591a\u516c\u4f17\u6ce8\u610f\u4e8b\u9879\uff1awiki.creativecommons.org/Considerations_for_licensees\n</code></pre> <p>=======================================================================</p> <p>\u521b\u4f5c\u5171\u7528\u7f72\u540d-\u76f8\u540c\u65b9\u5f0f\u5171\u4eab 4.0 \u56fd\u9645\u516c\u5171\u8bb8\u53ef\u8bc1</p> <p>\u901a\u8fc7\u884c\u4f7f\u88ab\u8bb8\u53ef\u6743\u5229\uff08\u4e0b\u6587\u5b9a\u4e49\uff09\uff0c\u60a8\u63a5\u53d7\u5e76\u540c\u610f\u53d7\u672c\u521b\u4f5c\u5171\u7528\u7f72\u540d-\u76f8\u540c\u65b9\u5f0f\u5171\u4eab 4.0 \u56fd\u9645\u516c\u5171\u8bb8\u53ef\u8bc1\uff08\u201c\u516c\u5171\u8bb8\u53ef\u8bc1\u201d\uff09\u7684\u6761\u6b3e\u548c\u6761\u4ef6\u7ea6\u675f\u3002\u5982\u679c\u6b64\u516c\u5171\u8bb8\u53ef\u8bc1\u53ef\u88ab\u89e3\u91ca\u4e3a\u5408\u540c\uff0c\u60a8\u56e0\u63a5\u53d7\u8fd9\u4e9b\u6761\u6b3e\u548c\u6761\u4ef6\u800c\u83b7\u6388\u88ab\u8bb8\u53ef\u6743\u5229\uff0c\u8bb8\u53ef\u8005\u56e0\u60a8\u6839\u636e\u8fd9\u4e9b\u6761\u6b3e\u548c\u6761\u4ef6\u4f7f\u88ab\u8bb8\u53ef\u6750\u6599\u53ef\u7528\u800c\u83b7\u5f97\u5229\u76ca\uff0c\u5e76\u56e0\u6b64\u5411\u60a8\u6388\u4e88\u6743\u5229\u3002</p> <p>\u7b2c 1 \u8282 -- \u5b9a\u4e49\u3002</p> <p>a. \u6539\u7f16\u6750\u6599\u6307\u4f9d\u636e\u7248\u6743\u53ca\u7c7b\u4f3c\u6743\u5229\u5bf9\u88ab\u8bb8\u53ef\u6750\u6599\u8fdb\u884c\u7ffb\u8bd1\u3001\u6539\u53d8\u3001\u7f16\u6392\u3001\u8f6c\u5316\u6216\u4ee5\u5176\u4ed6\u65b9\u5f0f\u4fee\u6539\u800c\u4ea7\u751f\u7684\u6750\u6599\u3002\u82e5\u88ab\u8bb8\u53ef\u6750\u6599\u662f\u4e00\u90e8\u97f3\u4e50\u4f5c\u54c1\u3001\u8868\u6f14\u6216\u5f55\u97f3\uff0c\u6539\u7f16\u6750\u6599\u5fc5\u5305\u62ec\u4ee5\u4e0e\u8fd0\u52a8\u56fe\u50cf\u540c\u6b65\u7684\u65b9\u5f0f\u4f7f\u7528\u88ab\u8bb8\u53ef\u6750\u6599\u3002</p> <p>b. \u6539\u7f16\u8bb8\u53ef\u8bc1\u6307\u60a8\u6839\u636e\u672c\u516c\u5171\u8bb8\u53ef\u8bc1\u7684\u6761\u6b3e\u548c\u6761\u4ef6\u5bf9\u60a8\u5728\u6539\u7f16\u6750\u6599\u4e2d\u7684\u8d21\u732e\u7533\u8bf7\u7684\u53d7\u7248\u6743\u548c\u7c7b\u4f3c\u6743\u5229\u7ea6\u675f\u7684\u8bb8\u53ef\u8bc1\u3002</p> <p>c. \u517c\u5bb9BY-SA \u8bb8\u53ef\u8bc1\u6307\u5728 creativecommons.org/compatiblelicenses \u4e0a\u5217\u51fa\u7684\u8bb8\u53ef\u8bc1\uff0c\u8be5\u8bb8\u53ef\u8bc1\u88ab\u521b\u4f5c\u5171\u7528\u6279\u51c6\u4e3a\u672c\u516c\u5171\u8bb8\u53ef\u8bc1\u7684\u57fa\u672c\u7b49\u540c\u7269\u3002</p> <p>d. \u7248\u6743\u53ca\u7c7b\u4f3c\u6743\u5229\u6307\u5305\u62ec\u4f46\u4e0d\u9650\u4e8e\u8868\u6f14\u6743\u3001\u5e7f\u64ad\u6743\u3001\u5f55\u97f3\u6743\u548c\u72ec\u521b\u6570\u636e\u5e93\u6743\u5728\u5185\u7684\u7248\u6743\u548c/\u6216\u4e0e\u7248\u6743\u5bc6\u5207\u76f8\u5173\u7684\u7c7b\u4f3c\u6743\u5229\uff0c\u4e0d\u8bba\u8fd9\u4e9b\u6743\u5229\u662f\u5982\u4f55\u6807\u8bb0\u6216\u5206\u7c7b\u7684\u3002\u5bf9\u4e8e\u672c\u516c\u5171\u8bb8\u53ef\u8bc1\u7684\u76ee\u7684\uff0c\u7b2c 2(b)(1)-(2) \u8282\u4e2d\u6307\u5b9a\u7684\u6743\u5229\u4e0d\u5c5e\u4e8e\u7248\u6743\u53ca\u7c7b\u4f3c\u6743\u5229\u3002</p> <p>e. \u6709\u6548\u6280\u672f\u63aa\u65bd\u6307\u5728\u6ca1\u6709\u9002\u5f53\u6743\u9650\u7684\u60c5\u51b5\u4e0b\uff0c\u6839\u636e1996\u5e7412\u670820\u65e5\u901a\u8fc7\u7684WIPO\u7248\u6743\u6761\u7ea6\u7b2c11\u6761\u4ee5\u53ca/\u6216\u7c7b\u4f3c\u56fd\u9645\u534f\u8bae\u89c4\u5b9a\u7684\u6cd5\u5f8b\u4e0d\u5f97\u89c4\u907f\u7684\u63aa\u65bd\u3002</p> <p>f. \u4f8b\u5916\u548c\u9650\u5236\u6307\u9002\u7528\u4e8e\u60a8\u5bf9\u88ab\u8bb8\u53ef\u6750\u6599\u4f7f\u7528\u7684\u5408\u7406\u4f7f\u7528\u3001\u5408\u7406\u4ea4\u6613\u548c/\u6216\u4efb\u4f55\u5176\u4ed6\u7248\u6743\u53ca\u7c7b\u4f3c\u6743\u5229\u7684\u4f8b\u5916\u6216\u9650\u5236\u3002</p> <p>g. \u8bb8\u53ef\u8bc1\u8981\u7d20\u6307\u521b\u4f5c\u5171\u7528\u516c\u5171\u8bb8\u53ef\u8bc1\u540d\u4e2d\u7684\u8bb8\u53ef\u8bc1\u5c5e\u6027\u3002\u8be5\u516c\u5171\u8bb8\u53ef\u8bc1\u7684\u8bb8\u53ef\u8bc1\u8981\u7d20\u4e3a\u7f72\u540d\u548c\u76f8\u540c\u65b9\u5f0f\u5171\u4eab\u3002</p> <p>h. \u88ab\u8bb8\u53ef\u6750\u6599\u6307\u88ab\u8bb8\u53ef\u8005\u5e94\u7528\u6b64\u516c\u5171\u8bb8\u53ef\u8bc1\u7684\u827a\u672f\u6216\u6587\u5b66\u4f5c\u54c1\uff0c\u6570\u636e\u5e93\u6216\u5176\u4ed6\u6750\u6599\u3002</p> <p>i. \u88ab\u8bb8\u53ef\u6743\u5229\u6307\u5728\u672c\u516c\u5171\u8bb8\u53ef\u8bc1\u6761\u6b3e\u548c\u6761\u4ef6\u9650\u5236\u4e0b\uff0c\u9002\u7528\u4e8e\u60a8\u5bf9\u88ab\u8bb8\u53ef\u6750\u6599\u4f7f\u7528\u3001\u4e14\u88ab\u8bb8\u53ef\u8005\u6709\u6743\u8bb8\u53ef\u7684\u6240\u6709\u7248\u6743\u53ca\u7c7b\u4f3c\u6743\u5229\u3002</p> <p>j. \u88ab\u8bb8\u53ef\u8005\u6307\u5728\u672c\u516c\u5171\u8bb8\u53ef\u8bc1\u4e0b\u6388\u4e88\u6743\u5229\u7684\u4e2a\u4eba\u6216\u5b9e\u4f53\u3002</p> <p>k. \u5171\u4eab\u6307\u4ee5\u4efb\u4f55\u9700\u8981\u88ab\u8bb8\u53ef\u6743\u5229\u8bb8\u53ef\u7684\u65b9\u5f0f\u6216\u8fc7\u7a0b\u5411\u516c\u4f17\u63d0\u4f9b\u6750\u6599\uff0c\u4f8b\u5982\u590d\u5236\u3001\u516c\u5f00\u5c55\u793a\u3001\u516c\u5f00\u8868\u6f14\u3001\u5206\u53d1\u3001\u4f20\u64ad\u3001\u4ea4\u6d41\u6216\u8fdb\u53e3\uff0c\u4ee5\u53ca\u4f7f\u516c\u4f17\u53ef\u4ee5\u8bbf\u95ee\u6750\u6599\uff0c\u5305\u62ec\u516c\u4f17\u53ef\u4ee5\u5355\u72ec\u9009\u62e9\u7684\u65f6\u95f4\u548c\u5730\u70b9\u8bbf\u95ee\u6750\u6599\u3002</p> <p>l. \u72ec\u521b\u6570\u636e\u5e93\u6743\u6307\u9664\u7248\u6743\u4ee5\u5916\u7684\u6743\u5229\uff0c\u8fd9\u4e9b\u6743\u5229\u6765\u81ea1996\u5e743\u670811\u65e5\u6b27\u6d32\u8bae\u4f1a\u548c\u7406\u4e8b\u4f1a\u901a\u8fc7\u7684\u201c\u6570\u636e\u5e93\u6cd5\u5f8b\u4fdd\u62a4\u6307\u4ee496/9/EC\u201d\uff0c\u4ee5\u53ca\u5176\u4ed6\u5728\u4e16\u754c\u8303\u56f4\u5185\u57fa\u672c\u7b49\u540c\u7684\u6743\u5229\u3002</p> <p>m. \u60a8\u6307\u884c\u4f7f\u88ab\u8bb8\u53ef\u6743\u5229\u7684\u4e2a\u4eba\u6216\u5b9e\u4f53\u3002\u60a8\u7684\u5bf9\u5e94\u542b\u4e49\u3002</p> <p>\u7b2c 2 \u8282 -- \u8303\u56f4\u3002</p> <p>a. \u8bb8\u53ef\u8bc1\u6388\u4e88\u3002</p> <pre><code>   1. \u6839\u636e\u672c\u516c\u5171\u8bb8\u53ef\u8bc1\u7684\u6761\u6b3e\u548c\u6761\u4ef6\uff0c\u8bb8\u53ef\u8005\u5728\u6b64\u6388\u4e88\u60a8\u4e00\u9879\u5168\u7403\u6027\u7684\u3001\u514d\u7248\u7a0e\u7684\u3001\u4e0d\u53ef\u8f6c\u6388\u6743\u7684\u3001\u975e\u72ec\u5360\u7684\u3001\u4e0d\u53ef\u64a4\u9500\u7684\u8bb8\u53ef\u8bc1\uff0c\u4ee5\u884c\u4f7f\u4ee5\u4e0b\u5bf9\u88ab\u8bb8\u53ef\u6750\u6599\u7684\u88ab\u8bb8\u53ef\u6743\u5229\uff1a\n\n        a. \u590d\u5236\u548c\u5171\u4eab\u88ab\u8bb8\u53ef\u6750\u6599\uff0c\u5168\u90e8\u6216\u90e8\u5206\uff1b\u548c\n\n        b. \u751f\u4ea7\u3001\u590d\u5236\u548c\u5171\u4eab\u6539\u7f16\u6750\u6599\u3002\n\n   2. \u4f8b\u5916\u548c\u9650\u5236\u3002\u5982\u679c\u4f8b\u5916\u548c\u9650\u5236\u9002\u7528\u4e8e\u60a8\u7684\u4f7f\u7528\uff0c\u4e3a\u907f\u514d\u7591\u4e49\uff0c\u672c\u516c\u5171\u8bb8\u53ef\u8bc1\u4e0d\u9002\u7528\uff0c\u60a8\u65e0\u9700\u9075\u5b88\u5176\u6761\u6b3e\u548c\u6761\u4ef6\u3002\n\n   3. \u671f\u9650\u3002\u672c\u516c\u5171\u8bb8\u53ef\u8bc1\u7684\u671f\u9650\u5728\u7b2c6(a)\u8282\u4e2d\u89c4\u5b9a\u3002\n\n   4. \u4ecb\u8d28\u548c\u683c\u5f0f\uff1b\u5141\u8bb8\u6280\u672f\u4fee\u6539\u3002\u8bb8\u53ef\u8005\u6388\u6743\u60a8\u5728\u6240\u6709\u73b0\u6709\u6216\u672a\u6765\u521b\u5efa\u7684\u5a92\u4f53\u548c\u683c\u5f0f\u4e2d\u884c\u4f7f\u88ab\u8bb8\u53ef\u6743\u5229\uff0c\u5e76\u8fdb\u884c\u5fc5\u8981\u7684\u6280\u672f\u4fee\u6539\u3002\u8bb8\u53ef\u8005\u5f03\u6743\u548c/\u6216\u540c\u610f\u4e0d\u4e3b\u5f20\u4efb\u4f55\u7981\u6b62\u60a8\u8fdb\u884c\u5fc5\u8981\u6280\u672f\u4fee\u6539\u7684\u6743\u5229\u6216\u6743\u9650\uff0c\u5305\u62ec\u7ed5\u8fc7\u6709\u6548\u6280\u672f\u63aa\u65bd\u7684\u5fc5\u8981\u6280\u672f\u4fee\u6539\u3002\u5c31\u672c\u516c\u5171\u8bb8\u53ef\u8bc1\u800c\u8a00\uff0c\u4ec5\u4f9d\u636e\u7b2c 2(a)(4) \u8282\u6388\u6743\u7684\u4fee\u6539\u4e0d\u6784\u6210\u6539\u7f16\u6750\u6599\u3002\n\n   5. \u4e0b\u884c\u63a5\u6536\u8005\u3002\n\n        a. \u8bb8\u53ef\u8005\u7684\u8981\u7ea6 -- \u88ab\u8bb8\u53ef\u6750\u6599\u3002\u88ab\u8bb8\u53ef\u6750\u6599\u7684\u6bcf\u4e00\u63a5\u6536\u8005\u81ea\u52a8\u4ece\u8bb8\u53ef\u8005\u5904\u83b7\u5f97\u5728\u672c\u516c\u5171\u8bb8\u53ef\u8bc1\u6761\u6b3e\u548c\u6761\u4ef6\u4e0b\u884c\u4f7f\u88ab\u8bb8\u53ef\u6743\u5229\u7684\u8981\u7ea6\u3002\n\n        b. \u8bb8\u53ef\u8005\u7684\u989d\u5916\u8981\u7ea6 -- \u6539\u7f16\u6750\u6599\u3002\u6bcf\u4e00\u4ece\u60a8\u5904\u63a5\u6536\u6539\u7f16\u6750\u6599\u7684\u63a5\u6536\u8005\u81ea\u52a8\u4ece\u8bb8\u53ef\u8005\u5904\u83b7\u5f97\u5728\u9002\u7528\u4e8e\u6539\u7f16\u6750\u6599\u7684\u6539\u7f16\u8bb8\u53ef\u8bc1\u6761\u6b3e\u548c\u6761\u4ef6\u4e0b\u884c\u4f7f\u88ab\u8bb8\u53ef\u6743\u5229\u7684\u8981\u7ea6\u3002\n\n        c. \u65e0\u4e0b\u884c\u9650\u5236\u3002\u60a8\u4e0d\u5f97\u5bf9\u88ab\u8bb8\u53ef\u6750\u6599\u63d0\u4f9b\u6216\u65bd\u52a0\u4efb\u4f55\u989d\u5916\u6216\u4e0d\u540c\u7684\u6761\u6b3e\u6216\u6761\u4ef6\uff0c\u6216\u5e94\u7528\u4efb\u4f55\u6709\u6548\u6280\u672f\u63aa\u65bd\uff0c\u5982\u679c\u8fd9\u4e9b\u63aa\u65bd\u9650\u5236\u4efb\u4f55\u88ab\u8bb8\u53ef\u6750\u6599\u63a5\u6536\u8005\u5bf9\u88ab\u8bb8\u53ef\u6743\u5229\u7684\u884c\u4f7f\u3002\n\n   6. \u65e0\u8ba4\u53ef\u3002\u672c\u6587\u4e2d\u7684\u4efb\u4f55\u5185\u5bb9\u5747\u4e0d\u6784\u6210\u6216\u53ef\u88ab\u89e3\u91ca\u4e3a\u5141\u8bb8\u60a8\u4e3b\u5f20\u6216\u6697\u793a\u60a8\u6216\u4f60\u7684\u4f7f\u7528\u88ab\u8bb8\u53ef\u6750\u6599\u4e0e\u8bb8\u53ef\u8005\u6216\u7b2c3(a)(1)(A)(i)\u8282\u4e2d\u89c4\u5b9a\u7684\u5176\u4ed6\u88ab\u7f72\u540d\u8005\u6709\u4efb\u4f55\u8054\u7cfb\u6216\u83b7\u5f97\u8ba4\u53ef\uff0c\u6216\u8005\u6388\u4e88\u5b98\u65b9\u5730\u4f4d\u3002\n</code></pre> <p>b. \u5176\u4ed6\u6743\u5229\u3002</p> <pre><code>   1. \u9053\u5fb7\u6743\u5229\uff0c\u5982\u5b8c\u6574\u6743\uff0c\u4e0d\u5728\u672c\u516c\u5171\u8bb8\u53ef\u8bc1\u4e0b\u8fdb\u884c\u8bb8\u53ef\uff1b\u516c\u5171\u66dd\u5149\u6743\u3001\u9690\u79c1\u6743\u548c/\u6216\u5176\u4ed6\u7c7b\u4f3c\u7684\u4e2a\u6027\u6743\u5229\u4e5f\u4e0d\u5728\u672c\u516c\u5171\u8bb8\u53ef\u8bc1\u4e0b\u8fdb\u884c\u8bb8\u53ef\uff1b\u7136\u800c\uff0c\u5c3d\u53ef\u80fd\u5730\uff0c\u8bb8\u53ef\u8005\u653e\u5f03\u548c/\u6216\u540c\u610f\u4e0d\u4e3b\u5f20\u8bb8\u53ef\u8005\u6301\u6709\u7684\u8fd9\u4e9b\u6743\u5229\uff0c\u524d\u63d0\u662f\u4ec5\u9650\u4e8e\u5141\u8bb8\u60a8\u884c\u4f7f\u88ab\u8bb8\u53ef\u6743\u5229\u6240\u9700\u7684\u6700\u5c0f\u7a0b\u5ea6\uff0c\u4f46\u4e0d\u8d85\u8fc7\u6b64\u9650\u5ea6\u3002\n\n   2. \u672c\u516c\u5171\u8bb8\u53ef\u8bc1\u4e0d\u5728\u4e13\u5229\u548c\u5546\u6807\u6743\u4e0b\u8fdb\u884c\u8bb8\u53ef\u3002\n\n   3. \u5728\u53ef\u80fd\u8303\u56f4\u5185\uff0c\u8bb8\u53ef\u8005\u653e\u5f03\u901a\u8fc7\u4efb\u4f55\u81ea\u613f\u6216\u53ef\u653e\u5f03\u7684\u6cd5\u5b9a\u6216\u5f3a\u5236\u6027\u8bb8\u53ef\u8bc1\u8ba1\u5212\u76f4\u63a5\u6216\u901a\u8fc7\u96c6\u4f53\u7ba1\u7406\u673a\u5236\u4ece\u60a8\u5904\u6536\u53d6\u884c\u4f7f\u88ab\u8bb8\u53ef\u6743\u5229\u7684\u4efb\u4f55\u7248\u7a0e\u7684\u6743\u5229\u3002\u5728\u6240\u6709\u5176\u4ed6\u60c5\u51b5\u4e0b\uff0c\u8bb8\u53ef\u8005\u660e\u786e\u4fdd\u7559\u6536\u53d6\u8fd9\u4e9b\u7248\u7a0e\u7684\u6743\u5229\u3002\n</code></pre> <p>\u7b2c 3 \u8282 -- \u8bb8\u53ef\u8bc1\u6761\u4ef6\u3002</p> <p>\u60a8\u5bf9\u88ab\u8bb8\u53ef\u6743\u5229\u7684\u884c\u4f7f\u660e\u786e\u53d7\u4ee5\u4e0b\u6761\u4ef6\u7ea6\u675f\u3002</p> <p>a. \u7f72\u540d\u3002</p> <pre><code>   1. \u5982\u679c\u60a8\u5171\u4eab\u88ab\u8bb8\u53ef\u6750\u6599\uff08\u5305\u62ec\u4fee\u6539\u540e\u7684\u5f62\u5f0f\uff09\uff0c\u60a8\u5fc5\u987b\uff1a\n\n        a. \u4fdd\u7559\u4ee5\u4e0b\u5185\u5bb9\uff08\u5982\u679c\u8bb8\u53ef\u8005\u4e0e\u88ab\u8bb8\u53ef\u6750\u6599\u4e00\u8d77\u63d0\u4f9b\uff09\uff1a\n\n             i. \u521b\u4f5c\u8005\u4ee5\u53ca\u4efb\u4f55\u6307\u5b9a\u63a5\u6536\u7f72\u540d\u7684\u4eba\u7684\u8eab\u4efd\uff0c\u5728\u8bb8\u53ef\u8005\u8981\u6c42\u7684\u5408\u7406\u65b9\u5f0f\u4e0b\uff08\u5305\u62ec\u5982\u679c\u6307\u5b9a\u7684\u8bdd\uff0c\u4f7f\u7528\u5047\u540d\uff09\uff1b\n\n            ii. \u7248\u6743\u58f0\u660e\uff1b\n\n           iii. \u63d0\u53ca\u672c\u516c\u5171\u8bb8\u53ef\u8bc1\u7684\u58f0\u660e\uff1b\n\n            iv. \u63d0\u53ca\u514d\u8d23\u58f0\u660e\u7684\u58f0\u660e\uff1b\n\n             v. \u5728\u5408\u7406\u53ef\u884c\u7684\u8303\u56f4\u5185\u63d0\u4f9b\u6307\u5411\u88ab\u8bb8\u53ef\u6750\u6599\u7684 URI \u6216\u8d85\u94fe\u63a5\uff1b\n\n        b. \u8868\u660e\u60a8\u662f\u5426\u4fee\u6539\u4e86\u88ab\u8bb8\u53ef\u6750\u6599\uff0c\u5e76\u4fdd\u7559\u4efb\u4f55\u5148\u524d\u4fee\u6539\u7684\u6807\u8bc6\uff1b\u548c\n\n        c. \u8868\u660e\u88ab\u8bb8\u53ef\u6750\u6599\u662f\u5728\u672c\u516c\u5171\u8bb8\u53ef\u8bc1\u4e0b\u8bb8\u53ef\u7684\uff0c\u5e76\u5305\u542b\u672c\u516c\u5171\u8bb8\u53ef\u8bc1\u7684\u6587\u672c\uff0c\u6216\u5176 URI \u6216\u8d85\u94fe\u63a5\u3002\n\n   2. \u60a8\u53ef\u4ee5\u6839\u636e\u60a8\u5171\u4eab\u88ab\u8bb8\u53ef\u6750\u6599\u7684\u5a92\u4ecb\u3001\u624b\u6bb5\u548c\u4e0a\u4e0b\u6587\uff0c\u4ee5\u4efb\u4f55\u5408\u7406\u7684\u65b9\u5f0f\u6ee1\u8db3\u7b2c 3(a)(1) \u8282\u4e2d\u7684\u6761\u4ef6\u3002\u4f8b\u5982\uff0c\u63d0\u4f9b\u5305\u542b\u6240\u9700\u4fe1\u606f\u7684\u8d44\u6e90\u7684 URI \u6216\u8d85\u94fe\u63a5\u53ef\u80fd\u662f\u4e00\u79cd\u5408\u7406\u7684\u65b9\u6cd5\u3002\n\n   3. \u5982\u679c\u8bb8\u53ef\u8bc1\u8005\u8981\u6c42\uff0c\u60a8\u5fc5\u987b\u5728\u5408\u7406\u53ef\u884c\u7684\u8303\u56f4\u5185\u79fb\u9664\u7b2c 3(a)(1)(A) \u8282\u6240\u8981\u6c42\u7684\u4efb\u4f55\u4fe1\u606f\u3002\n</code></pre> <p>b. \u76f8\u540c\u65b9\u5f0f\u5171\u4eab\u3002</p> <pre><code> \u9664\u7b2c 3(a) \u8282\u4e2d\u7684\u6761\u4ef6\u5916\uff0c\u5982\u679c\u60a8\u5171\u4eab\u60a8\u521b\u4f5c\u7684\u6539\u7f16\u6750\u6599\uff0c\u4ee5\u4e0b\u6761\u4ef6\u4e5f\u9002\u7528\u3002\n\n   1. \u60a8\u5e94\u7528\u7684\u6539\u7f16\u8bb8\u53ef\u8bc1\u5fc5\u987b\u662f\u5177\u6709\u76f8\u540c\u8bb8\u53ef\u8bc1\u8981\u7d20\u7684\u521b\u4f5c\u5171\u7528\u8bb8\u53ef\u8bc1\uff0c\u6b64\u7248\u672c\u6216\u66f4\u9ad8\u7248\u672c\uff0c\u6216\u517c\u5bb9 BY-SA \u8bb8\u53ef\u8bc1\u3002\n\n   2. \u60a8\u5fc5\u987b\u5305\u62ec\u60a8\u5e94\u7528\u7684\u6539\u7f16\u8bb8\u53ef\u8bc1\u7684\u6587\u672c\uff0c\u6216\u5176 URI \u6216\u8d85\u94fe\u63a5\u3002\u60a8\u53ef\u4ee5\u6839\u636e\u60a8\u5171\u4eab\u6539\u7f16\u6750\u6599\u7684\u5a92\u4ecb\u3001\u624b\u6bb5\u548c\u4e0a\u4e0b\u6587\uff0c\u4ee5\u4efb\u4f55\u5408\u7406\u7684\u65b9\u5f0f\u6ee1\u8db3\u6b64\u6761\u4ef6\u3002\n\n   3. \u60a8\u4e0d\u5f97\u5bf9\u6539\u7f16\u6750\u6599\u63d0\u4f9b\u6216\u65bd\u52a0\u4efb\u4f55\u989d\u5916\u7684\u6216\u4e0d\u540c\u7684\u6761\u6b3e\u6216\u6761\u4ef6\uff0c\u6216\u5e94\u7528\u4efb\u4f55\u6709\u6548\u6280\u672f\u63aa\u65bd\uff0c\u5982\u679c\u8fd9\u4e9b\u63aa\u65bd\u9650\u5236\u5728\u6539\u7f16\u8bb8\u53ef\u8bc1\u4e0b\u6388\u4e88\u7684\u6743\u5229\u7684\u884c\u4f7f\u3002\n</code></pre> <p>\u7b2c 4 \u8282 -- \u72ec\u521b\u6570\u636e\u5e93\u6743\u3002</p> <p>\u5982\u679c\u88ab\u8bb8\u53ef\u6743\u5229\u5305\u62ec\u9002\u7528\u4e8e\u60a8\u5bf9\u88ab\u8bb8\u53ef\u6750\u6599\u7684\u4f7f\u7528\u7684\u72ec\u521b\u6570\u636e\u5e93\u6743\uff1a</p> <p>a. \u4e3a\u907f\u514d\u7591\u4e49\uff0c\u7b2c 2(a)(1) \u8282\u6388\u4e88\u60a8\u63d0\u53d6\u3001\u518d\u5229\u7528\u3001\u590d\u5236\u548c\u5171\u4eab\u6570\u636e\u5e93\u5185\u5bb9\u5168\u90e8\u6216\u5b9e\u8d28\u90e8\u5206\u7684\u6743\u5229\uff1b</p> <p>b. \u5982\u679c\u60a8\u5c06\u6570\u636e\u5e93\u5185\u5bb9\u7684\u5168\u90e8\u6216\u5b9e\u8d28\u90e8\u5206\u5305\u542b\u5728\u60a8\u62e5\u6709\u72ec\u521b\u6570\u636e\u5e93\u6743\u7684\u6570\u636e\u5e93\u4e2d\uff0c\u5219\u8be5\u6570\u636e\u5e93\uff08\u4f46\u4e0d\u662f\u5176\u5355\u4e2a\u5185\u5bb9\uff09\u4e3a\u6539\u7f16\u6750\u6599\uff0c\u9002\u7528\u4e8e\u7b2c 3(b) \u8282\uff1b\u548c</p> <p>c. \u5982\u679c\u60a8\u5171\u4eab\u6570\u636e\u5e93\u5185\u5bb9\u7684\u5168\u90e8\u6216\u5b9e\u8d28\u90e8\u5206\uff0c\u60a8\u5fc5\u987b\u9075\u5b88\u7b2c 3(a) \u8282\u4e2d\u7684\u6761\u4ef6\u3002</p> <p>\u4e3a\u907f\u514d\u7591\u4e49\uff0c\u672c\u7b2c 4 \u8282\u8865\u5145\u4f46\u4e0d\u53d6\u4ee3\u60a8\u5bf9\u4e8e\u5305\u542b\u5176\u4ed6\u7248\u6743\u53ca\u7c7b\u4f3c\u6743\u5229\u7684\u88ab\u8bb8\u53ef\u6743\u5229\u7684\u4e49\u52a1\u3002</p> <p>\u7b2c 5 \u8282 -- \u514d\u8d23\u548c\u8d23\u4efb\u9650\u5236\u3002</p> <p>a. \u9664\u975e\u8bb8\u53ef\u8005\u53e6\u6709\u5355\u72ec\u627f\u8bfa\uff0c\u5c3d\u53ef\u80fd\u5730\uff0c\u8bb8\u53ef\u8005\u4ee5\u201c\u6309\u539f\u6837\u201d\u548c\u201c\u6309\u53ef\u7528\u201d\u7684\u65b9\u5f0f\u63d0\u4f9b\u88ab\u8bb8\u53ef\u6750\u6599\uff0c\u5e76\u4e14\u4e0d\u5bf9\u88ab\u8bb8\u53ef\u6750\u6599\u505a\u4efb\u4f55\u5f62\u5f0f\u7684\u58f0\u660e\u6216\u4fdd\u8bc1\uff0c\u65e0\u8bba\u662f\u660e\u793a\u7684\u3001\u6697\u793a\u7684\u3001\u6cd5\u5b9a\u7684\u6216\u5176\u4ed6\u7684\u3002\u8fd9\u5305\u62ec\u4f46\u4e0d\u9650\u4e8e\u6807\u9898\u3001\u9002\u9500\u6027\u3001\u7279\u5b9a\u7528\u9014\u7684\u9002\u7528\u6027\u3001\u975e\u4fb5\u6743\u6027\u3001\u9690\u6027\u6216\u5176\u4ed6\u7f3a\u9677\u7684\u4e0d\u5b58\u5728\u3001\u51c6\u786e\u6027\u6216\u9519\u8bef\u7684\u5b58\u5728\u4e0e\u5426\uff0c\u4e0d\u8bba\u5df2\u77e5\u6216\u53ef\u53d1\u73b0\u3002\u5728\u4e0d\u5141\u8bb8\u514d\u8d23\u58f0\u660e\u7684\u60c5\u51b5\u4e0b\uff0c\u672c\u514d\u8d23\u58f0\u660e\u53ef\u80fd\u4e0d\u9002\u7528\u4e8e\u60a8\u3002</p> <p>b. \u5c3d\u53ef\u80fd\u5730\uff0c\u8bb8\u53ef\u8005\u5728\u4efb\u4f55\u6cd5\u5f8b\u7406\u8bba\u4e0b\uff08\u5305\u62ec\u4f46\u4e0d\u9650\u4e8e\u758f\u5ffd\uff09\u6216\u5176\u4ed6\u60c5\u51b5\u4e0b\uff0c\u5bf9\u56e0\u672c\u516c\u5171\u8bb8\u53ef\u8bc1\u6216\u4f7f\u7528\u88ab\u8bb8\u53ef\u6750\u6599\u5f15\u8d77\u7684\u4efb\u4f55\u76f4\u63a5\u7684\u3001\u7279\u6b8a\u7684\u3001\u95f4\u63a5\u7684\u3001\u9644\u968f\u7684\u3001\u540e\u679c\u6027\u7684\u3001\u60e9\u7f5a\u6027\u7684\u3001\u5178\u578b\u6027\u7684\u6216\u5176\u4ed6\u635f\u5931\u3001\u6210\u672c\u3001\u8d39\u7528\u6216\u635f\u5bb3\u4e0d\u627f\u62c5\u4efb\u4f55\u8d23\u4efb\uff0c\u5373\u4fbf\u8bb8\u53ef\u8005\u5df2\u88ab\u544a\u77e5\u53ef\u80fd\u4f1a\u53d1\u751f\u8fd9\u79cd\u635f\u5931\u3001\u6210\u672c\u3001\u8d39\u7528\u6216\u635f\u5bb3\u3002\u5728\u4e0d\u5141\u8bb8\u8d23\u4efb\u9650\u5236\u7684\u60c5\u51b5\u4e0b\uff0c\u6b64\u9650\u5236\u53ef\u80fd\u4e0d\u9002\u7528\u4e8e\u60a8\u3002</p> <p>c. \u4e0a\u8ff0\u514d\u8d23\u58f0\u660e\u548c\u8d23\u4efb\u9650\u5236\u5e94\u89e3\u91ca\u4e3a\u5c3d\u91cf\u6700\u63a5\u8fd1\u7edd\u5bf9\u7684\u514d\u8d23\u58f0\u660e\u548c\u8d23\u4efb\u8c41\u514d\u3002</p> <p>\u7b2c 6 \u8282 -- \u671f\u9650\u548c\u7ec8\u6b62\u3002</p> <p>a. \u672c\u516c\u5171\u8bb8\u53ef\u8bc1\u9002\u7528\u4e8e\u6b64\u5904\u6240\u8bb8\u53ef\u7684\u7248\u6743\u53ca\u7c7b\u4f3c\u6743\u5229\u7684\u671f\u9650\u3002\u4f46\u662f\uff0c\u5982\u679c\u60a8\u672a\u80fd\u9075\u5b88\u672c\u516c\u5171\u8bb8\u53ef\u8bc1\uff0c\u5219\u60a8\u7684\u6743\u5229\u5c06\u81ea\u52a8\u7ec8\u6b62\u3002</p> <p>b. \u5982\u679c\u6839\u636e\u7b2c 6(a) \u8282\u60a8\u7684\u4f7f\u7528\u6743\u5229\u7ec8\u6b62\uff0c\u5b83\u5c06\u6062\u590d\uff1a</p> <pre><code>   1. \u8fdd\u53cd\u884c\u4e3a\u7ea0\u6b63\u4e4b\u65e5\u8d77 30 \u5929\u5185\u53d1\u73b0\u7684\u8fdd\u53cd\u884c\u4e3a\uff0c\u81ea\u52a8\u7ea0\u6b63\u4e4b\u65e5\u8d77\u6062\u590d\uff1b\u6216\n\n   2. \u8bb8\u53ef\u8005\u660e\u793a\u6062\u590d\u3002\n\n \u4e3a\u907f\u514d\u7591\u4e49\uff0c\u672c\u7b2c 6(b) \u8282\u4e0d\u5f71\u54cd\u8bb8\u53ef\u8005\u56e0\u60a8\u8fdd\u53cd\u672c\u516c\u5171\u8bb8\u53ef\u8bc1\u800c\u53ef\u80fd\u62e5\u6709\u7684\u4efb\u4f55\u8865\u6551\u6743\u3002\n</code></pre> <p>c. \u4e3a\u907f\u514d\u7591\u4e49\uff0c\u8bb8\u53ef\u8005\u4e5f\u53ef\u4ee5\u5728\u4e0d\u540c\u6761\u4ef6\u4e0b\u63d0\u4f9b\u88ab\u8bb8\u53ef\u6750\u6599\u6216\u968f\u65f6\u505c\u6b62\u5206\u53d1\u88ab\u8bb8\u53ef\u6750\u6599\uff1b\u7136\u800c\uff0c\u8fd9\u5e76\u4e0d\u4f1a\u7ec8\u6b62\u672c\u516c\u5171\u8bb8\u53ef\u8bc1\u3002</p> <p>d. \u7b2c 1 \u8282\uff0c\u7b2c 5 \u8282\uff0c\u7b2c 6 \u8282\uff0c\u7b2c 7 \u8282\u548c\u7b2c 8 \u8282\u5728\u672c\u516c\u5171\u8bb8\u53ef\u8bc1\u7ec8\u6b62\u540e\u7ee7\u7eed\u6709\u6548\u3002</p> <p>\u7b2c 7 \u8282 -- \u5176\u4ed6\u6761\u6b3e\u548c\u6761\u4ef6\u3002</p> <p>a. \u9664\u975e\u8bb8\u53ef\u8005\u660e\u786e\u540c\u610f\uff0c\u5426\u5219\u8bb8\u53ef\u8005\u4e0d\u53d7\u4efb\u4f55\u60a8\u4f20\u8fbe\u7684\u989d\u5916\u6216\u4e0d\u540c\u6761\u6b3e\u548c\u6761\u4ef6\u7684\u7ea6\u675f\u3002</p> <p>b. \u4efb\u4f55\u672a\u5728\u6b64\u8bf4\u660e\u7684\u5173\u4e8e\u88ab\u8bb8\u53ef\u6750\u6599\u7684\u5b89\u6392\u3001\u7406\u89e3\u6216\u534f\u8bae\u5747\u72ec\u7acb\u4e8e\u672c\u516c\u5171\u8bb8\u53ef\u8bc1\u7684\u6761\u6b3e\u548c\u6761\u4ef6\u3002</p> <p>\u7b2c 8 \u8282 -- \u89e3\u91ca\u3002</p> <p>a. \u4e3a\u907f\u514d\u7591\u4e49\uff0c\u672c\u516c\u5171\u8bb8\u53ef\u8bc1\u4e0d\u4f1a\u4e5f\u4e0d\u5e94\u88ab\u89e3\u91ca\u4e3a\u51cf\u5c11\u3001\u9650\u5236\u3001\u7ea6\u675f\u6216\u65bd\u52a0\u4efb\u4f55\u6761\u4ef6\uff0c\u4ee5\u9650\u5236\u672a\u7ecf\u672c\u516c\u5171\u8bb8\u53ef\u8bc1\u6388\u6743\u7684\u60c5\u51b5\u4e0b\u5bf9\u88ab\u8bb8\u53ef\u6750\u6599\u7684\u4efb\u4f55\u5408\u6cd5\u4f7f\u7528\u3002</p> <p>b. \u5c3d\u53ef\u80fd\u5730\uff0c\u5982\u679c\u672c\u516c\u5171\u8bb8\u53ef\u8bc1\u7684\u4efb\u4f55\u6761\u6b3e\u88ab\u8ba4\u4e3a\u4e0d\u53ef\u6267\u884c\uff0c\u5176\u5c06\u81ea\u52a8\u4fee\u6b63\u4e3a\u4f7f\u5176\u4e3a\u6700\u4f4e\u9650\u5ea6\u7684\u5fc5\u8981\u7684\u7a0b\u5ea6\u4ee5\u4f7f\u5176\u53ef\u4ee5\u6267\u884c\u3002\u5982\u679c\u6761\u6b3e\u4e0d\u80fd\u4fee\u6b63\uff0c\u5b83\u5c06\u4ece\u672c\u516c\u5171\u8bb8\u53ef\u8bc1\u4e2d\u5206\u79bb\uff0c\u4f46\u4e0d\u5f71\u54cd\u5176\u4f59\u6761\u6b3e\u548c\u6761\u4ef6\u7684\u53ef\u6267\u884c\u6027\u3002</p> <p>c. \u9664\u975e\u8bb8\u53ef\u8005\u660e\u786e\u540c\u610f\uff0c\u672c\u516c\u5171\u8bb8\u53ef\u8bc1\u7684\u4efb\u4f55\u6761\u6b3e\u6216\u6761\u4ef6\u4e0d\u4f1a\u88ab\u653e\u5f03\uff0c\u4e5f\u4e0d\u4f1a\u540c\u610f\u672a\u9075\u5b88\u3002</p> <p>d. \u672c\u516c\u5171\u8bb8\u53ef\u8bc1\u7684\u4efb\u4f55\u5185\u5bb9\u5747\u4e0d\u6784\u6210\u6216\u53ef\u88ab\u89e3\u91ca\u4e3a\u9650\u5236\u6216\u653e\u5f03\u8bb8\u53ef\u8005\u6216\u60a8\u7684\u4efb\u4f55\u7279\u6743\u548c\u8c41\u514d\uff0c\u5305\u62ec\u4efb\u4f55\u7ba1\u8f96\u6743\u6216\u6743\u5a01\u7684\u6cd5\u5f8b\u7a0b\u5e8f\u4e2d\u7684\u7279\u6743\u548c\u8c41\u514d\u3002</p> <p>=======================================================================</p> <p>\u521b\u4f5c\u5171\u7528\u4e0d\u662f\u5176\u516c\u5171\u8bb8\u53ef\u8bc1\u7684\u4e00\u65b9\u3002\u5c3d\u7ba1\u5982\u6b64\uff0c\u521b\u4f5c\u5171\u7528\u53ef\u80fd\u9009\u62e9\u5bf9\u5176\u53d1\u5e03\u7684\u6750\u6599 \u4f7f\u7528\u5176\u516c\u5171\u8bb8\u53ef\u8bc1\uff0c\u5e76\u5728\u8fd9\u4e9b\u60c5\u51b5\u4e0b\u88ab\u89c6\u4e3a\u201c\u8bb8\u53ef\u8005\u201d\u3002\u521b\u4f5c\u5171\u7528\u516c\u5171\u8bb8\u53ef\u8bc1\u7684\u6587\u672c\u901a\u8fc7 CC0 \u516c\u5171\u9886\u57df\u5949\u732e\u7248\u63d0\u4ea4\u516c\u5171\u9886\u57df\u3002 \u9664\u975e\u7528\u4e8e\u8868\u793a\u6750\u6599\u662f\u6839\u636e\u521b\u4f5c\u5171\u7528\u516c\u5171\u8bb8\u53ef\u8bc1\u5171\u4eab\u7684\u6709\u9650\u76ee\u7684 \u6216\u5176\u4ed6\u521b\u4f5c\u5171\u7528\u53d1\u5e03\u5728 creativecommons.org/policies \u7684\u653f\u7b56\u5141\u8bb8\u7684\uff0c\u521b\u4f5c\u5171\u7528\u672a\u7ecf\u4e8b\u5148\u4e66\u9762\u540c\u610f\uff0c\u4e0d\u6388 \u6388\u6743\u4f7f\u7528\u5176\u5546\u6807\u201c\u521b\u4f5c\u5171\u7528\u201d\u6216\u5176\u4efb\u610f\u5176\u4ed6\u5546\u6807\u6216\u6807\u5fd7\uff0c\u5305\u62ec\u4f46\u4e0d\u9650\u4e8e\u5bf9\u4efb\u4f55\u672a\u6388\u6743\u7684\u4fee\u6539\u5176\u4efb\u4f55\u516c\u5171\u8bb8\u53ef\u8bc1\u6216\u4efb\u4f55\u5176\u4ed6\u5173\u4e8e\u4f7f\u7528\u8bb8\u53ef\u6750\u6599\u7684\u5b89\u6392\u3001\u7406\u89e3\u6216\u534f\u8bae\u3002\u4e3a\u907f\u514d\u7591\u4e49\uff0c\u672c\u6bb5\u4e0d\u5c5e\u4e8e\u516c\u5171\u8bb8\u53ef\u8bc1\u7684\u4e00\u90e8\u5206\u3002</p> <p>\u521b\u4f5c\u5171\u7528\u53ef\u901a\u8fc7 creativecommons.org \u8054\u7cfb\u3002</p>"},{"location":"lessons/sketchnotes/README_chs/","title":"README chs","text":"<p>\u6240\u6709\u8bfe\u7a0b\u7684\u624b\u7ed8\u7b14\u8bb0\u53ef\u4ee5\u5728\u8fd9\u91cc\u4e0b\u8f7d\u3002</p> <p>\ud83c\udfa8 \u7531Tomomi Imura\u521b\u4f5c (Twitter: @girlie_mac, GitHub: girliemac)</p> <p></p>"}]}