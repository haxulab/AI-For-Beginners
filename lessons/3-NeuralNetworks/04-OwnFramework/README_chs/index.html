<!DOCTYPE html>
<html class="writer-html5" lang="en" >
<head>
    <meta charset="utf-8" />
    <meta http-equiv="X-UA-Compatible" content="IE=edge" />
    <meta name="viewport" content="width=device-width, initial-scale=1.0" />
      <link rel="shortcut icon" href="../../../../img/favicon.ico" />
    <title>神经网络介绍. 多层感知器 - 人工智能初学者课程</title>
    <link rel="stylesheet" href="../../../../css/theme.css" />
    <link rel="stylesheet" href="../../../../css/theme_extra.css" />
        <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/11.8.0/styles/github.min.css" />
    
      <script>
        // Current page data
        var mkdocs_page_name = "\u795e\u7ecf\u7f51\u7edc\u4ecb\u7ecd. \u591a\u5c42\u611f\u77e5\u5668";
        var mkdocs_page_input_path = "lessons/3-NeuralNetworks/04-OwnFramework/README_chs.md";
        var mkdocs_page_url = null;
      </script>
    
    <!--[if lt IE 9]>
      <script src="../../../../js/html5shiv.min.js"></script>
    <![endif]-->
      <script src="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/11.8.0/highlight.min.js"></script>
      <script>hljs.highlightAll();</script> 
</head>

<body class="wy-body-for-nav" role="document">

  <div class="wy-grid-for-nav">
    <nav data-toggle="wy-nav-shift" class="wy-nav-side stickynav">
    <div class="wy-side-scroll">
      <div class="wy-side-nav-search">
          <a href="../../../.." class="icon icon-home"> 人工智能初学者课程
        </a><div role="search">
  <form id ="rtd-search-form" class="wy-form" action="../../../../search.html" method="get">
      <input type="text" name="q" placeholder="Search docs" aria-label="Search docs" title="Type search term here" />
  </form>
</div>
      </div>

      <div class="wy-menu wy-menu-vertical" data-spy="affix" role="navigation" aria-label="Navigation menu">
              <ul>
                <li class="toctree-l1"><a class="reference internal" href="../../../../README_chs/">课程介绍</a>
                </li>
              </ul>
              <p class="caption"><span class="caption-text">课程设置</span></p>
              <ul>
                  <li class="toctree-l1"><a class="reference internal" href="../../../0-course-setup/for-teachers_chs/">给教育者</a>
                  </li>
                  <li class="toctree-l1"><a class="reference internal" href="../../../0-course-setup/how-to-run_chs/">如何运行代码</a>
                  </li>
                  <li class="toctree-l1"><a class="reference internal" href="../../../0-course-setup/setup_chs/">开始使用这个课程</a>
                  </li>
              </ul>
              <p class="caption"><span class="caption-text">人工智能简介</span></p>
              <ul>
                  <li class="toctree-l1"><a class="reference internal" href="../../../1-Intro/README_chs/">人工智能简介</a>
                  </li>
                  <li class="toctree-l1"><a class="reference internal" href="../../../1-Intro/assignment_chs/">游戏开发马拉松</a>
                  </li>
              </ul>
              <p class="caption"><span class="caption-text">知识表示与专家系统</span></p>
              <ul>
                  <li class="toctree-l1"><a class="reference internal" href="../../../2-Symbolic/README_chs/">知识表示与专家系统</a>
                  </li>
                  <li class="toctree-l1"><a class="reference internal" href="../../../2-Symbolic/assignment_chs/">构建一个本体</a>
                  </li>
              </ul>
              <p class="caption"><span class="caption-text">神经网络</span></p>
              <ul class="current">
                  <li class="toctree-l1"><a class="reference internal" href="../../README_chs/">神经网络介绍</a>
                  </li>
                  <li class="toctree-l1"><a class="reference internal" href="../../03-Perceptron/README_chs/">神经网络入门：感知器</a>
                  </li>
                  <li class="toctree-l1 current"><a class="reference internal current" href="#">神经网络介绍. 多层感知器</a>
    <ul class="current">
    <li class="toctree-l2"><a class="reference internal" href="#_2">课前测验</a>
    </li>
    <li class="toctree-l2"><a class="reference internal" href="#_3">机器学习形式化</a>
    </li>
    <li class="toctree-l2"><a class="reference internal" href="#_4">梯度下降优化</a>
    </li>
    <li class="toctree-l2"><a class="reference internal" href="#_5">多层感知器和反向传播</a>
    </li>
    <li class="toctree-l2"><a class="reference internal" href="#_6">结论</a>
    </li>
    <li class="toctree-l2"><a class="reference internal" href="#_7">🚀 挑战</a>
    </li>
    <li class="toctree-l2"><a class="reference internal" href="#_8">课后测验</a>
    </li>
    <li class="toctree-l2"><a class="reference internal" href="#_9">复习与自学</a>
    </li>
    <li class="toctree-l2"><a class="reference internal" href="#_10">作业</a>
    </li>
    </ul>
                  </li>
                  <li class="toctree-l1"><a class="reference internal" href="../../05-Frameworks/README_chs/">神经网络框架</a>
                  </li>
              </ul>
              <p class="caption"><span class="caption-text">计算机视觉</span></p>
              <ul>
                  <li class="toctree-l1"><a class="reference internal" href="../../../4-ComputerVision/06-IntroCV/README_chs/">计算机视觉简介</a>
                  </li>
                  <li class="toctree-l1"><a class="reference internal" >卷积神经网络</a>
    <ul>
                <li class="toctree-l2"><a class="reference internal" href="../../../4-ComputerVision/07-ConvNets/CNN_Architectures_chs/">著名的 CNN 架构</a>
                </li>
                <li class="toctree-l2"><a class="reference internal" href="../../../4-ComputerVision/07-ConvNets/README_chs/">卷积神经网络</a>
                </li>
    </ul>
                  </li>
                  <li class="toctree-l1"><a class="reference internal" >迁移学习</a>
    <ul>
                <li class="toctree-l2"><a class="reference internal" href="../../../4-ComputerVision/08-TransferLearning/README_chs/">预训练网络和迁移学习</a>
                </li>
                <li class="toctree-l2"><a class="reference internal" href="../../../4-ComputerVision/08-TransferLearning/TrainingTricks_chs/">深度学习训练技巧</a>
                </li>
    </ul>
                  </li>
                  <li class="toctree-l1"><a class="reference internal" href="../../../4-ComputerVision/09-Autoencoders/README_chs/">自动编码器</a>
                  </li>
                  <li class="toctree-l1"><a class="reference internal" href="../../../4-ComputerVision/10-GANs/README_chs/">生成对抗网络</a>
                  </li>
                  <li class="toctree-l1"><a class="reference internal" href="../../../4-ComputerVision/11-ObjectDetection/README_chs/">目标检测</a>
                  </li>
                  <li class="toctree-l1"><a class="reference internal" href="../../../4-ComputerVision/12-Segmentation/README_chs/">分割</a>
                  </li>
              </ul>
              <p class="caption"><span class="caption-text">自然语言处理</span></p>
              <ul>
                  <li class="toctree-l1"><a class="reference internal" href="../../../5-NLP/13-TextRep/README_chs/">将文本表示为张量</a>
                  </li>
                  <li class="toctree-l1"><a class="reference internal" href="../../../5-NLP/14-Embeddings/README_chs/">嵌入</a>
                  </li>
                  <li class="toctree-l1"><a class="reference internal" href="../../../5-NLP/15-LanguageModeling/README_chs/">语言建模</a>
                  </li>
                  <li class="toctree-l1"><a class="reference internal" href="../../../5-NLP/16-RNN/README_chs/">循环神经网络</a>
                  </li>
                  <li class="toctree-l1"><a class="reference internal" href="../../../5-NLP/17-GenerativeNetworks/README_chs/">生成网络</a>
                  </li>
                  <li class="toctree-l1"><a class="" href="../../../5-NLP/18-Transformers/READMEtransformers_chs">注意机制和Transformer</a>
                  </li>
                  <li class="toctree-l1"><a class="reference internal" href="../../../5-NLP/19-NER/README_chs/">命名实体识别</a>
                  </li>
                  <li class="toctree-l1"><a class="" href="../../../5-NLP/20-LangModels/READMELargeLang_chs">预训练大语言模型</a>
                  </li>
              </ul>
              <p class="caption"><span class="caption-text">其他技术</span></p>
              <ul>
                  <li class="toctree-l1"><a class="reference internal" href="../../../6-Other/21-GeneticAlgorithms/README_chs/">遗传算法</a>
                  </li>
                  <li class="toctree-l1"><a class="reference internal" href="../../../6-Other/22-DeepRL/README_chs/">深度强化学习</a>
                  </li>
                  <li class="toctree-l1"><a class="reference internal" href="../../../6-Other/23-MultiagentSystems/README_chs/">多智能体系统</a>
                  </li>
              </ul>
              <p class="caption"><span class="caption-text">AI伦理</span></p>
              <ul>
                  <li class="toctree-l1"><a class="reference internal" href="../../../7-Ethics/README_chs/">道德与负责任的人工智能</a>
                  </li>
              </ul>
              <p class="caption"><span class="caption-text">多模态网络</span></p>
              <ul>
                  <li class="toctree-l1"><a class="reference internal" href="../../../X-Extras/X1-MultiModal/README_chs/">多模态网络</a>
                  </li>
              </ul>
      </div>
    </div>
    </nav>

    <section data-toggle="wy-nav-shift" class="wy-nav-content-wrap">
      <nav class="wy-nav-top" role="navigation" aria-label="Mobile navigation menu">
          <i data-toggle="wy-nav-top" class="fa fa-bars"></i>
          <a href="../../../..">人工智能初学者课程</a>
        
      </nav>
      <div class="wy-nav-content">
        <div class="rst-content"><div role="navigation" aria-label="breadcrumbs navigation">
  <ul class="wy-breadcrumbs">
    <li><a href="../../../.." class="icon icon-home" aria-label="Docs"></a></li>
          <li class="breadcrumb-item">神经网络</li>
      <li class="breadcrumb-item active">神经网络介绍. 多层感知器</li>
    <li class="wy-breadcrumbs-aside">
    </li>
  </ul>
  <hr/>
</div>
          <div role="main" class="document" itemscope="itemscope" itemtype="http://schema.org/Article">
            <div class="section" itemprop="articleBody">
              
                <h1 id="_1">神经网络介绍. 多层感知器</h1>
<p>在上一节中，你了解了最简单的神经网络模型 - 单层感知器，这是一个线性双类分类模型。</p>
<p>在本节中，我们将扩展这个模型到一个更灵活的框架，允许我们：</p>
<ul>
<li>除了双类之外，还能执行<strong>多类分类</strong></li>
<li>除了分类之外，还能解决<strong>回归问题</strong></li>
<li>分离那些不是线性可分的类</li>
</ul>
<p>我们还将开发我们自己的 Python 模块化框架，允许我们构建不同的神经网络架构。</p>
<h2 id="_2"><a href="https://red-field-0a6ddfd03.1.azurestaticapps.net/quiz/104">课前测验</a></h2>
<h2 id="_3">机器学习形式化</h2>
<p>让我们先形式化机器学习问题。假设我们有一个带有标签 <strong>Y</strong> 的训练数据集 <strong>X</strong>，我们需要构建一个模型 <em>f</em>，以使其预测最准确。预测质量由<strong>损失函数</strong> &lagran; 测量。以下损失函数经常使用：</p>
<ul>
<li>对于回归问题，当我们需要预测一个数值时，我们可以使用<strong>绝对误差</strong> &sum;<sub>i</sub>|f(x<sup>(i)</sup>)-y<sup>(i)</sup>| 或<strong>平方误差</strong> &sum;<sub>i</sub>(f(x<sup>(i)</sup>)-y<sup>(i)</sup>)<sup>2</sup></li>
<li>对于分类，我们使用<strong>0-1损失</strong>（实际上与模型的<strong>准确度</strong>相同）或<strong>逻辑损失</strong>。</li>
</ul>
<p>对于单层感知器，函数 <em>f</em> 被定义为线性函数 <em>f(x)=wx+b</em>（这里 <em>w</em> 是权重矩阵，<em>x</em> 是输入特征向量，<em>b</em> 是偏置向量）。对于不同的神经网络架构，这个函数可以采用更复杂的形式。</p>
<blockquote>
<p>在分类的情况下，通常希望获得对应类别的概率作为网络输出。为了将任意数值转换为概率（例如规范化输出），我们通常使用<strong>softmax</strong> 函数 &sigma;，函数 <em>f</em> 变为 <em>f(x)=&sigma;(wx+b)</em></p>
</blockquote>
<p>在上述 <em>f</em> 的定义中，<em>w</em> 和 <em>b</em> 被称为<strong>参数</strong> &theta;=⟨<em>w,b</em>⟩。给定数据集⟨<strong>X</strong>,<strong>Y</strong>⟩，我们可以计算整个数据集上的总体误差作为参数 &theta; 的函数。</p>
<blockquote>
<p>✅ <strong>神经网络训练的目标是通过改变参数 &theta; 来最小化误差</strong></p>
</blockquote>
<h2 id="_4">梯度下降优化</h2>
<p>有一种众所周知的函数优化方法称为<strong>梯度下降</strong>。其思想是我们可以计算损失函数相对于参数的导数（在多维情况下称为<strong>梯度</strong>），并以这种方式改变参数，使得误差减少。这可以形式化如下：</p>
<ul>
<li>通过一些随机值 w<sup>(0)</sup>, b<sup>(0)</sup> 初始化参数</li>
<li>重复以下步骤多次：<ul>
<li>w<sup>(i+1)</sup> = w<sup>(i)</sup>-&eta;&part;&lagran;/&part;w</li>
<li>b<sup>(i+1)</sup> = b<sup>(i)</sup>-&eta;&part;&lagran;/&part;b</li>
</ul>
</li>
</ul>
<p>在训练过程中，假设优化步骤是考虑整个数据集来计算的（记住，损失是根据所有训练样本的总和计算的）。然而，在实际生活中，我们取称为<strong>小批量</strong>的小部分数据集，并基于数据子集计算梯度。因为每次子集是随机取的，这种方法称为<strong>随机梯度下降</strong>（SGD）。</p>
<h2 id="_5">多层感知器和反向传播</h2>
<p>正如我们上面所见的，一个层的网络能够对线性可分的类进行分类。为了构建一个更丰富的模型，我们可以将网络的几层组合起来。数学上，这意味着函数 <em>f</em> 将具有更复杂的形式，并将在几个步骤中计算：
* z<sub>1</sub>=w<sub>1</sub>x+b<sub>1</sub>
* z<sub>2</sub>=w<sub>2</sub>&alpha;(z<sub>1</sub>)+b<sub>2</sub>
* f = &sigma;(z<sub>2</sub>)</p>
<p>这里，&alpha; 是一个<strong>非线性激活函数</strong>，&sigma; 是一个 softmax 函数，参数 &theta;=&lt;<em>w<sub>1</sub>,b<sub>1</sub>,w<sub>2</sub>,b<sub>2</sub></em>&gt;</p>
<p>梯度下降算法将保持不变，但是计算梯度会更困难。根据链式求导法则，我们可以计算导数为：</p>
<ul>
<li>&part;&lagran;/&part;w<sub>2</sub> = (&part;&lagran;/&part;&sigma;)(&part;&sigma;/&part;z<sub>2</sub>)(&part;z<sub>2</sub>/&part;w<sub>2</sub>)</li>
<li>&part;&lagran;/&part;w<sub>1</sub> = (&part;&lagran;/&part;&sigma;)(&part;&sigma;/&part;z<sub>2</sub>)(&part;z<sub>2</sub>/&part;&alpha;)(&part;&alpha;/&part;z<sub>1</sub>)(&part;z<sub>1</sub>/&part;w<sub>1</sub>)</li>
</ul>
<blockquote>
<p>✅ 链式求导法则用于计算损失函数相对于参数的导数。</p>
</blockquote>
<p>请注意，这些表达式最左边的部分是相同的，因此我们可以有效地从损失函数开始计算导数，并通过计算图 "向后" 计算。因此，多层感知器的训练方法称为<strong>反向传播</strong>，或 'backprop'。</p>
<p><img alt="计算图" src="../images/ComputeGraphGrad.png" /></p>
<blockquote>
<p>TODO: 图片引用</p>
<p>✅ 我们将在我们的笔记本示例中更详细地介绍反向传播。</p>
</blockquote>
<h2 id="_6">结论</h2>
<p>在本课中，我们构建了自己的神经网络库，并将其用于一个简单的二维分类任务。</p>
<h2 id="_7">🚀 挑战</h2>
<p>在配套的笔记本中，你将实现你自己的构建和训练多层感知器的框架。你将能够详细了解现代神经网络如何运行。</p>
<p>进入 <a href="../OwnFramework.ipynb">OwnFramework</a> 笔记本并完成它。</p>
<h2 id="_8"><a href="https://red-field-0a6ddfd03.1.azurestaticapps.net/quiz/204">课后测验</a></h2>
<h2 id="_9">复习与自学</h2>
<p>反向传播是 AI 和 ML 中常用的算法，值得<a href="https://wikipedia.org/wiki/Backpropagation">更详细地研究</a></p>
<h2 id="_10"><a href="../lab/README_chs/">作业</a></h2>
<p>在本次实验中，你需要使用本节课中构建的框架来解决 MNIST 手写数字分类问题。</p>
<ul>
<li><a href="../lab/README_chs/">说明</a></li>
<li><a href="../lab/MyFW_MNIST.ipynb">笔记本</a></li>
</ul>
              
            </div>
          </div><footer>
    <div class="rst-footer-buttons" role="navigation" aria-label="Footer Navigation">
        <a href="../../03-Perceptron/README_chs/" class="btn btn-neutral float-left" title="神经网络入门：感知器"><span class="icon icon-circle-arrow-left"></span> Previous</a>
        <a href="../../05-Frameworks/README_chs/" class="btn btn-neutral float-right" title="神经网络框架">Next <span class="icon icon-circle-arrow-right"></span></a>
    </div>

  <hr/>

  <div role="contentinfo">
    <!-- Copyright etc -->
  </div>

  Built with <a href="https://www.mkdocs.org/">MkDocs</a> using a <a href="https://github.com/readthedocs/sphinx_rtd_theme">theme</a> provided by <a href="https://readthedocs.org">Read the Docs</a>.
</footer>
          
        </div>
      </div>

    </section>

  </div>

  <div class="rst-versions" role="note" aria-label="Versions">
  <span class="rst-current-version" data-toggle="rst-current-version">
    
    
      <span><a href="../../03-Perceptron/README_chs/" style="color: #fcfcfc">&laquo; Previous</a></span>
    
    
      <span><a href="../../05-Frameworks/README_chs/" style="color: #fcfcfc">Next &raquo;</a></span>
    
  </span>
</div>
    <script src="../../../../js/jquery-3.6.0.min.js"></script>
    <script>var base_url = "../../../..";</script>
    <script src="../../../../js/theme_extra.js"></script>
    <script src="../../../../js/theme.js"></script>
      <script src="../../../../search/main.js"></script>
    <script>
        jQuery(function () {
            SphinxRtdTheme.Navigation.enable(true);
        });
    </script>

</body>
</html>
