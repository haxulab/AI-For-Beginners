
<!doctype html>
<html lang="en" class="no-js">
  <head>
    
      <meta charset="utf-8">
      <meta name="viewport" content="width=device-width,initial-scale=1">
      
      
      
      
      
      
      <link rel="icon" href="../../../../assets/images/favicon.png">
      <meta name="generator" content="mkdocs-1.6.1, mkdocs-material-9.5.46">
    
    
      
        <title>Attention Mechanisms and Transformers - 人工智能初学者课程</title>
      
    
    
      <link rel="stylesheet" href="../../../../assets/stylesheets/main.6f8fc17f.min.css">
      
      


    
    
      
    
    
      
        
        
        <link rel="preconnect" href="https://fonts.gstatic.com" crossorigin>
        <link rel="stylesheet" href="https://fonts.googleapis.com/css?family=Roboto:300,300i,400,400i,700,700i%7CRoboto+Mono:400,400i,700,700i&display=fallback">
        <style>:root{--md-text-font:"Roboto";--md-code-font:"Roboto Mono"}</style>
      
    
    
    <script>__md_scope=new URL("../../../..",location),__md_hash=e=>[...e].reduce(((e,_)=>(e<<5)-e+_.charCodeAt(0)),0),__md_get=(e,_=localStorage,t=__md_scope)=>JSON.parse(_.getItem(t.pathname+"."+e)),__md_set=(e,_,t=localStorage,a=__md_scope)=>{try{t.setItem(a.pathname+"."+e,JSON.stringify(_))}catch(e){}}</script>
    
      

    
    
    
  </head>
  
  
    <body dir="ltr">
  
    
    <input class="md-toggle" data-md-toggle="drawer" type="checkbox" id="__drawer" autocomplete="off">
    <input class="md-toggle" data-md-toggle="search" type="checkbox" id="__search" autocomplete="off">
    <label class="md-overlay" for="__drawer"></label>
    <div data-md-component="skip">
      
        
        <a href="#attention-mechanisms-and-transformers" class="md-skip">
          Skip to content
        </a>
      
    </div>
    <div data-md-component="announce">
      
    </div>
    
    
      

  

<header class="md-header md-header--shadow" data-md-component="header">
  <nav class="md-header__inner md-grid" aria-label="Header">
    <a href="../../../.." title="人工智能初学者课程" class="md-header__button md-logo" aria-label="人工智能初学者课程" data-md-component="logo">
      
  
  <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M12 8a3 3 0 0 0 3-3 3 3 0 0 0-3-3 3 3 0 0 0-3 3 3 3 0 0 0 3 3m0 3.54C9.64 9.35 6.5 8 3 8v11c3.5 0 6.64 1.35 9 3.54 2.36-2.19 5.5-3.54 9-3.54V8c-3.5 0-6.64 1.35-9 3.54"/></svg>

    </a>
    <label class="md-header__button md-icon" for="__drawer">
      
      <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M3 6h18v2H3zm0 5h18v2H3zm0 5h18v2H3z"/></svg>
    </label>
    <div class="md-header__title" data-md-component="header-title">
      <div class="md-header__ellipsis">
        <div class="md-header__topic">
          <span class="md-ellipsis">
            人工智能初学者课程
          </span>
        </div>
        <div class="md-header__topic" data-md-component="header-topic">
          <span class="md-ellipsis">
            
              Attention Mechanisms and Transformers
            
          </span>
        </div>
      </div>
    </div>
    
    
      <script>var palette=__md_get("__palette");if(palette&&palette.color){if("(prefers-color-scheme)"===palette.color.media){var media=matchMedia("(prefers-color-scheme: light)"),input=document.querySelector(media.matches?"[data-md-color-media='(prefers-color-scheme: light)']":"[data-md-color-media='(prefers-color-scheme: dark)']");palette.color.media=input.getAttribute("data-md-color-media"),palette.color.scheme=input.getAttribute("data-md-color-scheme"),palette.color.primary=input.getAttribute("data-md-color-primary"),palette.color.accent=input.getAttribute("data-md-color-accent")}for(var[key,value]of Object.entries(palette.color))document.body.setAttribute("data-md-color-"+key,value)}</script>
    
    
    
      <label class="md-header__button md-icon" for="__search">
        
        <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M9.5 3A6.5 6.5 0 0 1 16 9.5c0 1.61-.59 3.09-1.56 4.23l.27.27h.79l5 5-1.5 1.5-5-5v-.79l-.27-.27A6.52 6.52 0 0 1 9.5 16 6.5 6.5 0 0 1 3 9.5 6.5 6.5 0 0 1 9.5 3m0 2C7 5 5 7 5 9.5S7 14 9.5 14 14 12 14 9.5 12 5 9.5 5"/></svg>
      </label>
      <div class="md-search" data-md-component="search" role="dialog">
  <label class="md-search__overlay" for="__search"></label>
  <div class="md-search__inner" role="search">
    <form class="md-search__form" name="search">
      <input type="text" class="md-search__input" name="query" aria-label="Search" placeholder="Search" autocapitalize="off" autocorrect="off" autocomplete="off" spellcheck="false" data-md-component="search-query" required>
      <label class="md-search__icon md-icon" for="__search">
        
        <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M9.5 3A6.5 6.5 0 0 1 16 9.5c0 1.61-.59 3.09-1.56 4.23l.27.27h.79l5 5-1.5 1.5-5-5v-.79l-.27-.27A6.52 6.52 0 0 1 9.5 16 6.5 6.5 0 0 1 3 9.5 6.5 6.5 0 0 1 9.5 3m0 2C7 5 5 7 5 9.5S7 14 9.5 14 14 12 14 9.5 12 5 9.5 5"/></svg>
        
        <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M20 11v2H8l5.5 5.5-1.42 1.42L4.16 12l7.92-7.92L13.5 5.5 8 11z"/></svg>
      </label>
      <nav class="md-search__options" aria-label="Search">
        
        <button type="reset" class="md-search__icon md-icon" title="Clear" aria-label="Clear" tabindex="-1">
          
          <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M19 6.41 17.59 5 12 10.59 6.41 5 5 6.41 10.59 12 5 17.59 6.41 19 12 13.41 17.59 19 19 17.59 13.41 12z"/></svg>
        </button>
      </nav>
      
    </form>
    <div class="md-search__output">
      <div class="md-search__scrollwrap" tabindex="0" data-md-scrollfix>
        <div class="md-search-result" data-md-component="search-result">
          <div class="md-search-result__meta">
            Initializing search
          </div>
          <ol class="md-search-result__list" role="presentation"></ol>
        </div>
      </div>
    </div>
  </div>
</div>
    
    
  </nav>
  
</header>
    
    <div class="md-container" data-md-component="container">
      
      
        
          
        
      
      <main class="md-main" data-md-component="main">
        <div class="md-main__inner md-grid">
          
            
              
              <div class="md-sidebar md-sidebar--primary" data-md-component="sidebar" data-md-type="navigation" >
                <div class="md-sidebar__scrollwrap">
                  <div class="md-sidebar__inner">
                    



<nav class="md-nav md-nav--primary" aria-label="Navigation" data-md-level="0">
  <label class="md-nav__title" for="__drawer">
    <a href="../../../.." title="人工智能初学者课程" class="md-nav__button md-logo" aria-label="人工智能初学者课程" data-md-component="logo">
      
  
  <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M12 8a3 3 0 0 0 3-3 3 3 0 0 0-3-3 3 3 0 0 0-3 3 3 3 0 0 0 3 3m0 3.54C9.64 9.35 6.5 8 3 8v11c3.5 0 6.64 1.35 9 3.54 2.36-2.19 5.5-3.54 9-3.54V8c-3.5 0-6.64 1.35-9 3.54"/></svg>

    </a>
    人工智能初学者课程
  </label>
  
  <ul class="md-nav__list" data-md-scrollfix>
    
      
      
  
  
  
  
    <li class="md-nav__item">
      <a href="../../../.." class="md-nav__link">
        
  
  <span class="md-ellipsis">
    课程介绍
  </span>
  

      </a>
    </li>
  

    
      
      
  
  
  
  
    
    
    
    
    <li class="md-nav__item md-nav__item--nested">
      
        
        
        <input class="md-nav__toggle md-toggle " type="checkbox" id="__nav_2" >
        
          
          <label class="md-nav__link" for="__nav_2" id="__nav_2_label" tabindex="0">
            
  
  <span class="md-ellipsis">
    课程设置
  </span>
  

            <span class="md-nav__icon md-icon"></span>
          </label>
        
        <nav class="md-nav" data-md-level="1" aria-labelledby="__nav_2_label" aria-expanded="false">
          <label class="md-nav__title" for="__nav_2">
            <span class="md-nav__icon md-icon"></span>
            课程设置
          </label>
          <ul class="md-nav__list" data-md-scrollfix>
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../../0-course-setup/for-teachers_chs/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    给教育者
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../../0-course-setup/how-to-run_chs/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    如何运行代码
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../../0-course-setup/setup_chs/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    开始使用这个课程
  </span>
  

      </a>
    </li>
  

              
            
          </ul>
        </nav>
      
    </li>
  

    
      
      
  
  
  
  
    
    
    
    
    <li class="md-nav__item md-nav__item--nested">
      
        
        
        <input class="md-nav__toggle md-toggle " type="checkbox" id="__nav_3" >
        
          
          <label class="md-nav__link" for="__nav_3" id="__nav_3_label" tabindex="0">
            
  
  <span class="md-ellipsis">
    人工智能简介
  </span>
  

            <span class="md-nav__icon md-icon"></span>
          </label>
        
        <nav class="md-nav" data-md-level="1" aria-labelledby="__nav_3_label" aria-expanded="false">
          <label class="md-nav__title" for="__nav_3">
            <span class="md-nav__icon md-icon"></span>
            人工智能简介
          </label>
          <ul class="md-nav__list" data-md-scrollfix>
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../../1-Intro/README_chs/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    人工智能简介
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../../1-Intro/assignment_chs/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    游戏开发马拉松
  </span>
  

      </a>
    </li>
  

              
            
          </ul>
        </nav>
      
    </li>
  

    
      
      
  
  
  
  
    
    
    
    
    <li class="md-nav__item md-nav__item--nested">
      
        
        
        <input class="md-nav__toggle md-toggle " type="checkbox" id="__nav_4" >
        
          
          <label class="md-nav__link" for="__nav_4" id="__nav_4_label" tabindex="0">
            
  
  <span class="md-ellipsis">
    知识表示与专家系统
  </span>
  

            <span class="md-nav__icon md-icon"></span>
          </label>
        
        <nav class="md-nav" data-md-level="1" aria-labelledby="__nav_4_label" aria-expanded="false">
          <label class="md-nav__title" for="__nav_4">
            <span class="md-nav__icon md-icon"></span>
            知识表示与专家系统
          </label>
          <ul class="md-nav__list" data-md-scrollfix>
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../../2-Symbolic/README_chs/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    知识表示与专家系统
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../../2-Symbolic/assignment_chs/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    构建一个本体
  </span>
  

      </a>
    </li>
  

              
            
          </ul>
        </nav>
      
    </li>
  

    
      
      
  
  
  
  
    
    
    
    
    <li class="md-nav__item md-nav__item--nested">
      
        
        
        <input class="md-nav__toggle md-toggle " type="checkbox" id="__nav_5" >
        
          
          <label class="md-nav__link" for="__nav_5" id="__nav_5_label" tabindex="0">
            
  
  <span class="md-ellipsis">
    神经网络
  </span>
  

            <span class="md-nav__icon md-icon"></span>
          </label>
        
        <nav class="md-nav" data-md-level="1" aria-labelledby="__nav_5_label" aria-expanded="false">
          <label class="md-nav__title" for="__nav_5">
            <span class="md-nav__icon md-icon"></span>
            神经网络
          </label>
          <ul class="md-nav__list" data-md-scrollfix>
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../../3-NeuralNetworks/README_chs/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    神经网络介绍
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../../3-NeuralNetworks/03-Perceptron/README_chs/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    神经网络入门：感知器
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../../3-NeuralNetworks/04-OwnFramework/README_chs/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    神经网络介绍. 多层感知器
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../../3-NeuralNetworks/05-Frameworks/README_chs/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    神经网络框架
  </span>
  

      </a>
    </li>
  

              
            
          </ul>
        </nav>
      
    </li>
  

    
      
      
  
  
  
  
    
    
    
    
    <li class="md-nav__item md-nav__item--nested">
      
        
        
        <input class="md-nav__toggle md-toggle " type="checkbox" id="__nav_6" >
        
          
          <label class="md-nav__link" for="__nav_6" id="__nav_6_label" tabindex="0">
            
  
  <span class="md-ellipsis">
    计算机视觉
  </span>
  

            <span class="md-nav__icon md-icon"></span>
          </label>
        
        <nav class="md-nav" data-md-level="1" aria-labelledby="__nav_6_label" aria-expanded="false">
          <label class="md-nav__title" for="__nav_6">
            <span class="md-nav__icon md-icon"></span>
            计算机视觉
          </label>
          <ul class="md-nav__list" data-md-scrollfix>
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../../4-ComputerVision/06-IntroCV/README_chs/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    计算机视觉简介
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    
    
    
    
    <li class="md-nav__item md-nav__item--nested">
      
        
        
        <input class="md-nav__toggle md-toggle " type="checkbox" id="__nav_6_2" >
        
          
          <label class="md-nav__link" for="__nav_6_2" id="__nav_6_2_label" tabindex="0">
            
  
  <span class="md-ellipsis">
    卷积神经网络
  </span>
  

            <span class="md-nav__icon md-icon"></span>
          </label>
        
        <nav class="md-nav" data-md-level="2" aria-labelledby="__nav_6_2_label" aria-expanded="false">
          <label class="md-nav__title" for="__nav_6_2">
            <span class="md-nav__icon md-icon"></span>
            卷积神经网络
          </label>
          <ul class="md-nav__list" data-md-scrollfix>
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../../4-ComputerVision/07-ConvNets/CNN_Architectures_chs/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    著名的 CNN 架构
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../../4-ComputerVision/07-ConvNets/README_chs/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    卷积神经网络
  </span>
  

      </a>
    </li>
  

              
            
          </ul>
        </nav>
      
    </li>
  

              
            
              
                
  
  
  
  
    
    
    
    
    <li class="md-nav__item md-nav__item--nested">
      
        
        
        <input class="md-nav__toggle md-toggle " type="checkbox" id="__nav_6_3" >
        
          
          <label class="md-nav__link" for="__nav_6_3" id="__nav_6_3_label" tabindex="0">
            
  
  <span class="md-ellipsis">
    迁移学习
  </span>
  

            <span class="md-nav__icon md-icon"></span>
          </label>
        
        <nav class="md-nav" data-md-level="2" aria-labelledby="__nav_6_3_label" aria-expanded="false">
          <label class="md-nav__title" for="__nav_6_3">
            <span class="md-nav__icon md-icon"></span>
            迁移学习
          </label>
          <ul class="md-nav__list" data-md-scrollfix>
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../../4-ComputerVision/08-TransferLearning/README_chs/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    预训练网络和迁移学习
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../../4-ComputerVision/08-TransferLearning/TrainingTricks_chs/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    深度学习训练技巧
  </span>
  

      </a>
    </li>
  

              
            
          </ul>
        </nav>
      
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../../4-ComputerVision/09-Autoencoders/README_chs/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    自动编码器
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../../4-ComputerVision/10-GANs/README_chs/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    生成对抗网络
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../../4-ComputerVision/11-ObjectDetection/README_chs/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    目标检测
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../../4-ComputerVision/12-Segmentation/README_chs/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    分割
  </span>
  

      </a>
    </li>
  

              
            
          </ul>
        </nav>
      
    </li>
  

    
      
      
  
  
  
  
    
    
    
    
    <li class="md-nav__item md-nav__item--nested">
      
        
        
        <input class="md-nav__toggle md-toggle " type="checkbox" id="__nav_7" >
        
          
          <label class="md-nav__link" for="__nav_7" id="__nav_7_label" tabindex="0">
            
  
  <span class="md-ellipsis">
    自然语言处理
  </span>
  

            <span class="md-nav__icon md-icon"></span>
          </label>
        
        <nav class="md-nav" data-md-level="1" aria-labelledby="__nav_7_label" aria-expanded="false">
          <label class="md-nav__title" for="__nav_7">
            <span class="md-nav__icon md-icon"></span>
            自然语言处理
          </label>
          <ul class="md-nav__list" data-md-scrollfix>
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../13-TextRep/README_chs/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    将文本表示为张量
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../14-Embeddings/README_chs/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    嵌入
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../15-LanguageModeling/README_chs/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    语言建模
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../16-RNN/README_chs/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    循环神经网络
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../17-GenerativeNetworks/README_chs/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    生成网络
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../READMEtransformers_chs/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    注意机制和Transformer
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../19-NER/README_chs/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    命名实体识别
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../20-LangModels/READMELargeLang_chs/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    预训练大语言模型
  </span>
  

      </a>
    </li>
  

              
            
          </ul>
        </nav>
      
    </li>
  

    
      
      
  
  
  
  
    
    
    
    
    <li class="md-nav__item md-nav__item--nested">
      
        
        
        <input class="md-nav__toggle md-toggle " type="checkbox" id="__nav_8" >
        
          
          <label class="md-nav__link" for="__nav_8" id="__nav_8_label" tabindex="0">
            
  
  <span class="md-ellipsis">
    其他技术
  </span>
  

            <span class="md-nav__icon md-icon"></span>
          </label>
        
        <nav class="md-nav" data-md-level="1" aria-labelledby="__nav_8_label" aria-expanded="false">
          <label class="md-nav__title" for="__nav_8">
            <span class="md-nav__icon md-icon"></span>
            其他技术
          </label>
          <ul class="md-nav__list" data-md-scrollfix>
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../../6-Other/21-GeneticAlgorithms/README_chs/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    遗传算法
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../../6-Other/22-DeepRL/README_chs/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    深度强化学习
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../../6-Other/23-MultiagentSystems/README_chs/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    多智能体系统
  </span>
  

      </a>
    </li>
  

              
            
          </ul>
        </nav>
      
    </li>
  

    
      
      
  
  
  
  
    
    
    
    
    <li class="md-nav__item md-nav__item--nested">
      
        
        
        <input class="md-nav__toggle md-toggle " type="checkbox" id="__nav_9" >
        
          
          <label class="md-nav__link" for="__nav_9" id="__nav_9_label" tabindex="0">
            
  
  <span class="md-ellipsis">
    AI伦理
  </span>
  

            <span class="md-nav__icon md-icon"></span>
          </label>
        
        <nav class="md-nav" data-md-level="1" aria-labelledby="__nav_9_label" aria-expanded="false">
          <label class="md-nav__title" for="__nav_9">
            <span class="md-nav__icon md-icon"></span>
            AI伦理
          </label>
          <ul class="md-nav__list" data-md-scrollfix>
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../../7-Ethics/README_chs/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    道德与负责任的人工智能
  </span>
  

      </a>
    </li>
  

              
            
          </ul>
        </nav>
      
    </li>
  

    
      
      
  
  
  
  
    
    
    
    
    <li class="md-nav__item md-nav__item--nested">
      
        
        
        <input class="md-nav__toggle md-toggle " type="checkbox" id="__nav_10" >
        
          
          <label class="md-nav__link" for="__nav_10" id="__nav_10_label" tabindex="0">
            
  
  <span class="md-ellipsis">
    多模态网络
  </span>
  

            <span class="md-nav__icon md-icon"></span>
          </label>
        
        <nav class="md-nav" data-md-level="1" aria-labelledby="__nav_10_label" aria-expanded="false">
          <label class="md-nav__title" for="__nav_10">
            <span class="md-nav__icon md-icon"></span>
            多模态网络
          </label>
          <ul class="md-nav__list" data-md-scrollfix>
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../../X-Extras/X1-MultiModal/README_chs/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    多模态网络
  </span>
  

      </a>
    </li>
  

              
            
          </ul>
        </nav>
      
    </li>
  

    
  </ul>
</nav>
                  </div>
                </div>
              </div>
            
            
              
              <div class="md-sidebar md-sidebar--secondary" data-md-component="sidebar" data-md-type="toc" >
                <div class="md-sidebar__scrollwrap">
                  <div class="md-sidebar__inner">
                    

<nav class="md-nav md-nav--secondary" aria-label="Table of contents">
  
  
  
    
  
  
    <label class="md-nav__title" for="__toc">
      <span class="md-nav__icon md-icon"></span>
      Table of contents
    </label>
    <ul class="md-nav__list" data-md-component="toc" data-md-scrollfix>
      
        <li class="md-nav__item">
  <a href="#pre-lecture-quiz" class="md-nav__link">
    <span class="md-ellipsis">
      Pre-lecture quiz
    </span>
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#transformer-models" class="md-nav__link">
    <span class="md-ellipsis">
      Transformer models
    </span>
  </a>
  
    <nav class="md-nav" aria-label="Transformer models">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#positional-encodingembedding" class="md-nav__link">
    <span class="md-ellipsis">
      Positional Encoding/Embedding
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#multi-head-self-attention" class="md-nav__link">
    <span class="md-ellipsis">
      Multi-Head Self-Attention
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#encoder-decoder-attention" class="md-nav__link">
    <span class="md-ellipsis">
      Encoder-Decoder Attention
    </span>
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
      
        <li class="md-nav__item">
  <a href="#bert" class="md-nav__link">
    <span class="md-ellipsis">
      BERT
    </span>
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#exercises-transformers" class="md-nav__link">
    <span class="md-ellipsis">
      ✍️ Exercises: Transformers
    </span>
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#conclusion" class="md-nav__link">
    <span class="md-ellipsis">
      Conclusion
    </span>
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#challenge" class="md-nav__link">
    <span class="md-ellipsis">
      🚀 Challenge
    </span>
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#post-lecture-quiz" class="md-nav__link">
    <span class="md-ellipsis">
      Post-lecture quiz
    </span>
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#review-self-study" class="md-nav__link">
    <span class="md-ellipsis">
      Review &amp; Self Study
    </span>
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#assignment" class="md-nav__link">
    <span class="md-ellipsis">
      Assignment
    </span>
  </a>
  
</li>
      
    </ul>
  
</nav>
                  </div>
                </div>
              </div>
            
          
          
            <div class="md-content" data-md-component="content">
              <article class="md-content__inner md-typeset">
                
                  


<h1 id="attention-mechanisms-and-transformers">Attention Mechanisms and Transformers</h1>
<h2 id="pre-lecture-quiz"><a href="https://red-field-0a6ddfd03.1.azurestaticapps.net/quiz/118">Pre-lecture quiz</a></h2>
<p>One of the most important problems in the NLP domain is <strong>machine translation</strong>, an essential task that underlies tools such as Google Translate. In this section, we will focus on machine translation, or, more generally, on any <em>sequence-to-sequence</em> task (which is also called <strong>sentence transduction</strong>).</p>
<p>With RNNs, sequence-to-sequence is implemented by two recurrent networks, where one network, the <strong>encoder</strong>, collapses an input sequence into a hidden state, while another network, the <strong>decoder</strong>, unrolls this hidden state into a translated result. There are a couple of problems with this approach:</p>
<ul>
<li>The final state of the encoder network has a hard time remembering the beginning of a sentence, thus causing poor quality of the model for long sentences</li>
<li>All words in a sequence have the same impact on the result. In reality, however, specific words in the input sequence often have more impact on sequential outputs than others.</li>
</ul>
<p><strong>Attention Mechanisms</strong> provide a means of weighting the contextual impact of each input vector on each output prediction of the RNN. The way it is implemented is by creating shortcuts between intermediate states of the input RNN and the output RNN. In this manner, when generating output symbol y<sub>t</sub>, we will take into account all input hidden states h<sub>i</sub>, with different weight coefficients &alpha;<sub>t,i</sub>.</p>
<p><img alt="Image showing an encoder/decoder model with an additive attention layer" src="../images/encoder-decoder-attention.png" /></p>
<blockquote>
<p>The encoder-decoder model with additive attention mechanism in <a href="https://arxiv.org/pdf/1409.0473.pdf">Bahdanau et al., 2015</a>, cited from <a href="https://lilianweng.github.io/lil-log/2018/06/24/attention-attention.html">this blog post</a></p>
</blockquote>
<p>The attention matrix {&alpha;<sub>i,j</sub>} would represent the degree that certain input words play in the generation of a given word in the output sequence. Below is an example of such a matrix:</p>
<p><img alt="Image showing a sample alignment found by RNNsearch-50, taken from Bahdanau - arviz.org" src="../images/bahdanau-fig3.png" /></p>
<blockquote>
<p>Figure from <a href="https://arxiv.org/pdf/1409.0473.pdf">Bahdanau et al., 2015</a> (Fig.3)</p>
</blockquote>
<p>Attention mechanisms are responsible for much of the current or near current state of the art in NLP. Adding attention however greatly increases the number of model parameters which led to scaling issues with RNNs. A key constraint of scaling RNNs is that the recurrent nature of the models makes it challenging to batch and parallelize training. In an RNN each element of a sequence needs to be processed in sequential order which means it cannot be easily parallelized.</p>
<p><img alt="Encoder Decoder with Attention" src="../images/EncDecAttention.gif" /></p>
<blockquote>
<p>Figure from <a href="https://research.googleblog.com/2016/09/a-neural-network-for-machine.html">Google's Blog</a></p>
</blockquote>
<p>The adoption of attention mechanisms combined with this constraint led to the creation of the now State of the Art Transformer Models that we know and use today such as BERT to Open-GPT3.</p>
<h2 id="transformer-models">Transformer models</h2>
<p>One of the main ideas behind transformers is to avoid sequential nature of RNNs and to create a model that is parallelizable during training. This is achieved by implementing two ideas:</p>
<ul>
<li>positional encoding</li>
<li>using self-attention mechanism to capture patterns instead of RNNs (or CNNs) (that is why the paper that introduces transformers is called <em><a href="https://arxiv.org/abs/1706.03762">Attention is all you need</a></em></li>
</ul>
<h3 id="positional-encodingembedding">Positional Encoding/Embedding</h3>
<p>The idea of positional encoding is the following. 
1. When using RNNs, the relative position of the tokens is represented by the number of steps, and thus does not need to be explicitly represented. 
2. However, once we switch to attention, we need to know the relative positions of tokens within a sequence. 
3. To get positional encoding, we augment our sequence of tokens with a sequence of token positions in the sequence (i.e., a sequence of numbers 0,1, ...).
4. We then mix the token position with a token embedding vector. To transform the position (integer) into a vector, we can use different approaches:</p>
<ul>
<li>Trainable embedding, similar to token embedding. This is the approach we consider here. We apply embedding layers on top of both tokens and their positions, resulting in embedding vectors of the same dimensions, which we then add together.</li>
<li>Fixed position encoding function, as proposed in the original paper.</li>
</ul>
<p><img src="images/pos-embedding.png" width="50%"/></p>
<blockquote>
<p>Image by the author</p>
</blockquote>
<p>The result that we get with positional embedding embeds both the original token and its position within a sequence.</p>
<h3 id="multi-head-self-attention">Multi-Head Self-Attention</h3>
<p>Next, we need to capture some patterns within our sequence. To do this, transformers use a <strong>self-attention</strong> mechanism, which is essentially attention applied to the same sequence as the input and output. Applying self-attention allows us to take into account <strong>context</strong> within the sentence, and see which words are inter-related. For example, it allows us to see which words are referred to by coreferences, such as <em>it</em>, and also take the context into account:</p>
<p><img alt="" src="../images/CoreferenceResolution.png" /></p>
<blockquote>
<p>Image from the <a href="https://research.googleblog.com/2017/08/transformer-novel-neural-network.html">Google Blog</a></p>
</blockquote>
<p>In transformers, we use <strong>Multi-Head Attention</strong> in order to give the network the power to capture several different types of dependencies, eg. long-term vs. short-term word relations, co-reference vs. something else, etc.</p>
<p><a href="../TransformersTF.ipynb">TensorFlow Notebook</a> contains more detains on the implementation of transformer layers.</p>
<h3 id="encoder-decoder-attention">Encoder-Decoder Attention</h3>
<p>In transformers, attention is used in two places:</p>
<ul>
<li>To capture patterns within the input text using self-attention</li>
<li>To perform sequence translation - it is the attention layer between encoder and decoder.</li>
</ul>
<p>Encoder-decoder attention is very similar to the attention mechanism used in RNNs, as described in the beginning of this section. This animated diagram explains the role of encoder-decoder attention.</p>
<p><img alt="Animated GIF showing how the evaluations are performed in transformer models." src="../images/transformer-animated-explanation.gif" /></p>
<p>Since each input position is mapped independently to each output position, transformers can parallelize better than RNNs, which enables much larger and more expressive language models. Each attention head can be used to learn different relationships between words that improves downstream Natural Language Processing tasks.</p>
<h2 id="bert">BERT</h2>
<p><strong>BERT</strong> (Bidirectional Encoder Representations from Transformers) is a very large multi layer transformer network with 12 layers for <em>BERT-base</em>, and 24 for <em>BERT-large</em>. The model is first pre-trained on a large corpus of text data (WikiPedia + books) using unsupervised training (predicting masked words in a sentence). During pre-training the model absorbs significant levels of language understanding which can then be leveraged with other datasets using fine tuning. This process is called <strong>transfer learning</strong>.</p>
<p><img alt="picture from http://jalammar.github.io/illustrated-bert/" src="../images/jalammarBERT-language-modeling-masked-lm.png" /></p>
<blockquote>
<p>Image <a href="http://jalammar.github.io/illustrated-bert/">source</a></p>
</blockquote>
<h2 id="exercises-transformers">✍️ Exercises: Transformers</h2>
<p>Continue your learning in the following notebooks:</p>
<ul>
<li><a href="../TransformersPyTorch.ipynb">Transformers in PyTorch</a></li>
<li><a href="../TransformersTF.ipynb">Transformers in TensorFlow</a></li>
</ul>
<h2 id="conclusion">Conclusion</h2>
<p>In this lesson you learned about Transformers and Attention Mechanisms, all essential tools in the NLP toolbox. There are many variations of Transformer architectures including BERT, DistilBERT. BigBird, OpenGPT3 and more that can be fine tuned. The <a href="https://github.com/huggingface/">HuggingFace package</a> provides repository for training many of these architectures with both PyTorch and TensorFlow.</p>
<h2 id="challenge">🚀 Challenge</h2>
<h2 id="post-lecture-quiz"><a href="https://red-field-0a6ddfd03.1.azurestaticapps.net/quiz/218">Post-lecture quiz</a></h2>
<h2 id="review-self-study">Review &amp; Self Study</h2>
<ul>
<li><a href="https://mchromiak.github.io/articles/2017/Sep/12/Transformer-Attention-is-all-you-need/">Blog post</a>, explaining the classical <a href="https://arxiv.org/abs/1706.03762">Attention is all you need</a> paper on transformers.</li>
<li><a href="https://towardsdatascience.com/transformers-explained-visually-part-1-overview-of-functionality-95a6dd460452">A series of blog posts</a> on transformers, explaining the architecture in detail.</li>
</ul>
<h2 id="assignment"><a href="../assignment_chs/">Assignment</a></h2>












                
              </article>
            </div>
          
          
<script>var target=document.getElementById(location.hash.slice(1));target&&target.name&&(target.checked=target.name.startsWith("__tabbed_"))</script>
        </div>
        
      </main>
      
        <footer class="md-footer">
  
  <div class="md-footer-meta md-typeset">
    <div class="md-footer-meta__inner md-grid">
      <div class="md-copyright">
  
  
    Made with
    <a href="https://squidfunk.github.io/mkdocs-material/" target="_blank" rel="noopener">
      Material for MkDocs
    </a>
  
</div>
      
    </div>
  </div>
</footer>
      
    </div>
    <div class="md-dialog" data-md-component="dialog">
      <div class="md-dialog__inner md-typeset"></div>
    </div>
    
    
    <script id="__config" type="application/json">{"base": "../../../..", "features": [], "search": "../../../../assets/javascripts/workers/search.6ce7567c.min.js", "translations": {"clipboard.copied": "Copied to clipboard", "clipboard.copy": "Copy to clipboard", "search.result.more.one": "1 more on this page", "search.result.more.other": "# more on this page", "search.result.none": "No matching documents", "search.result.one": "1 matching document", "search.result.other": "# matching documents", "search.result.placeholder": "Type to start searching", "search.result.term.missing": "Missing", "select.version": "Select version"}}</script>
    
    
      <script src="../../../../assets/javascripts/bundle.83f73b43.min.js"></script>
      
    
  </body>
</html>