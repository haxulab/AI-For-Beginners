<!DOCTYPE html>
<html class="writer-html5" lang="en" >
<head>
    <meta charset="utf-8" />
    <meta http-equiv="X-UA-Compatible" content="IE=edge" />
    <meta name="viewport" content="width=device-width, initial-scale=1.0" />
      <link rel="shortcut icon" href="../../img/favicon.ico" />
    <title>Natural Language Processing - 人工智能初学者课程</title>
    <link rel="stylesheet" href="../../css/theme.css" />
    <link rel="stylesheet" href="../../css/theme_extra.css" />
        <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/11.8.0/styles/github.min.css" />
    
      <script>
        // Current page data
        var mkdocs_page_name = "Natural Language Processing";
        var mkdocs_page_input_path = "lessons/5-NLP/README.md";
        var mkdocs_page_url = null;
      </script>
    
    <!--[if lt IE 9]>
      <script src="../../js/html5shiv.min.js"></script>
    <![endif]-->
      <script src="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/11.8.0/highlight.min.js"></script>
      <script>hljs.highlightAll();</script> 
</head>

<body class="wy-body-for-nav" role="document">

  <div class="wy-grid-for-nav">
    <nav data-toggle="wy-nav-shift" class="wy-nav-side stickynav">
    <div class="wy-side-scroll">
      <div class="wy-side-nav-search">
          <a href="../.." class="icon icon-home"> 人工智能初学者课程
        </a><div role="search">
  <form id ="rtd-search-form" class="wy-form" action="../../search.html" method="get">
      <input type="text" name="q" placeholder="Search docs" aria-label="Search docs" title="Type search term here" />
  </form>
</div>
      </div>

      <div class="wy-menu wy-menu-vertical" data-spy="affix" role="navigation" aria-label="Navigation menu">
              <ul>
                <li class="toctree-l1"><a class="reference internal" href="../../README_chs/">课程介绍</a>
                </li>
              </ul>
              <p class="caption"><span class="caption-text">课程设置</span></p>
              <ul>
                  <li class="toctree-l1"><a class="reference internal" href="../0-course-setup/for-teachers_chs/">给教育者</a>
                  </li>
                  <li class="toctree-l1"><a class="reference internal" href="../0-course-setup/how-to-run_chs/">如何运行代码</a>
                  </li>
                  <li class="toctree-l1"><a class="reference internal" href="../0-course-setup/setup_chs/">开始使用这个课程</a>
                  </li>
              </ul>
              <p class="caption"><span class="caption-text">人工智能简介</span></p>
              <ul>
                  <li class="toctree-l1"><a class="reference internal" href="../1-Intro/README_chs/">人工智能简介</a>
                  </li>
                  <li class="toctree-l1"><a class="reference internal" href="../1-Intro/assignment_chs/">游戏开发马拉松</a>
                  </li>
              </ul>
              <p class="caption"><span class="caption-text">知识表示与专家系统</span></p>
              <ul>
                  <li class="toctree-l1"><a class="reference internal" href="../2-Symbolic/README_chs/">知识表示与专家系统</a>
                  </li>
                  <li class="toctree-l1"><a class="reference internal" href="../2-Symbolic/assignment_chs/">构建一个本体</a>
                  </li>
              </ul>
              <p class="caption"><span class="caption-text">神经网络</span></p>
              <ul>
                  <li class="toctree-l1"><a class="reference internal" href="../3-NeuralNetworks/README_chs/">神经网络介绍</a>
                  </li>
                  <li class="toctree-l1"><a class="reference internal" href="../3-NeuralNetworks/03-Perceptron/README_chs/">神经网络入门：感知器</a>
                  </li>
                  <li class="toctree-l1"><a class="reference internal" href="../3-NeuralNetworks/04-OwnFramework/README_chs/">神经网络介绍. 多层感知器</a>
                  </li>
                  <li class="toctree-l1"><a class="reference internal" href="../3-NeuralNetworks/05-Frameworks/README_chs/">神经网络框架</a>
                  </li>
              </ul>
              <p class="caption"><span class="caption-text">计算机视觉</span></p>
              <ul>
                  <li class="toctree-l1"><a class="reference internal" href="../4-ComputerVision/06-IntroCV/README_chs/">计算机视觉简介</a>
                  </li>
                  <li class="toctree-l1"><a class="reference internal" >卷积神经网络</a>
    <ul>
                <li class="toctree-l2"><a class="reference internal" href="../4-ComputerVision/07-ConvNets/CNN_Architectures_chs/">著名的 CNN 架构</a>
                </li>
                <li class="toctree-l2"><a class="reference internal" href="../4-ComputerVision/07-ConvNets/README_chs/">卷积神经网络</a>
                </li>
    </ul>
                  </li>
                  <li class="toctree-l1"><a class="reference internal" >迁移学习</a>
    <ul>
                <li class="toctree-l2"><a class="reference internal" href="../4-ComputerVision/08-TransferLearning/README_chs/">预训练网络和迁移学习</a>
                </li>
                <li class="toctree-l2"><a class="reference internal" href="../4-ComputerVision/08-TransferLearning/TrainingTricks_chs/">深度学习训练技巧</a>
                </li>
    </ul>
                  </li>
                  <li class="toctree-l1"><a class="reference internal" href="../4-ComputerVision/09-Autoencoders/README_chs/">自动编码器</a>
                  </li>
                  <li class="toctree-l1"><a class="reference internal" href="../4-ComputerVision/10-GANs/README_chs/">生成对抗网络</a>
                  </li>
                  <li class="toctree-l1"><a class="reference internal" href="../4-ComputerVision/11-ObjectDetection/README_chs/">目标检测</a>
                  </li>
                  <li class="toctree-l1"><a class="reference internal" href="../4-ComputerVision/12-Segmentation/README_chs/">分割</a>
                  </li>
              </ul>
              <p class="caption"><span class="caption-text">自然语言处理</span></p>
              <ul>
                  <li class="toctree-l1"><a class="reference internal" href="13-TextRep/README_chs/">将文本表示为张量</a>
                  </li>
                  <li class="toctree-l1"><a class="reference internal" href="14-Embeddings/README_chs/">嵌入</a>
                  </li>
                  <li class="toctree-l1"><a class="reference internal" href="15-LanguageModeling/README_chs/">语言建模</a>
                  </li>
                  <li class="toctree-l1"><a class="reference internal" href="16-RNN/README_chs/">循环神经网络</a>
                  </li>
                  <li class="toctree-l1"><a class="reference internal" href="17-GenerativeNetworks/README_chs/">生成网络</a>
                  </li>
                  <li class="toctree-l1"><a class="" href="18-Transformers/READMEtransformers_chs">注意机制和Transformer</a>
                  </li>
                  <li class="toctree-l1"><a class="reference internal" href="19-NER/README_chs/">命名实体识别</a>
                  </li>
                  <li class="toctree-l1"><a class="" href="20-LangModels/READMELargeLang_chs">预训练大语言模型</a>
                  </li>
              </ul>
              <p class="caption"><span class="caption-text">其他技术</span></p>
              <ul>
                  <li class="toctree-l1"><a class="reference internal" href="../6-Other/21-GeneticAlgorithms/README_chs/">遗传算法</a>
                  </li>
                  <li class="toctree-l1"><a class="reference internal" href="../6-Other/22-DeepRL/README_chs/">深度强化学习</a>
                  </li>
                  <li class="toctree-l1"><a class="reference internal" href="../6-Other/23-MultiagentSystems/README_chs/">多智能体系统</a>
                  </li>
              </ul>
              <p class="caption"><span class="caption-text">AI伦理</span></p>
              <ul>
                  <li class="toctree-l1"><a class="reference internal" href="../7-Ethics/README_chs/">道德与负责任的人工智能</a>
                  </li>
              </ul>
              <p class="caption"><span class="caption-text">多模态网络</span></p>
              <ul>
                  <li class="toctree-l1"><a class="reference internal" href="../X-Extras/X1-MultiModal/README_chs/">多模态网络</a>
                  </li>
              </ul>
      </div>
    </div>
    </nav>

    <section data-toggle="wy-nav-shift" class="wy-nav-content-wrap">
      <nav class="wy-nav-top" role="navigation" aria-label="Mobile navigation menu">
          <i data-toggle="wy-nav-top" class="fa fa-bars"></i>
          <a href="../..">人工智能初学者课程</a>
        
      </nav>
      <div class="wy-nav-content">
        <div class="rst-content"><div role="navigation" aria-label="breadcrumbs navigation">
  <ul class="wy-breadcrumbs">
    <li><a href="../.." class="icon icon-home" aria-label="Docs"></a></li>
      <li class="breadcrumb-item active">Natural Language Processing</li>
    <li class="wy-breadcrumbs-aside">
    </li>
  </ul>
  <hr/>
</div>
          <div role="main" class="document" itemscope="itemscope" itemtype="http://schema.org/Article">
            <div class="section" itemprop="articleBody">
              
                <h1 id="natural-language-processing">Natural Language Processing</h1>
<p><img alt="Summary of NLP tasks in a doodle" src="../sketchnotes/ai-nlp.png" /></p>
<p>In this section, we will focus on using Neural Networks to handle tasks related to <strong>Natural Language Processing (NLP)</strong>. There are many NLP problems that we want computers to be able to solve:</p>
<ul>
<li><strong>Text classification</strong> is a typical classification problem pertaining to text sequences. Examples include classifying e-mail messages as spam vs. no-spam, or categorizing articles as sport, business, politics, etc. Also, when developing chat bots, we often need to understand what a user wanted to say -- in this case we are dealing with <strong>intent classification</strong>. Often, in intent classification we need to deal with many categories.</li>
<li><strong>Sentiment analysis</strong> is a typical regression problem, where we need to attribute a number (a sentiment) corresponding to how positive/negative the meaning of a sentence is. A more advanced version of sentiment analysis is <strong>aspect-based sentiment analysis</strong> (ABSA), where we attribute sentiment not to the whole sentence, but to different parts of it (aspects), eg. <em>In this restaurant, I liked the cuisine, but the atmosphere was awful</em>.</li>
<li><strong>Named Entity Recognition</strong> (NER) refers to the problem of extracting certain entities from text. For example, we might need to understand that in the phrase <em>I need to fly to Paris tomorrow</em> the word <em>tomorrow</em> refers to DATE, and <em>Paris</em> is a LOCATION.  </li>
<li><strong>Keyword extraction</strong> is similar to NER, but we need to extract words important to the meaning of the sentence automatically, without pre-training for specific entity types.</li>
<li><strong>Text clustering</strong> can be useful when we want to group together similar sentences, for example, similar requests in technical support conversations.</li>
<li><strong>Question answering</strong> refers to the ability of a model to answer a specific question. The model receives a text passage and a question as inputs, and it needs to provide a place in the text where the answer to the question is contained (or, sometimes, to generate the answer text).</li>
<li><strong>Text Generation</strong> is the ability of a model to generate new text. It can be considered as classification task that predicts next letter/word based on some <em>text prompt</em>. Advanced text generation models, such as GPT-3, are able to solve other NLP tasks such as classification using a technique called <a href="https://towardsdatascience.com/software-3-0-how-prompting-will-change-the-rules-of-the-game-a982fbfe1e0">prompt programming</a> or <a href="https://medium.com/swlh/openai-gpt-3-and-prompt-engineering-dcdc2c5fcd29">prompt engineering</a></li>
<li><strong>Text summarization</strong> is a technique when we want a computer to "read" long text and summarize it in a few sentences.</li>
<li><strong>Machine translation</strong> can be viewed as a combination of text understanding in one language, and text generation in another one.</li>
</ul>
<p>Initially, most of NLP tasks were solved using traditional methods such as grammars. For example, in machine translation parsers were used to transform initial sentence into a syntax tree, then higher level semantic structures were extracted to represent the meaning of the sentence, and based on this meaning and grammar of the target language the result was generated. Nowadays, many NLP tasks are more effectively solved using neural networks.</p>
<blockquote>
<p>Many classical NLP methods are implemented in <a href="https://www.nltk.org">Natural Language Processing Toolkit (NLTK)</a> Python library. There is a great <a href="https://www.nltk.org/book/">NLTK Book</a> available online that covers how different NLP tasks can be solved using NLTK.</p>
</blockquote>
<p>In our course, we will mostly focus on using Neural Networks for NLP, and we will use NLTK where needed.</p>
<p>We have already learned about using neural networks for dealing with tabular data and with images. The main difference between those types of data and text is that text is a sequence of variable length, while the input size in case of images is known in advance. While convolutional networks can extract patterns from input data, patterns in text are more complex. Eg., we can have negation being separated from the subject be arbitrary for many words (eg. <em>I do not like oranges</em>, vs. <em>I do not like those big colorful tasty oranges</em>), and that should still be interpreted as one pattern. Thus, to handle language we need to introduce new neural network types, such as <em>recurrent networks</em> and <em>transformers</em>.</p>
<h2 id="install-libraries">Install Libraries</h2>
<p>If you are using local Python installation to run this course, you may need to install all required libraries for NLP using the following commands:</p>
<p><strong>For PyTorch</strong></p>
<pre><code class="language-bash">pip install -r requirements-torch.txt
</code></pre>
<p><strong>For TensorFlow</strong></p>
<pre><code class="language-bash">pip install -r requirements-tf.txt
</code></pre>
<blockquote>
<p>You can try NLP with TensorFlow on <a href="https://docs.microsoft.com/learn/modules/intro-natural-language-processing-tensorflow/?WT.mc_id=academic-77998-cacaste">Microsoft Learn</a></p>
</blockquote>
<h2 id="gpu-warning">GPU Warning</h2>
<p>In this section, in some of the examples we will be training quite large models.
* <strong>Use a GPU-Enabled Computer</strong>: It's advisable to run your notebooks on a GPU-enabled computer to reduce waiting times when working with large models.
* <strong>GPU Memory Constraints</strong>: Running on a GPU may lead to situations where you run out of GPU memory, especially when training large models.
* <strong>GPU Memory Consumption</strong>: The amount of GPU memory consumed during training depends on various factors, including the minibatch size.
* <strong>Minimize Minibatch Size</strong>: If you encounter GPU memory issues, consider reducing the minibatch size in your code as a potential solution.
* <strong>TensorFlow GPU Memory Release</strong>: Older versions of TensorFlow may not release GPU memory correctly when training multiple models within one Python kernel. To manage GPU memory usage effectively, you can configure TensorFlow to allocate GPU memory only as needed.
* <strong>Code Inclusion</strong>: To set TensorFlow to grow GPU memory allocation only when required, include the following code in your notebooks:</p>
<pre><code class="language-python">physical_devices = tf.config.list_physical_devices('GPU') 
if len(physical_devices)&gt;0:
    tf.config.experimental.set_memory_growth(physical_devices[0], True) 
</code></pre>
<p>If you're interested in learning about NLP from a classic ML perspective, visit <a href="https://github.com/microsoft/ML-For-Beginners/tree/main/6-NLP">this suite of lessons</a></p>
<h2 id="in-this-section">In this Section</h2>
<p>In this section we will learn about:</p>
<ul>
<li><a href="13-TextRep/README_chs/">Representing text as tensors</a></li>
<li><a href="14-Emdeddings/README_chs.md">Word Embeddings</a></li>
<li><a href="15-LanguageModeling/README_chs/">Language Modeling</a></li>
<li><a href="16-RNN/README_chs/">Recurrent Neural Networks</a></li>
<li><a href="17-GenerativeNetworks/README_chs/">Generative Networks</a></li>
<li><a href="18-Transformers/README_chs.md">Transformers</a></li>
</ul>
              
            </div>
          </div><footer>

  <hr/>

  <div role="contentinfo">
    <!-- Copyright etc -->
  </div>

  Built with <a href="https://www.mkdocs.org/">MkDocs</a> using a <a href="https://github.com/readthedocs/sphinx_rtd_theme">theme</a> provided by <a href="https://readthedocs.org">Read the Docs</a>.
</footer>
          
        </div>
      </div>

    </section>

  </div>

  <div class="rst-versions" role="note" aria-label="Versions">
  <span class="rst-current-version" data-toggle="rst-current-version">
    
    
    
  </span>
</div>
    <script src="../../js/jquery-3.6.0.min.js"></script>
    <script>var base_url = "../..";</script>
    <script src="../../js/theme_extra.js"></script>
    <script src="../../js/theme.js"></script>
      <script src="../../search/main.js"></script>
    <script>
        jQuery(function () {
            SphinxRtdTheme.Navigation.enable(true);
        });
    </script>

</body>
</html>
