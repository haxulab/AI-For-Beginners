<!DOCTYPE html>
<html class="writer-html5" lang="en" >
<head>
    <meta charset="utf-8" />
    <meta http-equiv="X-UA-Compatible" content="IE=edge" />
    <meta name="viewport" content="width=device-width, initial-scale=1.0" />
      <link rel="shortcut icon" href="../../../img/favicon.ico" />
    <title>Generative networks - 人工智能初学者课程</title>
    <link rel="stylesheet" href="../../../css/theme.css" />
    <link rel="stylesheet" href="../../../css/theme_extra.css" />
        <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/11.8.0/styles/github.min.css" />
    
      <script>
        // Current page data
        var mkdocs_page_name = "Generative networks";
        var mkdocs_page_input_path = "lessons/5-NLP/17-GenerativeNetworks/README.md";
        var mkdocs_page_url = null;
      </script>
    
    <!--[if lt IE 9]>
      <script src="../../../js/html5shiv.min.js"></script>
    <![endif]-->
      <script src="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/11.8.0/highlight.min.js"></script>
      <script>hljs.highlightAll();</script> 
</head>

<body class="wy-body-for-nav" role="document">

  <div class="wy-grid-for-nav">
    <nav data-toggle="wy-nav-shift" class="wy-nav-side stickynav">
    <div class="wy-side-scroll">
      <div class="wy-side-nav-search">
          <a href="../../.." class="icon icon-home"> 人工智能初学者课程
        </a><div role="search">
  <form id ="rtd-search-form" class="wy-form" action="../../../search.html" method="get">
      <input type="text" name="q" placeholder="Search docs" aria-label="Search docs" title="Type search term here" />
  </form>
</div>
      </div>

      <div class="wy-menu wy-menu-vertical" data-spy="affix" role="navigation" aria-label="Navigation menu">
              <ul>
                <li class="toctree-l1"><a class="reference internal" href="../../../README_chs/">课程介绍</a>
                </li>
              </ul>
              <p class="caption"><span class="caption-text">课程设置</span></p>
              <ul>
                  <li class="toctree-l1"><a class="reference internal" href="../../0-course-setup/for-teachers_chs/">给教育者</a>
                  </li>
                  <li class="toctree-l1"><a class="reference internal" href="../../0-course-setup/how-to-run_chs/">如何运行代码</a>
                  </li>
                  <li class="toctree-l1"><a class="reference internal" href="../../0-course-setup/setup_chs/">开始使用这个课程</a>
                  </li>
              </ul>
              <p class="caption"><span class="caption-text">人工智能简介</span></p>
              <ul>
                  <li class="toctree-l1"><a class="reference internal" href="../../1-Intro/README_chs/">人工智能简介</a>
                  </li>
                  <li class="toctree-l1"><a class="reference internal" href="../../1-Intro/assignment_chs/">游戏开发马拉松</a>
                  </li>
              </ul>
              <p class="caption"><span class="caption-text">知识表示与专家系统</span></p>
              <ul>
                  <li class="toctree-l1"><a class="reference internal" href="../../2-Symbolic/README_chs/">知识表示与专家系统</a>
                  </li>
                  <li class="toctree-l1"><a class="reference internal" href="../../2-Symbolic/assignment_chs/">构建一个本体</a>
                  </li>
              </ul>
              <p class="caption"><span class="caption-text">神经网络</span></p>
              <ul>
                  <li class="toctree-l1"><a class="reference internal" href="../../3-NeuralNetworks/README_chs/">神经网络介绍</a>
                  </li>
                  <li class="toctree-l1"><a class="reference internal" href="../../3-NeuralNetworks/03-Perceptron/README_chs/">神经网络入门：感知器</a>
                  </li>
                  <li class="toctree-l1"><a class="reference internal" href="../../3-NeuralNetworks/04-OwnFramework/README_chs/">神经网络介绍. 多层感知器</a>
                  </li>
                  <li class="toctree-l1"><a class="reference internal" href="../../3-NeuralNetworks/05-Frameworks/README_chs/">神经网络框架</a>
                  </li>
              </ul>
              <p class="caption"><span class="caption-text">计算机视觉</span></p>
              <ul>
                  <li class="toctree-l1"><a class="reference internal" href="../../4-ComputerVision/06-IntroCV/README_chs/">计算机视觉简介</a>
                  </li>
                  <li class="toctree-l1"><a class="reference internal" >卷积神经网络</a>
    <ul>
                <li class="toctree-l2"><a class="reference internal" href="../../4-ComputerVision/07-ConvNets/CNN_Architectures_chs/">著名的 CNN 架构</a>
                </li>
                <li class="toctree-l2"><a class="reference internal" href="../../4-ComputerVision/07-ConvNets/README_chs/">卷积神经网络</a>
                </li>
    </ul>
                  </li>
                  <li class="toctree-l1"><a class="reference internal" >迁移学习</a>
    <ul>
                <li class="toctree-l2"><a class="reference internal" href="../../4-ComputerVision/08-TransferLearning/README_chs/">预训练网络和迁移学习</a>
                </li>
                <li class="toctree-l2"><a class="reference internal" href="../../4-ComputerVision/08-TransferLearning/TrainingTricks_chs/">深度学习训练技巧</a>
                </li>
    </ul>
                  </li>
                  <li class="toctree-l1"><a class="reference internal" href="../../4-ComputerVision/09-Autoencoders/README_chs/">自动编码器</a>
                  </li>
                  <li class="toctree-l1"><a class="reference internal" href="../../4-ComputerVision/10-GANs/README_chs/">生成对抗网络</a>
                  </li>
                  <li class="toctree-l1"><a class="reference internal" href="../../4-ComputerVision/11-ObjectDetection/README_chs/">目标检测</a>
                  </li>
                  <li class="toctree-l1"><a class="reference internal" href="../../4-ComputerVision/12-Segmentation/README_chs/">分割</a>
                  </li>
              </ul>
              <p class="caption"><span class="caption-text">自然语言处理</span></p>
              <ul>
                  <li class="toctree-l1"><a class="reference internal" href="../13-TextRep/README_chs/">将文本表示为张量</a>
                  </li>
                  <li class="toctree-l1"><a class="reference internal" href="../14-Embeddings/README_chs/">嵌入</a>
                  </li>
                  <li class="toctree-l1"><a class="reference internal" href="../15-LanguageModeling/README_chs/">语言建模</a>
                  </li>
                  <li class="toctree-l1"><a class="reference internal" href="../16-RNN/README_chs/">循环神经网络</a>
                  </li>
                  <li class="toctree-l1"><a class="reference internal" href="README_chs/">生成网络</a>
                  </li>
                  <li class="toctree-l1"><a class="" href="../18-Transformers/READMEtransformers_chs">注意机制和Transformer</a>
                  </li>
                  <li class="toctree-l1"><a class="reference internal" href="../19-NER/README_chs/">命名实体识别</a>
                  </li>
                  <li class="toctree-l1"><a class="" href="../20-LangModels/READMELargeLang_chs">预训练大语言模型</a>
                  </li>
              </ul>
              <p class="caption"><span class="caption-text">其他技术</span></p>
              <ul>
                  <li class="toctree-l1"><a class="reference internal" href="../../6-Other/21-GeneticAlgorithms/README_chs/">遗传算法</a>
                  </li>
                  <li class="toctree-l1"><a class="reference internal" href="../../6-Other/22-DeepRL/README_chs/">深度强化学习</a>
                  </li>
                  <li class="toctree-l1"><a class="reference internal" href="../../6-Other/23-MultiagentSystems/README_chs/">多智能体系统</a>
                  </li>
              </ul>
              <p class="caption"><span class="caption-text">AI伦理</span></p>
              <ul>
                  <li class="toctree-l1"><a class="reference internal" href="../../7-Ethics/README_chs/">道德与负责任的人工智能</a>
                  </li>
              </ul>
              <p class="caption"><span class="caption-text">多模态网络</span></p>
              <ul>
                  <li class="toctree-l1"><a class="reference internal" href="../../X-Extras/X1-MultiModal/README_chs/">多模态网络</a>
                  </li>
              </ul>
      </div>
    </div>
    </nav>

    <section data-toggle="wy-nav-shift" class="wy-nav-content-wrap">
      <nav class="wy-nav-top" role="navigation" aria-label="Mobile navigation menu">
          <i data-toggle="wy-nav-top" class="fa fa-bars"></i>
          <a href="../../..">人工智能初学者课程</a>
        
      </nav>
      <div class="wy-nav-content">
        <div class="rst-content"><div role="navigation" aria-label="breadcrumbs navigation">
  <ul class="wy-breadcrumbs">
    <li><a href="../../.." class="icon icon-home" aria-label="Docs"></a></li>
      <li class="breadcrumb-item active">Generative networks</li>
    <li class="wy-breadcrumbs-aside">
    </li>
  </ul>
  <hr/>
</div>
          <div role="main" class="document" itemscope="itemscope" itemtype="http://schema.org/Article">
            <div class="section" itemprop="articleBody">
              
                <h1 id="generative-networks">Generative networks</h1>
<h2 id="pre-lecture-quiz"><a href="https://red-field-0a6ddfd03.1.azurestaticapps.net/quiz/117">Pre-lecture quiz</a></h2>
<p>Recurrent Neural Networks (RNNs) and their gated cell variants such as Long Short Term Memory Cells (LSTMs) and Gated Recurrent Units (GRUs) provided a mechanism for language modeling in that they can learn word ordering and provide predictions for the next word in a sequence. This allows us to use RNNs for <strong>generative tasks</strong>, such as ordinary text generation, machine translation, and even image captioning.</p>
<blockquote>
<p>✅ Think about all the times you've benefited from generative tasks such as text completion as you type. Do some research into your favorite applications to see if they leveraged RNNs.</p>
</blockquote>
<p>In RNN architecture we discussed in the previous unit, each RNN unit produced the next hidden state as an output. However, we can also add another output to each recurrent unit, which would allow us to output a <strong>sequence</strong> (which is equal in length to the original sequence). Moreover, we can use RNN units that do not accept an input at each step, and just take some initial state vector, and then produce a sequence of outputs.</p>
<p>This allows for different neural architectures that are shown in the picture below:</p>
<p><img alt="Image showing common recurrent neural network patterns." src="images/unreasonable-effectiveness-of-rnn.jpg" /></p>
<blockquote>
<p>Image from blog post <a href="http://karpathy.github.io/2015/05/21/rnn-effectiveness/">Unreasonable Effectiveness of Recurrent Neural Networks</a> by <a href="http://karpathy.github.io/">Andrej Karpaty</a></p>
</blockquote>
<ul>
<li><strong>One-to-one</strong> is a traditional neural network with one input and one output</li>
<li><strong>One-to-many</strong> is a generative architecture that accepts one input value, and generates a sequence of output values. For example, if we want to train an <strong>image captioning</strong> network that would produce a textual description of a picture, we can a picture as input, pass it through a CNN to obtain its hidden state, and then have a recurrent chain generate caption word-by-word</li>
<li><strong>Many-to-one</strong> corresponds to the RNN architectures we described in the previous unit, such as text classification</li>
<li><strong>Many-to-many</strong>, or <strong>sequence-to-sequence</strong> corresponds to tasks such as <strong>machine translation</strong>, where we have first RNN collect all information from the input sequence into the hidden state, and another RNN chain unrolls this state into the output sequence.</li>
</ul>
<p>In this unit, we will focus on simple generative models that help us generate text. For simplicity, we will use character-level tokenization.</p>
<p>We will train this RNN to generate text step by step. On each step, we will take a sequence of characters of length <code>nchars</code>, and ask the network to generate the next output character for each input character:</p>
<p><img alt="Image showing an example RNN generation of the word 'HELLO'." src="images/rnn-generate.png" /></p>
<p>When generating text (during inference), we start with some <strong>prompt</strong>, which is passed through RNN cells to generate its intermediate state, and then from this state the generation starts. We generate one character at a time, and pass the state and the generated character to another RNN cell to generate the next one, until we generate enough characters.</p>
<p><img src="images/rnn-generate-inf.png" width="60%"/></p>
<blockquote>
<p>Image by the author</p>
</blockquote>
<h2 id="exercises-generative-networks">✍️ Exercises: Generative Networks</h2>
<p>Continue your learning in the following notebooks:</p>
<ul>
<li><a href="GenerativePyTorch.ipynb">Generative Networks with PyTorch</a></li>
<li><a href="GenerativeTF.ipynb">Generative Networks with TensorFlow</a></li>
</ul>
<h2 id="soft-text-generation-and-temperature">Soft text generation and temperature</h2>
<p>The output of each RNN cell is a probability distribution of characters. If we always take the character with the highest probability as the next character in generated text, the text often can become "cycled" between the same character sequences again and again, like in this example:</p>
<pre><code>today of the second the company and a second the company ...
</code></pre>
<p>However, if we look at the probability distribution for the next character, it could be that the difference between a few highest probabilities is not huge, e.g. one character can have probability 0.2, another - 0.19, etc. For example, when looking for the next character in the sequence '<em>play</em>', next character can equally well be either space, or <strong>e</strong> (as in the word <em>player</em>).</p>
<p>This leads us to the conclusion that it is not always "fair" to select the character with a higher probability, because choosing the second highest might still lead us to meaningful text. It is more wise to <strong>sample</strong> characters from the probability distribution given by the network output. We can also use a parameter, <strong>temperature</strong>, that will flatten out the probability distribution, in case we want to add more randomness, or make it more steep, if we want to stick more to the highest-probability characters.</p>
<p>Explore how this soft text generation is implemented in the notebooks linked above.</p>
<h2 id="conclusion">Conclusion</h2>
<p>While text generation may be useful in its own right, the major benefits come from the ability to generate text using RNNs from some initial feature vector. For example, text generation is used as part of machine translation (sequence-to-sequence, in this case state vector from <em>encoder</em> is used to generate or <em>decode</em> translated message), or generating textual description of an image (in which case the feature vector would come from CNN extractor).</p>
<h2 id="challenge">🚀 Challenge</h2>
<p>Take some lessons on Microsoft Learn on this topic</p>
<ul>
<li>Text Generation with <a href="https://docs.microsoft.com/learn/modules/intro-natural-language-processing-pytorch/6-generative-networks/?WT.mc_id=academic-77998-cacaste">PyTorch</a>/<a href="https://docs.microsoft.com/learn/modules/intro-natural-language-processing-tensorflow/5-generative-networks/?WT.mc_id=academic-77998-cacaste">TensorFlow</a></li>
</ul>
<h2 id="post-lecture-quiz"><a href="https://red-field-0a6ddfd03.1.azurestaticapps.net/quiz/217">Post-lecture quiz</a></h2>
<h2 id="review-self-study">Review &amp; Self Study</h2>
<p>Here are some articles to expand your knowledge</p>
<ul>
<li>Different approaches to text generation with Markov Chain, LSTM and GPT-2: <a href="https://towardsdatascience.com/text-generation-gpt-2-lstm-markov-chain-9ea371820e1e">blog post</a></li>
<li>Text generation sample in <a href="https://keras.io/examples/generative/lstm_character_level_text_generation/">Keras documentation</a></li>
</ul>
<h2 id="assignment"><a href="lab/README_chs/">Assignment</a></h2>
<p>We have seen how to generate text character-by-character. In the lab, you will explore word-level text generation.</p>
              
            </div>
          </div><footer>

  <hr/>

  <div role="contentinfo">
    <!-- Copyright etc -->
  </div>

  Built with <a href="https://www.mkdocs.org/">MkDocs</a> using a <a href="https://github.com/readthedocs/sphinx_rtd_theme">theme</a> provided by <a href="https://readthedocs.org">Read the Docs</a>.
</footer>
          
        </div>
      </div>

    </section>

  </div>

  <div class="rst-versions" role="note" aria-label="Versions">
  <span class="rst-current-version" data-toggle="rst-current-version">
    
    
    
  </span>
</div>
    <script src="../../../js/jquery-3.6.0.min.js"></script>
    <script>var base_url = "../../..";</script>
    <script src="../../../js/theme_extra.js"></script>
    <script src="../../../js/theme.js"></script>
      <script src="../../../search/main.js"></script>
    <script>
        jQuery(function () {
            SphinxRtdTheme.Navigation.enable(true);
        });
    </script>

</body>
</html>
