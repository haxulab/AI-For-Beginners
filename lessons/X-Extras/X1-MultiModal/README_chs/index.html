<!DOCTYPE html>
<html class="writer-html5" lang="en" >
<head>
    <meta charset="utf-8" />
    <meta http-equiv="X-UA-Compatible" content="IE=edge" />
    <meta name="viewport" content="width=device-width, initial-scale=1.0" />
      <link rel="shortcut icon" href="../../../../img/favicon.ico" />
    <title>多模态网络 - 人工智能初学者课程</title>
    <link rel="stylesheet" href="../../../../css/theme.css" />
    <link rel="stylesheet" href="../../../../css/theme_extra.css" />
        <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/11.8.0/styles/github.min.css" />
    
      <script>
        // Current page data
        var mkdocs_page_name = "\u591a\u6a21\u6001\u7f51\u7edc";
        var mkdocs_page_input_path = "lessons/X-Extras/X1-MultiModal/README_chs.md";
        var mkdocs_page_url = null;
      </script>
    
    <!--[if lt IE 9]>
      <script src="../../../../js/html5shiv.min.js"></script>
    <![endif]-->
      <script src="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/11.8.0/highlight.min.js"></script>
      <script>hljs.highlightAll();</script> 
</head>

<body class="wy-body-for-nav" role="document">

  <div class="wy-grid-for-nav">
    <nav data-toggle="wy-nav-shift" class="wy-nav-side stickynav">
    <div class="wy-side-scroll">
      <div class="wy-side-nav-search">
          <a href="../../../.." class="icon icon-home"> 人工智能初学者课程
        </a><div role="search">
  <form id ="rtd-search-form" class="wy-form" action="../../../../search.html" method="get">
      <input type="text" name="q" placeholder="Search docs" aria-label="Search docs" title="Type search term here" />
  </form>
</div>
      </div>

      <div class="wy-menu wy-menu-vertical" data-spy="affix" role="navigation" aria-label="Navigation menu">
              <ul>
                <li class="toctree-l1"><a class="reference internal" href="../../../../README_chs/">课程介绍</a>
                </li>
              </ul>
              <p class="caption"><span class="caption-text">课程设置</span></p>
              <ul>
                  <li class="toctree-l1"><a class="reference internal" href="../../../0-course-setup/for-teachers_chs/">给教育者</a>
                  </li>
                  <li class="toctree-l1"><a class="reference internal" href="../../../0-course-setup/how-to-run_chs/">如何运行代码</a>
                  </li>
                  <li class="toctree-l1"><a class="reference internal" href="../../../0-course-setup/setup_chs/">开始使用这个课程</a>
                  </li>
              </ul>
              <p class="caption"><span class="caption-text">人工智能简介</span></p>
              <ul>
                  <li class="toctree-l1"><a class="reference internal" href="../../../1-Intro/README_chs/">人工智能简介</a>
                  </li>
                  <li class="toctree-l1"><a class="reference internal" href="../../../1-Intro/assignment_chs/">游戏开发马拉松</a>
                  </li>
              </ul>
              <p class="caption"><span class="caption-text">知识表示与专家系统</span></p>
              <ul>
                  <li class="toctree-l1"><a class="reference internal" href="../../../2-Symbolic/README_chs/">知识表示与专家系统</a>
                  </li>
                  <li class="toctree-l1"><a class="reference internal" href="../../../2-Symbolic/assignment_chs/">构建一个本体</a>
                  </li>
              </ul>
              <p class="caption"><span class="caption-text">神经网络</span></p>
              <ul>
                  <li class="toctree-l1"><a class="reference internal" href="../../../3-NeuralNetworks/README_chs/">神经网络介绍</a>
                  </li>
                  <li class="toctree-l1"><a class="reference internal" href="../../../3-NeuralNetworks/03-Perceptron/README_chs/">神经网络入门：感知器</a>
                  </li>
                  <li class="toctree-l1"><a class="reference internal" href="../../../3-NeuralNetworks/04-OwnFramework/README_chs/">神经网络介绍. 多层感知器</a>
                  </li>
                  <li class="toctree-l1"><a class="reference internal" href="../../../3-NeuralNetworks/05-Frameworks/README_chs/">神经网络框架</a>
                  </li>
              </ul>
              <p class="caption"><span class="caption-text">计算机视觉</span></p>
              <ul>
                  <li class="toctree-l1"><a class="reference internal" href="../../../4-ComputerVision/06-IntroCV/README_chs/">计算机视觉简介</a>
                  </li>
                  <li class="toctree-l1"><a class="reference internal" >卷积神经网络</a>
    <ul>
                <li class="toctree-l2"><a class="reference internal" href="../../../4-ComputerVision/07-ConvNets/CNN_Architectures_chs/">著名的 CNN 架构</a>
                </li>
                <li class="toctree-l2"><a class="reference internal" href="../../../4-ComputerVision/07-ConvNets/README_chs/">卷积神经网络</a>
                </li>
    </ul>
                  </li>
                  <li class="toctree-l1"><a class="reference internal" >迁移学习</a>
    <ul>
                <li class="toctree-l2"><a class="reference internal" href="../../../4-ComputerVision/08-TransferLearning/README_chs/">预训练网络和迁移学习</a>
                </li>
                <li class="toctree-l2"><a class="reference internal" href="../../../4-ComputerVision/08-TransferLearning/TrainingTricks_chs/">深度学习训练技巧</a>
                </li>
    </ul>
                  </li>
                  <li class="toctree-l1"><a class="reference internal" href="../../../4-ComputerVision/09-Autoencoders/README_chs/">自动编码器</a>
                  </li>
                  <li class="toctree-l1"><a class="reference internal" href="../../../4-ComputerVision/10-GANs/README_chs/">生成对抗网络</a>
                  </li>
                  <li class="toctree-l1"><a class="reference internal" href="../../../4-ComputerVision/11-ObjectDetection/README_chs/">目标检测</a>
                  </li>
                  <li class="toctree-l1"><a class="reference internal" href="../../../4-ComputerVision/12-Segmentation/README_chs/">分割</a>
                  </li>
              </ul>
              <p class="caption"><span class="caption-text">自然语言处理</span></p>
              <ul>
                  <li class="toctree-l1"><a class="reference internal" href="../../../5-NLP/13-TextRep/README_chs/">将文本表示为张量</a>
                  </li>
                  <li class="toctree-l1"><a class="reference internal" href="../../../5-NLP/14-Embeddings/README_chs/">嵌入</a>
                  </li>
                  <li class="toctree-l1"><a class="reference internal" href="../../../5-NLP/15-LanguageModeling/README_chs/">语言建模</a>
                  </li>
                  <li class="toctree-l1"><a class="reference internal" href="../../../5-NLP/16-RNN/README_chs/">循环神经网络</a>
                  </li>
                  <li class="toctree-l1"><a class="reference internal" href="../../../5-NLP/17-GenerativeNetworks/README_chs/">生成网络</a>
                  </li>
                  <li class="toctree-l1"><a class="" href="../../../5-NLP/18-Transformers/READMEtransformers_chs">注意机制和Transformer</a>
                  </li>
                  <li class="toctree-l1"><a class="reference internal" href="../../../5-NLP/19-NER/README_chs/">命名实体识别</a>
                  </li>
                  <li class="toctree-l1"><a class="" href="../../../5-NLP/20-LangModels/READMELargeLang_chs">预训练大语言模型</a>
                  </li>
              </ul>
              <p class="caption"><span class="caption-text">其他技术</span></p>
              <ul>
                  <li class="toctree-l1"><a class="reference internal" href="../../../6-Other/21-GeneticAlgorithms/README_chs/">遗传算法</a>
                  </li>
                  <li class="toctree-l1"><a class="reference internal" href="../../../6-Other/22-DeepRL/README_chs/">深度强化学习</a>
                  </li>
                  <li class="toctree-l1"><a class="reference internal" href="../../../6-Other/23-MultiagentSystems/README_chs/">多智能体系统</a>
                  </li>
              </ul>
              <p class="caption"><span class="caption-text">AI伦理</span></p>
              <ul>
                  <li class="toctree-l1"><a class="reference internal" href="../../../7-Ethics/README_chs/">道德与负责任的人工智能</a>
                  </li>
              </ul>
              <p class="caption"><span class="caption-text">多模态网络</span></p>
              <ul class="current">
                  <li class="toctree-l1 current"><a class="reference internal current" href="#">多模态网络</a>
    <ul class="current">
    <li class="toctree-l2"><a class="reference internal" href="#clip">对比图像预训练（CLIP）</a>
    </li>
    <li class="toctree-l2"><a class="reference internal" href="#clip_1">✍️ 示例： 使用CLIP进行图像分类和图像搜索</a>
    </li>
    <li class="toctree-l2"><a class="reference internal" href="#vqgan-clip">使用VQGAN + CLIP进行图像生成</a>
    </li>
    <li class="toctree-l2"><a class="reference internal" href="#dall-e">DALL-E</a>
        <ul>
    <li class="toctree-l3"><a class="reference internal" href="#dall-e-1">DALL-E 1</a>
    </li>
    <li class="toctree-l3"><a class="reference internal" href="#dall-e-2">DALL-E 2</a>
    </li>
        </ul>
    </li>
    <li class="toctree-l2"><a class="reference internal" href="#_2">参考文献</a>
    </li>
    </ul>
                  </li>
              </ul>
      </div>
    </div>
    </nav>

    <section data-toggle="wy-nav-shift" class="wy-nav-content-wrap">
      <nav class="wy-nav-top" role="navigation" aria-label="Mobile navigation menu">
          <i data-toggle="wy-nav-top" class="fa fa-bars"></i>
          <a href="../../../..">人工智能初学者课程</a>
        
      </nav>
      <div class="wy-nav-content">
        <div class="rst-content"><div role="navigation" aria-label="breadcrumbs navigation">
  <ul class="wy-breadcrumbs">
    <li><a href="../../../.." class="icon icon-home" aria-label="Docs"></a></li>
          <li class="breadcrumb-item">多模态网络</li>
      <li class="breadcrumb-item active">多模态网络</li>
    <li class="wy-breadcrumbs-aside">
    </li>
  </ul>
  <hr/>
</div>
          <div role="main" class="document" itemscope="itemscope" itemtype="http://schema.org/Article">
            <div class="section" itemprop="articleBody">
              
                <h1 id="_1">多模态网络</h1>
<p>在transformer模型成功解决NLP任务之后，同样或相似的架构被应用于计算机视觉任务。现在越来越多的人对构建能够<em>结合</em>视觉和自然语言能力的模型感兴趣。OpenAI对此做了一些尝试，其中一个被称为CLIP和DALL.E。</p>
<h2 id="clip">对比图像预训练（CLIP）</h2>
<p>CLIP的主要思想是能够比较文本提示和图像，并确定图像与提示的对应程度。</p>
<p><img alt="CLIP架构" src="../images/clip-arch.png" /></p>
<blockquote>
<p><em>图片来自<a href="https://openai.com/blog/clip/">这篇博客文章</a></em></p>
</blockquote>
<p>该模型在从互联网上获取的图像及其标题上进行训练。对于每个批次，我们获取N对（图像，文本），并将它们转换为一些向量表示I<sub>1</sub>,..., I<sub>N</sub> / T<sub>1</sub>, ..., T<sub>N</sub>。然后将这些表示匹配在一起。损失函数被定义为最大化对应于一对（例如I<sub>i</sub>和T<sub>i</sub>）的向量之间的余弦相似度，并最小化所有其他对之间的余弦相似度。这就是这种方法被称为<strong>对比</strong>的原因。</p>
<p>CLIP模型/库可以从<a href="https://github.com/openai/CLIP">OpenAI GitHub</a>获取。该方法在<a href="https://openai.com/blog/clip/">这篇博客文章</a>中有所描述，并在<a href="https://arxiv.org/pdf/2103.00020.pdf">这篇论文</a>中有更详细的描述。</p>
<p>一旦这个模型被预训练完成，我们可以给它一个图像批次和一个文本提示批次，它将返回一个包含概率的张量。CLIP可用于多个任务：</p>
<p><strong>图像分类</strong></p>
<p>假设我们需要在猫、狗和人类之间对图像进行分类。在这种情况下，我们可以给模型一个图像，和一系列的文本提示：“<em>一张猫的照片</em>”，“<em>一张狗的照片</em>”，“<em>一张人的照片</em>”。在结果的3个概率向量中，我们只需选择数值最高的索引。</p>
<p><img alt="用于图像分类的CLIP" src="../images/clip-class.png" /></p>
<blockquote>
<p><em>图片来自<a href="https://openai.com/blog/clip/">这篇博客文章</a></em></p>
</blockquote>
<p><strong>基于文本的图像搜索</strong></p>
<p>我们也可以做相反的操作。如果我们有一个图像集合，我们可以将这个集合传递给模型，再加上一个文本提示——这将给我们与所给提示最相似的图像。</p>
<h2 id="clip_1">✍️ 示例： <a href="../Clip.ipynb">使用CLIP进行图像分类和图像搜索</a></h2>
<p>打开<a href="../Clip.ipynb">Clip.ipynb</a>笔记本，看看CLIP的实际应用。</p>
<h2 id="vqgan-clip">使用VQGAN + CLIP进行图像生成</h2>
<p>CLIP还可以用于从文本提示生成<strong>图像</strong>。为此，我们需要一个<strong>生成器模型</strong>，它能够根据一些向量输入生成图像。这样的模型之一称为<a href="https://compvis.github.io/taming-transformers/">VQGAN</a>（矢量量化GAN）。</p>
<p>VQGAN区别于普通<a href="../../../4-ComputerVision/10-GANs/README_chs/">GAG</a>的主要思想如下：
* 使用自回归transformer架构生成组成图像的情境丰富的视觉序列。这些视觉部分由<a href="../../../4-ComputerVision/07-ConvNets/README_chs/">CNN</a>学习。
* 使用子图像判别器检测图像部分是“真实”还是“伪造”的（与传统GAN的“全或不全”方法不同）。</p>
<p>通过访问<a href="https://compvis.github.io/taming-transformers/">Taming Transformers</a>网站了解更多关于VQGAN的信息。</p>
<p>VQGAN与传统GAN的一个重要区别是，后者可以从任何输入向量生成一张不错的图像，而VQGAN则可能生成不连贯的图像。因此，我们需要进一步指导图像创建过程，这可以通过CLIP来完成。</p>
<p><img alt="VQGAN+CLIP架构" src="../images/vqgan.png" /></p>
<p>为了生成与文本提示相对应的图像，我们首先从一些随机编码向量开始，经过VQGAN生成图像。然后使用CLIP产生一个损失函数，显示图像与文本提示的对应程度。然后的目标是通过反向传播调整输入向量参数，以最小化该损失。</p>
<p>一个实现VQGAN+CLIP的极佳库是<a href="http://github.com/pixray/pixray">Pixray</a></p>
<table>
<thead>
<tr>
<th><img alt="由Pixray生成的图片" src="../images/a_closeup_watercolor_portrait_of_young_male_teacher_of_literature_with_a_book.png" /></th>
<th><img alt="由pixray生成的图片" src="../images/a_closeup_oil_portrait_of_young_female_teacher_of_computer_science_with_a_computer.png" /></th>
<th><img alt="由Pixray生成的图片" src="../images/a_closeup_oil_portrait_of_old_male_teacher_of_math.png" /></th>
</tr>
</thead>
<tbody>
<tr>
<td>根据提示<em>一张年轻男老师手持书本的近距离水彩肖像</em>生成的图片</td>
<td>根据提示<em>一张年轻女计算机科学老师手旁电脑的近距离油画肖像</em>生成的图片</td>
<td>根据提示<em>一张老年男数学老师站在黑板前的近距离油画肖像</em>生成的图片</td>
</tr>
</tbody>
</table>
<blockquote>
<p>图片来自<a href="http://soshnikov.com">Dmitry Soshnikov</a>的<strong>人工教师</strong>系列</p>
</blockquote>
<h2 id="dall-e">DALL-E</h2>
<h3 id="dall-e-1"><a href="https://openai.com/research/dall-e">DALL-E 1</a></h3>
<p>DALL-E是一个版本的GPT-3，用于从提示中生成图像。它经过了具有120亿参数的训练。</p>
<p>不同于CLIP，DALL-E同时接收文本和图像作为单一的令牌流。因此，在多个提示中，你可以根据文本生成图像。</p>
<h3 id="dall-e-2"><a href="https://openai.com/dall-e-2">DALL-E 2</a></h3>
<p>DALL.E 1和2之间的主要区别是，DALL-E 2生成的图像和艺术作品更加逼真。</p>
<p>使用DALL-E生成的图像示例：
<img alt="由Pixray生成的图片" src="../images/DALL%C2%B7E%202023-06-20%2015.56.56%20-%20a%20closeup%20watercolor%20portrait%20of%20young%20male%20teacher%20of%20literature%20with%20a%20book.png" /> |  <img alt="由pixray生成的图片" src="../images/DALL%C2%B7E%202023-06-20%2015.57.43%20-%20a%20closeup%20oil%20portrait%20of%20young%20female%20teacher%20of%20computer%20science%20with%20a%20computer.png" /> | <img alt="由Pixray生成的图片" src="../images/DALL%C2%B7E%202023-06-20%2015.58.42%20-%20%20a%20closeup%20oil%20portrait%20of%20old%20male%20teacher%20of%20mathematics%20in%20front%20of%20blackboard.png" />
----|----|----
根据提示<em>一张年轻男文学老师手持书本的近距离水彩肖像</em>生成的图片 | 根据提示<em>一张年轻女计算机科学老师手旁电脑的近距离油画肖像</em>生成的图片 | 根据提示<em>一张老年男数学老师站在黑板前的近距离油画肖像</em>生成的图片</p>
<h2 id="_2">参考文献</h2>
<ul>
<li>VQGAN论文：<a href="https://compvis.github.io/taming-transformers/paper/paper.pdf">用于高分辨率图像合成的驯化transformer</a></li>
<li>CLIP论文：<a href="https://arxiv.org/pdf/2103.00020.pdf">从自然语言监督中学习可转移的视觉模型</a></li>
</ul>
              
            </div>
          </div><footer>
    <div class="rst-footer-buttons" role="navigation" aria-label="Footer Navigation">
        <a href="../../../7-Ethics/README_chs/" class="btn btn-neutral float-left" title="道德与负责任的人工智能"><span class="icon icon-circle-arrow-left"></span> Previous</a>
    </div>

  <hr/>

  <div role="contentinfo">
    <!-- Copyright etc -->
  </div>

  Built with <a href="https://www.mkdocs.org/">MkDocs</a> using a <a href="https://github.com/readthedocs/sphinx_rtd_theme">theme</a> provided by <a href="https://readthedocs.org">Read the Docs</a>.
</footer>
          
        </div>
      </div>

    </section>

  </div>

  <div class="rst-versions" role="note" aria-label="Versions">
  <span class="rst-current-version" data-toggle="rst-current-version">
    
    
      <span><a href="../../../7-Ethics/README_chs/" style="color: #fcfcfc">&laquo; Previous</a></span>
    
    
  </span>
</div>
    <script src="../../../../js/jquery-3.6.0.min.js"></script>
    <script>var base_url = "../../../..";</script>
    <script src="../../../../js/theme_extra.js"></script>
    <script src="../../../../js/theme.js"></script>
      <script src="../../../../search/main.js"></script>
    <script>
        jQuery(function () {
            SphinxRtdTheme.Navigation.enable(true);
        });
    </script>

</body>
</html>
