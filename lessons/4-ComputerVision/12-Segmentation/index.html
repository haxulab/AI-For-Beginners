<!DOCTYPE html>
<html class="writer-html5" lang="en" >
<head>
    <meta charset="utf-8" />
    <meta http-equiv="X-UA-Compatible" content="IE=edge" />
    <meta name="viewport" content="width=device-width, initial-scale=1.0" />
      <link rel="shortcut icon" href="../../../img/favicon.ico" />
    <title>Segmentation - äººå·¥æ™ºèƒ½åˆå­¦è€…è¯¾ç¨‹</title>
    <link rel="stylesheet" href="../../../css/theme.css" />
    <link rel="stylesheet" href="../../../css/theme_extra.css" />
        <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/11.8.0/styles/github.min.css" />
    
      <script>
        // Current page data
        var mkdocs_page_name = "Segmentation";
        var mkdocs_page_input_path = "lessons/4-ComputerVision/12-Segmentation/README.md";
        var mkdocs_page_url = null;
      </script>
    
    <!--[if lt IE 9]>
      <script src="../../../js/html5shiv.min.js"></script>
    <![endif]-->
      <script src="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/11.8.0/highlight.min.js"></script>
      <script>hljs.highlightAll();</script> 
</head>

<body class="wy-body-for-nav" role="document">

  <div class="wy-grid-for-nav">
    <nav data-toggle="wy-nav-shift" class="wy-nav-side stickynav">
    <div class="wy-side-scroll">
      <div class="wy-side-nav-search">
          <a href="../../.." class="icon icon-home"> äººå·¥æ™ºèƒ½åˆå­¦è€…è¯¾ç¨‹
        </a><div role="search">
  <form id ="rtd-search-form" class="wy-form" action="../../../search.html" method="get">
      <input type="text" name="q" placeholder="Search docs" aria-label="Search docs" title="Type search term here" />
  </form>
</div>
      </div>

      <div class="wy-menu wy-menu-vertical" data-spy="affix" role="navigation" aria-label="Navigation menu">
              <ul>
                <li class="toctree-l1"><a class="reference internal" href="../../../README_chs/">è¯¾ç¨‹ä»‹ç»</a>
                </li>
              </ul>
              <p class="caption"><span class="caption-text">è¯¾ç¨‹è®¾ç½®</span></p>
              <ul>
                  <li class="toctree-l1"><a class="reference internal" href="../../0-course-setup/for-teachers_chs/">ç»™æ•™è‚²è€…</a>
                  </li>
                  <li class="toctree-l1"><a class="reference internal" href="../../0-course-setup/how-to-run_chs/">å¦‚ä½•è¿è¡Œä»£ç </a>
                  </li>
                  <li class="toctree-l1"><a class="reference internal" href="../../0-course-setup/setup_chs/">å¼€å§‹ä½¿ç”¨è¿™ä¸ªè¯¾ç¨‹</a>
                  </li>
              </ul>
              <p class="caption"><span class="caption-text">äººå·¥æ™ºèƒ½ç®€ä»‹</span></p>
              <ul>
                  <li class="toctree-l1"><a class="reference internal" href="../../1-Intro/README_chs/">äººå·¥æ™ºèƒ½ç®€ä»‹</a>
                  </li>
                  <li class="toctree-l1"><a class="reference internal" href="../../1-Intro/assignment_chs/">æ¸¸æˆå¼€å‘é©¬æ‹‰æ¾</a>
                  </li>
              </ul>
              <p class="caption"><span class="caption-text">çŸ¥è¯†è¡¨ç¤ºä¸ä¸“å®¶ç³»ç»Ÿ</span></p>
              <ul>
                  <li class="toctree-l1"><a class="reference internal" href="../../2-Symbolic/README_chs/">çŸ¥è¯†è¡¨ç¤ºä¸ä¸“å®¶ç³»ç»Ÿ</a>
                  </li>
                  <li class="toctree-l1"><a class="reference internal" href="../../2-Symbolic/assignment_chs/">æ„å»ºä¸€ä¸ªæœ¬ä½“</a>
                  </li>
              </ul>
              <p class="caption"><span class="caption-text">ç¥ç»ç½‘ç»œ</span></p>
              <ul>
                  <li class="toctree-l1"><a class="reference internal" href="../../3-NeuralNetworks/README_chs/">ç¥ç»ç½‘ç»œä»‹ç»</a>
                  </li>
                  <li class="toctree-l1"><a class="reference internal" href="../../3-NeuralNetworks/03-Perceptron/README_chs/">ç¥ç»ç½‘ç»œå…¥é—¨ï¼šæ„ŸçŸ¥å™¨</a>
                  </li>
                  <li class="toctree-l1"><a class="reference internal" href="../../3-NeuralNetworks/04-OwnFramework/README_chs/">ç¥ç»ç½‘ç»œä»‹ç». å¤šå±‚æ„ŸçŸ¥å™¨</a>
                  </li>
                  <li class="toctree-l1"><a class="reference internal" href="../../3-NeuralNetworks/05-Frameworks/README_chs/">ç¥ç»ç½‘ç»œæ¡†æ¶</a>
                  </li>
              </ul>
              <p class="caption"><span class="caption-text">è®¡ç®—æœºè§†è§‰</span></p>
              <ul>
                  <li class="toctree-l1"><a class="reference internal" href="../06-IntroCV/README_chs/">è®¡ç®—æœºè§†è§‰ç®€ä»‹</a>
                  </li>
                  <li class="toctree-l1"><a class="reference internal" >å·ç§¯ç¥ç»ç½‘ç»œ</a>
    <ul>
                <li class="toctree-l2"><a class="reference internal" href="../07-ConvNets/CNN_Architectures_chs/">è‘—åçš„ CNN æ¶æ„</a>
                </li>
                <li class="toctree-l2"><a class="reference internal" href="../07-ConvNets/README_chs/">å·ç§¯ç¥ç»ç½‘ç»œ</a>
                </li>
    </ul>
                  </li>
                  <li class="toctree-l1"><a class="reference internal" >è¿ç§»å­¦ä¹ </a>
    <ul>
                <li class="toctree-l2"><a class="reference internal" href="../08-TransferLearning/README_chs/">é¢„è®­ç»ƒç½‘ç»œå’Œè¿ç§»å­¦ä¹ </a>
                </li>
                <li class="toctree-l2"><a class="reference internal" href="../08-TransferLearning/TrainingTricks_chs/">æ·±åº¦å­¦ä¹ è®­ç»ƒæŠ€å·§</a>
                </li>
    </ul>
                  </li>
                  <li class="toctree-l1"><a class="reference internal" href="../09-Autoencoders/README_chs/">è‡ªåŠ¨ç¼–ç å™¨</a>
                  </li>
                  <li class="toctree-l1"><a class="reference internal" href="../10-GANs/README_chs/">ç”Ÿæˆå¯¹æŠ—ç½‘ç»œ</a>
                  </li>
                  <li class="toctree-l1"><a class="reference internal" href="../11-ObjectDetection/README_chs/">ç›®æ ‡æ£€æµ‹</a>
                  </li>
                  <li class="toctree-l1"><a class="reference internal" href="README_chs/">åˆ†å‰²</a>
                  </li>
              </ul>
              <p class="caption"><span class="caption-text">è‡ªç„¶è¯­è¨€å¤„ç†</span></p>
              <ul>
                  <li class="toctree-l1"><a class="reference internal" href="../../5-NLP/13-TextRep/README_chs/">å°†æ–‡æœ¬è¡¨ç¤ºä¸ºå¼ é‡</a>
                  </li>
                  <li class="toctree-l1"><a class="reference internal" href="../../5-NLP/14-Embeddings/README_chs/">åµŒå…¥</a>
                  </li>
                  <li class="toctree-l1"><a class="reference internal" href="../../5-NLP/15-LanguageModeling/README_chs/">è¯­è¨€å»ºæ¨¡</a>
                  </li>
                  <li class="toctree-l1"><a class="reference internal" href="../../5-NLP/16-RNN/README_chs/">å¾ªç¯ç¥ç»ç½‘ç»œ</a>
                  </li>
                  <li class="toctree-l1"><a class="reference internal" href="../../5-NLP/17-GenerativeNetworks/README_chs/">ç”Ÿæˆç½‘ç»œ</a>
                  </li>
                  <li class="toctree-l1"><a class="" href="../../5-NLP/18-Transformers/READMEtransformers_chs">æ³¨æ„æœºåˆ¶å’ŒTransformer</a>
                  </li>
                  <li class="toctree-l1"><a class="reference internal" href="../../5-NLP/19-NER/README_chs/">å‘½åå®ä½“è¯†åˆ«</a>
                  </li>
                  <li class="toctree-l1"><a class="" href="../../5-NLP/20-LangModels/READMELargeLang_chs">é¢„è®­ç»ƒå¤§è¯­è¨€æ¨¡å‹</a>
                  </li>
              </ul>
              <p class="caption"><span class="caption-text">å…¶ä»–æŠ€æœ¯</span></p>
              <ul>
                  <li class="toctree-l1"><a class="reference internal" href="../../6-Other/21-GeneticAlgorithms/README_chs/">é—ä¼ ç®—æ³•</a>
                  </li>
                  <li class="toctree-l1"><a class="reference internal" href="../../6-Other/22-DeepRL/README_chs/">æ·±åº¦å¼ºåŒ–å­¦ä¹ </a>
                  </li>
                  <li class="toctree-l1"><a class="reference internal" href="../../6-Other/23-MultiagentSystems/README_chs/">å¤šæ™ºèƒ½ä½“ç³»ç»Ÿ</a>
                  </li>
              </ul>
              <p class="caption"><span class="caption-text">AIä¼¦ç†</span></p>
              <ul>
                  <li class="toctree-l1"><a class="reference internal" href="../../7-Ethics/README_chs/">é“å¾·ä¸è´Ÿè´£ä»»çš„äººå·¥æ™ºèƒ½</a>
                  </li>
              </ul>
              <p class="caption"><span class="caption-text">å¤šæ¨¡æ€ç½‘ç»œ</span></p>
              <ul>
                  <li class="toctree-l1"><a class="reference internal" href="../../X-Extras/X1-MultiModal/README_chs/">å¤šæ¨¡æ€ç½‘ç»œ</a>
                  </li>
              </ul>
      </div>
    </div>
    </nav>

    <section data-toggle="wy-nav-shift" class="wy-nav-content-wrap">
      <nav class="wy-nav-top" role="navigation" aria-label="Mobile navigation menu">
          <i data-toggle="wy-nav-top" class="fa fa-bars"></i>
          <a href="../../..">äººå·¥æ™ºèƒ½åˆå­¦è€…è¯¾ç¨‹</a>
        
      </nav>
      <div class="wy-nav-content">
        <div class="rst-content"><div role="navigation" aria-label="breadcrumbs navigation">
  <ul class="wy-breadcrumbs">
    <li><a href="../../.." class="icon icon-home" aria-label="Docs"></a></li>
      <li class="breadcrumb-item active">Segmentation</li>
    <li class="wy-breadcrumbs-aside">
    </li>
  </ul>
  <hr/>
</div>
          <div role="main" class="document" itemscope="itemscope" itemtype="http://schema.org/Article">
            <div class="section" itemprop="articleBody">
              
                <h1 id="segmentation">Segmentation</h1>
<p>We have previously learned about Object Detection, which allows us to locate objects in the image by predicting their <em>bounding boxes</em>. However, for some tasks we do not only need bounding boxes, but also more precise object localization. This task is called  <strong>segmentation</strong>.</p>
<h2 id="pre-lecture-quiz"><a href="https://red-field-0a6ddfd03.1.azurestaticapps.net/quiz/112">Pre-lecture quiz</a></h2>
<p>Segmentation can be viewed as <strong>pixel classification</strong>, whereas for <strong>each</strong> pixel of image we must predict its class (<em>background</em> being one of the classes). There are two main segmentation algorithms:</p>
<ul>
<li><strong>Semantic segmentation</strong> only tells the pixel class, and does not make a distinction between different objects of the same class</li>
<li><strong>Instance segmentation</strong> divides classes into different instances.</li>
</ul>
<p>For instance segmentation, these sheep are different objects, but for semantic segmentation all sheep are represented by one class.</p>
<p><img src="images/instance_vs_semantic.jpeg" width="50%"></p>
<blockquote>
<p>Image from <a href="https://nirmalamurali.medium.com/image-classification-vs-semantic-segmentation-vs-instance-segmentation-625c33a08d50">this blog post</a></p>
</blockquote>
<p>There are different neural architectures for segmentation, but they all have the same structure. In a way, it is similar to the autoencoder you learned about previously, but instead of deconstructing the original image, our goal is to deconstruct a <strong>mask</strong>. Thus, a segmentation network has the following parts:</p>
<ul>
<li><strong>Encoder</strong> extracts features from input image</li>
<li><strong>Decoder</strong> transforms those features into the <strong>mask image</strong>, with the same size and number of channels corresponding to the number of classes.</li>
</ul>
<p><img src="images/segm.png" width="80%"></p>
<blockquote>
<p>Image from <a href="https://arxiv.org/pdf/2001.05566.pdf">this publication</a></p>
</blockquote>
<p>We should especially mention the loss function that is used for segmentation. When using classical autoencoders, we need to measure the similarity between two images, and we can use mean square error (MSE) to do that. In segmentation, each pixel in the target mask image represents the class number (one-hot-encoded along the third dimension), so we need to use loss functions specific for classification - cross-entropy loss, averaged over all pixels. If the mask is binary - <strong>binary cross-entropy loss</strong> (BCE) is used.</p>
<blockquote>
<p>âœ… One-hot encoding is a way to encode a class label into a vector of length equal to the number of classes. Take a look at <a href="https://datagy.io/sklearn-one-hot-encode/">this article</a> on this technique.</p>
</blockquote>
<h2 id="segmentation-for-medical-imaging">Segmentation for Medical Imaging</h2>
<p>In this lesson, we will see the segmentation in action by training the network to recognize human nevi (also known as moles) on medical images. We will be using <a href="https://www.fc.up.pt/addi/ph2%20database.html">PH<sup>2</sup> Database</a> of dermoscopy images as the image source. This dataset contains 200 images of three classes: typical nevus, atypical nevus, and melanoma. All images also contain a corresponding <strong>mask</strong> that outlines the nevus.</p>
<blockquote>
<p>âœ… This technique is particularly appropriate for this type of medical imaging, but what other real-world applications could you envision?</p>
</blockquote>
<p><img alt="navi" src="images/navi.png"/></p>
<blockquote>
<p>Image from the PH<sup>2</sup> Database</p>
</blockquote>
<p>We will train a model to segment any nevus from its background.</p>
<h2 id="exercises-semantic-segmentation">âœï¸ Exercises: Semantic Segmentation</h2>
<p>Open the notebooks below to learn more about different semantic segmentation architectures, practice working with them, and see them in action.</p>
<ul>
<li><a href="SemanticSegmentationPytorch.ipynb">Semantic Segmentation Pytorch</a></li>
<li><a href="SemanticSegmentationTF.ipynb">Semantic Segmentation TensorFlow</a></li>
</ul>
<h2 id="post-lecture-quiz"><a href="https://red-field-0a6ddfd03.1.azurestaticapps.net/quiz/212">Post-lecture quiz</a></h2>
<h2 id="conclusion">Conclusion</h2>
<p>Segmentation is a very powerful technique for image classification, moving beyond bounding boxes to pixel-level classification. It is a technique used in medical imaging, among other applications.</p>
<h2 id="challenge">ğŸš€ Challenge</h2>
<p>Body segmentation is just one of the common tasks that we can do with images of people. Another important tasks include <strong>skeleton detection</strong> and <strong>pose detection</strong>. Try out <a href="https://github.com/CMU-Perceptual-Computing-Lab/openpose">OpenPose</a> library to see how pose detection can be used.</p>
<h2 id="review-self-study">Review &amp; Self Study</h2>
<p>This <a href="https://wikipedia.org/wiki/Image_segmentation">wikipedia article</a> offers a good overview of the various applications of this technique. Learn more on your own about the subdomains of Instance segmentation and Panoptic segmentation in this field of inquiry.</p>
<h2 id="assignment"><a href="lab/README_chs/">Assignment</a></h2>
<p>In this lab, try <strong>human body segmentation</strong> using <a href="https://www.kaggle.com/datasets/tapakah68/segmentation-full-body-mads-dataset">Segmentation Full Body MADS Dataset</a> from Kaggle.</p>
              
            </div>
          </div><footer>

  <hr/>

  <div role="contentinfo">
    <!-- Copyright etc -->
  </div>

  Built with <a href="https://www.mkdocs.org/">MkDocs</a> using a <a href="https://github.com/readthedocs/sphinx_rtd_theme">theme</a> provided by <a href="https://readthedocs.org">Read the Docs</a>.
</footer>
          
        </div>
      </div>

    </section>

  </div>

  <div class="rst-versions" role="note" aria-label="Versions">
  <span class="rst-current-version" data-toggle="rst-current-version">
    
    
    
  </span>
</div>
    <script src="../../../js/jquery-3.6.0.min.js"></script>
    <script>var base_url = "../../..";</script>
    <script src="../../../js/theme_extra.js"></script>
    <script src="../../../js/theme.js"></script>
      <script src="../../../search/main.js"></script>
    <script>
        jQuery(function () {
            SphinxRtdTheme.Navigation.enable(true);
        });
    </script>

</body>
</html>
