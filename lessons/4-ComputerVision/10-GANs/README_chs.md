# 生成对抗网络

在前一节中，我们了解了**生成模型**：可以生成与训练数据集中的图像相似的新图像的模型。VAE 是生成模型的一个很好的例子。

## [课程前测验](https://red-field-0a6ddfd03.1.azurestaticapps.net/quiz/110)

然而，如果我们尝试使用 VAE 生成一些真正有意义的东西，比如合理分辨率的绘画，我们会发现训练并不收敛。对于这种情况，我们需要学习另一种专门针对生成模型的架构——**生成对抗网络（Generative Adversarial Networks, GANs）**。

GAN 的主要想法是让两个神经网络相互对抗进行训练：

<img src="images/gan_architecture.png" width="70%"/>

> 图片来自 [Dmitry Soshnikov](http://soshnikov.com)

> ✅ 一些术语：
> * **生成器**是一个网络，它接受一些随机向量，并生成图像作为结果
> * **判别器**是一个网络，可以判断输入的图像是真实图像（来自训练数据集）还是生成器生成的图像。它本质上是一个图像分类器。

### 判别器

判别器的架构与普通的图像分类网络没有区别。在最简单的情况下，它可以是一个全连接分类器，但更可能的是一个[卷积网络](../07-ConvNets/README.md)。

> ✅ 一个基于卷积网络的 GAN 被称为 [DCGAN](https://arxiv.org/pdf/1511.06434.pdf)

CNN 判别器由以下层组成：几个卷积+池化层（具有递减的空间尺寸），和一个或多个全连接层来获得“特征向量”，最终的二分类器。

> ✅ 在此上下文中的“池化”是一种减小图像大小的技术。“池化层通过将某一层的神经元簇输出组合成下一层中的一个神经元，来减少数据维度。” - [来源](https://wikipedia.org/wiki/Convolutional_neural_network#Pooling_layers)

### 生成器

生成器稍微有些复杂。你可以将其视为一个反向的判别器。从潜在向量（代替特征向量）开始，它具有一个全连接层，将其转换为所需的大小/形状，随后是反卷积+上采样。这类似于[自编码器](../09-Autoencoders/README.md)的*解码器*部分。

> ✅ 因为卷积层作为遍历图像的线性滤波器被实现，反卷积本质上类似于卷积，可以使用相同的层逻辑来实现。

<img src="images/gan_arch_detail.png" width="70%"/>

> 图片来自 [Dmitry Soshnikov](http://soshnikov.com)

### 训练GAN

GAN 被称为**对抗性**，因为生成器和判别器之间始终存在竞争。在这种竞争中，生成器和判别器都在不断改进，从而使网络学会生成越来越好的图片。

训练分为两个阶段：

* **训练判别器**。这个任务相当简单：我们用生成器生成一批图像，标记为 0，表示假图像，再从输入数据集中取一批图像（标记为 1，真实图像）。我们获得一些*判别器损失*，并进行反向传播。
* **训练生成器**。这稍微有些复杂，因为我们不知道生成器的期望输出。我们取一个由生成器后跟判别器组成的整个 GAN 网络，用一些随机向量喂给它，并期望结果为 1（对应于真实图像）。然后我们冻结判别器的参数（不希望在此步骤对其进行训练），并进行反向传播。

在此过程中，生成器和判别器的损失并不会显著下降。在理想情况下，它们应该振荡，对应于两个网络都在提高其性能。

## ✍️ 练习：GANs

* [TensorFlow/Keras 中的 GAN 笔记本](GANTF.ipynb)
* [PyTorch 中的 GAN 笔记本](GANPyTorch.ipynb)

### GAN训练的问题

GANs 特别难以训练。以下是一些问题：

* **模式崩溃**。这个术语指的是生成器学会生成一种成功欺骗判别器的图像，而不是各种不同的图像。
* **对超参数的敏感性**。你可能会发现 GAN 根本不收敛，然后突然由于学习率的减少而收敛。
* 保持**生成器和判别器之间的平衡**。在许多情况下，判别器的损失可能会相对较快地降到零，这导致生成器无法进一步训练。为了解决这个问题，我们可以尝试为生成器和判别器设置不同的学习率，或者如果损失已经太低则跳过判别器训练。
* 训练**高分辨率**。与自编码器有相同的问题，当重建包含太多卷积层的网络会导致伪像。这个问题通常通过所谓的**逐步生长**来解决，首先在低分辨率图像上训练几层，然后“解锁”或添加层。另一种解决方法是增加层之间的额外连接并同时训练多个分辨率，详见这篇[多尺度梯度 GANs 论文](https://arxiv.org/abs/1903.06048)。

## 风格迁移

GAN对于生成艺术图像非常有效。另一种有趣的技术是所谓的**风格迁移**，它将一个**内容图像**重新绘制成不同的风格，应用于**风格图像**中的滤镜。

它的工作方式如下：
* 我们从一个随机噪声图像开始（或者从一个内容图像开始，但为了理解，我们更容易从随机噪声开始）
* 我们的目标是创建一个既接近内容图像又接近风格图像的图像。这通过两个损失函数来确定：
   - **内容损失**是基于 CNN 在某些层级从当前图像和内容图像中提取的特征来计算的
   - **风格损失**巧妙地使用 Gram 矩阵在当前图像和风格图像之间计算（更多详情在[示例笔记本](StyleTransfer.ipynb)中）
* 为了使图像更平滑并消除噪声，我们还引入了**变分损失**，它计算邻近像素之间的平均距离
* 主优化循环使用梯度下降（或其他一些优化算法）调整当前图像，以最小化总损失，总损失是所有三种损失的加权总和。

## ✍️ 示例：[风格迁移](StyleTransfer.ipynb)

## [课程后测验](https://red-field-0a6ddfd03.1.azurestaticapps.net/quiz/210)

## 结论

在本课中，你了解了 GAN 及其训练方法。你还了解了这种类型的神经网络可能面临的特殊挑战，以及一些应对策略。

## 🚀 挑战

使用你自己的图像运行[风格迁移笔记本](StyleTransfer.ipynb)。

## 复习与自学

有关 GAN 的更多参考，请阅读以下资源：

* Marco Pasini， [《我训练 GAN 一年中学到的 10 个教训》](https://towardsdatascience.com/10-lessons-i-learned-training-generative-adversarial-networks-gans-for-a-year-c9071159628)
* [StyleGAN](https://en.wikipedia.org/wiki/StyleGAN)，一个实际可考虑的 GAN 架构
* [在 Azure ML 上使用 GAN 创建生成艺术](https://soshnikov.com/scienceart/creating-generative-art-using-gan-on-azureml/)

## 作业

重温与本课相关的两个笔记本之一，并在你自己的图像上重新训练 GAN。你能创造什么？