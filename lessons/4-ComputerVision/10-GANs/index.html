<!DOCTYPE html>
<html class="writer-html5" lang="en" >
<head>
    <meta charset="utf-8" />
    <meta http-equiv="X-UA-Compatible" content="IE=edge" />
    <meta name="viewport" content="width=device-width, initial-scale=1.0" />
      <link rel="shortcut icon" href="../../../img/favicon.ico" />
    <title>Generative Adversarial Networks - 人工智能初学者课程</title>
    <link rel="stylesheet" href="../../../css/theme.css" />
    <link rel="stylesheet" href="../../../css/theme_extra.css" />
        <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/11.8.0/styles/github.min.css" />
    
      <script>
        // Current page data
        var mkdocs_page_name = "Generative Adversarial Networks";
        var mkdocs_page_input_path = "lessons/4-ComputerVision/10-GANs/README.md";
        var mkdocs_page_url = null;
      </script>
    
    <!--[if lt IE 9]>
      <script src="../../../js/html5shiv.min.js"></script>
    <![endif]-->
      <script src="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/11.8.0/highlight.min.js"></script>
      <script>hljs.highlightAll();</script> 
</head>

<body class="wy-body-for-nav" role="document">

  <div class="wy-grid-for-nav">
    <nav data-toggle="wy-nav-shift" class="wy-nav-side stickynav">
    <div class="wy-side-scroll">
      <div class="wy-side-nav-search">
          <a href="../../.." class="icon icon-home"> 人工智能初学者课程
        </a><div role="search">
  <form id ="rtd-search-form" class="wy-form" action="../../../search.html" method="get">
      <input type="text" name="q" placeholder="Search docs" aria-label="Search docs" title="Type search term here" />
  </form>
</div>
      </div>

      <div class="wy-menu wy-menu-vertical" data-spy="affix" role="navigation" aria-label="Navigation menu">
              <ul>
                <li class="toctree-l1"><a class="reference internal" href="../../../README_chs/">课程介绍</a>
                </li>
              </ul>
              <p class="caption"><span class="caption-text">课程设置</span></p>
              <ul>
                  <li class="toctree-l1"><a class="reference internal" href="../../0-course-setup/for-teachers_chs/">给教育者</a>
                  </li>
                  <li class="toctree-l1"><a class="reference internal" href="../../0-course-setup/how-to-run_chs/">如何运行代码</a>
                  </li>
                  <li class="toctree-l1"><a class="reference internal" href="../../0-course-setup/setup_chs/">开始使用这个课程</a>
                  </li>
              </ul>
              <p class="caption"><span class="caption-text">人工智能简介</span></p>
              <ul>
                  <li class="toctree-l1"><a class="reference internal" href="../../1-Intro/README_chs/">人工智能简介</a>
                  </li>
                  <li class="toctree-l1"><a class="reference internal" href="../../1-Intro/assignment_chs/">游戏开发马拉松</a>
                  </li>
              </ul>
              <p class="caption"><span class="caption-text">知识表示与专家系统</span></p>
              <ul>
                  <li class="toctree-l1"><a class="reference internal" href="../../2-Symbolic/README_chs/">知识表示与专家系统</a>
                  </li>
                  <li class="toctree-l1"><a class="reference internal" href="../../2-Symbolic/assignment_chs/">构建一个本体</a>
                  </li>
              </ul>
              <p class="caption"><span class="caption-text">神经网络</span></p>
              <ul>
                  <li class="toctree-l1"><a class="reference internal" href="../../3-NeuralNetworks/README_chs/">神经网络介绍</a>
                  </li>
                  <li class="toctree-l1"><a class="reference internal" href="../../3-NeuralNetworks/03-Perceptron/README_chs/">神经网络入门：感知器</a>
                  </li>
                  <li class="toctree-l1"><a class="reference internal" href="../../3-NeuralNetworks/04-OwnFramework/README_chs/">神经网络介绍. 多层感知器</a>
                  </li>
                  <li class="toctree-l1"><a class="reference internal" href="../../3-NeuralNetworks/05-Frameworks/README_chs/">神经网络框架</a>
                  </li>
              </ul>
              <p class="caption"><span class="caption-text">计算机视觉</span></p>
              <ul>
                  <li class="toctree-l1"><a class="reference internal" href="../06-IntroCV/README_chs/">计算机视觉简介</a>
                  </li>
                  <li class="toctree-l1"><a class="reference internal" >卷积神经网络</a>
    <ul>
                <li class="toctree-l2"><a class="reference internal" href="../07-ConvNets/CNN_Architectures_chs/">著名的 CNN 架构</a>
                </li>
                <li class="toctree-l2"><a class="reference internal" href="../07-ConvNets/README_chs/">卷积神经网络</a>
                </li>
    </ul>
                  </li>
                  <li class="toctree-l1"><a class="reference internal" >迁移学习</a>
    <ul>
                <li class="toctree-l2"><a class="reference internal" href="../08-TransferLearning/README_chs/">预训练网络和迁移学习</a>
                </li>
                <li class="toctree-l2"><a class="reference internal" href="../08-TransferLearning/TrainingTricks_chs/">深度学习训练技巧</a>
                </li>
    </ul>
                  </li>
                  <li class="toctree-l1"><a class="reference internal" href="../09-Autoencoders/README_chs/">自动编码器</a>
                  </li>
                  <li class="toctree-l1"><a class="reference internal" href="README_chs/">生成对抗网络</a>
                  </li>
                  <li class="toctree-l1"><a class="reference internal" href="../11-ObjectDetection/README_chs/">目标检测</a>
                  </li>
                  <li class="toctree-l1"><a class="reference internal" href="../12-Segmentation/README_chs/">分割</a>
                  </li>
              </ul>
              <p class="caption"><span class="caption-text">自然语言处理</span></p>
              <ul>
                  <li class="toctree-l1"><a class="reference internal" href="../../5-NLP/13-TextRep/README_chs/">将文本表示为张量</a>
                  </li>
                  <li class="toctree-l1"><a class="reference internal" href="../../5-NLP/14-Embeddings/README_chs/">嵌入</a>
                  </li>
                  <li class="toctree-l1"><a class="reference internal" href="../../5-NLP/15-LanguageModeling/README_chs/">语言建模</a>
                  </li>
                  <li class="toctree-l1"><a class="reference internal" href="../../5-NLP/16-RNN/README_chs/">循环神经网络</a>
                  </li>
                  <li class="toctree-l1"><a class="reference internal" href="../../5-NLP/17-GenerativeNetworks/README_chs/">生成网络</a>
                  </li>
                  <li class="toctree-l1"><a class="" href="../../5-NLP/18-Transformers/READMEtransformers_chs">注意机制和Transformer</a>
                  </li>
                  <li class="toctree-l1"><a class="reference internal" href="../../5-NLP/19-NER/README_chs/">命名实体识别</a>
                  </li>
                  <li class="toctree-l1"><a class="" href="../../5-NLP/20-LangModels/READMELargeLang_chs">预训练大语言模型</a>
                  </li>
              </ul>
              <p class="caption"><span class="caption-text">其他技术</span></p>
              <ul>
                  <li class="toctree-l1"><a class="reference internal" href="../../6-Other/21-GeneticAlgorithms/README_chs/">遗传算法</a>
                  </li>
                  <li class="toctree-l1"><a class="reference internal" href="../../6-Other/22-DeepRL/README_chs/">深度强化学习</a>
                  </li>
                  <li class="toctree-l1"><a class="reference internal" href="../../6-Other/23-MultiagentSystems/README_chs/">多智能体系统</a>
                  </li>
              </ul>
              <p class="caption"><span class="caption-text">AI伦理</span></p>
              <ul>
                  <li class="toctree-l1"><a class="reference internal" href="../../7-Ethics/README_chs/">道德与负责任的人工智能</a>
                  </li>
              </ul>
              <p class="caption"><span class="caption-text">多模态网络</span></p>
              <ul>
                  <li class="toctree-l1"><a class="reference internal" href="../../X-Extras/X1-MultiModal/README_chs/">多模态网络</a>
                  </li>
              </ul>
      </div>
    </div>
    </nav>

    <section data-toggle="wy-nav-shift" class="wy-nav-content-wrap">
      <nav class="wy-nav-top" role="navigation" aria-label="Mobile navigation menu">
          <i data-toggle="wy-nav-top" class="fa fa-bars"></i>
          <a href="../../..">人工智能初学者课程</a>
        
      </nav>
      <div class="wy-nav-content">
        <div class="rst-content"><div role="navigation" aria-label="breadcrumbs navigation">
  <ul class="wy-breadcrumbs">
    <li><a href="../../.." class="icon icon-home" aria-label="Docs"></a></li>
      <li class="breadcrumb-item active">Generative Adversarial Networks</li>
    <li class="wy-breadcrumbs-aside">
    </li>
  </ul>
  <hr/>
</div>
          <div role="main" class="document" itemscope="itemscope" itemtype="http://schema.org/Article">
            <div class="section" itemprop="articleBody">
              
                <h1 id="generative-adversarial-networks">Generative Adversarial Networks</h1>
<p>In the previous section, we learned about <strong>generative models</strong>: models that can generate new images similar to the ones in the training dataset. VAE was a good example of a generative model.</p>
<h2 id="pre-lecture-quiz"><a href="https://red-field-0a6ddfd03.1.azurestaticapps.net/quiz/110">Pre-lecture quiz</a></h2>
<p>However, if we try to generate something really meaningful, like a painting at reasonable resolution, with VAE, we will see that training does not converge well. For this use case, we should learn about another architecture specifically targeted at generative models - <strong>Generative Adversarial Networks</strong>, or GANs.</p>
<p>The main idea of a GAN is to have two neural networks that will be trained against each other:</p>
<p><img src="images/gan_architecture.png" width="70%"/></p>
<blockquote>
<p>Image by <a href="http://soshnikov.com">Dmitry Soshnikov</a></p>
<p>✅ A little vocabulary:
* <strong>Generator</strong> is a network that takes some random vector, and produces the image as a result
* <strong>Discriminator</strong> is a network that takes an image, and it should tell whether it is a real image (from training dataset), or it was generated by a generator. It is essentially an image classifier.</p>
</blockquote>
<h3 id="discriminator">Discriminator</h3>
<p>The architecture of discriminator does not differ from an ordinary image classification network. In the simplest case it can be fully-connected classifier, but most probably it will be a <a href="../07-ConvNets/README_chs/">convolutional network</a>.</p>
<blockquote>
<p>✅ A GAN based on convolutional networks is called a <a href="https://arxiv.org/pdf/1511.06434.pdf">DCGAN</a></p>
</blockquote>
<p>A CNN discriminator consists of the following layers: several convolutions+poolings (with decreasing spatial size) and, one-or-more fully-connected layers to get "feature vector", final binary classifier.</p>
<blockquote>
<p>✅ A 'pooling' in this context is a technique that reduces the size of the image. "Pooling layers reduce the dimensions of data by combining the outputs of neuron clusters at one layer into a single neuron in the next layer." - <a href="https://wikipedia.org/wiki/Convolutional_neural_network#Pooling_layers">source</a></p>
</blockquote>
<h3 id="generator">Generator</h3>
<p>A Generator is slightly more tricky. You can consider it to be a reversed discriminator. Starting from a latent vector (in place of a feature vector), it has a fully-connected layer to convert it into the required size/shape, followed by deconvolutions+upscaling. This is similar to <em>decoder</em> part of <a href="../09-Autoencoders/README_chs/">autoencoder</a>.</p>
<blockquote>
<p>✅ Because the convolution layer is implemented as a linear filter traversing the image, deconvolution is essentially similar to convolution, and can be implemented using the same layer logic.</p>
</blockquote>
<p><img src="images/gan_arch_detail.png" width="70%"/></p>
<blockquote>
<p>Image by <a href="http://soshnikov.com">Dmitry Soshnikov</a></p>
</blockquote>
<h3 id="training-the-gan">Training the GAN</h3>
<p>GANs are called <strong>adversarial</strong> because there is a constant competition between the generator and the discriminator. During this competition, both generator and discriminator improve, thus the network learns to produce better and better pictures.</p>
<p>The training happens in two stages:</p>
<ul>
<li><strong>Training the discriminator</strong>. This task is pretty straightforward: we generate a batch of images by the generator, labeling them 0, which stands for fake image, and taking a batch of images from the input dataset (with label 1, real image). We obtain some <em>discriminator loss</em>, and perform backprop.</li>
<li><strong>Training the generator</strong>. This is slightly more tricky, because we do not know the expected output for the generator directly. We take the whole GAN network consisting of a generator followed by discriminator, feed it with some random vectors, and expect the result to be 1 (corresponding to real images). We then freeze the parameters of the discriminator (we do not want it to be trained at this step), and perform the backprop.</li>
</ul>
<p>During this process, both the generator and the discriminator losses are not going down significantly. In the ideal situation, they should oscillate, corresponding to both networks improving their performance.</p>
<h2 id="exercises-gans">✍️ Exercises: GANs</h2>
<ul>
<li><a href="GANTF.ipynb">GAN Notebook in TensorFlow/Keras</a></li>
<li><a href="GANPyTorch.ipynb">GAN Notebook in PyTorch</a></li>
</ul>
<h3 id="problems-with-gan-training">Problems with GAN training</h3>
<p>GANs are known to be especially difficult to train. Here are a few problems:</p>
<ul>
<li><strong>Mode Collapse</strong>. By this term we mean that the generator learns to produce one successful image that tricks the generator, and not a variety of different images.</li>
<li><strong>Sensitivity to hyperparameters</strong>. Often you can see that a GAN does not converge at all, and then suddenly decreases in the learning rate leading to convergence.</li>
<li>Keeping a <strong>balance</strong> between the generator and the discriminator. In many cases discriminator loss can drop to zero relatively quickly, which results in the generator being unable to train further. To overcome this, we can try setting different learning rates for the generator and discriminator, or skip discriminator training if the loss is already too low.</li>
<li>Training for <strong>high resolution</strong>. Reflecting the same problem as with autoencoders, this problem is triggered because reconstructing too many layers of convolutional network leads to artifacts. This problem is typically solved with so-called <strong>progressive growing</strong>, when first a few layers are trained on low-res images, and then layers are "unblocked" or added. Another solution would be adding extra connections between layers and training several resolutions at once - see this <a href="https://arxiv.org/abs/1903.06048">Multi-Scale Gradient GANs paper</a> for details.</li>
</ul>
<h2 id="style-transfer">Style Transfer</h2>
<p>GANs is a great way to generate artistic images. Another interesting technique is so-called <strong>style transfer</strong>, which takes one <strong>content image</strong>, and re-draws it in a different style, applying filters from <strong>style image</strong>. </p>
<p>The way it works is the following:
* We start with a random noise image (or with a content image, but for the sake of understanding it is easier to start from random noise)
* Our goal would be to create such an image, that would be close to both content image and style image. This would be determined by two loss functions:
   - <strong>Content loss</strong> is computed based on the features extracted by the CNN at some layers from current image and content image
   - <strong>Style loss</strong> is computed between current image and style image in a clever way using Gram matrices (more details in the <a href="StyleTransfer.ipynb">example notebook</a>)
* To make the image smoother and remove noise, we also introduce <strong>Variation loss</strong>, which computes average distance between neighboring pixels
* The main optimization loop adjusts current image using gradient descent (or some other optimization algorithm) to minimize the total loss, which is a weighted sum of all three losses. </p>
<h2 id="example-style-transfer">✍️ Example: <a href="StyleTransfer.ipynb">Style Transfer</a></h2>
<h2 id="post-lecture-quiz"><a href="https://red-field-0a6ddfd03.1.azurestaticapps.net/quiz/210">Post-lecture quiz</a></h2>
<h2 id="conclusion">Conclusion</h2>
<p>In this lesson, you learned about GANS and how to train them. You also learned about the special challenges that this type of Neural Network can face, and some strategies on how to move past them.</p>
<h2 id="challenge">🚀 Challenge</h2>
<p>Run through the <a href="StyleTransfer.ipynb">Style Transfer notebook</a> using your own images.</p>
<h2 id="review-self-study">Review &amp; Self Study</h2>
<p>For reference, read more about GANs in these resources:</p>
<ul>
<li>Marco Pasini, <a href="https://towardsdatascience.com/10-lessons-i-learned-training-generative-adversarial-networks-gans-for-a-year-c9071159628">10 Lessons I Learned Training GANs for one Year</a></li>
<li><a href="https://en.wikipedia.org/wiki/StyleGAN">StyleGAN</a>, a <em>de facto</em> GAN architecture to consider</li>
<li><a href="https://soshnikov.com/scienceart/creating-generative-art-using-gan-on-azureml/">Creating Generative Art using GANs on Azure ML</a></li>
</ul>
<h2 id="assignment">Assignment</h2>
<p>Revisit one of the two notebooks associated to this lesson and retrain the GAN on your own images. What can you create?</p>
              
            </div>
          </div><footer>

  <hr/>

  <div role="contentinfo">
    <!-- Copyright etc -->
  </div>

  Built with <a href="https://www.mkdocs.org/">MkDocs</a> using a <a href="https://github.com/readthedocs/sphinx_rtd_theme">theme</a> provided by <a href="https://readthedocs.org">Read the Docs</a>.
</footer>
          
        </div>
      </div>

    </section>

  </div>

  <div class="rst-versions" role="note" aria-label="Versions">
  <span class="rst-current-version" data-toggle="rst-current-version">
    
    
    
  </span>
</div>
    <script src="../../../js/jquery-3.6.0.min.js"></script>
    <script>var base_url = "../../..";</script>
    <script src="../../../js/theme_extra.js"></script>
    <script src="../../../js/theme.js"></script>
      <script src="../../../search/main.js"></script>
    <script>
        jQuery(function () {
            SphinxRtdTheme.Navigation.enable(true);
        });
    </script>

</body>
</html>
