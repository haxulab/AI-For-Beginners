<!DOCTYPE html>
<html class="writer-html5" lang="en" >
<head>
    <meta charset="utf-8" />
    <meta http-equiv="X-UA-Compatible" content="IE=edge" />
    <meta name="viewport" content="width=device-width, initial-scale=1.0" />
      <link rel="shortcut icon" href="../../../img/favicon.ico" />
    <title>Introduction to Computer Vision - 人工智能初学者课程</title>
    <link rel="stylesheet" href="../../../css/theme.css" />
    <link rel="stylesheet" href="../../../css/theme_extra.css" />
        <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/11.8.0/styles/github.min.css" />
    
      <script>
        // Current page data
        var mkdocs_page_name = "Introduction to Computer Vision";
        var mkdocs_page_input_path = "lessons/4-ComputerVision/06-IntroCV/README.md";
        var mkdocs_page_url = null;
      </script>
    
    <!--[if lt IE 9]>
      <script src="../../../js/html5shiv.min.js"></script>
    <![endif]-->
      <script src="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/11.8.0/highlight.min.js"></script>
      <script>hljs.highlightAll();</script> 
</head>

<body class="wy-body-for-nav" role="document">

  <div class="wy-grid-for-nav">
    <nav data-toggle="wy-nav-shift" class="wy-nav-side stickynav">
    <div class="wy-side-scroll">
      <div class="wy-side-nav-search">
          <a href="../../.." class="icon icon-home"> 人工智能初学者课程
        </a><div role="search">
  <form id ="rtd-search-form" class="wy-form" action="../../../search.html" method="get">
      <input type="text" name="q" placeholder="Search docs" aria-label="Search docs" title="Type search term here" />
  </form>
</div>
      </div>

      <div class="wy-menu wy-menu-vertical" data-spy="affix" role="navigation" aria-label="Navigation menu">
              <ul>
                <li class="toctree-l1"><a class="reference internal" href="../../../README_chs/">课程介绍</a>
                </li>
              </ul>
              <p class="caption"><span class="caption-text">课程设置</span></p>
              <ul>
                  <li class="toctree-l1"><a class="reference internal" href="../../0-course-setup/for-teachers_chs/">给教育者</a>
                  </li>
                  <li class="toctree-l1"><a class="reference internal" href="../../0-course-setup/how-to-run_chs/">如何运行代码</a>
                  </li>
                  <li class="toctree-l1"><a class="reference internal" href="../../0-course-setup/setup_chs/">开始使用这个课程</a>
                  </li>
              </ul>
              <p class="caption"><span class="caption-text">人工智能简介</span></p>
              <ul>
                  <li class="toctree-l1"><a class="reference internal" href="../../1-Intro/README_chs/">人工智能简介</a>
                  </li>
                  <li class="toctree-l1"><a class="reference internal" href="../../1-Intro/assignment_chs/">游戏开发马拉松</a>
                  </li>
              </ul>
              <p class="caption"><span class="caption-text">知识表示与专家系统</span></p>
              <ul>
                  <li class="toctree-l1"><a class="reference internal" href="../../2-Symbolic/README_chs/">知识表示与专家系统</a>
                  </li>
                  <li class="toctree-l1"><a class="reference internal" href="../../2-Symbolic/assignment_chs/">构建一个本体</a>
                  </li>
              </ul>
              <p class="caption"><span class="caption-text">神经网络</span></p>
              <ul>
                  <li class="toctree-l1"><a class="reference internal" href="../../3-NeuralNetworks/README_chs/">神经网络介绍</a>
                  </li>
                  <li class="toctree-l1"><a class="reference internal" href="../../3-NeuralNetworks/03-Perceptron/README_chs/">神经网络入门：感知器</a>
                  </li>
                  <li class="toctree-l1"><a class="reference internal" href="../../3-NeuralNetworks/04-OwnFramework/README_chs/">神经网络介绍. 多层感知器</a>
                  </li>
                  <li class="toctree-l1"><a class="reference internal" href="../../3-NeuralNetworks/05-Frameworks/README_chs/">神经网络框架</a>
                  </li>
              </ul>
              <p class="caption"><span class="caption-text">计算机视觉</span></p>
              <ul>
                  <li class="toctree-l1"><a class="reference internal" href="README_chs/">计算机视觉简介</a>
                  </li>
                  <li class="toctree-l1"><a class="reference internal" >卷积神经网络</a>
    <ul>
                <li class="toctree-l2"><a class="reference internal" href="../07-ConvNets/CNN_Architectures_chs/">著名的 CNN 架构</a>
                </li>
                <li class="toctree-l2"><a class="reference internal" href="../07-ConvNets/README_chs/">卷积神经网络</a>
                </li>
    </ul>
                  </li>
                  <li class="toctree-l1"><a class="reference internal" >迁移学习</a>
    <ul>
                <li class="toctree-l2"><a class="reference internal" href="../08-TransferLearning/README_chs/">预训练网络和迁移学习</a>
                </li>
                <li class="toctree-l2"><a class="reference internal" href="../08-TransferLearning/TrainingTricks_chs/">深度学习训练技巧</a>
                </li>
    </ul>
                  </li>
                  <li class="toctree-l1"><a class="reference internal" href="../09-Autoencoders/README_chs/">自动编码器</a>
                  </li>
                  <li class="toctree-l1"><a class="reference internal" href="../10-GANs/README_chs/">生成对抗网络</a>
                  </li>
                  <li class="toctree-l1"><a class="reference internal" href="../11-ObjectDetection/README_chs/">目标检测</a>
                  </li>
                  <li class="toctree-l1"><a class="reference internal" href="../12-Segmentation/README_chs/">分割</a>
                  </li>
              </ul>
              <p class="caption"><span class="caption-text">自然语言处理</span></p>
              <ul>
                  <li class="toctree-l1"><a class="reference internal" href="../../5-NLP/13-TextRep/README_chs/">将文本表示为张量</a>
                  </li>
                  <li class="toctree-l1"><a class="reference internal" href="../../5-NLP/14-Embeddings/README_chs/">嵌入</a>
                  </li>
                  <li class="toctree-l1"><a class="reference internal" href="../../5-NLP/15-LanguageModeling/README_chs/">语言建模</a>
                  </li>
                  <li class="toctree-l1"><a class="reference internal" href="../../5-NLP/16-RNN/README_chs/">循环神经网络</a>
                  </li>
                  <li class="toctree-l1"><a class="reference internal" href="../../5-NLP/17-GenerativeNetworks/README_chs/">生成网络</a>
                  </li>
                  <li class="toctree-l1"><a class="" href="../../5-NLP/18-Transformers/READMEtransformers_chs">注意机制和Transformer</a>
                  </li>
                  <li class="toctree-l1"><a class="reference internal" href="../../5-NLP/19-NER/README_chs/">命名实体识别</a>
                  </li>
                  <li class="toctree-l1"><a class="" href="../../5-NLP/20-LangModels/READMELargeLang_chs">预训练大语言模型</a>
                  </li>
              </ul>
              <p class="caption"><span class="caption-text">其他技术</span></p>
              <ul>
                  <li class="toctree-l1"><a class="reference internal" href="../../6-Other/21-GeneticAlgorithms/README_chs/">遗传算法</a>
                  </li>
                  <li class="toctree-l1"><a class="reference internal" href="../../6-Other/22-DeepRL/README_chs/">深度强化学习</a>
                  </li>
                  <li class="toctree-l1"><a class="reference internal" href="../../6-Other/23-MultiagentSystems/README_chs/">多智能体系统</a>
                  </li>
              </ul>
              <p class="caption"><span class="caption-text">AI伦理</span></p>
              <ul>
                  <li class="toctree-l1"><a class="reference internal" href="../../7-Ethics/README_chs/">道德与负责任的人工智能</a>
                  </li>
              </ul>
              <p class="caption"><span class="caption-text">多模态网络</span></p>
              <ul>
                  <li class="toctree-l1"><a class="reference internal" href="../../X-Extras/X1-MultiModal/README_chs/">多模态网络</a>
                  </li>
              </ul>
      </div>
    </div>
    </nav>

    <section data-toggle="wy-nav-shift" class="wy-nav-content-wrap">
      <nav class="wy-nav-top" role="navigation" aria-label="Mobile navigation menu">
          <i data-toggle="wy-nav-top" class="fa fa-bars"></i>
          <a href="../../..">人工智能初学者课程</a>
        
      </nav>
      <div class="wy-nav-content">
        <div class="rst-content"><div role="navigation" aria-label="breadcrumbs navigation">
  <ul class="wy-breadcrumbs">
    <li><a href="../../.." class="icon icon-home" aria-label="Docs"></a></li>
      <li class="breadcrumb-item active">Introduction to Computer Vision</li>
    <li class="wy-breadcrumbs-aside">
    </li>
  </ul>
  <hr/>
</div>
          <div role="main" class="document" itemscope="itemscope" itemtype="http://schema.org/Article">
            <div class="section" itemprop="articleBody">
              
                <h1 id="introduction-to-computer-vision">Introduction to Computer Vision</h1>
<p><a href="https://wikipedia.org/wiki/Computer_vision">Computer Vision</a> is a discipline whose aim is to allow computers to gain high-level understanding of digital images. This is quite a broad definition, because <em>understanding</em> can mean many different things, including finding an object on a picture (<strong>object detection</strong>), understanding what is happening (<strong>event detection</strong>), describing a picture in text, or reconstructing a scene in 3D. There are also special tasks related to human images: age and emotion estimation, face detection and identification, and 3D pose estimation, to name a few.</p>
<h2 id="pre-lecture-quiz"><a href="https://red-field-0a6ddfd03.1.azurestaticapps.net/quiz/106">Pre-lecture quiz</a></h2>
<p>One of the simplest tasks of computer vision is <strong>image classification</strong>.</p>
<p>Computer vision is often considered to be a branch of AI. Nowadays, most of computer vision tasks are solved using neural networks. We will learn more about the special type of neural networks used for computer vision, <a href="../07-ConvNets/README_chs/">convolutional neural networks</a>, throughout this section.</p>
<p>However, before you pass the image to a neural network, in many cases it makes sense to use some algorithmic techniques to enhance the image.</p>
<p>There are several Python libraries available for image processing:</p>
<ul>
<li><strong><a href="https://imageio.readthedocs.io/en/stable/">imageio</a></strong> can be used for reading/writing different image formats. It also support ffmpeg, a useful tool to convert video frames to images.</li>
<li><strong><a href="https://pillow.readthedocs.io/en/stable/index.html">Pillow</a></strong> (also known as PIL) is a bit more powerful, and also supports some image manipulation such as morphing, palette adjustments, and more.</li>
<li><strong><a href="https://opencv.org/">OpenCV</a></strong> is a powerful image processing library written in C++, which has become the <em>de facto</em> standard for image processing. It has a convenient Python interface.</li>
<li><strong><a href="http://dlib.net/">dlib</a></strong> is a C++ library that implements many machine learning algorithms, including some of the Computer Vision algorithms. It also has a Python interface, and can be used for challenging tasks such as face and facial landmark detection.</li>
</ul>
<h2 id="opencv">OpenCV</h2>
<p><a href="https://opencv.org/">OpenCV</a> is considered to be the <em>de facto</em> standard for image processing. It contains a lot of useful algorithms, implemented in C++. You can call OpenCV from Python as well.</p>
<p>A good place to learn OpenCV is <a href="https://learnopencv.com/getting-started-with-opencv/">this Learn OpenCV course</a>. In our curriculum, our goal is not to learn OpenCV, but to show you some examples when it can be used, and how.</p>
<h3 id="loading-images">Loading Images</h3>
<p>Images in Python can be conveniently represented by NumPy arrays. For example, grayscale images with the size of 320x200 pixels would be stored in a 200x320 array, and color images of the same dimension would have shape of 200x320x3 (for 3 color channels). To load an image, you can use the following code:</p>
<pre><code class="language-python">import cv2
import matplotlib.pyplot as plt

im = cv2.imread('image.jpeg')
plt.imshow(im)
</code></pre>
<p>Traditionally, OpenCV uses BGR (Blue-Green-Red) encoding for color images, while the rest of Python tools use the more traditional RGB (Red-Green-Blue). For the image to look right, you need to convert it to the RGB color space, either by swapping dimensions in the NumPy array, or by calling an OpenCV function:</p>
<pre><code class="language-python">im = cv2.cvtColor(im,cv2.COLOR_BGR2RGB)
</code></pre>
<p>The same <code>cvtColor</code> function can be used to perform other color space transformations such as converting an image to grayscale or to the HSV (Hue-Saturation-Value) color space.</p>
<p>You can also use OpenCV to load video frame-by-frame - an example is given in the exercise <a href="OpenCV.ipynb">OpenCV Notebook</a>.</p>
<h3 id="image-processing">Image Processing</h3>
<p>Before feeding an image to a neural network, you may want to apply several pre-processing steps. OpenCV can do many things, including:</p>
<ul>
<li><strong>Resizing</strong> the image using <code>im = cv2.resize(im, (320,200),interpolation=cv2.INTER_LANCZOS)</code></li>
<li><strong>Blurring</strong> the image using <code>im = cv2.medianBlur(im,3)</code> or <code>im = cv2.GaussianBlur(im, (3,3), 0)</code></li>
<li>Changing the <strong>brightness and contrast</strong> of the image can be done by NumPy array manipulations, as described <a href="https://stackoverflow.com/questions/39308030/how-do-i-increase-the-contrast-of-an-image-in-python-opencv">in this Stackoverflow note</a>.</li>
<li>Using <a href="https://docs.opencv.org/4.x/d7/d4d/tutorial_py_thresholding.html">thresholding</a> by calling <code>cv2.threshold</code>/<code>cv2.adaptiveThreshold</code> functions, which is often preferable to adjusting brightness or contrast.</li>
<li>Applying different <a href="https://docs.opencv.org/4.5.5/da/d6e/tutorial_py_geometric_transformations.html">transformations</a> to the image:<ul>
<li><strong><a href="https://docs.opencv.org/4.5.5/d4/d61/tutorial_warp_affine.html">Affine transformations</a></strong> can be useful if you need to combine rotation, resizing and skewing to the image and you know the source and destination location of three points in the image. Affine transformations keep parallel lines parallel.</li>
<li><strong><a href="https://medium.com/analytics-vidhya/opencv-perspective-transformation-9edffefb2143">Perspective transformations</a></strong> can be useful when you know the source and destination positions of 4 points in the image. For example, if you take a picture of a rectangular document via a smartphone camera from some angle, and you want to make a rectangular image of the document itself.</li>
</ul>
</li>
<li>Understanding movement inside the image by using <strong><a href="https://docs.opencv.org/4.5.5/d4/dee/tutorial_optical_flow.html">optical flow</a></strong>.</li>
</ul>
<h2 id="examples-of-using-computer-vision">Examples of using Computer Vision</h2>
<p>In our <a href="OpenCV.ipynb">OpenCV Notebook</a>, we give some examples of when computer vision can be used to perform specific tasks:</p>
<ul>
<li><strong>Pre-processing a photograph of a Braille book</strong>. We focus on how we can use thresholding, feature detection, perspective transformation and NumPy manipulations to separate individual Braille symbols for further classification by a neural network.</li>
</ul>
<table>
<thead>
<tr>
<th><img alt="Braille Image" src="data/braille.jpeg" /></th>
<th><img alt="Braille Image Pre-processed" src="images/braille-result.png" /></th>
<th><img alt="Braille Symbols" src="images/braille-symbols.png" /></th>
</tr>
</thead>
<tbody>
<tr>
<td></td>
<td></td>
<td></td>
</tr>
</tbody>
</table>
<blockquote>
<p>Image from <a href="OpenCV.ipynb">OpenCV.ipynb</a></p>
</blockquote>
<ul>
<li><strong>Detecting motion in video using frame difference</strong>. If the camera is fixed, then frames from the camera feed should be pretty similar to each other. Since frames are represented as arrays, just by subtracting those arrays for two subsequent frames we will get the pixel difference, which should be low for static frames, and become higher once there is substantial motion in the image.</li>
</ul>
<p><img alt="Image of video frames and frame differences" src="images/frame-difference.png" /></p>
<blockquote>
<p>Image from <a href="OpenCV.ipynb">OpenCV.ipynb</a></p>
</blockquote>
<ul>
<li>
<p><strong>Detecting motion using Optical Flow</strong>. <a href="https://docs.opencv.org/3.4/d4/dee/tutorial_optical_flow.html">Optical flow</a> allows us to understand how individual pixels on video frames move. There are two types of optical flow:</p>
</li>
<li>
<p><strong>Dense Optical Flow</strong> computes the vector field that shows for each pixel where is it moving</p>
</li>
<li><strong>Sparse Optical Flow</strong> is based on taking some distinctive features in the image (eg. edges), and building their trajectory from frame to frame.</li>
</ul>
<p><img alt="Image of Optical Flow" src="images/optical.png" /></p>
<blockquote>
<p>Image from <a href="OpenCV.ipynb">OpenCV.ipynb</a></p>
</blockquote>
<h2 id="example-notebooks-opencv-try-opencv-in-action">✍️ Example Notebooks: OpenCV <a href="OpenCV.ipynb">try OpenCV in Action</a></h2>
<p>Let's do some experiments with OpenCV by exploring <a href="OpenCV.ipynb">OpenCV Notebook</a></p>
<h2 id="conclusion">Conclusion</h2>
<p>Sometimes, relatively complex tasks such as movement detection or fingertip detection can be solved purely by computer vision. Thus, it is very helpful to know the basic techniques of computer vision, and what libraries like OpenCV can do.</p>
<h2 id="challenge">🚀 Challenge</h2>
<p>Watch <a href="https://docs.microsoft.com/shows/ai-show/ai-show--2021-opencv-ai-competition--grand-prize-winners--cortic-tigers--episode-32?WT.mc_id=academic-77998-cacaste">this video</a> from the AI show to learn about the Cortic Tigers project and how they built a block-based solution to democratize computer vision tasks via a robot. Do some research on other projects like this that help onboard new learners into the field.</p>
<h2 id="post-lecture-quiz"><a href="https://red-field-0a6ddfd03.1.azurestaticapps.net/quiz/206">Post-lecture quiz</a></h2>
<h2 id="review-self-study">Review &amp; Self Study</h2>
<p>Read more on optical flow <a href="https://learnopencv.com/optical-flow-in-opencv/">in this great tutorial</a>.</p>
<h2 id="assignment"><a href="lab/README_chs/">Assignment</a></h2>
<p>In this lab, you will take a video with simple gestures, and your goal is to extract up/down/left/right movements using optical flow.</p>
<p><img src="images/palm-movement.png" width="30%" alt="Palm Movement Frame"/></p>
              
            </div>
          </div><footer>

  <hr/>

  <div role="contentinfo">
    <!-- Copyright etc -->
  </div>

  Built with <a href="https://www.mkdocs.org/">MkDocs</a> using a <a href="https://github.com/readthedocs/sphinx_rtd_theme">theme</a> provided by <a href="https://readthedocs.org">Read the Docs</a>.
</footer>
          
        </div>
      </div>

    </section>

  </div>

  <div class="rst-versions" role="note" aria-label="Versions">
  <span class="rst-current-version" data-toggle="rst-current-version">
    
    
    
  </span>
</div>
    <script src="../../../js/jquery-3.6.0.min.js"></script>
    <script>var base_url = "../../..";</script>
    <script src="../../../js/theme_extra.js"></script>
    <script src="../../../js/theme.js"></script>
      <script src="../../../search/main.js"></script>
    <script>
        jQuery(function () {
            SphinxRtdTheme.Navigation.enable(true);
        });
    </script>

</body>
</html>
