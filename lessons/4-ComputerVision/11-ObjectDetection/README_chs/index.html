<!DOCTYPE html>
<html class="writer-html5" lang="en" >
<head>
    <meta charset="utf-8" />
    <meta http-equiv="X-UA-Compatible" content="IE=edge" />
    <meta name="viewport" content="width=device-width, initial-scale=1.0" />
      <link rel="shortcut icon" href="../../../../img/favicon.ico" />
    <title>目标检测 - 人工智能初学者课程</title>
    <link rel="stylesheet" href="../../../../css/theme.css" />
    <link rel="stylesheet" href="../../../../css/theme_extra.css" />
        <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/11.8.0/styles/github.min.css" />
    
      <script>
        // Current page data
        var mkdocs_page_name = "\u76ee\u6807\u68c0\u6d4b";
        var mkdocs_page_input_path = "lessons/4-ComputerVision/11-ObjectDetection/README_chs.md";
        var mkdocs_page_url = null;
      </script>
    
    <!--[if lt IE 9]>
      <script src="../../../../js/html5shiv.min.js"></script>
    <![endif]-->
      <script src="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/11.8.0/highlight.min.js"></script>
      <script>hljs.highlightAll();</script> 
</head>

<body class="wy-body-for-nav" role="document">

  <div class="wy-grid-for-nav">
    <nav data-toggle="wy-nav-shift" class="wy-nav-side stickynav">
    <div class="wy-side-scroll">
      <div class="wy-side-nav-search">
          <a href="../../../.." class="icon icon-home"> 人工智能初学者课程
        </a><div role="search">
  <form id ="rtd-search-form" class="wy-form" action="../../../../search.html" method="get">
      <input type="text" name="q" placeholder="Search docs" aria-label="Search docs" title="Type search term here" />
  </form>
</div>
      </div>

      <div class="wy-menu wy-menu-vertical" data-spy="affix" role="navigation" aria-label="Navigation menu">
              <ul>
                <li class="toctree-l1"><a class="reference internal" href="../../../../README_chs/">课程介绍</a>
                </li>
              </ul>
              <p class="caption"><span class="caption-text">课程设置</span></p>
              <ul>
                  <li class="toctree-l1"><a class="reference internal" href="../../../0-course-setup/for-teachers_chs/">给教育者</a>
                  </li>
                  <li class="toctree-l1"><a class="reference internal" href="../../../0-course-setup/how-to-run_chs/">如何运行代码</a>
                  </li>
                  <li class="toctree-l1"><a class="reference internal" href="../../../0-course-setup/setup_chs/">开始使用这个课程</a>
                  </li>
              </ul>
              <p class="caption"><span class="caption-text">人工智能简介</span></p>
              <ul>
                  <li class="toctree-l1"><a class="reference internal" href="../../../1-Intro/README_chs/">人工智能简介</a>
                  </li>
                  <li class="toctree-l1"><a class="reference internal" href="../../../1-Intro/assignment_chs/">游戏开发马拉松</a>
                  </li>
              </ul>
              <p class="caption"><span class="caption-text">知识表示与专家系统</span></p>
              <ul>
                  <li class="toctree-l1"><a class="reference internal" href="../../../2-Symbolic/README_chs/">知识表示与专家系统</a>
                  </li>
                  <li class="toctree-l1"><a class="reference internal" href="../../../2-Symbolic/assignment_chs/">构建一个本体</a>
                  </li>
              </ul>
              <p class="caption"><span class="caption-text">神经网络</span></p>
              <ul>
                  <li class="toctree-l1"><a class="reference internal" href="../../../3-NeuralNetworks/README_chs/">神经网络介绍</a>
                  </li>
                  <li class="toctree-l1"><a class="reference internal" href="../../../3-NeuralNetworks/03-Perceptron/README_chs/">神经网络入门：感知器</a>
                  </li>
                  <li class="toctree-l1"><a class="reference internal" href="../../../3-NeuralNetworks/04-OwnFramework/README_chs/">神经网络介绍. 多层感知器</a>
                  </li>
                  <li class="toctree-l1"><a class="reference internal" href="../../../3-NeuralNetworks/05-Frameworks/README_chs/">神经网络框架</a>
                  </li>
              </ul>
              <p class="caption"><span class="caption-text">计算机视觉</span></p>
              <ul class="current">
                  <li class="toctree-l1"><a class="reference internal" href="../../06-IntroCV/README_chs/">计算机视觉简介</a>
                  </li>
                  <li class="toctree-l1"><a class="reference internal" >卷积神经网络</a>
    <ul>
                <li class="toctree-l2"><a class="reference internal" href="../../07-ConvNets/CNN_Architectures_chs/">著名的 CNN 架构</a>
                </li>
                <li class="toctree-l2"><a class="reference internal" href="../../07-ConvNets/README_chs/">卷积神经网络</a>
                </li>
    </ul>
                  </li>
                  <li class="toctree-l1"><a class="reference internal" >迁移学习</a>
    <ul>
                <li class="toctree-l2"><a class="reference internal" href="../../08-TransferLearning/README_chs/">预训练网络和迁移学习</a>
                </li>
                <li class="toctree-l2"><a class="reference internal" href="../../08-TransferLearning/TrainingTricks_chs/">深度学习训练技巧</a>
                </li>
    </ul>
                  </li>
                  <li class="toctree-l1"><a class="reference internal" href="../../09-Autoencoders/README_chs/">自动编码器</a>
                  </li>
                  <li class="toctree-l1"><a class="reference internal" href="../../10-GANs/README_chs/">生成对抗网络</a>
                  </li>
                  <li class="toctree-l1 current"><a class="reference internal current" href="#">目标检测</a>
    <ul class="current">
    <li class="toctree-l2"><a class="reference internal" href="#_2">课前测验</a>
    </li>
    <li class="toctree-l2"><a class="reference internal" href="#_3">一个简单的目标检测方法</a>
    </li>
    <li class="toctree-l2"><a class="reference internal" href="#_4">用回归进行目标检测</a>
    </li>
    <li class="toctree-l2"><a class="reference internal" href="#_5">目标检测的数据集</a>
    </li>
    <li class="toctree-l2"><a class="reference internal" href="#_6">目标检测的度量标准</a>
        <ul>
    <li class="toctree-l3"><a class="reference internal" href="#iou">交并比（IoU）</a>
    </li>
    <li class="toctree-l3"><a class="reference internal" href="#ap">平均精度（AP）</a>
    </li>
    <li class="toctree-l3"><a class="reference internal" href="#ap-iou">AP 和 IoU</a>
    </li>
    <li class="toctree-l3"><a class="reference internal" href="#-map">平均平均精度 - mAP</a>
    </li>
        </ul>
    </li>
    <li class="toctree-l2"><a class="reference internal" href="#_7">不同的目标检测方法</a>
        <ul>
    <li class="toctree-l3"><a class="reference internal" href="#r-cnn-cnn">R-CNN: 基于区域的CNN</a>
    </li>
    <li class="toctree-l3"><a class="reference internal" href="#f-rcnn-r-cnn">F-RCNN - 快速R-CNN</a>
    </li>
    <li class="toctree-l3"><a class="reference internal" href="#r-cnn">更快的R-CNN</a>
    </li>
    <li class="toctree-l3"><a class="reference internal" href="#r-fcn">R-FCN: 基于区域的全卷积网络</a>
    </li>
    <li class="toctree-l3"><a class="reference internal" href="#yolo-">YOLO - 你只看一次</a>
    </li>
    <li class="toctree-l3"><a class="reference internal" href="#_8">其他算法</a>
    </li>
        </ul>
    </li>
    <li class="toctree-l2"><a class="reference internal" href="#_9">✍️ 练习：目标检测</a>
    </li>
    <li class="toctree-l2"><a class="reference internal" href="#_10">结论</a>
    </li>
    <li class="toctree-l2"><a class="reference internal" href="#_11">🚀 挑战</a>
    </li>
    <li class="toctree-l2"><a class="reference internal" href="#_12">课后测验</a>
    </li>
    <li class="toctree-l2"><a class="reference internal" href="#_13">复习与自学</a>
    </li>
    <li class="toctree-l2"><a class="reference internal" href="#_14">作业：目标检测</a>
    </li>
    </ul>
                  </li>
                  <li class="toctree-l1"><a class="reference internal" href="../../12-Segmentation/README_chs/">分割</a>
                  </li>
              </ul>
              <p class="caption"><span class="caption-text">自然语言处理</span></p>
              <ul>
                  <li class="toctree-l1"><a class="reference internal" href="../../../5-NLP/13-TextRep/README_chs/">将文本表示为张量</a>
                  </li>
                  <li class="toctree-l1"><a class="reference internal" href="../../../5-NLP/14-Embeddings/README_chs/">嵌入</a>
                  </li>
                  <li class="toctree-l1"><a class="reference internal" href="../../../5-NLP/15-LanguageModeling/README_chs/">语言建模</a>
                  </li>
                  <li class="toctree-l1"><a class="reference internal" href="../../../5-NLP/16-RNN/README_chs/">循环神经网络</a>
                  </li>
                  <li class="toctree-l1"><a class="reference internal" href="../../../5-NLP/17-GenerativeNetworks/README_chs/">生成网络</a>
                  </li>
                  <li class="toctree-l1"><a class="" href="../../../5-NLP/18-Transformers/READMEtransformers_chs">注意机制和Transformer</a>
                  </li>
                  <li class="toctree-l1"><a class="reference internal" href="../../../5-NLP/19-NER/README_chs/">命名实体识别</a>
                  </li>
                  <li class="toctree-l1"><a class="" href="../../../5-NLP/20-LangModels/READMELargeLang_chs">预训练大语言模型</a>
                  </li>
              </ul>
              <p class="caption"><span class="caption-text">其他技术</span></p>
              <ul>
                  <li class="toctree-l1"><a class="reference internal" href="../../../6-Other/21-GeneticAlgorithms/README_chs/">遗传算法</a>
                  </li>
                  <li class="toctree-l1"><a class="reference internal" href="../../../6-Other/22-DeepRL/README_chs/">深度强化学习</a>
                  </li>
                  <li class="toctree-l1"><a class="reference internal" href="../../../6-Other/23-MultiagentSystems/README_chs/">多智能体系统</a>
                  </li>
              </ul>
              <p class="caption"><span class="caption-text">AI伦理</span></p>
              <ul>
                  <li class="toctree-l1"><a class="reference internal" href="../../../7-Ethics/README_chs/">道德与负责任的人工智能</a>
                  </li>
              </ul>
              <p class="caption"><span class="caption-text">多模态网络</span></p>
              <ul>
                  <li class="toctree-l1"><a class="reference internal" href="../../../X-Extras/X1-MultiModal/README_chs/">多模态网络</a>
                  </li>
              </ul>
      </div>
    </div>
    </nav>

    <section data-toggle="wy-nav-shift" class="wy-nav-content-wrap">
      <nav class="wy-nav-top" role="navigation" aria-label="Mobile navigation menu">
          <i data-toggle="wy-nav-top" class="fa fa-bars"></i>
          <a href="../../../..">人工智能初学者课程</a>
        
      </nav>
      <div class="wy-nav-content">
        <div class="rst-content"><div role="navigation" aria-label="breadcrumbs navigation">
  <ul class="wy-breadcrumbs">
    <li><a href="../../../.." class="icon icon-home" aria-label="Docs"></a></li>
          <li class="breadcrumb-item">计算机视觉</li>
      <li class="breadcrumb-item active">目标检测</li>
    <li class="wy-breadcrumbs-aside">
    </li>
  </ul>
  <hr/>
</div>
          <div role="main" class="document" itemscope="itemscope" itemtype="http://schema.org/Article">
            <div class="section" itemprop="articleBody">
              
                <h1 id="_1">目标检测</h1>
<p>到目前为止我们讨论的图像分类模型都是将图像输入并生成一个分类结果，比如在MNIST问题中的类别“数字”。然而，在许多情况下，我们不仅希望知道图片中有物体，还希望能够确定它们的精确位置。这正是<strong>目标检测</strong>的目的。</p>
<h2 id="_2"><a href="https://red-field-0a6ddfd03.1.azurestaticapps.net/quiz/111">课前测验</a></h2>
<p><img alt="Object Detection" src="../images/Screen_Shot_2016-11-17_at_11.14.54_AM.png" /></p>
<blockquote>
<p>图片来自 <a href="https://pjreddie.com/darknet/yolov2/">YOLO v2 官网</a></p>
</blockquote>
<h2 id="_3">一个简单的目标检测方法</h2>
<p>假设我们想在一张图片中找到一只猫，一个非常简单的目标检测方法是：</p>
<ol>
<li>将图片分解成若干小块</li>
<li>在每个小块上运行图像分类</li>
<li>对于那些获得足够高激活的小块，可以认为包含了我们要找的物体</li>
</ol>
<p><img alt="Naive Object Detection" src="../images/naive-detection.png" /></p>
<blockquote>
<p><em>图片来自 <a href="ObjectDetection-TF.ipynb">实践笔记</a></em></p>
</blockquote>
<p>然而，这种方法远非理想，因为它只能非常不精确地定位物体的边界框。为了更精确地定位，我们需要运行某种<strong>回归</strong>来预测边界框的坐标——为此，我们需要特定的数据集。</p>
<h2 id="_4">用回归进行目标检测</h2>
<p><a href="https://towardsdatascience.com/object-detection-with-neural-networks-a4e2c46b4491">这篇博客</a>对检测形状进行了很好的入门介绍。</p>
<h2 id="_5">目标检测的数据集</h2>
<p>你可能会遇到以下用于此任务的数据集：</p>
<ul>
<li><a href="http://host.robots.ox.ac.uk/pascal/VOC/">PASCAL VOC</a> - 20个类别</li>
<li><a href="http://cocodataset.org/#home">COCO</a> - 常见物体在上下文中。80个类别，包括边界框和分割掩码</li>
</ul>
<p><img alt="COCO" src="../images/coco-examples.jpg" /></p>
<h2 id="_6">目标检测的度量标准</h2>
<h3 id="iou">交并比（IoU）</h3>
<p>图像分类很容易衡量算法的表现，而对于目标检测，我们不仅需要衡量类别的正确性，还需要衡量推断的边界框位置的精度。后者使用所谓的<strong>交并比</strong>（IoU），即衡量两个框（或任意两个区域）的重叠程度。</p>
<p><img alt="IoU" src="../images/iou_equation.png" /></p>
<blockquote>
<p><em>图2来自<a href="https://pyimagesearch.com/2016/11/07/intersection-over-union-iou-for-object-detection/">这篇关于IoU的优秀博客文章</a></em></p>
</blockquote>
<p>其思想很简单——我们将两个图形之间的交集面积除以它们的并集面积。对于两个相同的区域，IoU为1，而对于完全不相交的区域则为0。否则它会在0到1之间变化。我们通常仅考虑那些IoU超过某个值的边界框。</p>
<h3 id="ap">平均精度（AP）</h3>
<p>假设我们想衡量某个给定类别$C$的物体识别得有多好。为此，我们使用<strong>平均精度</strong>指标，其计算方法如下：</p>
<ol>
<li>考虑显示检测阈值（从0到1）上精度的精度-召回率曲线</li>
<li>根据阈值，我们将在图像中检测到更多或更少的物体，并得到不同的精度和召回率值。</li>
<li>曲线将如下图所示：</li>
</ol>
<p><img src="https://github.com/shwars/NeuroWorkshop/raw/master/images/ObjDetectionPrecisionRecall.png"/></p>
<blockquote>
<p><em>图片来自<a href="http://github.com/shwars/NeuroWorkshop">NeuroWorkshop</a></em></p>
</blockquote>
<p>给定类别$C$的平均精度是该曲线下的面积。确切地说，召回轴通常分为10部分，并且在所有这些点上平均精度：</p>
<p>$$
AP = {1\over11}\sum_{i=0}^{10}\mbox{Precision}(\mbox{Recall}={i\over10})
$$</p>
<h3 id="ap-iou">AP 和 IoU</h3>
<p>我们只考虑那些IoU超过某个值的检测。例如，在PASCAL VOC数据集中，通常假设$\mbox{IoU Threshold} = 0.5$，而在COCO中，AP是针对不同的$\mbox{IoU Threshold}$值测量的。</p>
<p><img src="https://github.com/shwars/NeuroWorkshop/raw/master/images/ObjDetectionPrecisionRecallIoU.png"/></p>
<blockquote>
<p><em>图片来自<a href="http://github.com/shwars/NeuroWorkshop">NeuroWorkshop</a></em></p>
</blockquote>
<h3 id="-map">平均平均精度 - mAP</h3>
<p>目标检测的主要指标称为<strong>平均平均精度</strong>，或<strong>mAP</strong>。它是所有物体类别上的平均精度值，有时也包括$\mbox{IoU Threshold}$。更详细的计算<strong>mAP</strong>的过程在<a href="https://medium.com/@timothycarlen/understanding-the-map-evaluation-metric-for-object-detection-a07fe6962cf3">本博客文章</a>中进行了描述，并且在<a href="https://gist.github.com/tarlen5/008809c3decf19313de216b9208f3734">这里有代码示例</a>。</p>
<h2 id="_7">不同的目标检测方法</h2>
<p>目标检测算法大致可以分为两大类：</p>
<ul>
<li><strong>区域提议网络</strong>（R-CNN, Fast R-CNN, Faster R-CNN）。主要思想是生成<strong>兴趣区域</strong>（ROI）并在其上运行CNN，寻找最大激活。这有点类似于简单方法，区别在于ROIs以更巧妙的方式生成。这种方法的主要缺点之一是速度慢，因为我们需要对图片进行多次CNN分类器的传递。</li>
<li><strong>一通道</strong>（YOLO, SSD, RetinaNet）方法。在这些架构中，我们设计网络以在一次传递中预测类别和ROIs。</li>
</ul>
<h3 id="r-cnn-cnn">R-CNN: 基于区域的CNN</h3>
<p><a href="http://islab.ulsan.ac.kr/files/announcement/513/rcnn_pami.pdf">R-CNN</a>使用<a href="http://www.huppelen.nl/publications/selectiveSearchDraft.pdf">选择性搜索</a>生成ROI区域的分层结构，然后通过CNN特征提取器和SVM分类器确定物体类别，并通过线性回归确定<em>边界框</em>坐标。<a href="https://arxiv.org/pdf/1506.01497v1.pdf">官方论文</a></p>
<p><img alt="RCNN" src="../images/rcnn1.png" /></p>
<blockquote>
<p><em>图片来自van de Sande等，ICCV’11</em></p>
</blockquote>
<p><img alt="RCNN-1" src="../images/rcnn2.png" /></p>
<blockquote>
<p><em>图片来自<a href="https://towardsdatascience.com/r-cnn-fast-r-cnn-faster-r-cnn-yolo-object-detection-algorithms-36d53571365e">这篇博客</a></em></p>
</blockquote>
<h3 id="f-rcnn-r-cnn">F-RCNN - 快速R-CNN</h3>
<p>这种方法类似于R-CNN，但区域是在卷积层之后定义的。</p>
<p><img alt="FRCNN" src="../images/f-rcnn.png" /></p>
<blockquote>
<p>图片来自<a href="https://www.cv-foundation.org/openaccess/content_iccv_2015/papers/Girshick_Fast_R-CNN_ICCV_2015_paper.pdf">官方论文</a>，<a href="https://arxiv.org/pdf/1504.08083.pdf">arXiv</a>，2015</p>
</blockquote>
<h3 id="r-cnn">更快的R-CNN</h3>
<p>这种方法的主要思想是使用神经网络预测ROIs——即所谓的<em>区域提议网络</em>。<a href="https://arxiv.org/pdf/1506.01497.pdf">论文</a>，2016</p>
<p><img alt="FasterRCNN" src="../images/faster-rcnn.png" /></p>
<blockquote>
<p>图片来自<a href="https://arxiv.org/pdf/1506.01497.pdf">官方论文</a></p>
</blockquote>
<h3 id="r-fcn">R-FCN: 基于区域的全卷积网络</h3>
<p>该算法比Faster R-CNN更快。主要思想如下：</p>
<ol>
<li>我们使用ResNet-101提取特征</li>
<li>特征由<strong>位置敏感得分图</strong>处理。每个$C$类别的对象分为$k\times k$区域，我们训练预测对象的部分。</li>
<li>在$k\times k$区域的每个部分，所有网络为对象类别投票，选择最高票数的对象类别。</li>
</ol>
<p><img alt="r-fcn image" src="../images/r-fcn.png" /></p>
<blockquote>
<p>图片来自<a href="https://arxiv.org/abs/1605.06409">官方论文</a></p>
</blockquote>
<h3 id="yolo-">YOLO - 你只看一次</h3>
<p>YOLO是一种实时的一通道算法。主要思想如下：</p>
<ul>
<li>将图像分为$S\times S$区域</li>
<li>对每个区域，<strong>CNN</strong>预测$n$个可能对象，<em>边界框</em>坐标和<em>置信度</em>=<em>概率</em> * IoU。</li>
</ul>
<p><img alt="YOLO" src="../images/yolo.png" /></p>
<blockquote>
<p>图片来自<a href="https://arxiv.org/abs/1506.02640">官方论文</a></p>
</blockquote>
<h3 id="_8">其他算法</h3>
<ul>
<li>RetinaNet: <a href="https://arxiv.org/abs/1708.02002">官方论文</a></li>
<li><a href="https://pytorch.org/vision/stable/_modules/torchvision/models/detection/retinanet.html">Torchvision中的PyTorch实现</a></li>
<li><a href="https://github.com/fizyr/keras-retinanet">Keras实现</a></li>
<li><a href="https://keras.io/examples/vision/retinanet/">Keras样例中的RetinaNet目标检测</a></li>
<li>SSD (单次检测器): <a href="https://arxiv.org/abs/1512.02325">官方论文</a></li>
</ul>
<h2 id="_9">✍️ 练习：目标检测</h2>
<p>继续在以下笔记本中学习：</p>
<p><a href="../ObjectDetection.ipynb">ObjectDetection.ipynb</a></p>
<h2 id="_10">结论</h2>
<p>在本课中，你快速浏览了各种完成目标检测的方法！</p>
<h2 id="_11">🚀 挑战</h2>
<p>阅读这些关于YOLO的文章和笔记本，并尝试一下：</p>
<ul>
<li><a href="https://www.analyticsvidhya.com/blog/2018/12/practical-guide-object-detection-yolo-framewor-python/">好的博客文章</a>描述YOLO</li>
<li><a href="https://pjreddie.com/darknet/yolo/">官方站点</a></li>
<li>Yolo: <a href="https://github.com/experiencor/keras-yolo2">Keras实现</a>，<a href="https://github.com/experiencor/basic-yolo-keras/blob/master/Yolo%20Step-by-Step.ipynb">一步一步的笔记本</a></li>
<li>Yolo v2: <a href="https://github.com/experiencor/keras-yolo2">Keras实现</a>，<a href="https://github.com/experiencor/keras-yolo2/blob/master/Yolo%20Step-by-Step.ipynb">一步一步的笔记本</a></li>
</ul>
<h2 id="_12"><a href="https://red-field-0a6ddfd03.1.azurestaticapps.net/quiz/211">课后测验</a></h2>
<h2 id="_13">复习与自学</h2>
<ul>
<li><a href="https://tjmachinelearning.com/lectures/1718/obj/">目标检测</a> 作者是Nikhil Sardana</li>
<li><a href="https://lilianweng.github.io/lil-log/2018/12/27/object-detection-part-4.html">目标检测算法的一个好的比较</a></li>
<li><a href="https://medium.com/comet-app/review-of-deep-learning-algorithms-for-object-detection-c1f3d437b852">深度学习算法目标检测回顾</a></li>
<li><a href="https://www.analyticsvidhya.com/blog/2018/10/a-step-by-step-introduction-to-the-basic-object-detection-algorithms-part-1/">基础目标检测算法的逐步介绍</a></li>
<li><a href="https://www.analyticsvidhya.com/blog/2018/11/implementation-faster-r-cnn-python-object-detection/">在Python中实现Faster R-CNN进行目标检测</a></li>
</ul>
<h2 id="_14"><a href="../lab/README_chs/">作业：目标检测</a></h2>
              
            </div>
          </div><footer>
    <div class="rst-footer-buttons" role="navigation" aria-label="Footer Navigation">
        <a href="../../10-GANs/README_chs/" class="btn btn-neutral float-left" title="生成对抗网络"><span class="icon icon-circle-arrow-left"></span> Previous</a>
        <a href="../../12-Segmentation/README_chs/" class="btn btn-neutral float-right" title="分割">Next <span class="icon icon-circle-arrow-right"></span></a>
    </div>

  <hr/>

  <div role="contentinfo">
    <!-- Copyright etc -->
  </div>

  Built with <a href="https://www.mkdocs.org/">MkDocs</a> using a <a href="https://github.com/readthedocs/sphinx_rtd_theme">theme</a> provided by <a href="https://readthedocs.org">Read the Docs</a>.
</footer>
          
        </div>
      </div>

    </section>

  </div>

  <div class="rst-versions" role="note" aria-label="Versions">
  <span class="rst-current-version" data-toggle="rst-current-version">
    
    
      <span><a href="../../10-GANs/README_chs/" style="color: #fcfcfc">&laquo; Previous</a></span>
    
    
      <span><a href="../../12-Segmentation/README_chs/" style="color: #fcfcfc">Next &raquo;</a></span>
    
  </span>
</div>
    <script src="../../../../js/jquery-3.6.0.min.js"></script>
    <script>var base_url = "../../../..";</script>
    <script src="../../../../js/theme_extra.js"></script>
    <script src="../../../../js/theme.js"></script>
      <script src="../../../../search/main.js"></script>
    <script>
        jQuery(function () {
            SphinxRtdTheme.Navigation.enable(true);
        });
    </script>

</body>
</html>
