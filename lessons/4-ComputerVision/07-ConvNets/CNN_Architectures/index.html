<!DOCTYPE html>
<html class="writer-html5" lang="en" >
<head>
    <meta charset="utf-8" />
    <meta http-equiv="X-UA-Compatible" content="IE=edge" />
    <meta name="viewport" content="width=device-width, initial-scale=1.0" />
      <link rel="shortcut icon" href="../../../../img/favicon.ico" />
    <title>Well-Known CNN Architectures - 人工智能初学者课程</title>
    <link rel="stylesheet" href="../../../../css/theme.css" />
    <link rel="stylesheet" href="../../../../css/theme_extra.css" />
        <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/11.8.0/styles/github.min.css" />
    
      <script>
        // Current page data
        var mkdocs_page_name = "Well-Known CNN Architectures";
        var mkdocs_page_input_path = "lessons/4-ComputerVision/07-ConvNets/CNN_Architectures.md";
        var mkdocs_page_url = null;
      </script>
    
    <!--[if lt IE 9]>
      <script src="../../../../js/html5shiv.min.js"></script>
    <![endif]-->
      <script src="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/11.8.0/highlight.min.js"></script>
      <script>hljs.highlightAll();</script> 
</head>

<body class="wy-body-for-nav" role="document">

  <div class="wy-grid-for-nav">
    <nav data-toggle="wy-nav-shift" class="wy-nav-side stickynav">
    <div class="wy-side-scroll">
      <div class="wy-side-nav-search">
          <a href="../../../.." class="icon icon-home"> 人工智能初学者课程
        </a><div role="search">
  <form id ="rtd-search-form" class="wy-form" action="../../../../search.html" method="get">
      <input type="text" name="q" placeholder="Search docs" aria-label="Search docs" title="Type search term here" />
  </form>
</div>
      </div>

      <div class="wy-menu wy-menu-vertical" data-spy="affix" role="navigation" aria-label="Navigation menu">
              <ul>
                <li class="toctree-l1"><a class="reference internal" href="../../../../README_chs/">课程介绍</a>
                </li>
              </ul>
              <p class="caption"><span class="caption-text">课程设置</span></p>
              <ul>
                  <li class="toctree-l1"><a class="reference internal" href="../../../0-course-setup/for-teachers_chs/">给教育者</a>
                  </li>
                  <li class="toctree-l1"><a class="reference internal" href="../../../0-course-setup/how-to-run_chs/">如何运行代码</a>
                  </li>
                  <li class="toctree-l1"><a class="reference internal" href="../../../0-course-setup/setup_chs/">开始使用这个课程</a>
                  </li>
              </ul>
              <p class="caption"><span class="caption-text">人工智能简介</span></p>
              <ul>
                  <li class="toctree-l1"><a class="reference internal" href="../../../1-Intro/README_chs/">人工智能简介</a>
                  </li>
                  <li class="toctree-l1"><a class="reference internal" href="../../../1-Intro/assignment_chs/">游戏开发马拉松</a>
                  </li>
              </ul>
              <p class="caption"><span class="caption-text">知识表示与专家系统</span></p>
              <ul>
                  <li class="toctree-l1"><a class="reference internal" href="../../../2-Symbolic/README_chs/">知识表示与专家系统</a>
                  </li>
                  <li class="toctree-l1"><a class="reference internal" href="../../../2-Symbolic/assignment_chs/">构建一个本体</a>
                  </li>
              </ul>
              <p class="caption"><span class="caption-text">神经网络</span></p>
              <ul>
                  <li class="toctree-l1"><a class="reference internal" href="../../../3-NeuralNetworks/README_chs/">神经网络介绍</a>
                  </li>
                  <li class="toctree-l1"><a class="reference internal" href="../../../3-NeuralNetworks/03-Perceptron/README_chs/">神经网络入门：感知器</a>
                  </li>
                  <li class="toctree-l1"><a class="reference internal" href="../../../3-NeuralNetworks/04-OwnFramework/README_chs/">神经网络介绍. 多层感知器</a>
                  </li>
                  <li class="toctree-l1"><a class="reference internal" href="../../../3-NeuralNetworks/05-Frameworks/README_chs/">神经网络框架</a>
                  </li>
              </ul>
              <p class="caption"><span class="caption-text">计算机视觉</span></p>
              <ul>
                  <li class="toctree-l1"><a class="reference internal" href="../../06-IntroCV/README_chs/">计算机视觉简介</a>
                  </li>
                  <li class="toctree-l1"><a class="reference internal" >卷积神经网络</a>
    <ul>
                <li class="toctree-l2"><a class="reference internal" href="../CNN_Architectures_chs/">著名的 CNN 架构</a>
                </li>
                <li class="toctree-l2"><a class="reference internal" href="../README_chs/">卷积神经网络</a>
                </li>
    </ul>
                  </li>
                  <li class="toctree-l1"><a class="reference internal" >迁移学习</a>
    <ul>
                <li class="toctree-l2"><a class="reference internal" href="../../08-TransferLearning/README_chs/">预训练网络和迁移学习</a>
                </li>
                <li class="toctree-l2"><a class="reference internal" href="../../08-TransferLearning/TrainingTricks_chs/">深度学习训练技巧</a>
                </li>
    </ul>
                  </li>
                  <li class="toctree-l1"><a class="reference internal" href="../../09-Autoencoders/README_chs/">自动编码器</a>
                  </li>
                  <li class="toctree-l1"><a class="reference internal" href="../../10-GANs/README_chs/">生成对抗网络</a>
                  </li>
                  <li class="toctree-l1"><a class="reference internal" href="../../11-ObjectDetection/README_chs/">目标检测</a>
                  </li>
                  <li class="toctree-l1"><a class="reference internal" href="../../12-Segmentation/README_chs/">分割</a>
                  </li>
              </ul>
              <p class="caption"><span class="caption-text">自然语言处理</span></p>
              <ul>
                  <li class="toctree-l1"><a class="reference internal" href="../../../5-NLP/13-TextRep/README_chs/">将文本表示为张量</a>
                  </li>
                  <li class="toctree-l1"><a class="reference internal" href="../../../5-NLP/14-Embeddings/README_chs/">嵌入</a>
                  </li>
                  <li class="toctree-l1"><a class="reference internal" href="../../../5-NLP/15-LanguageModeling/README_chs/">语言建模</a>
                  </li>
                  <li class="toctree-l1"><a class="reference internal" href="../../../5-NLP/16-RNN/README_chs/">循环神经网络</a>
                  </li>
                  <li class="toctree-l1"><a class="reference internal" href="../../../5-NLP/17-GenerativeNetworks/README_chs/">生成网络</a>
                  </li>
                  <li class="toctree-l1"><a class="" href="../../../5-NLP/18-Transformers/READMEtransformers_chs">注意机制和Transformer</a>
                  </li>
                  <li class="toctree-l1"><a class="reference internal" href="../../../5-NLP/19-NER/README_chs/">命名实体识别</a>
                  </li>
                  <li class="toctree-l1"><a class="" href="../../../5-NLP/20-LangModels/READMELargeLang_chs">预训练大语言模型</a>
                  </li>
              </ul>
              <p class="caption"><span class="caption-text">其他技术</span></p>
              <ul>
                  <li class="toctree-l1"><a class="reference internal" href="../../../6-Other/21-GeneticAlgorithms/README_chs/">遗传算法</a>
                  </li>
                  <li class="toctree-l1"><a class="reference internal" href="../../../6-Other/22-DeepRL/README_chs/">深度强化学习</a>
                  </li>
                  <li class="toctree-l1"><a class="reference internal" href="../../../6-Other/23-MultiagentSystems/README_chs/">多智能体系统</a>
                  </li>
              </ul>
              <p class="caption"><span class="caption-text">AI伦理</span></p>
              <ul>
                  <li class="toctree-l1"><a class="reference internal" href="../../../7-Ethics/README_chs/">道德与负责任的人工智能</a>
                  </li>
              </ul>
              <p class="caption"><span class="caption-text">多模态网络</span></p>
              <ul>
                  <li class="toctree-l1"><a class="reference internal" href="../../../X-Extras/X1-MultiModal/README_chs/">多模态网络</a>
                  </li>
              </ul>
      </div>
    </div>
    </nav>

    <section data-toggle="wy-nav-shift" class="wy-nav-content-wrap">
      <nav class="wy-nav-top" role="navigation" aria-label="Mobile navigation menu">
          <i data-toggle="wy-nav-top" class="fa fa-bars"></i>
          <a href="../../../..">人工智能初学者课程</a>
        
      </nav>
      <div class="wy-nav-content">
        <div class="rst-content"><div role="navigation" aria-label="breadcrumbs navigation">
  <ul class="wy-breadcrumbs">
    <li><a href="../../../.." class="icon icon-home" aria-label="Docs"></a></li>
      <li class="breadcrumb-item active">Well-Known CNN Architectures</li>
    <li class="wy-breadcrumbs-aside">
    </li>
  </ul>
  <hr/>
</div>
          <div role="main" class="document" itemscope="itemscope" itemtype="http://schema.org/Article">
            <div class="section" itemprop="articleBody">
              
                <h1 id="well-known-cnn-architectures">Well-Known CNN Architectures</h1>
<h3 id="vgg-16">VGG-16</h3>
<p>VGG-16 is a network that achieved 92.7% accuracy in ImageNet top-5 classification in 2014. It has the following layer structure:</p>
<p><img alt="ImageNet Layers" src="../images/vgg-16-arch1.jpg" /></p>
<p>As you can see, VGG follows a traditional pyramid architecture, which is a sequence of convolution-pooling layers.</p>
<p><img alt="ImageNet Pyramid" src="../images/vgg-16-arch.jpg" /></p>
<blockquote>
<p>Image from <a href="https://www.researchgate.net/figure/Vgg16-model-structure-To-get-the-VGG-NIN-model-we-replace-the-2-nd-4-th-6-th-7-th_fig2_335194493">Researchgate</a></p>
</blockquote>
<h3 id="resnet">ResNet</h3>
<p>ResNet is a family of models proposed by Microsoft Research in 2015. The main idea of ResNet is to use <strong>residual blocks</strong>:</p>
<p><img src="images/resnet-block.png" width="300"/></p>
<blockquote>
<p>Image from <a href="https://arxiv.org/pdf/1512.03385.pdf">this paper</a></p>
</blockquote>
<p>The reason for using identity pass-through is to have our layer predict <strong>the difference</strong> between the result of a previous layer and the output of the residual block - hence the name <em>residual</em>. Those blocks are much easier to train, and one can construct networks with several hundreds of those blocks (most common variants are ResNet-52, ResNet-101 and ResNet-152).</p>
<p>You can also think of this network as being able to adjust its complexity to the dataset. Initially, when you are starting to train the network, the weights values are small, and most of the signal goes through passthrough identity layers. As training progresses and weights become larger, the significance of network parameters grow, and the networks adjusts to accommodate required expressive power to correctly classify training images.</p>
<h3 id="google-inception">Google Inception</h3>
<p>Google Inception architecture takes this idea one step further, and builds each network layer as a combination of several different paths:</p>
<p><img src="images/inception.png" width="400"/></p>
<blockquote>
<p>Image from <a href="https://www.researchgate.net/figure/Inception-module-with-dimension-reductions-left-and-schema-for-Inception-ResNet-v1_fig2_355547454">Researchgate</a></p>
</blockquote>
<p>Here, we need to emphasize the role of 1x1 convolutions, because at first they do not make sense. Why would we need to run through the image with 1x1 filter? However, you need to remember that convolution filters also work with several depth channels (originally - RGB colors, in subsequent layers - channels for different filters), and 1x1 convolution is used to mix those input channels together using different trainable weights. It can be also viewed as downsampling (pooling) over channel dimension.</p>
<p>Here is <a href="https://medium.com/analytics-vidhya/talented-mr-1x1-comprehensive-look-at-1x1-convolution-in-deep-learning-f6b355825578">a good blog post</a> on the subject, and <a href="https://arxiv.org/pdf/1312.4400.pdf">the original paper</a>.</p>
<h3 id="mobilenet">MobileNet</h3>
<p>MobileNet is a family of models with reduced size, suitable for mobile devices. Use them if you are short in resources, and can sacrifice a little bit of accuracy. The main idea behind them is so-called <strong>depthwise separable convolution</strong>, which allows representing convolution filters by a composition of spatial convolutions and 1x1 convolution over depth channels. This significantly reduces the number of parameters, making the network smaller in size, and also easier to train with less data.</p>
<p>Here is <a href="https://medium.com/analytics-vidhya/image-classification-with-mobilenet-cc6fbb2cd470">a good blog post on MobileNet</a>.</p>
<h2 id="conclusion">Conclusion</h2>
<p>In this unit, you have learned the main concept behind computer vision neural networks - convolutional networks. Real-life architectures that power image classification, object detection, and even image generation networks are all based on CNNs, just with more layers and some additional training tricks.</p>
<h2 id="challenge">🚀 Challenge</h2>
<p>In the accompanying notebooks, there are notes at the bottom about how to obtain greater accuracy. Do some experiments to see if you can achieve higher accuracy.</p>
<h2 id="post-lecture-quiz"><a href="https://red-field-0a6ddfd03.1.azurestaticapps.net/quiz/207">Post-lecture quiz</a></h2>
<h2 id="review-self-study">Review &amp; Self Study</h2>
<p>While CNNs are most often used for Computer Vision tasks, they are generally good for extracting fixed-sized patterns. For example, if we are dealing with sounds, we may also want to use CNNs to look for some specific patterns in audio signal - in which case filters would be 1-dimensional (and this CNN would be called 1D-CNN). Also, sometimes 3D-CNN is used to extract features in multi-dimensional space, such as certain events occurring on video - CNN can capture certain patterns of feature changing over time. Do some review and self-study about other tasks that can be done with CNNs.</p>
<h2 id="assignment"><a href="../lab/README_chs/">Assignment</a></h2>
<p>In this lab, you are tasked with classifying different cat and dog breeds. These images are more complex than the MNIST dataset and of higher dimensions, and there are more than 10 classes.</p>
              
            </div>
          </div><footer>

  <hr/>

  <div role="contentinfo">
    <!-- Copyright etc -->
  </div>

  Built with <a href="https://www.mkdocs.org/">MkDocs</a> using a <a href="https://github.com/readthedocs/sphinx_rtd_theme">theme</a> provided by <a href="https://readthedocs.org">Read the Docs</a>.
</footer>
          
        </div>
      </div>

    </section>

  </div>

  <div class="rst-versions" role="note" aria-label="Versions">
  <span class="rst-current-version" data-toggle="rst-current-version">
    
    
    
  </span>
</div>
    <script src="../../../../js/jquery-3.6.0.min.js"></script>
    <script>var base_url = "../../../..";</script>
    <script src="../../../../js/theme_extra.js"></script>
    <script src="../../../../js/theme.js"></script>
      <script src="../../../../search/main.js"></script>
    <script>
        jQuery(function () {
            SphinxRtdTheme.Navigation.enable(true);
        });
    </script>

</body>
</html>
