<!DOCTYPE html>
<html class="writer-html5" lang="en" >
<head>
    <meta charset="utf-8" />
    <meta http-equiv="X-UA-Compatible" content="IE=edge" />
    <meta name="viewport" content="width=device-width, initial-scale=1.0" />
      <link rel="shortcut icon" href="../../../../img/favicon.ico" />
    <title>深度学习训练技巧 - 人工智能初学者课程</title>
    <link rel="stylesheet" href="../../../../css/theme.css" />
    <link rel="stylesheet" href="../../../../css/theme_extra.css" />
        <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/11.8.0/styles/github.min.css" />
    
      <script>
        // Current page data
        var mkdocs_page_name = "\u6df1\u5ea6\u5b66\u4e60\u8bad\u7ec3\u6280\u5de7";
        var mkdocs_page_input_path = "lessons/4-ComputerVision/08-TransferLearning/TrainingTricks_chs.md";
        var mkdocs_page_url = null;
      </script>
    
    <!--[if lt IE 9]>
      <script src="../../../../js/html5shiv.min.js"></script>
    <![endif]-->
      <script src="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/11.8.0/highlight.min.js"></script>
      <script>hljs.highlightAll();</script> 
</head>

<body class="wy-body-for-nav" role="document">

  <div class="wy-grid-for-nav">
    <nav data-toggle="wy-nav-shift" class="wy-nav-side stickynav">
    <div class="wy-side-scroll">
      <div class="wy-side-nav-search">
          <a href="../../../.." class="icon icon-home"> 人工智能初学者课程
        </a><div role="search">
  <form id ="rtd-search-form" class="wy-form" action="../../../../search.html" method="get">
      <input type="text" name="q" placeholder="Search docs" aria-label="Search docs" title="Type search term here" />
  </form>
</div>
      </div>

      <div class="wy-menu wy-menu-vertical" data-spy="affix" role="navigation" aria-label="Navigation menu">
              <ul>
                <li class="toctree-l1"><a class="reference internal" href="../../../../README_chs/">课程介绍</a>
                </li>
              </ul>
              <p class="caption"><span class="caption-text">课程设置</span></p>
              <ul>
                  <li class="toctree-l1"><a class="reference internal" href="../../../0-course-setup/for-teachers_chs/">给教育者</a>
                  </li>
                  <li class="toctree-l1"><a class="reference internal" href="../../../0-course-setup/how-to-run_chs/">如何运行代码</a>
                  </li>
                  <li class="toctree-l1"><a class="reference internal" href="../../../0-course-setup/setup_chs/">开始使用这个课程</a>
                  </li>
              </ul>
              <p class="caption"><span class="caption-text">人工智能简介</span></p>
              <ul>
                  <li class="toctree-l1"><a class="reference internal" href="../../../1-Intro/README_chs/">人工智能简介</a>
                  </li>
                  <li class="toctree-l1"><a class="reference internal" href="../../../1-Intro/assignment_chs/">游戏开发马拉松</a>
                  </li>
              </ul>
              <p class="caption"><span class="caption-text">知识表示与专家系统</span></p>
              <ul>
                  <li class="toctree-l1"><a class="reference internal" href="../../../2-Symbolic/README_chs/">知识表示与专家系统</a>
                  </li>
                  <li class="toctree-l1"><a class="reference internal" href="../../../2-Symbolic/assignment_chs/">构建一个本体</a>
                  </li>
              </ul>
              <p class="caption"><span class="caption-text">神经网络</span></p>
              <ul>
                  <li class="toctree-l1"><a class="reference internal" href="../../../3-NeuralNetworks/README_chs/">神经网络介绍</a>
                  </li>
                  <li class="toctree-l1"><a class="reference internal" href="../../../3-NeuralNetworks/03-Perceptron/README_chs/">神经网络入门：感知器</a>
                  </li>
                  <li class="toctree-l1"><a class="reference internal" href="../../../3-NeuralNetworks/04-OwnFramework/README_chs/">神经网络介绍. 多层感知器</a>
                  </li>
                  <li class="toctree-l1"><a class="reference internal" href="../../../3-NeuralNetworks/05-Frameworks/README_chs/">神经网络框架</a>
                  </li>
              </ul>
              <p class="caption"><span class="caption-text">计算机视觉</span></p>
              <ul class="current">
                  <li class="toctree-l1"><a class="reference internal" href="../../06-IntroCV/README_chs/">计算机视觉简介</a>
                  </li>
                  <li class="toctree-l1"><a class="reference internal" >卷积神经网络</a>
    <ul>
                <li class="toctree-l2"><a class="reference internal" href="../../07-ConvNets/CNN_Architectures_chs/">著名的 CNN 架构</a>
                </li>
                <li class="toctree-l2"><a class="reference internal" href="../../07-ConvNets/README_chs/">卷积神经网络</a>
                </li>
    </ul>
                  </li>
                  <li class="toctree-l1 current"><a class="reference internal current" >迁移学习</a>
    <ul class="current">
                <li class="toctree-l2"><a class="reference internal" href="../README_chs/">预训练网络和迁移学习</a>
                </li>
                <li class="toctree-l2 current"><a class="reference internal current" href="#">深度学习训练技巧</a>
    <ul class="current">
    <li class="toctree-l3"><a class="reference internal" href="#_2">保持值在合理区间内</a>
    </li>
    <li class="toctree-l3"><a class="reference internal" href="#_3">初始权值初始化</a>
    </li>
    <li class="toctree-l3"><a class="reference internal" href="#_4">批量归一化</a>
    </li>
    <li class="toctree-l3"><a class="reference internal" href="#_5">随机失活</a>
    </li>
    <li class="toctree-l3"><a class="reference internal" href="#_6">防止过拟合</a>
    </li>
    <li class="toctree-l3"><a class="reference internal" href="#_7">优化器 / 训练算法</a>
        <ul>
    <li class="toctree-l4"><a class="reference internal" href="#_8">动量</a>
    </li>
    <li class="toctree-l4"><a class="reference internal" href="#adamadagrad">Adam，Adagrad 等</a>
    </li>
    <li class="toctree-l4"><a class="reference internal" href="#_9">梯度剪裁</a>
    </li>
    <li class="toctree-l4"><a class="reference internal" href="#_10">学习率衰减</a>
    </li>
        </ul>
    </li>
    <li class="toctree-l3"><a class="reference internal" href="#_11">不同的网络架构</a>
    </li>
    </ul>
                </li>
    </ul>
                  </li>
                  <li class="toctree-l1"><a class="reference internal" href="../../09-Autoencoders/README_chs/">自动编码器</a>
                  </li>
                  <li class="toctree-l1"><a class="reference internal" href="../../10-GANs/README_chs/">生成对抗网络</a>
                  </li>
                  <li class="toctree-l1"><a class="reference internal" href="../../11-ObjectDetection/README_chs/">目标检测</a>
                  </li>
                  <li class="toctree-l1"><a class="reference internal" href="../../12-Segmentation/README_chs/">分割</a>
                  </li>
              </ul>
              <p class="caption"><span class="caption-text">自然语言处理</span></p>
              <ul>
                  <li class="toctree-l1"><a class="reference internal" href="../../../5-NLP/13-TextRep/README_chs/">将文本表示为张量</a>
                  </li>
                  <li class="toctree-l1"><a class="reference internal" href="../../../5-NLP/14-Embeddings/README_chs/">嵌入</a>
                  </li>
                  <li class="toctree-l1"><a class="reference internal" href="../../../5-NLP/15-LanguageModeling/README_chs/">语言建模</a>
                  </li>
                  <li class="toctree-l1"><a class="reference internal" href="../../../5-NLP/16-RNN/README_chs/">循环神经网络</a>
                  </li>
                  <li class="toctree-l1"><a class="reference internal" href="../../../5-NLP/17-GenerativeNetworks/README_chs/">生成网络</a>
                  </li>
                  <li class="toctree-l1"><a class="" href="../../../5-NLP/18-Transformers/READMEtransformers_chs">注意机制和Transformer</a>
                  </li>
                  <li class="toctree-l1"><a class="reference internal" href="../../../5-NLP/19-NER/README_chs/">命名实体识别</a>
                  </li>
                  <li class="toctree-l1"><a class="" href="../../../5-NLP/20-LangModels/READMELargeLang_chs">预训练大语言模型</a>
                  </li>
              </ul>
              <p class="caption"><span class="caption-text">其他技术</span></p>
              <ul>
                  <li class="toctree-l1"><a class="reference internal" href="../../../6-Other/21-GeneticAlgorithms/README_chs/">遗传算法</a>
                  </li>
                  <li class="toctree-l1"><a class="reference internal" href="../../../6-Other/22-DeepRL/README_chs/">深度强化学习</a>
                  </li>
                  <li class="toctree-l1"><a class="reference internal" href="../../../6-Other/23-MultiagentSystems/README_chs/">多智能体系统</a>
                  </li>
              </ul>
              <p class="caption"><span class="caption-text">AI伦理</span></p>
              <ul>
                  <li class="toctree-l1"><a class="reference internal" href="../../../7-Ethics/README_chs/">道德与负责任的人工智能</a>
                  </li>
              </ul>
              <p class="caption"><span class="caption-text">多模态网络</span></p>
              <ul>
                  <li class="toctree-l1"><a class="reference internal" href="../../../X-Extras/X1-MultiModal/README_chs/">多模态网络</a>
                  </li>
              </ul>
      </div>
    </div>
    </nav>

    <section data-toggle="wy-nav-shift" class="wy-nav-content-wrap">
      <nav class="wy-nav-top" role="navigation" aria-label="Mobile navigation menu">
          <i data-toggle="wy-nav-top" class="fa fa-bars"></i>
          <a href="../../../..">人工智能初学者课程</a>
        
      </nav>
      <div class="wy-nav-content">
        <div class="rst-content"><div role="navigation" aria-label="breadcrumbs navigation">
  <ul class="wy-breadcrumbs">
    <li><a href="../../../.." class="icon icon-home" aria-label="Docs"></a></li>
          <li class="breadcrumb-item">计算机视觉</li>
          <li class="breadcrumb-item">迁移学习</li>
      <li class="breadcrumb-item active">深度学习训练技巧</li>
    <li class="wy-breadcrumbs-aside">
    </li>
  </ul>
  <hr/>
</div>
          <div role="main" class="document" itemscope="itemscope" itemtype="http://schema.org/Article">
            <div class="section" itemprop="articleBody">
              
                <h1 id="_1">深度学习训练技巧</h1>
<p>随着神经网络变得越来越深，它们的训练过程变得越来越具有挑战性。一个主要问题是所谓的<a href="https://en.wikipedia.org/wiki/Vanishing_gradient_problem">梯度消失</a>或<a href="https://deepai.org/machine-learning-glossary-and-terms/exploding-gradient-problem#:~:text=Exploding%20gradients%20are%20a%20problem,updates%20are%20small%20and%20controlled">梯度爆炸</a>。<a href="https://towardsdatascience.com/the-vanishing-exploding-gradient-problem-in-deep-neural-networks-191358470c11">这篇文章</a>对这些问题进行了很好的介绍。</p>
<p>为了提高深度网络训练的效率，有几种技巧可以使用。</p>
<h2 id="_2">保持值在合理区间内</h2>
<p>为了使数值计算更稳定，我们希望确保神经网络中的所有值在合理的范围内，通常为[-1..1]或[0..1]。这不是一个非常严格的要求，但浮点数计算的性质如此，无法准确地处理不同数量级的值。例如，如果我们加上10<sup>-10</sup>和10<sup>10</sup>，我们可能会得到10<sup>10</sup>，因为较小的值将被“转换”到与较大的值相同的数量级，从而失去有效数。</p>
<p>大多数激活函数在[-1..1]附近都有非线性，因此将所有输入数据缩放到[-1..1]或[0..1]区间是有意义的。</p>
<h2 id="_3">初始权值初始化</h2>
<p>理想情况是，经过网络层后，值保持在同一范围内。因此，重要的是以保持值分布的方式初始化权重。</p>
<p>正态分布 <strong>N(0,1)</strong> 不是一个好主意，因为如果我们有 <em>n</em> 个输入，输出的标准差将为 <em>n</em>，从而导致值可能跳出 [0..1] 区间。</p>
<p>以下初始化方法经常使用：</p>
<ul>
<li>均匀分布 -- <code>uniform</code></li>
<li><strong>N(0,1/n)</strong> -- <code>gaussian</code></li>
<li><strong>N(0,1/&radic;n_in)</strong> 保证对于均值为零、标准差为1的输入，同样的均值/标准差保持不变</li>
<li><strong>N(0,&radic;2/(n_in+n_out))</strong> -- 所谓的 <strong>Xavier 初始化</strong> (<code>glorot</code>)，它有助于在前向和后向传播期间保持信号在范围内</li>
</ul>
<h2 id="_4">批量归一化</h2>
<p>即使有了合适的权重初始化，权重在训练过程中仍可能变得任意大或小，这将使信号超出适当的范围。通过使用一种<strong>归一化</strong>技术可以将信号拉回到合适的范围。虽然有几种 (权重归一化、层归一化)，但最常用的是批量归一化。</p>
<p><strong>批量归一化</strong> 的想法是考虑小批量中的所有值，并基于这些值执行归一化（即减去均值并除以标准差）。它实现为一个网络层，在应用权重之后、激活函数之前进行归一化。结果是，我们很可能会看到更高的最终准确性和更快的训练速度。</p>
<p>这里是关于批量归一化的<a href="https://arxiv.org/pdf/1502.03167.pdf">原始论文</a>，<a href="https://en.wikipedia.org/wiki/Batch_normalization">维基百科的解释</a>，以及<a href="https://towardsdatascience.com/batch-normalization-in-3-levels-of-understanding-14c2da90a338">一个很好的介绍性博客文章</a>（还有一个<a href="https://habrahabr.ru/post/309302/">俄文版</a>）。</p>
<h2 id="_5">随机失活</h2>
<p><strong>随机失活</strong> 是一种有趣的技术，在训练过程中移除一定比例的随机神经元。它也实现为一个带有一个参数（要移除的神经元的百分比，通常为10%-50%）的层，在训练期间它会将输入向量的随机元素置为零，然后传递到下一层。</p>
<p>虽然这听起来像是一个奇怪的主意，但你可以在 <a href="../Dropout.ipynb"><code>Dropout.ipynb</code></a> 笔记本中看到这对训练 MNIST 数字分类器的效果。它加快了训练速度，并使我们能够在较少的训练周期内达到更高的准确性。</p>
<p>这种效果可以通过几种方式解释：</p>
<ul>
<li>这可以被视为对模型的随机冲击因素，将优化从局部最小值中带出。</li>
<li>这可以被视为<em>隐式模型平均</em>，因为我们可以说在随机失活期间，我们在训练略有不同的模型。</li>
</ul>
<blockquote>
<p><em>有些人说，当一个醉酒的人尝试学习一些东西时，他会在第二天早上比一个清醒的人记得更好，因为脑中的一些失灵神经元会更好地适应以抓住意义。我们自己从未测试过这是否属实</em></p>
</blockquote>
<h2 id="_6">防止过拟合</h2>
<p>深度学习的一个非常重要的方面是能够防止<a href="../../3-NeuralNetworks/05-Frameworks/Overfitting_chs.md">过拟合</a>。虽然使用非常强大的神经网络模型可能很诱人，但我们应该始终在模型参数数量和训练样本数量之间找到平衡。</p>
<blockquote>
<p>确保你理解我们早先介绍的<a href="../../3-NeuralNetworks/05-Frameworks/Overfitting_chs.md">过拟合</a>概念！</p>
</blockquote>
<p>有几种防止过拟合的方法：</p>
<ul>
<li>提前停止 -- 连续监控验证集上的错误，并在验证错误开始增加时停止训练。</li>
<li>显示权重衰减 / 正则化 -- 为权值的高绝对值添加额外的惩罚项，防止模型得到非常不稳定的结果。</li>
<li>模型平均 -- 训练多个模型然后平均结果，这有助于最小化方差。</li>
<li>随机失活 (隐式模型平均)</li>
</ul>
<h2 id="_7">优化器 / 训练算法</h2>
<p>训练的另一个重要方面是选择好的训练算法。虽然经典的<strong>梯度下降</strong>是一个合理的选择，但它有时可能太慢，或者导致其他问题。</p>
<p>在深度学习中，我们使用<strong>随机梯度下降</strong>（SGD），它是应用于随机选择的小批量训练集的梯度下降。使用以下公式调整权重：</p>
<p>w<sup>t+1</sup> = w<sup>t</sup> - &eta;&nabla;&lagran;</p>
<h3 id="_8">动量</h3>
<p>在<strong>动量 SGD</strong>中，我们保留上一步骤的部分梯度。这类似于我们朝某个方向移动带有惯性并在受到不同方向的冲击时，我们的轨迹不会立即改变，而是保留部分原始运动。这里我们引入另一个向量 v 表示<em>速度</em>：</p>
<ul>
<li>v<sup>t+1</sup> = &gamma; v<sup>t</sup> - &eta;&nabla;&lagran;</li>
<li>w<sup>t+1</sup> = w<sup>t</sup>+v<sup>t+1</sup></li>
</ul>
<p>参数 &gamma; 表示我们考虑惯性的程度：&gamma;=0 对应经典 SGD；&gamma;=1 是纯粹的运动方程。</p>
<h3 id="adamadagrad">Adam，Adagrad 等</h3>
<p>由于在每一层中我们将信号乘以某个矩阵 W<sub>i</sub>，根据 ||W<sub>i</sub>||，梯度要么会缩小接近 0，要么无限上升。这就是梯度爆炸/消失问题的本质。</p>
<p>解决这个问题的一个方法是只在方程中使用梯度的方向，并忽略绝对值，即</p>
<p>w<sup>t+1</sup> = w<sup>t</sup> - &eta;(&nabla;&lagran;/||&nabla;&lagran;||)，其中 ||&nabla;&lagran;|| = &radic;&sum;(&nabla;&lagran;)<sup>2</sup></p>
<p>这个算法称为<strong>Adagrad</strong>。其他使用相同思路的算法：<strong>RMSProp</strong>、<strong>Adam</strong></p>
<blockquote>
<p><strong>Adam</strong> 被认为是许多应用中非常有效的算法，所以如果你不确定用哪个 - 用 Adam。</p>
</blockquote>
<h3 id="_9">梯度剪裁</h3>
<p>梯度剪裁是上面思想的扩展。当 ||&nabla;&lagran;|| &le; &theta; 时，我们在权重优化中考虑原始梯度；当 ||&nabla;&lagran;|| &gt; &theta; 时，我们将梯度除以其范数。这里 &theta; 是一个参数，在大多数情况下我们可以取 &theta;=1 或 &theta;=10。</p>
<h3 id="_10">学习率衰减</h3>
<p>训练成功通常取决于学习率参数 &eta;。合理地假设较大的 &eta; 值会导致更快的训练，这是我们通常希望在训练开始时发生的，然后较小的 &eta; 值允许我们微调网络。因此，在大多数情况下，我们希望在训练过程中减少 &eta;。</p>
<p>这可以通过在每个训练周期之后将 &eta; 乘以某个数（例如 0.98）来实现，或者使用更复杂的<strong>学习率调度</strong>。</p>
<h2 id="_11">不同的网络架构</h2>
<p>为你的问题选择合适的网络架构可能很棘手。通常的做法是选择已被验证可以用于特定任务（或类似任务）的架构。这里有一篇<a href="https://www.topbots.com/a-brief-history-of-neural-network-architectures/">神经网络架构简史</a>综述，适用于计算机视觉。</p>
<blockquote>
<p>重要的是选择适用于我们拥有的训练样本数量的强大架构。选择过于强大的模型可能导致<a href="../../3-NeuralNetworks/05-Frameworks/Overfitting_chs.md">过拟合</a></p>
</blockquote>
<p>另一种好的方法是使用一种将自动调整到所需复杂度的架构。<strong>ResNet</strong> 和 <strong>Inception</strong> 架构在某种程度上是自适应的。<a href="../../07-ConvNets/CNN_Architectures_chs/">更多计算机视觉架构</a></p>
              
            </div>
          </div><footer>
    <div class="rst-footer-buttons" role="navigation" aria-label="Footer Navigation">
        <a href="../README_chs/" class="btn btn-neutral float-left" title="预训练网络和迁移学习"><span class="icon icon-circle-arrow-left"></span> Previous</a>
        <a href="../../09-Autoencoders/README_chs/" class="btn btn-neutral float-right" title="自动编码器">Next <span class="icon icon-circle-arrow-right"></span></a>
    </div>

  <hr/>

  <div role="contentinfo">
    <!-- Copyright etc -->
  </div>

  Built with <a href="https://www.mkdocs.org/">MkDocs</a> using a <a href="https://github.com/readthedocs/sphinx_rtd_theme">theme</a> provided by <a href="https://readthedocs.org">Read the Docs</a>.
</footer>
          
        </div>
      </div>

    </section>

  </div>

  <div class="rst-versions" role="note" aria-label="Versions">
  <span class="rst-current-version" data-toggle="rst-current-version">
    
    
      <span><a href="../README_chs/" style="color: #fcfcfc">&laquo; Previous</a></span>
    
    
      <span><a href="../../09-Autoencoders/README_chs/" style="color: #fcfcfc">Next &raquo;</a></span>
    
  </span>
</div>
    <script src="../../../../js/jquery-3.6.0.min.js"></script>
    <script>var base_url = "../../../..";</script>
    <script src="../../../../js/theme_extra.js"></script>
    <script src="../../../../js/theme.js"></script>
      <script src="../../../../search/main.js"></script>
    <script>
        jQuery(function () {
            SphinxRtdTheme.Navigation.enable(true);
        });
    </script>

</body>
</html>
