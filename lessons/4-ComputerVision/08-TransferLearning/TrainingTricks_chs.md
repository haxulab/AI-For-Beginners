# 深度学习训练技巧

随着神经网络变得越来越深，它们的训练过程变得越来越具有挑战性。一个主要问题是所谓的[梯度消失](https://en.wikipedia.org/wiki/Vanishing_gradient_problem)或[梯度爆炸](https://deepai.org/machine-learning-glossary-and-terms/exploding-gradient-problem#:~:text=Exploding%20gradients%20are%20a%20problem,updates%20are%20small%20and%20controlled)。[这篇文章](https://towardsdatascience.com/the-vanishing-exploding-gradient-problem-in-deep-neural-networks-191358470c11)对这些问题进行了很好的介绍。

为了提高深度网络训练的效率，有几种技巧可以使用。

## 保持值在合理区间内

为了使数值计算更稳定，我们希望确保神经网络中的所有值在合理的范围内，通常为[-1..1]或[0..1]。这不是一个非常严格的要求，但浮点数计算的性质如此，无法准确地处理不同数量级的值。例如，如果我们加上10<sup>-10</sup>和10<sup>10</sup>，我们可能会得到10<sup>10</sup>，因为较小的值将被“转换”到与较大的值相同的数量级，从而失去有效数。

大多数激活函数在[-1..1]附近都有非线性，因此将所有输入数据缩放到[-1..1]或[0..1]区间是有意义的。

## 初始权值初始化

理想情况是，经过网络层后，值保持在同一范围内。因此，重要的是以保持值分布的方式初始化权重。

正态分布 **N(0,1)** 不是一个好主意，因为如果我们有 *n* 个输入，输出的标准差将为 *n*，从而导致值可能跳出 [0..1] 区间。

以下初始化方法经常使用：

 * 均匀分布 -- `uniform`
 * **N(0,1/n)** -- `gaussian`
 * **N(0,1/&radic;n_in)** 保证对于均值为零、标准差为1的输入，同样的均值/标准差保持不变
 * **N(0,&radic;2/(n_in+n_out))** -- 所谓的 **Xavier 初始化** (`glorot`)，它有助于在前向和后向传播期间保持信号在范围内

## 批量归一化

即使有了合适的权重初始化，权重在训练过程中仍可能变得任意大或小，这将使信号超出适当的范围。通过使用一种**归一化**技术可以将信号拉回到合适的范围。虽然有几种 (权重归一化、层归一化)，但最常用的是批量归一化。

**批量归一化** 的想法是考虑小批量中的所有值，并基于这些值执行归一化（即减去均值并除以标准差）。它实现为一个网络层，在应用权重之后、激活函数之前进行归一化。结果是，我们很可能会看到更高的最终准确性和更快的训练速度。

这里是关于批量归一化的[原始论文](https://arxiv.org/pdf/1502.03167.pdf)，[维基百科的解释](https://en.wikipedia.org/wiki/Batch_normalization)，以及[一个很好的介绍性博客文章](https://towardsdatascience.com/batch-normalization-in-3-levels-of-understanding-14c2da90a338)（还有一个[俄文版](https://habrahabr.ru/post/309302/)）。

## 随机失活

**随机失活** 是一种有趣的技术，在训练过程中移除一定比例的随机神经元。它也实现为一个带有一个参数（要移除的神经元的百分比，通常为10%-50%）的层，在训练期间它会将输入向量的随机元素置为零，然后传递到下一层。

虽然这听起来像是一个奇怪的主意，但你可以在 [`Dropout.ipynb`](Dropout.ipynb) 笔记本中看到这对训练 MNIST 数字分类器的效果。它加快了训练速度，并使我们能够在较少的训练周期内达到更高的准确性。

这种效果可以通过几种方式解释：

 * 这可以被视为对模型的随机冲击因素，将优化从局部最小值中带出。
 * 这可以被视为*隐式模型平均*，因为我们可以说在随机失活期间，我们在训练略有不同的模型。

> *有些人说，当一个醉酒的人尝试学习一些东西时，他会在第二天早上比一个清醒的人记得更好，因为脑中的一些失灵神经元会更好地适应以抓住意义。我们自己从未测试过这是否属实*

## 防止过拟合

深度学习的一个非常重要的方面是能够防止[过拟合](../../3-NeuralNetworks/05-Frameworks/Overfitting.md)。虽然使用非常强大的神经网络模型可能很诱人，但我们应该始终在模型参数数量和训练样本数量之间找到平衡。

> 确保你理解我们早先介绍的[过拟合](../../3-NeuralNetworks/05-Frameworks/Overfitting.md)概念！

有几种防止过拟合的方法：

 * 提前停止 -- 连续监控验证集上的错误，并在验证错误开始增加时停止训练。
 * 显示权重衰减 / 正则化 -- 为权值的高绝对值添加额外的惩罚项，防止模型得到非常不稳定的结果。
 * 模型平均 -- 训练多个模型然后平均结果，这有助于最小化方差。
 * 随机失活 (隐式模型平均)

## 优化器 / 训练算法

训练的另一个重要方面是选择好的训练算法。虽然经典的**梯度下降**是一个合理的选择，但它有时可能太慢，或者导致其他问题。

在深度学习中，我们使用**随机梯度下降**（SGD），它是应用于随机选择的小批量训练集的梯度下降。使用以下公式调整权重：

w<sup>t+1</sup> = w<sup>t</sup> - &eta;&nabla;&lagran;

### 动量

在**动量 SGD**中，我们保留上一步骤的部分梯度。这类似于我们朝某个方向移动带有惯性并在受到不同方向的冲击时，我们的轨迹不会立即改变，而是保留部分原始运动。这里我们引入另一个向量 v 表示*速度*：

* v<sup>t+1</sup> = &gamma; v<sup>t</sup> - &eta;&nabla;&lagran;
* w<sup>t+1</sup> = w<sup>t</sup>+v<sup>t+1</sup>

参数 &gamma; 表示我们考虑惯性的程度：&gamma;=0 对应经典 SGD；&gamma;=1 是纯粹的运动方程。

### Adam，Adagrad 等

由于在每一层中我们将信号乘以某个矩阵 W<sub>i</sub>，根据 ||W<sub>i</sub>||，梯度要么会缩小接近 0，要么无限上升。这就是梯度爆炸/消失问题的本质。

解决这个问题的一个方法是只在方程中使用梯度的方向，并忽略绝对值，即

w<sup>t+1</sup> = w<sup>t</sup> - &eta;(&nabla;&lagran;/||&nabla;&lagran;||)，其中 ||&nabla;&lagran;|| = &radic;&sum;(&nabla;&lagran;)<sup>2</sup>

这个算法称为**Adagrad**。其他使用相同思路的算法：**RMSProp**、**Adam**

> **Adam** 被认为是许多应用中非常有效的算法，所以如果你不确定用哪个 - 用 Adam。

### 梯度剪裁

梯度剪裁是上面思想的扩展。当 ||&nabla;&lagran;|| &le; &theta; 时，我们在权重优化中考虑原始梯度；当 ||&nabla;&lagran;|| > &theta; 时，我们将梯度除以其范数。这里 &theta; 是一个参数，在大多数情况下我们可以取 &theta;=1 或 &theta;=10。

### 学习率衰减

训练成功通常取决于学习率参数 &eta;。合理地假设较大的 &eta; 值会导致更快的训练，这是我们通常希望在训练开始时发生的，然后较小的 &eta; 值允许我们微调网络。因此，在大多数情况下，我们希望在训练过程中减少 &eta;。

这可以通过在每个训练周期之后将 &eta; 乘以某个数（例如 0.98）来实现，或者使用更复杂的**学习率调度**。

## 不同的网络架构

为你的问题选择合适的网络架构可能很棘手。通常的做法是选择已被验证可以用于特定任务（或类似任务）的架构。这里有一篇[神经网络架构简史](https://www.topbots.com/a-brief-history-of-neural-network-architectures/)综述，适用于计算机视觉。

> 重要的是选择适用于我们拥有的训练样本数量的强大架构。选择过于强大的模型可能导致[过拟合](../../3-NeuralNetworks/05-Frameworks/Overfitting.md)

另一种好的方法是使用一种将自动调整到所需复杂度的架构。**ResNet** 和 **Inception** 架构在某种程度上是自适应的。[更多计算机视觉架构](../07-ConvNets/CNN_Architectures.md)