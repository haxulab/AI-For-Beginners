# 道德与负责任的人工智能

你即将完成本课程，希望到现在你已经清楚地看到，人工智能是基于一系列形式化的数学方法，这些方法允许我们在数据中找到关系并训练模型来复制人类行为的某些方面。在这个历史时刻，我们认为人工智能是从数据中提取模式并将这些模式应用于解决新问题的非常强大的工具。

## [课前测验](https://white-water-09ec41f0f.azurestaticapps.net/quiz/5/)

然而，在科幻小说中，我们经常看到人工智能对人类构成威胁的故事。通常这些故事围绕某种人工智能的叛乱展开，即人工智能决定与人类对抗。这暗示人工智能有某种情感或能够做出开发者未预见的决策。

在本课程中我们所学的人工智能不过是大规模矩阵运算。它是帮助我们解决问题的非常强大的工具，正如任何其他强大的工具一样——它既可以用于好的目的，也可以用于坏的目的。重要的是，它可能被*误用*。

## 负责任的人工智能原则

为了避免人工智能的意外或故意误用，微软提出了重要的[负责任的人工智能原则](https://www.microsoft.com/ai/responsible-ai?WT.mc_id=academic-77998-cacaste)。以下概念是这些原则的基础：

* **公平性**与*模型偏见*问题密切相关，模型偏见可能是由于使用了有偏见的训练数据引起的。例如，当我们试图预测一个人获得软件开发人员工作的概率时，模型可能更倾向于男性——只是因为训练数据集可能倾向于男性。我们需要慎重平衡训练数据并调查模型以避免偏见，确保模型考虑到更相关的特征。
* **可靠性和安全性**。人工智能模型本质上可能会犯错误。神经网络返回概率，我们需要在做决策时将其考虑在内。每个模型都有一定的精度和召回率，我们需要了解这一点以防止错误建议可能造成的伤害。
* **隐私和安全**有一些与人工智能相关的特定含义。例如，当我们使用一些数据来训练模型时，这些数据会某种程度上“集成”进模型中。一方面，这增加了安全性和隐私性，另一方面——我们需要记住模型是基于哪些数据进行训练的。
* **包容性**意味着我们不是在构建人工智能来取代人们，而是增强人们，使我们的工作更具创造性。这也与公平性有关，因为在处理代表性不足的社区时，我们收集的大多数数据集可能会有偏见，我们需要确保这些社区被包括在内并得到人工智能的正确处理。
* **透明度**。这包括确保我们始终明确强调人工智能的使用。此外，在可能的情况下，我们希望使用*可解释*的人工智能系统。
* **问责制**。当人工智能模型做出一些决策时，并不总是很清楚谁对这些决策负责。我们需要确保我们了解人工智能决策的责任所在。在大多数情况下，我们希望将人类纳入做出重要决策的环节，以便实际的人对这些决策负责。

## 负责任的人工智能工具

微软开发了[负责任的人工智能工具箱](https://github.com/microsoft/responsible-ai-toolbox)，其中包含一组工具：

* 可解释性仪表板 (InterpretML)
* 公平性仪表板 (FairLearn)
* 错误分析仪表板
* 负责任的人工智能仪表板，包括

   - EconML - 因果分析工具，侧重于假设性问题
   - DiCE - 反事实分析工具，允许你查看需要更改哪些特征以影响模型的决策

如需了解更多关于人工智能伦理的信息，请访问[这个课程](https://github.com/microsoft/ML-For-Beginners/tree/main/1-Introduction/3-fairness?WT.mc_id=academic-77998-cacaste)中的机器学习课程，其中包括作业。

## 复习与自学

请学习此[学习路径](https://docs.microsoft.com/learn/modules/responsible-ai-principles/?WT.mc_id=academic-77998-cacaste)以了解更多关于负责任的人工智能的信息。

## [课后测验](https://white-water-09ec41f0f.azurestaticapps.net/quiz/6/)
